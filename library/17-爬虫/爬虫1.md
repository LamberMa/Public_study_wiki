爬虫

> - 基本操作
> - 高性能相关（Socket+select）
>   - twisted
>   - tornado
>   - gevent
> - Web版本微信（练习）
> - Scrapy框架（学习规则）
> - 自己爬虫框架

1. 爬虫基本操作

   URL指定内容获取到

   - 发送HTTP请求：URL
   - 基于正则表达式获取内容

   requests和bs4中的beautifulsoap（识别html标签）

   ```python
   import requests
   from bs4 import beautifulsoup
   response = request.get('http://xxxxxx')
   # python内置的html解析器：html.parse
   obj = beatifulsoup(response.text, 'html.parser')
   标前对象 = obj.find('a') # 找到匹配的成功的第一个标签
   标前对象 = obj.find_all('a') # 找到匹配的成功的多个标签，list
   xxx.find(name='标签名',id='id名称')
   参数：name，id，class_
   因为class和python内部关键字冲突，所以加一个小的下划线，或者
   attrs = {
       # 这里唯独不能写标签名称
       'class': 'xxx',
       'id': 'xxx'
   }
   
   pip3 install BeautifulSoup4
   ```

   response.text这个是字符串，response.content这个是字节，可以字节转。

   或者设置response.encoding=gbk。

```python
import requests 
from bs4 import BeautifulSoup  
response = requests.get('http://www.autohome.com.cn/news/')  
response.encoding='gbk'
soup = BeautifulSoup(response.text, 'html.parser') 
li_soup = soup.find(id='auto-channel-lazyload-article').find_all(name='li')
In [11]: for li in li_soup:
    ...:     print(li.find('h3'))
<h3>或退出中国 铃木正与长安商议解除合资</h3>
<h3>均降0.80万元 瑞迈柴油版全系车型调价</h3>
<h3>起售价降至44.38万 国产普拉多全系官降</h3>
None
<h3>从商用车切入 大众/福特将组成战略联盟</h3>
<h3>奥迪S3小心了 AMG A 35 L运动轿车谍照</h3>
<h3>6月25日亮相/三季度上市 吉利缤瑞消息</h3>
<h3>百人口碑评新车：中华V6大气外观得好评</h3>
<h3>汽车之家电动汽车挑战赛开场哨即将吹响</h3>
…………………………
```

记住这里是可能存在None的，因为实际的页面中，可能穿插着各种广告什么的，这些都是正常的，所以对于这种为None的就可以忽略了，因此在循环中可以做一个判断`if not li`然后直接continue就行了。

我们去到的列表中的元素每一个都是一个bs4.element.Tag的对象，因此如果要直接取内容的话直接用li.find('h3').text就行了。

找标签属性：

```python
# 得到一个属性的字典
In [15]: for li in li_soup:
    ...:     title = li.find('a')
    ...:     if not title:
    ...:         continue
    ...:     print(title.attrs)
    ...:     
{'href': '//www.autohome.com.cn/news/201806/918831.html#pvareaid=102624'}
{'href': '//www.autohome.com.cn/news/201806/918822.html#pvareaid=102624'}
{'href': '//www.autohome.com.cn/news/201806/918828.html#pvareaid=102624'}
{'href': '//www.autohome.com.cn/news/201806/918827.html#pvareaid=102624'}

##### 一样的效果
In [17]: for li in li_soup:
    ...:     title = li.find('a')
    ...:     if not title:
    ...:         continue
    ...:     print(title.attrs['href'])
    ...:     
    ...:     
//www.autohome.com.cn/news/201806/918831.html#pvareaid=102624
//www.autohome.com.cn/news/201806/918822.html#pvareaid=102624

# 或者使用get
In [16]: for li in li_soup:
    ...:     title = li.find('a')
    ...:     if not title:
    ...:         continue
    ...:     print(title.get('href'))
    ...:     
    ...:     
//www.autohome.com.cn/news/201806/918831.html#pvareaid=102624
//www.autohome.com.cn/news/201806/918822.html#pvareaid=102624
//www.autohome.com.cn/news/201806/918828.html#pvareaid=102624
//www.autohome.com.cn/news/201806/918827.html#pvareaid=102624
//www.autohome.com.cn/news/201806/918821.html#pvareaid=102624
```

找图片：

```python
In [18]: for li in li_soup:
    ...:     title = li.find('img')
    ...:     if not title:
    ...:         continue
    ...:     print(title.attrs['src'])
    ...:     
    ...:     
    ...:     
//www2.autoimg.cn/newsdfs/g26/M03/39/41/120x90_0_autohomecar__ChcCP1spq8KARebOAAGJFNHdNlQ952.jpg
//www2.autoimg.cn/newsdfs/g26/M02/39/0D/120x90_0_autohomecar__wKgHEVspsPaASndQAAFOtCp6URI106.jpg
```

如果要把图片下载下来呢？

```python

```

