## GIL(全局解释器锁)

- 参考资料：http://cenalulu.github.io/python/gil-in-python/

> 定义：
>
> In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython’s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.)

Python中的线程是操作系统的原生线程，Python虚拟机使用一个全局解释器锁（Global Interpreter Lock）来互斥线程对Python虚拟机的使用。为了支持多线程机制，一个基本的要求就是需要实现不同线程对共享资源访问的互斥，所以引入了GIL。
GIL：在一个线程拥有了解释器的访问权之后，其他的所有线程都必须等待它释放解释器的访问权，即使这些线程的下一条指令并不会互相影响。
在调用任何Python C API之前，要先获得GIL
GIL缺点：多处理器退化为单处理器；优点：避免大量的加锁解锁操作

### GIL的影响

无论你启多少个线程，你有多少个cpu, Python在执行一个进程的时候会淡定的在同一时刻只允许一个线程运行。
所以，python是无法利用多核CPU实现多线程的。
这样，python对于计算密集型的任务开多线程的效率甚至不如串行(没有大量切换)，但是，对于IO密集型的任务效率还是有显著提升的。

![](http://omk1n04i8.bkt.clouddn.com/17-9-13/66476109.jpg)

#### 在Python中哪一种多线程的程序表现较好？

上面说到由于GIL这一把锁，同一时刻的一个进程下只允许一个一个线程去使用CPU，达不到并行的效果。当线程遇到IO操作的时候（或者达到规定的时间片）就会让出cpu让其他的线程去使用cpu，直到IO结束才会继续调用cpu资源。这样的操作使得Python更适合IO密集型，而计算密集型在多个线程的时候会处于并发的状态，当一个线程计算一半的时候将CPU资源分配给其他的线程计算，上一个计算的结果还需要保存起来，占用资源，另外多个线程计算在切换的过程中是消耗资源的，并且计算的效率并没有提升反而有下降，故并不建议用python多线程运行计算密集型的代码。

> ##### IO密集型（IO bound）和CPU密集型（CPU bound）：
>
> I/O bound 指的是系统的CPU效能相对硬盘/内存的效能要好很多，此时，系统运作，大部分的状况是 CPU 在等 I/O (硬盘/内存) 的读/写，此时 CPU Loading 不高。
> CPU bound 指的是系统的 硬盘/内存 效能 相对 CPU 的效能 要好很多，此时，系统运作，大部分的状况是 CPU Loading 100%，CPU 要读/写 I/O (硬盘/内存)，I/O在很短的时间就可以完成，而 CPU 还有许多运算要处理，CPU Loading 很高。

结论：

- IO密集型：Python多线程是有意义的
- 计算密集型：Python多线程没多大用，反而会更慢，没串行来的快。

## 多线程性能测试

- 多核也就是多个CPU
  - cpu越多，提高的是计算的性能
  - 如果程序是IO操作的时候（多核和单核是一样的），再多的cpu也没有意义。

- 实现并发
  第一种：一个进程下，开多个线程
  第二种：开多个进程

- 多进程：
   优点：可以利用多核
   缺点：开销大

- 多线程
   优点：开销小
   缺点：不可以利用多核

- 多进程和多进程的应用场景
   - 计算密集型：也就是计算多，IO少。如果是计算密集型，就用多进程（如金融分析等）
   - IO密集型：也就是IO多，计算少。如果是IO密集型的，就用多线程（一般遇到的都是IO密集型的）

### 计算密集型

```python
# 计算密集型的要开启多进程
from  multiprocessing import Process
from threading import Thread
import time
def work():
    res = 0
    for i in range(10000000):
        res+=i
if __name__ == '__main__':
    l = []
    start = time.time()
    for i in range(4):
        p = Process(target=work)  #1.9371106624603271  #可以利用多核（也就是多个cpu）
        # p  = Thread(target=work)  #3.0401737689971924
        l.append(p)
        p.start()
    for p in l:
        p.join()
    stop = time.time()
    print('%s'%(stop-start))
```

### IO密集型

```python
# I/O密集型要开启多线程
from multiprocessing import Process
from threading import Thread
import time
def work():
    time.sleep(3)
if __name__ == '__main__':
    l = []
    start = time.time()
    for i in range(400):
        # p = Process(target=work)  #34.9549994468689   #因为开了好多进程，它的开销大，花费的时间也就长了
        p = Thread(target=work) #2.2151265144348145  #当开了多个线程的时候，它的开销小，花费的时间也小了
        l.append(p)
        p.start()
    for i in l :
        i.join()
    stop = time.time()
    print('%s'%(stop-start))
```

