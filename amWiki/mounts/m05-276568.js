if(typeof AWPageMounts=='undefined'){AWPageMounts={}};AWPageMounts['m05']=[{"name":"01-01、Time模块.md","path":"05-Python/00-Python常用模块详解/01-01、Time模块.md","content":"# Time模块\n\n#### 1.1 时间的表现形式\n\n- 时间戳（timestamp）：记录的是从1970年1月1日的00:00:00开始按照秒计算的偏移量，在python中很容易查看。那么时间戳一般用在什么地方呢？因为本来也不是要给你看的，这个是给计算机看的，我们可以通过时间戳来标记某个时间点的状态。\n\n  ```\n  import time\n  print(time.time())\n\n  结果：1500362894.7456193（历史的烙印）\n  ```\n\n- 格式化的时间字符串\n\n  ```\n  import time\n  print(time.strftime(\"%Y-%m-%d %X\"))\n  print(time.strftime(\"%Y\")) # 年\n  print(time.strftime(\"%m\")) # 月\n  print(time.strftime(\"%d\")) # 日\n  print(time.strftime(\"%X\")) # 时分秒的总和\n  print(time.strftime(\"%H\")) # 时\n  print(time.strftime(\"%M\")) # 分\n  print(time.strftime(\"%S\")) # 秒\n\n  结果：\n  2017-07-18 17:49:40\n  2017\n  07\n  18\n  17:49:40\n  17\n  49\n  40\n  ```\n\n- 结构化时间（时间元组）\n\n  ```\n  import time\n  a = time.localtime() # 返回的是一个对象\n  print(a)\n\n  time.struct_time(tm_year=2017, tm_mon=7, tm_mday=18, tm_hour=17, tm_min=52, tm_sec=7, tm_wday=1, tm_yday=199, tm_isdst=0)\n\n  tm_year：当前的年份\n  tm_mon：当前的月份\n  tm_mday：当前是几号，比如今天是7月18号\n  tm_hour：当前是几点，17点\n  tm_min：当前是多少分，52分\n  tm_sec：当前是多少秒，7s\n  tm_wday：当前是周几，从0开始算，显示为1应该是1+1=2，也就是周二。\n  tm_yday：一年中的第多少天，这是第199天\n  tm_isdst：是否是夏令时\n  ```\n\n  因为time.localtime()返回的是一个对象，因此需要取什么值，直接用`对象.属性值`的方法去调用就可以了。\n\n  并且localtime()可以接受一个参数，这个参数是一个时间戳，localtime可以把时间戳转化为结构化的时间，比如：\n\n  ```\n  import time\n  print((time.localtime(12312312231)))\n\n  结果：\n  time.struct_time(tm_year=2360, tm_mon=2, tm_mday=29, tm_hour=22, tm_min=43, tm_sec=51, tm_wday=0, tm_yday=60, tm_isdst=0)\n  ```\n\n  ​\n\n#### 1.2 三种时间格式的转换\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-19/71041677.jpg)\n\n```\n1）时间戳可以转化为结构化时间\n>>> time.gmtime(2333333)\ntime.struct_time(tm_year=1970, tm_mon=1, tm_mday=28, tm_hour=0, tm_min=8, tm_sec=53, tm_wday=2, tm_yday=28, tm_isdst=0)\n>>> time.localtime(2333333)\ntime.struct_time(tm_year=1970, tm_mon=1, tm_mday=28, tm_hour=8, tm_min=8, tm_sec=53, tm_wday=2, tm_yday=28, tm_isdst=0)\n其中gmtime为UTC时间。\n\n2）结构化时间转换为时间戳和字符串时间：\n>>> time.mktime(time.localtime())\n1500452640.0\n>>> time.strftime(\'%Y-%m-%d %H:%M:%S\',time.gmtime())\n\'2017-07-19 08:37:19\'\n>>> time.strftime(\'%Y-%m-%d %H:%M:%S\',time.localtime())\n\'2017-07-19 16:37:32\'\n>>> time.strftime(\'%Y-%m-%d %H:%M:%S\')                \n\'2017-07-19 16:37:46\'\nstrftime有两个参数，提一个是时间格式，第二个是结构化时间，可以指定gmtime或者是localtime，默认的不写的话那么就是localtime。\n\n比如显示昨天的时间：\n>>> time.strftime(\'%Y-%m-%d %H:%M:%S\',time.localtime(time.time()-24*3600))\n\'2017-07-18 16:42:46\'\n\n使用asctime也可以把结构化时间转换为时间字符串，只不过格式是固定的。参数默认为localtime。\n>>> time.asctime(time.localtime())\n\'Wed Jul 19 16:50:23 2017\'\n>>> time.asctime()               \n\'Wed Jul 19 16:50:27 2017\'\n\n\n3）时间戳转换为时间字符串\n>>> time.ctime()\n\'Wed Jul 19 16:46:34 2017\'\n>>> time.ctime(time.time())\n\'Wed Jul 19 16:46:42 2017\'\n把当前的时间戳转换为一个固定的时间字符串，括号里的参数默认就是当前的时间戳，也可以自己指定时间戳。\n\n\n4）时间字符串转化为结构化的时间\n>>> help(time.strptime) \nHelp on built-in function strptime in module time:\n\nstrptime(...)\n    strptime(string, format) -> struct_time\n    \n    Parse a string to a time tuple according to a format specification.\n    See the library reference manual for formatting codes (same as strftime()).\n\n>>> time.strptime(\'2017-07-19\',\'%Y-%m-%d\')\ntime.struct_time(tm_year=2017, tm_mon=7, tm_mday=19, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=200, tm_isdst=-1)\n```\n\n| 格式参数 |                    含义                    | 备注   |\n| :--: | :--------------------------------------: | ---- |\n|  %a  |             本地（locale）简化星期名称             |      |\n|  %A  |                 本地完整星期名称                 |      |\n|  %b  |                 本地简化月份名称                 |      |\n|  %B  |                 本地完整月份名称                 |      |\n|  %c  |               本地相应的日期和时间表示               |      |\n|  %d  |             个月中的第几天（01 - 31）             |      |\n|  %H  |         一天中的第几个小时（24小时制，00 - 23）         |      |\n|  %l  |           第几个小时（12小时制，01 - 12）           |      |\n|  %j  |            一年中的第几天（001 - 366）            |      |\n|  %m  |               月份（01 - 12）                |      |\n|  %M  |               分钟数（00 - 59）               |      |\n|  %p  |               本地am或者pm的相应符               | No1  |\n|  %S  |                秒（01 - 61）                | No2  |\n|  %U  | 一年中的星期数。（00 - 53星期天是一个星期的开始。）第一个星期天之前的所有天数都放在第0周。 | No3  |\n|  %w  |          一个星期中的第几天（0 - 6，0是星期天）          | No3  |\n|  %W  |       和%U基本相同，不同的是%W以星期一为一个星期的开始。        |      |\n|  %x  |                  本地相应日期                  |      |\n|  %X  |                  本地相应时间                  |      |\n|  %y  |             去掉世纪的年份（00 - 99）             |      |\n|  %Y  |                  完整的年份                   |      |\n|  %Z  |             时区的名字（如果不存在为空字符）             |      |\n|  %%  |                  ‘%’字符                   |      |\n\n- No1、“%p”只有与“%I”配合使用才有效果。\n- No2、文档中强调确实是0 - 61，而不是59，闰年秒占两秒（汗一个）。\n- No3、当使用strptime()函数时，只有当在这年中的周数和天数被确定的时候%U和%W才会被计算。\n\n#### 1.3 time的sleep方法\n\nsleep方法可以睡几秒，单位为秒：\n\n```\ntime.sleep(3)\n```\n","timestamp":1523777648264},{"name":"02-02、hashlib模块.md","path":"05-Python/00-Python常用模块详解/02-02、hashlib模块.md","content":"### hashlib模块\n\n#### 算法介绍\n\nPython的hashlib提供了常见的摘要算法，如MD5，SHA1等等。\n\n什么是摘要算法呢？摘要算法又称哈希算法、散列算法。它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示）。\n\n摘要算法就是通过摘要函数f()对任意长度的数据data计算出固定长度的摘要digest，目的是为了发现原始数据是否被人篡改过。\n\n摘要算法之所以能指出数据是否被篡改过，就是因为摘要函数是一个单向函数，计算f(data)很容易，但通过digest反推data却非常困难。而且，对原始数据做一个bit的修改，都会导致计算出的摘要完全不同。\n\n我们以常见的摘要算法MD5为例，计算出一个字符串的MD5值：\n\n```\nimport hashlib\n \nmd5 = hashlib.md5()\nmd5.update(\'how to use md5 in python hashlib?\')  # 要加密的内容\nprint md5.hexdigest()   # 查看加密的内容\n\n计算结果如下：\nd26a53750bc40b38b65a520292f69306\n```\n\n假如说同样的update执行两次，那么update里面的内容会进行叠加：\n\n```\nimport hashlib\n\na = hashlib.md5()\na.update(\'lamber\'.encode(\'utf-8\'))\nprint(a.hexdigest())\na.update(\'lamber\'.encode(\'utf-8\'))\nprint(a.hexdigest())\n\nb = hashlib.md5()\nb.update(\'lamberlamber\'.encode(\'utf-8\'))\nprint(a.hexdigest())\n\n结果：\n9586a9a5047a98db7d82ed3a748ea357\n064a55c29070323e6fe254819331a6aa\n064a55c29070323e6fe254819331a6aa\n```\n\n执行了两次a的update方法，第二次会叠加一个lamber执行。\n\n如果数据量很大，可以分块多次调用update()，最后计算的结果是一样的：\n\n```\nmd5 = hashlib.md5()\nmd5.update(\'how to use md5 in \')\nmd5.update(\'python hashlib?\')\nprint md5.hexdigest()\n```\n\nMD5是最常见的摘要算法，速度很快，生成结果是固定的128 bit字节，通常用一个32位的16进制字符串表示。另一种常见的摘要算法是SHA1，调用SHA1和调用MD5完全类似：\n\n```\nimport hashlib\n \nsha1 = hashlib.sha1()\nsha1.update(\'how to use sha1 in \')\nsha1.update(\'python hashlib?\')\nprint sha1.hexdigest()\n```\n\nSHA1的结果是160 bit字节，通常用一个40位的16进制字符串表示。比SHA1更安全的算法是SHA256和SHA512，不过越安全的算法越慢，而且摘要长度更长。\n\n#### 摘要算法的应用\n\n任何允许用户登录的网站都会存储用户登录的用户名和口令。如何存储用户名和口令呢？方法是存到数据库表中：\n\n```\nname    | password\n--------+----------\nmichael | 123456\nbob     | abc999\nalice   | alice2008\n```\n\n如果以明文保存用户口令，如果数据库泄露，所有用户的口令就落入黑客的手里。此外，网站运维人员是可以访问数据库的，也就是能获取到所有用户的口令。正确的保存口令的方式是不存储用户的明文口令，而是存储用户口令的摘要，比如MD5：\n\n```\nusername | password\n---------+---------------------------------\nmichael  | e10adc3949ba59abbe56e057f20f883e\nbob      | 878ef96e86145580c38c87f0410ad153\nalice    | 99b1c2188db85afee403b1536010c2c9\n```\n\n考虑这么个情况，很多用户喜欢用123456，888888，password这些简单的口令，于是，黑客可以事先计算出这些常用口令的MD5值，得到一个反推表：\n\n```\n\'e10adc3949ba59abbe56e057f20f883e\': \'123456\'\n\'21218cca77804d2ba1922c33e0151105\': \'888888\'\n\'5f4dcc3b5aa765d61d8327deb882cf99\': \'password\'\n```\n\n这样，无需破解，只需要对比数据库的MD5，黑客就获得了使用常用口令的用户账号。\n\n对于用户来讲，当然不要使用过于简单的口令。但是，我们能否在程序设计上对简单口令加强保护呢？\n\n由于常用口令的MD5值很容易被计算出来，所以，要确保存储的用户口令不是那些已经被计算出来的常用口令的MD5，这一方法通过对原始口令加一个复杂字符串来实现，俗称“加盐”：\n\n```\nhashlib.md5(\"salt\".encode(\"utf8\"))\n```\n\n经过Salt处理的MD5口令，只要Salt不被黑客知道，即使用户输入简单口令，也很难通过MD5反推明文口令。\n\n但是如果有两个用户都使用了相同的简单口令比如123456，在数据库中，将存储两条相同的MD5值，这说明这两个用户的口令是一样的。有没有办法让使用相同口令的用户存储不同的MD5呢？\n\n如果假定用户无法修改登录名，就可以通过把登录名作为Salt的一部分来计算MD5，从而实现相同口令的用户也存储不同的MD5。\n\n摘要算法在很多地方都有广泛的应用。要注意摘要算法不是加密算法，不能用于加密（因为无法通过摘要反推明文），只能用于防篡改，但是它的单向计算特性决定了可以在不存储明文口令的情况下验证用户口令。","timestamp":1523777648264},{"name":"03-03、random模块.md","path":"05-Python/00-Python常用模块详解/03-03、random模块.md","content":"### Random模块\n\n随机模块\n\n```\n>>> import random\n>>> random.random\n<built-in method random of Random object at 0x1ef7930>\n>>> random.random()\n0.9400308284872474\n>>> random.random()\n0.05308019119344831\n>>> random.random()\n0.8372423057785096\n```\n\n直接调用random模块的random方法返回的是一个介于0~1之间的浮点数，不会取到0也不会取到1.\n\n```\n>>> random.randint(1,100)  # 取一个整数，但是要给一个范围，范围的两头都能取到\n52\n>>> random.randrange(1,100) # 取一个整数，给一个范围，能取到左边的头，取不到右边的\n42\n>>> random.randrange(1,100,4) # randrange还可以指定步长。在第三个参数的位置\n57\n>>> random.choice(range(1,10)) # 从一个序列元素中随机取出一个元素(list tuple str)\n8\n>>> random.sample([1,2,3,4,5,6,7,8],3)\n[8, 3, 2]\n# sample指的是从一个序列中取出指定长度的片段，比如我这里是取3个，就是随机挑3个。\n>>> random.uniform(1,3) # 生成指定范围内的浮点数\n2.6525310648742746\n>>> a = [1,2,3,4,5,6,7,8,9,10]\n>>> random.shuffle(a)\n>>> a\n[3, 5, 7, 1, 2, 8, 9, 4, 10, 6]\n# 将一个序列的内容打乱，这个是会影响到原序列的。\n```\n\n##### 模拟验证码的练习\n\n```\nimport random\n\ndef get_random():\n    rst = []\n    for i in range(5):\n        rnum = str(random.randint(0,9)) # 一个随机数组\n        ralp = chr(random.randint(65,90)) # 一个随机大写字母\n        rst2 = random.choice([rnum,ralp]) # 从数字和字母里随机选一个。\n        rst.append(rst2)\n    return \'\'.join(rst)\n\nyanzhengma = get_random()\nprint(yanzhengma)\n```","timestamp":1523777648264},{"name":"04-04、OS模块.md","path":"05-Python/00-Python常用模块详解/04-04、OS模块.md","content":"### OS模块\n\nos模块式与操作系统交互的一个接口：\n\n- os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径，相当于linux的pwd\n\n```\nimport os\nprint(os.getcwd())\n\n结果：\nD:\\坚果云同步\\Python\\Day9\n```\n\n- os.chdir(\"dirname\")  改变当前脚本工作目录；相当于shell下cd\n\n```\n>>> os.getcwd()\n\'/home/lamber\'\n>>> os.chdir(\'/\')\n>>> os.getcwd()  \n\'/\'\n```\n\n- os.curdir  返回当前目录: (\'.\')\n\n```\n>>> os.curdir\n\'.\'\n```\n\n- os.pardir  获取当前目录的父目录字符串名：(\'..\')\n\n```\n>>> os.pardir\n\'..\'\n```\n\n- os.makedirs(\'dirname1/dirname2\')    可生成多层递归目录\n\n```python\n>>> os.makedirs(\'a/b/c/d\')\n\n[lamber@maxiaoyu ~]$ tree a\na\n└── b\n    └── c\n        └── d\n\n3 directories, 0 files\n```\n\n- os.removedirs(\'dirname1\')    若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推\n- os.mkdir(\'dirname\')    生成单级目录；相当于shell中mkdir dirname\n- os.rmdir(\'dirname\')    删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirname\n- os.listdir(\'dirname\')    列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印\n- os.remove()  删除一个文件\n- os.rename(\"oldname\",\"newname\")  重命名文件/目录\n- os.stat(\'path/filename\')  获取文件/目录信息，返回的是一个结构化的对象，通过对象调用属性的方式，我们就可以获取到相应的值。\n\n```\n>>> os.stat(\'a\')\nposix.stat_result(st_mode=16893, st_ino=1056448, st_dev=64769L, st_nlink=3, st_uid=1004, st_gid=1004, st_size=4096, st_atime=1500534941, st_mtime=1500534931, st_ctime=1500534931)\n\n和linux系统里面的进行对比：\n[lamber@maxiaoyu ~]$ stat a\n  File: ‘a’\n  Size: 4096            Blocks: 8          IO Block: 4096   directory\nDevice: fd01h/64769d    Inode: 1056448     Links: 3\nAccess: (0775/drwxrwxr-x)  Uid: ( 1004/  lamber)   Gid: ( 1004/  lamber)\nAccess: 2017-07-20 15:15:41.149279393 +0800\nModify: 2017-07-20 15:15:31.816264811 +0800\nChange: 2017-07-20 15:15:31.816264811 +0800\n Birth: -\n \nstat 结构:\n\nst_mode: inode 保护模式\nst_ino: inode 节点号。\nst_dev: inode 驻留的设备。\nst_nlink: inode 的链接数。\nst_uid: 所有者的用户ID。\nst_gid: 所有者的组ID。\nst_size: 普通文件以字节为单位的大小；包含等待某些特殊文件的数据。\nst_atime: 上次访问的时间。\nst_mtime: 最后一次修改的时间。\nst_ctime: 由操作系统报告的\"ctime\"。在某些系统上（如Unix）是最新的元数据更改的时间，在其它系统上（如Windows）是创建时间（详细信息参见平台的文档）。\n```\n\n- os.sep    输出操作系统特定的路径分隔符，win下为\"\\\\\",Linux下为\"/\"\n- os.linesep    输出当前平台使用的行终止符，win下为\"\\t\\n\",Linux下为\"\\n\"\n- os.pathsep    输出用于分割文件路径的字符串 win下为;,Linux下为:\n- os.name    输出字符串指示当前使用平台。win->\'nt\'; Linux->\'posix\'\n- os.system(\"bash command\")  运行shell命令，直接显示\n- os.environ  获取系统环境变量\n- os.path.abspath(path)  返回path规范化的绝对路径\n\n```\n>>> os.path.abspath(\'a\')\n\'/home/lamber/a\'\n```\n\n- os.path.split(path)  将path分割成目录和文件名二元组返回\n\n```\n>>> os.path.split(os.path.abspath(\'a\'))\n(\'/home/lamber\', \'a\')\n```\n\n- os.path.dirname(path)  返回path的目录。其实就是os.path.split(path)的第一个元素\n- os.path.basename(path)  返回path最后的文件名。如何path以／或\\结尾，那么就会返回空值。即os.path.split(path)的第二个元素\n- os.path.exists(path)  如果path存在，返回True；如果path不存在，返回False\n- os.path.isabs(path)  如果path是绝对路径，返回True\n- os.path.isfile(path)  如果path是一个存在的文件，返回True。否则返回False\n- os.path.isdir(path)  如果path是一个存在的目录，则返回True。否则返回False\n- os.path.join(path1[, path2[, ...]])  将多个路径组合后返回，第一个绝对路径之前的参数将被忽略\n\n```\na = os.path.basename(os.path.abspath(\'time.py\'))\nb = os.path.dirname(os.path.abspath(\'time.py\'))\nret = os.path.join(b,a)\nprint(ret)\n\n结果：\nD:\\坚果云同步\\Python\\Day9\\time.py\n```\n\n- os.path.getatime(path)  返回path所指向的文件或者目录的最后访问时间\n- os.path.getmtime(path)  返回path所指向的文件或者目录的最后修改时间\n- os.path.getsize(path) 返回path的大小\n- os.sep 返回当前操作系统的目录分割符，linux是\'\\\'，windows是\'/\'\n- os.walk 这个os函数提供的方法是遍历目录以及文件的利器。\n\n```\nwalk()方法语法格式如下(该方法没有返回值)：\nos.walk(top[, topdown=True[, onerror=None[, followlinks=False]]])\n```\n\n1. **top** -- 根目录下的每一个文件夹(包含它自己), 产生3-元组 (dirpath, dirnames, filenames)【文件夹路径, 文件夹名字, 文件名】。\n2. **topdown** --可选，为True或者没有指定, 一个目录的的3-元组将比它的任何子文件夹的3-元组先产生 (目录自上而下)。如果topdown为 False, 一个目录的3-元组将比它的任何子文件夹的3-元组后产生 (目录自下而上)。\n3. **onerror** -- 可选，是一个函数; 它调用时有一个参数, 一个OSError实例。报告这错误后，继续walk,或者抛出exception终止walk。\n4. **followlinks** -- 设置为 true，则通过软链接访问目录。\n\n\n\n","timestamp":1523777648264},{"name":"05-05、Logging模块.md","path":"05-Python/00-Python常用模块详解/05-05、Logging模块.md","content":"### logging模块\n\n首先日志是分等级的，这个其实很好理解，比如php日志或者nginx日志。都是分等级的，默认的级别是warning。具体级别是按照如下的排序进行设置的（debug<info<waring<error<critical）：\n\n```\nlogging.debug(\'debug\')\nlogging.info(\'info\')\nlogging.warning(\'warning\')\nlogging.error(\'error\')\nlogging.critical(\'crtical\')\n\n结果：\nWARNING:root:warning\nERROR:root:error\nCRITICAL:root:crtical\n```\n\n只有大于等于warning才会显示，其实说白了不同的等级就是记录的内容不一样罢了。根据用户的需要，有的记得多，有的记得少罢了。\n\n配置有两种方式：\n\n- config函数：\n\n配置参数\n\n```\nimport logging  \nlogging.basicConfig(level=logging.DEBUG,  \n                    format=\'%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s\',  \n                    datefmt=\'%a, %d %b %Y %H:%M:%S\',  \n                    filename=\'/tmp/test.log\',  \n                    filemode=\'w\')  \n  \nlogging.debug(\'debug message\')  \nlogging.info(\'info message\')  \nlogging.warning(\'warning message\')  \nlogging.error(\'error message\')  \nlogging.critical(\'critical message\')\n\n\nlogging.basicConfig()函数中可通过具体参数来更改logging模块默认行为，可用参数有：\n\nfilename：用指定的文件名创建FiledHandler，这样日志会被存储在指定的文件中。\nfilemode：文件打开方式，在指定了filename时使用这个参数，默认值为“a”还可指定为“w”。\nformat：指定handler使用的日志显示格式。\ndatefmt：指定日期时间格式。\nlevel：设置rootlogger（后边会讲解具体概念）的日志级别\nstream：用指定的stream创建StreamHandler。可以指定输出到sys.stderr,sys.stdout或者文件(f=open(‘test.log’,’w’))，默认为sys.stderr。若同时列出了filename和stream两个参数，则stream参数会被忽略。\n\nformat参数中可能用到的格式化串：\n%(name)s Logger的名字\n%(levelno)s 数字形式的日志级别\n%(levelname)s 文本形式的日志级别\n%(pathname)s 调用日志输出函数的模块的完整路径名，可能没有\n%(filename)s 调用日志输出函数的模块的文件名\n%(module)s 调用日志输出函数的模块名\n%(funcName)s 调用日志输出函数的函数名\n%(lineno)d 调用日志输出函数的语句所在的代码行\n%(created)f 当前时间，用UNIX标准的表示时间的浮 点数表示\n%(relativeCreated)d 输出日志信息时的，自Logger创建以 来的毫秒数\n%(asctime)s 字符串形式的当前时间。默认格式是 “2003-07-08 16:49:45,896”。逗号后面的是毫秒\n%(thread)d 线程ID。可能没有\n%(threadName)s 线程名。可能没有\n%(process)d 进程ID。可能没有\n%(message)s用户输出的消息\n```\n\n- logger对象（建议使用的）：\n\n```\nimport logging\n\nlogger = logging.getLogger()\n```\n\n如下是创建了logger对象后的默认的内容：\n\n```\n{\'filters\': [], \'name\': \'root\', \'level\': 30, \'parent\': None, \'propagate\': True, \'handlers\': [], \'disabled\': False}\n```\n\n创建一个文件流，还有一个屏幕流，分别输出到文件和屏幕：\n\n```\n# 创建一个handler（句柄），用于写入日志文件\nfh = logging.FileHandler(\'test.log\')\n\n# 再创建一个handler，用于输出到控制台\nch = logging.StreamHandler()\n\nformatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\n\nfh.setFormatter(formatter)\nch.setFormatter(formatter)\n\nlogger.addHandler(fh) #logger对象可以添加多个fh和ch对象\nlogger.addHandler(ch)\n\nlogger.debug(\'logger debug message\')\nlogger.info(\'logger info message\')\nlogger.warning(\'logger warning message\')\nlogger.error(\'logger error message\')\nlogger.critical(\'logger critical message\')\n\n默认是追加写\n```\n\nlogging库提供了多个组件：Logger、Handler、Filter、Formatter。Logger对象提供应用程序可直接使用的接口，Handler发送日志到适当的目的地，Filter提供了过滤日志信息的方法，Formatter指定日志显示格式。另外，可以通过：logger.setLevel(logging.Debug)设置级别,当然，也可以通过\n\nfh.setLevel(logging.Debug)单对文件流设置某个级别。","timestamp":1523777648264},{"name":"06-06、Json模块.md","path":"05-Python/00-Python常用模块详解/06-06、Json模块.md","content":"### Json模块\n\n#### 什么是序列化\n\n我们把对象(变量)从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等，都是一个意思。序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。反过来，把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling。\n\n#### Json\n\n如果我们要在不同的编程语言之间传递对象，就必须把对象序列化为标准格式，比如XML，但更好的方法是序列化为JSON，因为JSON表示出来就是一个字符串，可以被所有语言读取，也可以方便地存储到磁盘或者通过网络传输。JSON不仅是标准格式，并且比XML更快，而且可以直接在Web页面中读取，非常方便。\n\nJSON表示的对象就是标准的JavaScript语言的对象一个子集，JSON和Python内置的数据类型对应如下：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-25/74525809.jpg)\n\n\n\njson只有两个方法，一个是序列化的方法，一个是反序列化的方法：\n\n- 序列化：json.dumps(xxx) # 将xxx转为json字符串\n- 反序列化：json.loads(xxx) # 将xxx反序列化为dict格式的字符串\n\n值得注意的时候，json格式是有一个特点的，那么就是json也是类似于python字典中的键值对的形式，键值都要用英文的双引号括起来。但是python中的键值对用双引单引其实是无所谓的，因此在序列化的时候即使引用的内容是单引的在序列化过后也会变成双引。那么在反序列化的时候如果键值对的内容是单引的话会直接报错。\n\n还有一种方式是json.dump，没有s，使用格式如下：\n\n```\njson.dump(d,f)\n```\n\nd和之前的一样，f是一个文件句柄，他会把d格式化后的内容写到f这个文件句柄中去，其实就是省略了一个file.write的过程。\n\n下面看一个json的简单应用：\n\n```\nimport json\ni=10\ns=\'hello\'\nt=(1,4,6)\nl=[3,5,7]\nd={\'name\':\"yuan\"}\n\njson_str1=json.dumps(i)\njson_str2=json.dumps(s)\njson_str3=json.dumps(t)\njson_str4=json.dumps(l)\njson_str5=json.dumps(d)\n\nprint(json_str1)   #\'10\'\nprint(json_str2)   #\'\"hello\"\'\nprint(json_str3)   #\'[1, 4, 6]\'\nprint(json_str4)   #\'[3, 5, 7]\'\nprint(json_str5)   #\'{\"name\": \"yuan\"}\'\n```\n\n### 格式标准规范\n\n- key-value全都要用英文的双引号引起来，不能用单引号\n\n- 列表可以使用`[1,2,]`这种写法，字典也行，但是json格式化的字符串就不行了\n\n  ```\n  {\n    \"a\":\"a\",\n    \"b\":\"b\"\n  }\n  ```\n\n  b后面就不能有任何的逗号。。这就是一个问题。不然会报错。","timestamp":1523777648264},{"name":"07-07、pickle模块.md","path":"05-Python/00-Python常用模块详解/07-07、pickle模块.md","content":"### Pickle模块\n\npickle模块也是序列化模块，相比较json模块，这个可以作为了解的内容。pickle模块主要用于python程序之间数据交互，但是pickle可以序列化任意类型。\n\n```\nimport datetime\n\nprint(datetime.datetime.now())\n\n结果：\n2017-07-31 09:32:37.338636\n```\n\n对于这样的date数据，如果使用json的模块是没办法对这种“时间格式”进行操作的。因此在这里json存在一定的局限性。因此这里可以使用pickle模块，转化后的内容都是bytes的。\n\n```\nimport pickle\nimport datetime\n\nt = datetime.datetime.now()\nd = pickle.dumps(t)\nprint(d)\nprint(type(d))\n\n结果：\nb\'\\x80\\x03cdatetime\\ndatetime\\nq\\x00C\\n\\x07\\xe1\\x07\\x1f\\t&7\\x07x\\x13q\\x01\\x85q\\x02Rq\\x03.\'\n<class \'bytes\'>\n```\n\n因此在写入的时候不要忘了mode里面添加上b的选项：\n\n```\nimport pickle\nimport datetime\n\nt = datetime.datetime.now()\nd = pickle.dumps(t)\n\nf = open(\'b.txt\',mode=\'wb\')\nf.write(d)\nf.close()\n```\n\n读取的时候也要加上b选项：\n\n```\nf = open(\'b.txt\',\"rb\")\ndate = pickle.loads(f.read())\nprint(date)\n```\n\n不仅如此，pickle还可以序列化类，函数等等。因此python之间交互用pickle是最好的。不过以后pickle用的还是相对来说较少的。\n\n","timestamp":1523777648264},{"name":"08-08、re正则模块.md","path":"05-Python/00-Python常用模块详解/08-08、re正则模块.md","content":"### re模块\n\n#### 元字符（有特殊功能的字符）\n\n- .  ：（一个点）能匹配任何一个除换行符以外的符号，重要的就是\\n是不会被匹配的。\\t是可以的，\\r也ok。如果你要匹配到\\n你就老老实实写上去，没有跳过一说。\n\n\n- *：匹配的是0次到无穷多次，可以用{0,}来模拟\n\n```\n>>> re.findall(\"ab*c\",\"abbbbc\")\n[\'abbbbc\']\n```\n\n- +：匹配一次到n次前面的字符，可以使用{1,}来模拟\n\n\n- ?：匹配0次到1次前面的字符，可以使用{0,1}来模拟，那么相较于*，+还有?，这些都是贪婪匹配，简单来说就是尽可能多的去匹配，但是如果这些符号加上“?”以后就会变成惰性匹配，比如“\\*?”、\"+?\"、\"??\"，举个栗子：\n\n```\n>>> re.findall(\"abc*?\",\"abccccccc\") # *是0次到n次，惰性以后就按照最少的匹配\n[\'ab\']\n>>> re.findall(\"abc??\",\"abccccccc\") # ?是0次到1次，惰性以后那么就最少的0次\n[\'ab\']\n>>> re.findall(\"abc+?\",\"abccccccc\") # +是1次到n次，惰性以后那么就最少的1次\n[\'abc\']\n```\n\n- {}：匹配指定的次数，比如{n,m}，或者{n}次。\n- ^和$：这个和linux的类似，^代表以xx开始，\\$代表以xxx结尾。\n\n\n- []：字符集，比如我要去一个字符串里的abc或者adc可以使用如下的形式：\n\n```\n规则：a[bd]c，那么代表的意思就是abc或者是adc。\n在字符集中的元字符会作为普通字符而不再作为通配符的意义出现\n比如a[*]b，代表的是“a*b”，a[+]b代表的就是“a[+]b”\n\n\"-、^、\\\"这三个符号在字符集中有特殊的含义。\n[1-9],代表的是1到9中的任意一个数字\n[a-z],代表的是小写字母中的任意一个字母。\n[^lamber]：在字符集里的尖角号表示取非，即不是lamber的给取出来。\n[^\\d]：把不是数字的给取出来。\n```\n\n- \\d\n\n\\d用来匹配一个数字，那么\\d+就可以匹配数字出现一次到多次。\n\n```\n>>> re.findall(\"\\d+\",\"abb213bb22c4asdasd2asdas554\")\n[\'213\', \'22\', \'4\', \'2\', \'554\']\n```\n\n如果不用+的话，那么会把每一个单个的数字作为一个元素添加到列表内，即使数字在字符串中是连续的。使用\\d+就不会有这个情况了。\n\n- () ：分组，+和*还有？都是默认重复前面一个字符，如果我们要重复前面一组数据可以使用小括号括起来，比如：\n\n```\n(ad)+：表示1到n个“ad”。这个情况下这个ad肯定是成对出现的。不是针对单个的a也是单个的d。\n```\n\n上面说到的都是无命名分组，下面看一下有命名的分组：\n\n```\n>>> re.findall(r\"\\w+\\.articles\\.\\d{4}\",\"yuan.articles.1234\")\n[\'yuan.articles.1234\']\n>>> a = re.search(r\"(?P<author>\\w+)\\.articles\\.(?P<id>\\d{4})\",\"yuan.articles.1234\")\n>>> a.group(\'author\')\n\'yuan\'\n>>> a.group(\'id\') \n```\n\n有命名的分组的语法就是讲匹配的对象用小括号括起来，比如\\w+，改成(\\w+)，然后用一个\"?P\"的形式，这个就是python里面的一个固定写法，不要太过于纠结为什么要这样写。然后命名要用一个尖括号括起来，最后结果就是(?P\\<author\\>\\w+)这就是一个分组了。\n\n- | ：或的意思。\n\n```\n>>> re.findall(\"www\\.(?:oldboy|baidu)\\.com\",\"www.baidu.com\")\n[\'www.baidu.com\']\n>>> re.findall(\"www\\.(?:oldboy|baidu)\\.com\",\"www.oldboy.com\")\n[\'www.oldboy.com\']\n```\n\n- \\ ：转义符号，又叫脱意符号同时也可以让字符变成有特殊意义的字符。\n\n```\n**************特殊符号普通话***********************\n\\. 就是一个普通的.\n\\* 普通的*\n**************普通符号特殊化***********************\n\\d  匹配任何十进制数；它相当于类 [0-9]。\n\\D  匹配任何非数字字符；它相当于类 [^0-9]。\n\\s  匹配任何空白字符；它相当于类 [ \\t\\n\\r\\f\\v]。\n\\S  匹配任何非空白字符；它相当于类 [^ \\t\\n\\r\\f\\v]。\n\\w  匹配任何字母数字字符；它相当于类 [a-zA-Z0-9_]。\n\\W  匹配任何非字母数字字符；它相当于类 [^a-zA-Z0-9_]\n\\b  匹配一个特殊字符边界，比如空格 ，&，＃等\n\n\n比如取出一个字符串里所有的乘法运算\n>>> re.findall(\"(\\d+\\.?\\d*\\*\\d+\\.?\\d*)\",\"2*6+7*45+1.4*3-8/4\")  \n[\'2*6\', \'7*45\', \'1.4*3\']\n\n比如我要匹配a\\k\n>>> re.findall(\"a\\\\\\\\k\",\"a\\k\")  \n[\'a\\\\k\']\n```\n![](http://omk1n04i8.bkt.clouddn.com/17-7-31/38452288.jpg)\n\n在我们把规则交给正则之前先要交给python的解释器，但是\\在python中本身就是有特殊意义的。因此`\\\\`会被python解释器解释为一个\\交给正则。上面的这种解法可以通过在规则前加一个r表示告诉python解释器你就别多管闲事了，直接给正则处理就可以了。\n\n```\n比如我要取出单个的i而不是单词里的i\n>>> re.findall(r\"\\bi\",\"hello i am lily\")\n[\'i\']\n这里的r的作用是告诉python解释器不要去解析特殊字符了，直接交给正则去处理。\n如果不加r的话，python会按照ascii表中指代的所去解释，在ascii表中\\b代表退格(backspace)\n```\n\n#### 方法\n\n- re.findall(\'规则\',\'要查询的字符串\')\n\n此方法会把每次匹配到的结果作为一个元素放入到一个列表里\n\n```\n>>> re.findall(\"p..h\",\"hello python making\")\n[\'pyth\']\n```\n\nfindall方法有一个特点就是如果规则里面存在分组的话，会优先把分组的内容放到匹配到的结果列表里。其实匹配到的内容就是\"abablamber\"，但是只会优先把最后一个匹配到的分组放到里面。\n\n```\n>>> re.findall(\"(ab)+lamber\",\"asdas12abablamberasd7123\")\n[\'ab\']\n```\n\n如果要取消掉这个优先级的规则的话需要用特殊的语法，在分组中加一个“?:”如下所示：\n\n```\n>>> re.findall(\"(?:ab)+lamber\",\"asdas12abablamberasd7123\")\n[\'abablamber\']\n```\n\n- re.finditer(规则，字符串)\n\nfinditer返回的结果和findall是不同的，findall返回的是一个列表，finditer返回的是一个迭代器。返回的是一个迭代器对象的内存地址，每一次调用next(迭代器对象).group方法就可以打印出对应的值来。\n\n- re.search（规则，字符串），search匹配到了就不会再向下匹配\n\n匹配成功会返回一个对象，如果不成功会返回一个None。\n\n```\n>>> re.search(\"\\d+\",\"asdasd7asdasdas8dasd\")\n<_sre.SRE_Match object at 0x7f5227e94370>     # python 2.7\n<_sre.SRE_Match object; span=(6, 7), match=\'7\'>   # python 3\n```\n\n具体我匹配到的内容是什么，我需要调用这个返回的对象的一个group方法去查看。\n\n```\n>>> a = re.search(\"\\d+\",\"asdasd7asdasdas8dasd\")\n>>> a.group()\n\'7\'\n```\n\n- re.match(规则，字符串)\n\n  特点是只在字符串的开始匹配，如果一开头不匹配那么就是不匹配。\n\n  ```\n  print(re.match(\"\\w+\",\"asdasd7asdasdas8dasd\"))\n  结果:<_sre.SRE_Match object; span=(0, 20), match=\'asdasd7asdasdas8dasd\'>\n  print(re.match(\"\\d+\",\"asdasd7asdasdas8dasd\")) # 结果：None\n  ```\n\n- re.split(\"rule\",\"string\")\n\n```\n按照数字分：\nprint(re.split(\"\\d+\",\"asdasd7asdasdas8dasd\"))\n[\'asdasd\', \'asdasdas\', \'dasd\']\n指定分的次数：\nprint(re.split(\"\\d+\",\"asdasd7asdasdas8dasd223asdasda23\",2))\n结果：[\'asdasd\', \'asdasdas\', \'dasd223asdasda23\']\n```\n\n- re.sub(pattern,repl,string,count=0,flags=0)，相当于replace替换[规则，要替换的内容，文本]\n\n```\n>>> re.sub(\"\\d\",\"A\",\"asdasd12123sdasd\") \n\'asdasdAAAAAsdasd\'\n\n指定替换次数\n>>> re.sub(\"\\d\",\"A\",\"asdasd12123sdasd\",3)\n\'asdasdAAA23sdasd\'\n```\n\n- re.subn(pattern,repl,string,count,flags)\n\n```\n>>> re.subn(\"\\d\",\"A\",\"asdasd12123sdasd\") \n(\'asdasdAAAAAsdasd\', 5)\n```\n\n返回一个元组的结果，第一个是替换的结果，第二个是替换的次数。\n\n- re.compile(\"pattern\")，针对多个字符串处理，但是规则一致的时候可以提升效率。\n\n```\n把我们的规则保存进一个对象里面去，然后又这个对象直接去调用re的各种方法。\n>>> a = re.compile(\"\\d+\")\n>>> a.subn(\"A\",\"asdasd12123sdasd\")\n(\'asdasdAsdasd\', 1)\n>>> a.findall(\"asdasd12123sdasd\")\n[\'12123\']\n```\n\n#### 小练习\n\n> 计算：\n>\n> “1 - 2 \\* ( ( 60 - 30 + ( -40/5) * (9-2*5/3 + 7 /3\\*99/4\\*2998 +10 \\* 568/14 )) - (-4\\*3)/ (16-3\\*2) )”\n\n- “1 - 2 \\* ( ( 60 - 30 + ( -40/5) * (9-2*5/3 + 7 /3\\*99/4\\*2998 +10 \\* 568/14 )) - (-4\\*3)/ (16-3\\*2) )”\n- “1 - 2 \\* ( ( 60 - 30 + ( -8) * (9-2*5/3 + 7 /3\\*99/4\\*2998 +10 \\* 568/14 )) - (-4\\*3)/ (16-3\\*2) )”","timestamp":1523777648264},{"name":"09-09、subprocess.md","path":"05-Python/00-Python常用模块详解/09-09、subprocess.md","content":"# subprocess\n\n- subprocess.Popen()\n\n接收字符串格式的命令\n\n\n\n- ​\n\n","timestamp":1523777648264},{"name":"10-10、struct模块.md","path":"05-Python/00-Python常用模块详解/10-10、struct模块.md","content":"# Struct模块\n\n> Python是一门非常简洁的语言，对于数据类型的表示，不像其他语言预定义了许多类型（如：在C#中，光整型就定义了8种），它只定义了六种基本类型：字符串，整数，浮点数，元组，列表，字典。通过这六种数据类型，我们可以完成大部分工作。但当Python需要通过网络与其他的平台进行交互的时候，必须考虑到将这些数据类型与其他平台或语言之间的类型进行互相转换问题。打个比方：C++写的客户端发送一个int型(4字节)变量的数据到Python写的服务器，Python接收到表示这个整数的4个字节数据，怎么解析成Python认识的整数呢？ Python的标准模块struct就用来解决这个问题。\n\nstruct模块的内容不多，也不是太难，下面对其中最常用的方法进行介绍：\n\n## struck.pack\n\nstruct.pack用于将Python的值根据格式符，转换为字符串（因为Python中没有字节(Byte)类型，可以把这里的字符串理解为字节流，或字节数组）。其函数原型为：struct.pack(fmt, v1, v2, …)，参数fmt是格式字符串，关于格式字符串的相关信息在[下面](http://blog.csdn.net/jgood/article/details/4290158#fmt)有所介绍。v1, v2, …表示要转换的python值。下面的例子将两个整数转换为字符串（字节流）:\n\n```python\nimport struct\n \na = 20\nb = 400\n \nstr = struct.pack(\"ii\", a, b)  #转换后的str虽然是字符串类型，但相当于其他语言中的字节流（字节数组），可以在网络上传输\nprint \'length:\', len(str)\nprint str\nprint repr(str)\n \n#---- result\n#length: 8\n#\u0014    ----这里是乱码\n#\'/x14/x00/x00/x00/x90/x01/x00/x00\'\n```\n\n格式符”i”表示转换为int，’ii’表示有两个int变量。进行转换后的结果长度为8个字节（int类型占用4个字节，两个int为8个字节），可以看到输出的结果是乱码，因为结果是二进制数据，所以显示为乱码。可以使用python的内置函数repr来获取可识别的字符串，其中十六进制的0x00000014,\n 0x00001009分别表示20和400。\n\n## struct.unpack\n\nstruct.unpack做的工作刚好与struct.pack相反，用于将字节流转换成python数据类型。它的函数原型为：struct.unpack(fmt, string)，该函数返回一个**元组**。 下面是一个简单的例子：\n\n```python\nstr = struct.pack(\"ii\", 20, 400)\na1, a2 = struct.unpack(\"ii\", str)\nprint \'a1:\', a1\nprint \'a2:\', a2\n \n#---- result:\n#a1: 20\n#a2: 400\n```\n\n## struct.calcsize\n\nstruct.calcsize用于计算格式字符串所对应的结果的长度，如：struct.calcsize(‘ii’)，返回8。因为两个int类型所占用的长度是8个字节。\n\n## struct.pack_into,struct.unpack_from\n\n这两个函数在Python手册中有所介绍，但没有给出如何使用的例子。其实它们在实际应用中用的并不多。Google了很久，才找到一个例子，贴出来共享一下：\n\n```python\nimport struct\nfrom ctypes import create_string_buffer\n \nbuf = create_string_buffer(12)\nprint repr(buf.raw)\n \nstruct.pack_into(\"iii\", buf, 0, 1, 2, -1)\nprint repr(buf.raw)\n \nprint struct.unpack_from(\'iii\', buf, 0)\n \n#---- result\n#\'/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00\'\n#\'/x01/x00/x00/x00/x02/x00/x00/x00/xff/xff/xff/xff\'\n#(1, 2, -1)\n```\n\n\n\n## 关于格式字符串\n\n在Python手册中，给出了C语言中常用类型与Python类型对应的格式符：\n\n| 格式符  | C语言类型                | Python类型           | 注    |\n| ---- | -------------------- | ------------------ | ---- |\n| `x`  | pad byte             | no value           |      |\n| `c`  | `char`               | string of length 1 |      |\n| `b`  | `signed char`        | integer            |      |\n| `B`  | `unsigned char`      | integer            |      |\n| `?`  | `_Bool`              | bool               |      |\n| `h`  | `short`              | integer            |      |\n| `H`  | `unsigned short`     | integer            |      |\n| `i`  | `int`                | integer            |      |\n| `I`  | `unsigned int`       | integer or long    |      |\n| `l`  | `long`               | integer            |      |\n| `L`  | `unsigned long`      | long               |      |\n| `q`  | `long long`          | long               |      |\n| `Q`  | `unsigned long long` | long               |      |\n| `f`  | `float`              | float              |      |\n| `d`  | `double`             | float              |      |\n| `s`  | `char[]`             | string             |      |\n| `p`  | `char[]`             | string             |      |\n| `P`  | `void *`             | long               |      |","timestamp":1523777648264},{"name":"11-11、requests模块.md","path":"05-Python/00-Python常用模块详解/11-11、requests模块.md","content":"","timestamp":1523777648264},{"name":"12-12、argprase模块.md","path":"05-Python/00-Python常用模块详解/12-12、argprase模块.md","content":"# argprase模块\n\n>在多个文件或者不同语言协同的项目中，python脚本经常需要从命令行直接读取参数。万能的python就自带了[argprase包](https://docs.python.org/2/howto/argparse.html)使得这一工作变得简单而规范。\n>\n>PS：optparse包是类似的功能，只不过写起来更麻烦一些。如果脚本很简单或临时使用，没有多个复杂的参数选项，可以直接利用`sys.argv`将脚本后的参数依次读取(读进来的默认是字符串格式)。\n\n## 常用模式\n\n大多数情况下，脚本很可能需要多个参数，而且每次参数的类型用处各不相同，那么这个时候在参数前添加标签表明参数的类型和用途便十分有用，而利用argparse模块可以很方便得实现这一目的。\n\n```python\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\n# -*- coding: utf-8 -*-\nimport argparse\n\n# description参数可以用于插入描述脚本用途的信息，可以为空\nparser = argparse.ArgumentParser(description=\"your script description\")\n\n# 添加--verbose标签，标签别名可以为-v，这里action的意思是当读取的参数中出现--verbose/-v的时候\n# 参数字典的verbose建对应的值为True，而help参数用于描述--verbose参数的用途或意义。\nparser.add_argument(\'--verbose\', \'-v\', action=\'store_true\', help=\'verbose mode\')\n\n# 将变量以标签-值的字典形式存入args字典\nargs = parser.parse_args()\n\nprint(args)\nprint(args.verbose)\n```\n\n结果显示：\n\n```python\nNamespace(verbose=False)\nFalse\n```\n\n终端运行：\n\n```powershell\nD:\\坚果云同步\\Python\\Python_exercise\\Day21 Modules>python3 args.py -v\nNamespace(verbose=True)\n\nD:\\坚果云同步\\Python\\Python_exercise\\Day21 Modules>python3 args.py --verbose\nNamespace(verbose=True)\n\nD:\\坚果云同步\\Python\\Python_exercise\\Day21 Modules>python3 args.py --help\nusage: args.py [-h] [--verbose]\n\nyour script description\n\noptional arguments:\n  -h, --help     show this help message and exit\n  --verbose, -v  verbose mode\n\nD:\\坚果云同步\\Python\\Python_exercise\\Day21 Modules>python3 args.py -h\nusage: args.py [-h] [--verbose]\n\nyour script description\n\noptional arguments:\n  -h, --help     show this help message and exit\n  --verbose, -v  verbose mode\n\nD:\\坚果云同步\\Python\\Python_exercise\\Day21 Modules>python3 args.py -a\nusage: args.py [-h] [--verbose]\nargs.py: error: unrecognized arguments: -a\n```\n\n运行这个脚本后面跟了--verbose/-v的时候会输出前者，如果什么都没有会输出后者。如果输入了--verbose/-v以外的参数则会报错：unrecognized arguments\n稍微提一下，action参数表示值赋予键的方式，这里用到的是bool类型；如果是\'count\'表示将--verbose标签出现的次数作为verbose的值；\'append\'表示将每次出现的该便签后的值都存入同一个数组再赋值。（嘛，一般后面两种用的比较少就不多说了）\n**PS：--help标签在使用argparse模块时会自动创建，因此一般情况不需要我们主动定义帮助信息。**\n\n## 必要参数\n\n这种模式用于确保某些必需的参数有输入。\n`parser.add_argument(\'--verbose\', required=True, type=int)`\nrequired标签就是说--verbose参数是必需的，并且类型为int，输入别的类型会报错。\n\n## 位置参数\n\n位置参数与sys.argv调用比较像，参数没有显式的--xxx或者-xxx标签，因此调用属性也与sys.argv相同。\n\n```\nparser.add_argument(\'filename\')    # 输入的第一个参数赋予名为filename的键\nargs = parser.parse_args()\nprint \"Read in %s\" %(args.filename)\n```\n\n输入`python test.py test.txt`则会输出`Read in test.txt`\n此外，可以用nargs参数来限定输入的位置参数的个数，默认为1。当然nargs参数也可用于普通带标签的参数。\n`parser.add_argument(\'num\', nargs=2, type=int)`表示脚本可以读入两个整数赋予num键（此时的值为2个整数的数组）。nargs还可以\'*\'用来表示如果有该位置参数输入的话，之后所有的输入都将作为该位置参数的值；‘+’表示读取至少1个该位置参数。\'?\'表示该位置参数要么没有，要么就只要一个。（PS：跟正则表达式的符号用途一致。）比如用：\n\n```\nparser.add_argument(\'filename\')\nparser.add_argument(\'num\', nargs=\'*)\n```\n\n就可以运行`python test.py text.txt 1 2`\n由于没有标签，所以用位置参数的时候需要比较小心。\n\n## 输入类型\n\n之前已经提到了用type参数就可以指定输入的参数类型。而这个type类型还可以表示文件操作的类型从而直接进行文件的读写操作。\n\n```\nparser.add_argument(\'file\', type=argparser.FileType(\'r\'))    # 读取文件\nargs = parser.parse_args()\nfor line in args.file:\n    print line.strip()\n```\n\n## 参数默认值\n\n一般情况下会设置一些默认参数从而不需要每次输入某些不需要变动的参数，利用default参数即可实现。\n\n```\nparser.add_argument(\'filename\', default=\'text.txt\')\n```\n\n这个时候至直接运行`python text.py`就能得到`Read in text.txt`而不需要输入文件名了。\n\n## 候选参数\n\n表示该参数能接受的值只能来自某几个值候选值中，除此以外会报错，用choices参数即可。比如：\n\n```\nparser.add_argument(\'filename\', choices=[\'test1.txt\', \'text2.txt\'])\n```","timestamp":1523777648264},{"name":"13-13、configparser.md","path":"05-Python/00-Python常用模块详解/13-13、configparser.md","content":"# ConfigParser模块\n\n> configParser 模块用于操作配置文件\n>\n> 注：Parser汉译为“解析”之意。\n>\n> 配置文件的格式与windows ini文件类似，可以包含一个或多个节（section），每个节可以有多个参数（键=值）。\n\n","timestamp":1523777648264},{"name":"14-14、paramiko模块.md","path":"05-Python/00-Python常用模块详解/14-14、paramiko模块.md","content":"# Paramiko模块\n\n","timestamp":1523777648264},{"name":"15-15、itertools模块.md","path":"05-Python/00-Python常用模块详解/15-15、itertools模块.md","content":"# itertools\n\n> 高效的创建和使用迭代器的一个函数\n\n### chain\n\n将多个序列合并为一个序列返回\n\n```python\nimport itertools\nfor each in itertools.chain(\'i\', [1,\'test\',3], \'python\'):\n    print(each)\n```\n\nresult:\n\n```python\ni\n1\ntest\n3\np\ny\nt\nh\no\nn\n```\n\n## 排列组合\n\n在说下面的方法之前先提一下排列组合\n\n- 排列：就是指从给定个数的元素中取出指定个数的元素进行排序\n- 组合：从给定个数的元素中仅仅取出指定个数的元素，不考虑排序。\n\n### 排列\n\n比如从3个元素里挑出来两个进行排序，就比如123，那么可能的结果就是12,13,21,23,31,32也就是6种，其结果就相当于：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-10-11/48205857.jpg)\n\n从n个元素中挑出m个，那么有几种排列方法。\n\n### 组合\n\n组合是指的从给定的元素中取出指定个数的元素看有多少种组合，比如从红黄白黑四色球中任意取出两种有几种组合？这白黑和黑白其实是一种，这就是和排列不一样的地方，它并不考虑顺序的。\n\n那么结果很简单，就是6种，计算方法如下：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-10-12/74794348.jpg)\n\n组合计算公式如下：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-10-12/42428374.jpg)\n\n接下来看itertools针对于排列组合的方法\n\n- itertools.combinations(iterable,r)\n\n  ```python\n  import itertools\n  for each in itertools.combinations(\'abc\', 2):\n      print(each)\n      \n  结果：\n  (\'a\', \'b\')\n  (\'a\', \'c\')\n  (\'b\', \'c\')\n\n  说明：返回可迭代对象中指定长度的组合\n  ```\n\n- itertools.combinations_with_replacement(iterable,r)\n\n  ```python\n  import itertools\n  for each in itertools.combinations_with_replacement(\'abc\', 2):\n      print(each)\n      \n  结果：\n  (\'a\', \'a\')\n  (\'a\', \'b\')\n  (\'a\', \'c\')\n  (\'b\', \'b\')\n  (\'b\', \'c\')\n  (\'c\', \'c\')\n\n  说明：在组合的基础上允许单个元素的重复\n  ```\n\n- ​\n\n","timestamp":1523777648264},{"name":"01-defaultdict.md","path":"05-Python/00-Python常用模块详解/16-16、collections模块/01-defaultdict.md","content":"# defaultdict\r\n>在Python中有一些内置的数据类型，比如int, str, list, tuple, dict等。Python的collections模块在这些内置数据类型的基础上，提供了几个额外的数据类型：namedtuple, defaultdict, deque, Counter, OrderedDict等，其中defaultdict和namedtuple是两个很实用的扩展类型。defaultdict继承自dict，namedtuple继承自tuple。\r\n\r\n在使用Python原生的数据结构dict的时候，如果用d[key]这样的方式访问，当指定的key不存在时，是会抛出KeyError异常的。但是，如果使用defaultdict，只要你传入一个默认的工厂方法，那么请求一个不存在的key时， 便会调用这个工厂方法使用其结果来作为这个key的默认值。\r\n\r\ndefaultdict在使用的时候需要传一个工厂函数(function_factory)，defaultdict(function_factory)会构建一个类似dict的对象，该对象具有默认值，默认值通过调用工厂函数生成。","timestamp":1523777648264},{"name":"00-Python基础.md","path":"05-Python/01-Python基础/00-Python基础.md","content":"- 一年去一个国家\n- ​\n\n","timestamp":1523777648264},{"name":"01-变量.md","path":"05-Python/01-Python基础/01-变量.md","content":"python中变量的理解更好的要给理解方式应该是标签，比如一个列表[1,2,3]，两个变量a和b分别指向这个列表\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-18/42164188.jpg)\n\npython中的赋值语句始终是先执行右侧的，比如：\n\n```\nx = 3**2\n结果：9\n```\n\nid()查看的是对象的标识，我们可以把标识理解为对象在内存中的地址，即使是拥有同样的两个值的对象它的标识也是不一样的，比如：\n\n```\na = {\'name\':\'maxiaoyu\',\'age\':25}\nb = {\'name\':\'maxiaoyu\',\'age\':25}\nprint(id(a))\nprint(id(b))\n\n结果：\n822001629512\n822001629584\n```\n\n这种情况下标识才是一致的：\n\n```\na = {\'name\':\'maxiaoyu\',\'age\':25}\nb = a\nprint(id(a))\nprint(id(b))\nprint(a is b)\n\n结果：\n841123264840\n841123264840\nTrue\n```\n\n然而在编程中使用的最多的并不是比较两个对象的标识，而是比较两个对象的值，因此“==”用的频率要远高于“is”的使用率。is最多的使用情况是`x is None/x is not None`。用来判断对象绑定的内容是不是None。\n\n元组的不可变性是相对来说的。因为元组和python中的列表、字典、集合等一样，保存的是对象的引用，也就是说元组类型的不可变指的是元组数据结构的物理内容也就是保存的这个引用是不可变的，和引用的对象是无关的。\n\n```\n>>> a = (1,2,[\'a\',\'b\'])\n>>> b = (1,2,[\'a\',\'b\'])\n>>> a == b\nTrue\n>>> id(a[-1])\n139812209010016\n>>> a[-1].append(\'c\')\n>>> id(a[-1])        \n139812209010016\n>>> a\n(1, 2, [\'a\', \'b\', \'c\'])\n>>> a == b\nFalse\n```\n\n列表的加减内存地址还是不变的：\n\n```\na = [1,2]\nprint(id(a))\nb = [2,3]\na += b\nprint(id(a))\nprint(a)\n\n结果：\n148739579336\n148739579336\n[1, 2, 2, 3]\n```\n\n但是列表是不可变的，因此列表的加减就相当于创建一个新列表了。\n\n```\na = (1,2)\nprint(id(a))\nb = (2,3)\na += b\nprint(id(a))\nprint(a)\n\n结果：\n999073006344\n999072035688\n(1, 2, 2, 3)\n```\n\n","timestamp":1523777648264},{"name":"01-Python的函数.md","path":"05-Python/01-Python基础/02-2、Python函数部分/01-Python的函数.md","content":"# 函数\n\n> 为什么要定义函数？为了方便更好的维护，便于更好的管理和扩展，同时使用函数可以使代码的组织结构更加清晰，增强可读性，减少代码的冗余，可以进行代码的复用。\n\n## 介绍&定义\n\npython中包含内置函数，比如print就是一个函数：\n\n```\nprint(print)\n\n结果：\n<built-in function print>\n```\n\n内置函数是内置到解释器里面的，程序一启动拿过来可以直接用，无需定义。当然除了内置的函数之外我们还可以自定义，因为内置函数的功能是有限的，因此我们需要自定义我们需要的功能。自定义函数的定义：\n\n```python\ndef 函数名(arg1,arg2,arg3……):\n    \'\'\'描述信息\'\'\'\n    函数体\n    return              <--用来定义返回值，可以是任意类型，一般有参函数会用到。\n    \n官方函数参考：\ndef round(number, ndigits=None): # real signature unknown; restored from __doc__\n    \"\"\"\n    round(number[, ndigits]) -> number\n    \n    Round a number to a given precision in decimal digits (default 0 digits).\n    This returns an int when called with one argument, otherwise the\n    same type as the number. ndigits may be negative.\n    \"\"\"\n    return 0\n```\n\n### 函数的调用：\n\n```\n函数名()\n```\n\n需要记住的一个点是函数要先定义后使用。我们在写函数的时候应该习惯性的去写函数的定义和注释，方便后期的查阅和采集。\n\n```\ndef say_hello():\n    \'\'\'this is a test function to print hello on the screen\'\'\'\n    print(say_hello.__doc__)\n\nsay_hello()\n\n结果：\nthis is a test function to print hello on the screen\n```\n\n这个注释我们是可以通过`__doc__`方法取到的。\n\n现在我们定义的这个属于无参函数，无参函数一般都是固定的一串语句，不需要外部参数。定义有参函数如下，有参函数依赖于外部传递来的参数，内置函数有代表性的比如`len()`，如果不传递参数的话会报错。\n\n```python\ndef bar(x,y):\n    print(x)\n    print(y)\n```\n\npython属于弱类型的语言，因此传参的时候传递的参数也是没有类型限制的，因此我们可以通过在定义函数的时候加上注释来提醒别人。。\n\n\n\n### 定义空函数：\n\n```\ndef kong():\n    pass\n```\n\n函数体为pass，也就是什么都不干，那么这个函数的功能就是什么也不干，那么这个函数的可以应用于构思过程，比如我要写一个购物车，里面都有什么功能，需要什么函数来完成，但是细节我没必要立即去实现，因此函数体内部就可以使用pass。我现在是一种构思没必要立即去实现功能。虽然程序没有实现，但是程序体系结构立现。有什么思路就去实现什么功能，简单来说就是先把程序的框架搭建起来，然后后续慢慢的丰富具体的内容。\n\n## 函数的返回值\n\n- 可以是任意类型\n- 没有return返回是None\n- return一个值返回就是对应的值\n- return返回多个值返回的就是一个元组\n\nreturn来返回函数的返回值。\n\n不写return的话默认也会有值返回，只是返回的内容是None：\n\n```python\ndef a():\n    print(\"hello\")\nb = a()\nprint(b)\n\n结果：\nhello\nNone\n```\n\nreturn可以返回多个值，不仅如此return还可以返回多种类型。return多个元素会默认以元组的形式返回，因为python中会默认把用逗号链接的值放到一个元组里面去，那么针对这个问题就涉及到了元组的解压。\n\n### 关于元组的解压：\n\n```python\na,b,c,d,e,f = [1,2,3,4,5,6]\n\na,_,_,_,_,e = [1,2,3,4,5,6]\nprint(a)\nprint(e)\n\na,*_,e = [1,2,3,4,5,6,7]\nprint(e)\n\nhead,*_ = [1,2,3,4,5]\nprint(head)\n结果：1\n\n\n*_,tail = [1,2,3,4,5]\nprint(tail)\n结果：5\n```\n\n看上面的例子，我们定义a~f六个变量，它会一次去接收这个列表里的值，然后分别赋值给a-f六个变量，如果说两端的数目不匹配会进行报错，如果不想赋值的可以使用\"\\_\"来代替，多个下划线可以使用`*_`的形式来替代，那么对比过来元组和序列也是一样的，本身元组就是不可更改的序列。这种方法同样也适用于集合和字典，只不过字典取的是key，其实就是相当于循环遍历。\n\n那么说这个的目的其实是为了取函数的返回值，如果有多个返回值的时候返回的是一个元组。我们可以通过上面的办法取到返回的这些值。\n\n```\ndef ret():\n    return 1,2,3,4\n\na,b,c,d = ret()\nprint(a)\nprint(d)\n\nhead,*_ = ret()\n*_,tail = ret()\n\nprint(head,tail)\n```\n\nTip：函数只能执行一个return，你可以写多个，但是只执行一次，然后函数就结束掉了。\n","timestamp":1523777648264},{"name":"02-函数的参数.md","path":"05-Python/01-Python基础/02-2、Python函数部分/02-函数的参数.md","content":"# 函数的参数\n\n## 形参 & 实参\n\n![](http://omk1n04i8.bkt.clouddn.com/17-6-28/8104632.jpg)\n\nx和y其实就是变量名，在定义的阶段其实是不占用内容的。但是1和2是变量的值，它是要占用空间的，因此形参其实就是定义了一堆变量名，而实参则是实际的变量的值。其实就是相当于`x=1`，`y=2`。x和y指向了1和2所在的内存地址（绑定关系）。这种绑定关系只有在调用的时候才会生效，调用结束后失效，这种绑定关系只在函数内部有效：\n\n```\nx = \"我是外部的\"\ndef test(x,y):\n    print(x)\n    print(y)\n\ntest(\"我是内部的\",2)\nprint(x)\n\n结果：\n我是内部的\n2\n我是外部的\n```\n\n在调用的时候，实参的位置也可以放变量，不一定是放具体的值。当然你传一个列表，传一个字典……都是可以的。你传啥就是啥。实参的值要是不可变类型（数字、元组、字符串），虽然列表这种可变类型你也可以传，但是不可变类型传的就是值，可变类型传的是内存地址，生效范围就不是函数内部了，看下面的例子：\n\n不可变类型：\n\n```\ndef test(x):\n    x = 3\nx = 1\ntest(x)\nprint(x)\n\n结果：1\n```\n\n可变类型：\n\n```python\ndef test(x):\n    x.append(4)\nx = [1,2,3]\ntest(x)\nprint(x)\n\n结果：\n[1,2,3,4]\n```\n\n因为可变类型传的是内存地址，因此改了就是直接去操作对应的内存地址的数据了，因此数据被影响了。因此特别注意，不要在函数中动全局变量，只改内部就够了，也就是传值的时候别传递可变类型。\n\n## 位置参数 & 默认参数\n\n### 实参的角度\n\n- 按位置传值\n\n```\ndef test(x,y):\n    print(x)\n    print(y)\ntest(1,2)\n\n1对应x，2对应y，从实参的角度，这叫按位置传值。\n```\n\n- 按关键字传值\n\n```\ndef test(x,y):\n    print(x)\n    print(y)\ntest(x=1,y=2)\n\n按照关键字进行传值，你可以换位置，随便换都没事，因为这边按照关键字明确的指定了。\n```\n\n- 位置传值+关键字传值混用\n\n```\ndef test(x,y):\n    print(x)\n    print(y)\ntest(1,y=2)\n```\n\n这种情况下收到位置传值的限制，也就是说1的位置不能变，你把1和y=2的位置换一下就会报错了，因为y有指定值，但是1却没办法对应x了，报错信息如下：\n\n```\nSyntaxError: positional argument follows keyword argument\n```\n\n不能对一个形参多次赋值，不然会报错。也就是说你不管是用位置传参还是关键字传参，不能进行多次传值，不能重复传值。\n\n### 形参的角度\n\n- 位置参数：必须传值的参数，如果你定义一个位置参数就必须给他传值。经常发生变化的就定义成位置参数。\n\n```\ndef test(x,y):\n    print(x)\n    print(y)\n```\n\n不传值就会报错：\n\n```\nTypeError: test() missing 1 required positional argument: \'x\'\n```\n\n- 默认参数，不经常发生变化的就定义成默认参数。\n\n```\ndef test(x,y=\"hahaha\"):\n    print(x)\n    print(y)\n\ntest(1)\ntest(3,4)\n\n结果：\n1\nhahaha\n3\n4\n```\n\n在默认参数的时候传值不是必须的，如果没有传值不会报错直接会使用默认的。上面默认的就是y=“hahaha”。**默认参数必须放到位置参数的后面，不然会报错**。\n\n再来看一个问题：\n\n```\ntest1 = \"test\"\n\ndef test(x,y=test1):\n    print(x)\n    print(y)\ntest1 = \"hey!!\"\n\ntest(1)\n\n结果：\n1\ntest\n```\n\n可以发现test1 = “hey!!”并没有赋值进去，因为在def定义阶段，y=test1这个就已经加载到内存中了，也就是说y=\'test\'就已经确定了。后续的赋值便不会再印象函数这里面的y了。\n\n## 可变参数\n\n- *args(这只是一种约定俗称的写法，你可以用\\*a，或者\\*b)\n\n```python\ndef foo(x,*args):\n    print(x)\n    print(args)\nfoo(1,2,3,4,5,6,7,8)\n\n结果：\n1\n(2, 3, 4, 5, 6, 7, 8)\n```\n\n\\*args会把按位置传参多余的部分已元组的形式存放到args里面，而不会报错。一般\\*args和默认参数不会放到一块去用。因此`*args`的作用就是接受无穷无尽的参数，之前我们再写可以接受参数的函数的时候会用`def foo(x,y,z……)`，假如我需要接受的位置参数有很多，我们就可以使用`*args`来替代，简单来说我们就可以用它来带位置参数。\n\n```python\ndef foo(*args):\n    xxxxx\n    \n同样的在调用的时候实参也可以使用*的形式，比如：\n\ndef foo(x,y,z):\n    print(x)\n    print(y)\n    print(z)\n    \nfoo(*(1,2,3)) ==等同于== foo(1,2,3)\n相当于将这个(1,2,3)的元组给打散了去传值。\n```\n\n- **args\n\n比\\*args多了个星号，区别就在于一个`*`会把多余的元素转换成元组，但是`**args`的情况会把多余的元素转换成字典，因为是字典肯定就是键值对，要写成下面的格式：\n\n```\ndef foo(x,**args):\n    print(x)\n    print(args)\nfoo(1,a=2,b=3,c=4,d=5,e=6,f=7,g=8)\n\n结果：\n1\n{\'a\': 2, \'b\': 3, \'c\': 4, \'d\': 5, \'e\': 6, \'f\': 7, \'g\': 8}\n```\n\n如果调用foo不是一键值对的形式传值的话会报错，会报问题说我只要一个位置参数你为啥给我那么多。\n\n**总结一下**\n\n1. \\*args就是按照位置参数传值，如果多余的就给\\*args\n2. \\*\\*args是关键字传值，也就是a=1这种的，多余的会被\\*\\*args接收。\n\n```\ndef foo(*args,**kwargs)\n这种形式就可以接受各种类型的了各种值了。\n\n但是注意两点（实参的角度）\n1--不能重复传值\n2--关键字传值要在位置传值的后面\n```\n\n那么\\*可以用在实参的位置，打散了去看，同样的\\*\\*也是一样，打散了是可以的，但是注意关键字要对应，比如形参是x，你别给传一个a=xx就行：\n\n```\ndef foo(x,y,z):\n    print(x,y,z)\n\nfoo(**{\"x\":1,\"y\":2,\"z\":3})\n\n结果:\n1 2 3\n```","timestamp":1523777648264},{"name":"03-命名空间和作用域.md","path":"05-Python/01-Python基础/02-2、Python函数部分/03-命名空间和作用域.md","content":"## 名称空间和作用域\n\n什么是名称空间？\n\n```\nimport this\n\n回显：（Python内置的小彩蛋）\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\n# 优美胜于丑陋（Python以编写优美的代码为目标）\n\nExplicit is better than implicit.\n# 明了胜于晦涩（优美的代码应当是明了的，命名规范，风格相似）\n\nSimple is better than complex.\n# 简洁胜于复杂（优美的代码应当是简洁的，不要有复杂的内部实现）\n\nComplex is better than complicated.\n# 复杂胜于凌乱（如果复杂不可避免，那代码间也不能有难懂的关系，要保持接口简洁）\n\nFlat is better than nested.\n# 扁平胜于嵌套（优美的代码应当是扁平的，不能有太多的嵌套）\n\nSparse is better than dense.\n# 间隔胜于紧凑（优美的代码有适当的间隔，不要奢望一行代码解决问题）\n\nReadability counts.\n# 可读性很重要（优美的代码是可读的）\n\nSpecial cases aren’t special enough to break the rules.Although practicality beats purity.\n# 即便假借特例的实用性之名，也不可违背这些规则（这些规则至高无上）\n\nErrors should never pass silently.Unless explicitly silenced.\n# 不要包容所有错误，除非你确定需要这样做（精准地捕获异常，不写except:pass风格的代码）\n\nIn the face of ambiguity, refuse the temptation to guess.\n# 当存在多种可能，不要尝试去猜测\n\nThere should be one– and preferably only one –obvious way to do it.\n# 而是尽量找一种，最好是唯一一种明显的解决方案（如果不确定，就用穷举法）\n\nAlthough that way may not be obvious at first unless you’re Dutch.\n# 虽然这并不容易，因为你不是 Python 之父（这里的Dutch是指Guido）\n\nNow is better than never.Although never is often better than *right* now.\n# 做也许好过不做，但不假思索就动手还不如不做（动手之前要细思量）\n\nIf the implementation is hard to explain, it’s a bad idea.If the implementation is easy to explain, it may be a good idea.\n# 如果你无法向人描述你的方案，那肯定不是一个好方案；反之亦然（方案测评标准）\n\nNamespaces are one honking great idea — let’s do more of those!\n# 命名空间是一种绝妙的理念，我们应当多加利用（倡导与号召）\n```\n\n> 在python当中所有有关名字的定义都会放到名称空间，比如定义变量名，函数名。根据存放的内容不同有三种名称空间，内置的名称空间，全局的名称空间，局部的名称空间。\n\n### 内置名称空间\n\n解释器一启动就有的，python内置的，一启动就会加载到内存中的。我们可以直接调用的。\n\n```python\n>>> import builtins\n>>> dir(builtins)\n[\'ArithmeticError\', \'AssertionError\', \'AttributeError\', \'BaseException\', \'BlockingIOError\', \'BrokenPipeError\', \'BufferError\', \'BytesWarning\', \'ChildProcessError\', \'ConnectionAbortedError\', \'ConnectionError\', \'ConnectionRefusedError\', \'ConnectionResetError\', \'DeprecationWarning\', \'EOFError\', \'Ellipsis\', \'EnvironmentError\', \'Exception\', \'False\', \'FileExistsError\', \'FileNotFoundError\', \'FloatingPointError\', \'FutureWarning\', \'GeneratorExit\', \'IOError\', \'ImportError\', \'ImportWarning\', \'IndentationError\', \'IndexError\', \'InterruptedError\', \'IsADirectoryError\', \'KeyError\', \'KeyboardInterrupt\', \'LookupError\', \'MemoryError\', \'ModuleNotFoundError\', \'NameError\', \'None\', \'NotADirectoryError\', \'NotImplemented\', \'NotImplementedError\', \'OSError\', \'OverflowError\', \'PendingDeprecationWarning\', \'PermissionError\', \'ProcessLookupError\', \'RecursionError\', \'ReferenceError\', \'ResourceWarning\', \'RuntimeError\', \'RuntimeWarning\', \'StopAsyncIteration\', \'StopIteration\', \'SyntaxError\', \'SyntaxWarning\', \'SystemError\', \'SystemExit\', \'TabError\', \'TimeoutError\', \'True\', \'TypeError\', \'UnboundLocalError\', \'UnicodeDecodeError\', \'UnicodeEncodeError\', \'UnicodeError\', \'UnicodeTranslateError\', \'UnicodeWarning\', \'UserWarning\', \'ValueError\', \'Warning\', \'ZeroDivisionError\', \'__build_class__\', \'__debug__\', \'__doc__\', \'__import__\', \'__loader__\', \'__name__\', \'__package__\', \'__spec__\', \'abs\', \'all\', \'any\', \'ascii\', \'bin\', \'bool\', \'bytearray\', \'bytes\', \'callable\', \'chr\', \'classmethod\', \'compile\', \'complex\', \'copyright\', \'credits\', \'delattr\', \'dict\', \'dir\', \'divmod\', \'enumerate\', \'eval\', \'exec\', \'exit\', \'filter\', \'float\', \'format\', \'frozenset\', \'getattr\', \'globals\', \'hasattr\', \'hash\', \'help\', \'hex\', \'id\', \'input\', \'int\', \'isinstance\', \'issubclass\', \'iter\', \'len\', \'license\', \'list\', \'locals\', \'map\', \'max\', \'memoryview\', \'min\', \'next\', \'object\', \'oct\', \'open\', \'ord\', \'pow\', \'print\', \'property\', \'quit\', \'range\', \'repr\', \'reversed\', \'round\', \'set\', \'setattr\', \'slice\', \'sorted\', \'staticmethod\', \'str\', \'sum\', \'super\', \'tuple\', \'type\', \'vars\', \'zip\']\n```\n\n### 全局名称空间\n\n在python文件中顶头写的，没有任何缩进级别的，都是全局的。全局定义的名字，在哪都能调用。\n\n### 局部名称空间\n\n比如在函数内部定义的名称，可以把函数看做一个暗箱，里面有什么代码和内容其实并不会展现出来，因此里面有一个什么内容你也不知道，对外部（全局）是不可见的。不能够直接调用，这就是局部的，只在函数这个暗箱内才是有效的。\n\n因此内置名称空间和全局名称空间是全局作用域，局部名称空间是局部作用域。\n\n名称也要先定义在使用，函数也是，函数名也是名称空间的一种。\n\n```\ndef test1():\n    print(\"test1\")\n    test2()        <------虽然走到这一行test2()没有被定义但是并不会报错，因为语法没错。\n\ntest1()\n\ndef test2():\n    print(\"test2\")\n```\n\n比如上面这一段代码，虽然代码中定义了test1和test2方法，但是test2定义的要晚于调用，因此我们再执行的时候就执行到test1()这行调用代码的时候就会报错说test2这个name没有被定义。虽然明显的test1这个函数调用test2函数是有问题的，但是定义和调用是两个阶段，在定义阶段没有语法上的问题其实就是没问题的。这里就说到了python是如何读取程序文件的，python的读取时边读边解释。\n\n再说找变量的问题：\n\n```\nx = 1\ndef test1():\n    print(x)\ntest1()\n\n结果：1\n```\n\n这里调用的就是test1，print(x)，它首先会在函数内找x的定义（局部找），然后去找全局，发现全局有一个x=1，那么就print出来，假如说全局也没有的话那么就会去找内置的。为了验证先从局部去找我们在函数内部加一个x来看看结果：\n\n```\nx = 1\ndef test1():\n    x = 2333\n    print(x)\ntest1()\nprint(x)\n\n结果：\n2333\n1\n```\n\n可以发现打印结果完全就是不同的，函数内部的首先找到了局部的x = 2333然后把它打印了出来，函数外部的print直接调用的全局的x。\n\n查看全局名称空间和局部名称空间\n\n```\nx = 1\ndef test1():\n    x = 2333\n    print(globals())\n    print(locals())\ntest1()\n\n结果：\n{\'__name__\': \'__main__\', \'__doc__\': None, \'__package__\': None, \'__loader__\': <_frozen_importlib_external.SourceFileLoader object at 0x00000037B8C1A1D0>, \'__spec__\': None, \'__annotations__\': {}, \'__builtins__\': <module \'builtins\' (built-in)>, \'__file__\': \'D:/坚果云同步/Python/Day5（函数+）/初始函数.py\', \'__cached__\': None, \'x\': 1, \'test1\': <function test1 at 0x00000037B8B77048>}\n{\'x\': 2333}\n```\n\n我们可以发现在局部函数内打印的全局和局部的内容，全局的包括x = 1和test1函数，局部的就是x = 2333，都是以字典的形式呈现的，不过如果在全局的情况下的话：\n\n```\nx = 1\ndef test1():\n    x = 2333\n\n\nprint(globals())\nprint(locals())\n\n结果：\n{\'__name__\': \'__main__\', \'__doc__\': None, \'__package__\': None, \'__loader__\': <_frozen_importlib_external.SourceFileLoader object at 0x00000037B8C1A1D0>, \'__spec__\': None, \'__annotations__\': {}, \'__builtins__\': <module \'builtins\' (built-in)>, \'__file__\': \'D:/坚果云同步/Python/Day5（函数+）/初始函数.py\', \'__cached__\': None, \'x\': 1, \'test1\': <function test1 at 0x00000037B8B77048>}\n{\'__name__\': \'__main__\', \'__doc__\': None, \'__package__\': None, \'__loader__\': <_frozen_importlib_external.SourceFileLoader object at 0x00000037B8C1A1D0>, \'__spec__\': None, \'__annotations__\': {}, \'__builtins__\': <module \'builtins\' (built-in)>, \'__file__\': \'D:/坚果云同步/Python/Day5（函数+）/初始函数.py\', \'__cached__\': None, \'x\': 1, \'test1\': <function test1 at 0x00000037B8B77048>}\n```\n\n在全局的局部内容还是全局的，这些都是顶头写的。\n\n","timestamp":1523777648264},{"name":"04-函数的嵌套.md","path":"05-Python/01-Python基础/02-2、Python函数部分/04-函数的嵌套.md","content":"## 函数的嵌套\n\n### 函数的嵌套调用\n\n```\ndef my_max(x,y):\n    rst = x if x >y else y\n    return rst\ndef cal_4_num(a,b,c,d):\n    rst1 = my_max(a,b)\n    rst2 = my_max(c,d)\n    rst3 = my_max(rst1,rst2)\n    return rst3\nprint(cal_4_num(1,2100,4,6))\n```\n\n### 函数的嵌套定义\n\n```\ndef f1():\n    x = 1\n    print(\"---------\",x)\n    def f2():\n        print(\"------>\",x)\n        def f3():\n            print(\"---->\",x)\n        f3()\n    f2()\nf1()\n\n结果：\n--------- 1\n------> 1\n----> 1\n```\n\n函数是第一类对象的概念（函数可以被当做数据来传递，简单来说变量咋用函数就能咋用）\n\n```\n函数可以被赋值:\ndef f1():\n    print(\"f1\")\nf2 = f1\nprint(f1,f2)\n\n结果：\n<function f1 at 0x000000193DB47048> <function f1 at 0x000000193DB47048>\n\n把函数当成参数传递\ndef f1():\n    print(\"f1\")\n\ndef f2(func):\n    print(func)\n\nf2(f1)\nf2(f1())\n\n结果：\n<function f1 at 0x00000093B5F47048>\nf1\nNone\n```\n\n从上面的例子就可以看到f1这个函数可以像变量一样的被传递，f2(f1)，其实就是给f2传递f1的这个参数，结果会把f1的内存地址打印出来。对于f2(f1())，f1()也就是调用f1这个函数，把返回值作为参数传给f2。调用f1，结果会print一个f1，因为f1()被调用了，但是f1()只有一个print并没有return返回值，因此传过去的func就是None，打印出来也是None。","timestamp":1523777648264},{"name":"05-装饰器.md","path":"05-Python/01-Python基础/02-2、Python函数部分/05-装饰器.md","content":"\n\n# 装饰器\n\n## 什么是装饰器\n\n什么是装饰器？装饰的工具，比如戴眼镜，眼镜就是一个装饰器，眼镜并没有改眼睛的原始构造，但是还让我看的更清楚了（添加了新的功能），如下图。装饰器可以是任何可调用对象（比如说函数，类），被装饰者也可以是任意可调用对象（比如说函数）。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-9/78631206.jpg)\n\n\n\n## 为什么要用装饰器\n\n开放封闭原则，就是说你开发的一个东西一旦上线了，就要尽量去避免更改了，或者说你就别改了。但是有时候必须要修改，因为需求不断的变更，因此就需要在开发的时候留出一定的可扩展的可能性，这种可能性是在不修改源代码不修改调用方式来加功能。\n\n在了解装饰器之前首先要了解闭包。\n\n## 闭包\n\n> 内部函数的代码包含对外部作用域名字的引用，而不是对全局名字作用域的引用。其实，闭包指的是延伸了作用域的函数，其中包含函数定义体中引用、但是不在定义体中定义的非全局变量。函数是不是匿名的没有关系，关键是它能访问定义体之外定义的非全局变量。 \n\n```python\na = \"i am global\"\ndef f1():\n    a = \"i am local\"\n    def f2():\n        print(a)\n    return f2\nf = f1()\nprint(f)\nf()\n\n结果:\n<function f1.<locals>.f2 at 0x0000000484833A60>\ni am local\n```\n\n作用域在定义的时候其实就已经规定好了，可以看到上面的代码，虽然f接受了f2的内存地址并在全局调用了f2，但是由于f2的作用域并不是全局的因此f2会去优先找f1()局部的这个a变量，而不会看全局的a。\n\nf2属于内部函数，它引用的a在外部作用域也包含一个a，但是引用的并不是全局的那个，比如下面的情况就不是闭包：\n\n```\nx = 1\ndef f1():\n    def f2():\n        print(x)\n        \nf1()\n```\n\nf2()在内部引用的x实际上是调用的全局的x，闭包一定是对外部作用域的引用而不是全局的。\n\n```\ndef f1():\n    x = 1\n    def f2():\n        print(x)\n    return f2\nf = f1()\nprint(f.__closure__)\n\n结果：\n(<cell at 0x0000003D9B976498: int object at 0x000000007587B440>,)\n```\n\n`__closure__`可以显示它对外部命名空间的调用，这里是以一个列表的形式，这里显示的是这个值所在的内存地址，我们是可以把这个值取出来的：\n\n```\ndef f1():\n    x = 1\n    def f2():\n        print(x)\n    return f2\nf = f1()\nprint(f.__closure__[0].cell_contents)\n\n结果：\n1\n```\n\n也就是说闭包函数在返回的同时可以返回它的作用域，即这个闭包函数对外部作用域的调用。如果调用的作用域不是外部的而是全局的不会报错，但是`__closure__`返回的就是None了。\n\n```\nx = \"i am global\"\ndef f1():\n    # x = 1\n    def f2():\n        print(x)\n    return f2\nf = f1()\nprint(f.__closure__)\n\n结果：\nNone\n```\n\n#### 小结\n\n- 必须是内部定义的函数\n- 函数包含对外部作用域而不是全局作用域名字的引用\n\n闭包最重要的作用就是返回状态，状态即外部作用域。\n\n###### Example: 1\n\n```\nfrom urllib.request import urlopen\n\ndef f1(url):\n    def f2():\n        print(urlopen(url).read())\n    return f2\n\nbaidu = f1(\"http://www.baidu.com\")\nbaidu()\n```\n\n这里我引入了urllib模块，目的是获取网页的内容，但是获取什么网页的内容需要url传值，这里我们就可以利用闭包的方式，用baidu这个变量保存闭包函数的值，baidu内部不仅包含爬到的百度网页的内容，并且包含外部作用域f1中传过来的www.baidu.com，所以当我们要爬百度的内容的时候直接调用就可以了。\n\n###### Example: 2\n\n```\ndef make_averager():\n\tseries = []\n    def averager(new_value):\n        series.append(new_value)\n        total = sum(series)\n        return total/len(series)\n    return averag\n\n>>> avg = make_averager()\n>>> avg(10)\n10.0\n>>> avg(11)\n10.5\n>>> avg(12)\n11.0\n```\n\n上面的函数其实是一个持续计算不断增加的系列值的均值的一个高阶函数。调用 make_averager 时，返回一个 averager 函数对象。每次调用 averager 时，它会把参数添加到系列值中，然后计算当前平均值 。series被封装进了avg的`__closure__`里面去了，通过`print(avg.__closure__[0].cell_contents)`可以查看到。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-9/82258794.jpg)\n\n综上，闭包是一种函数，它会保留定义函数时存在的自由变量的绑定，这样调用函数时，虽然定义作用域不可用了，但是仍能使用那些绑定。注意，只有嵌套在其他函数中的函数才可能需要处理不在全局作用域中的外部变量 \n\n说完了闭包就来看一下装饰器。\n\n### 无参装饰器\n\n看例子：\n\n```\nimport time\n\ndef say_hello():\n    time.sleep(2)\n    print(\"hello everyone\")\n\nsay_hello()\n```\n\n这就是一个函数打印hello everyone。现在我要统计这个程序执行的时间.\n\n```\nimport time\n\ndef sum_time(func):\n    def wrapper(*args,**kwargs):\n        start = time.time()\n        func(*args,**kwargs)\n        stop = time.time()\n        print(\"run time is %s\" % (stop-start))\n    return wrapper\n\n@sum_time\ndef say_hello():\n    time.sleep(2)\n    print(\"hello everyone\")\n    \n结果：\nhello everyone\nrun time is 2.000821352005005\n```\n\n上面的用法就是装饰器的用法，加一个新功能，使用`@装饰器的名字`就可以了。那么上面的@sum_time都干了什么，我们只要添加了@sum_time,它就会把它正下方的函数名作为参数添加进去，也就是`sum_time(say_hello)`这个情况。然后把返回值赋值给say_hello，即`say_hello = sum_time(say_hello)`这个就是装饰器的用法。我们既没有修改原函数，也没有修改调用方法。\n\n所以说，总结一下：\n\n```\n@装饰器的名字 ====>  函数名 = 装饰器名字（函数名）\n```\n\n因此这个装饰器是需要有一个返回值的，因为要重新赋值给原函数。调用原函数其实就是装饰器装饰后的返回值，其实返回值就是一个内存地址。\n\n装饰器的本质是一个可调用的对象，这里其实就是函数，@函数名。再来看这个装饰器函数。\n\n```python\ndef sum_time(func):\n    def wrapper(*args,**kwargs):\n        start = time.time()\n        func(*args,**kwargs)\n        stop = time.time()\n        print(\"run time is %s\" % (stop-start))\n    return wrapper\n```\n\n这其实就是一个闭包函数，我们说在@sum_time的时候，装饰器会把正下方的函数当成参数传递给sum_time后调用，最后sum_time会返回内置函数wrapper，其实就是返回内置函数wrapper的内存地址，那么我们调用say_hello其实就是调用wrapper。装饰其中的`func(*args,**kwargs)`的内存地址是原say_hello函数的地址，调用say_hello的时候他的内存地址就已经不是原say_hello的内存地址了。\n\n### 有参装饰器\n\n```\ndef auth2(auth_type):\n    def auth(func):\n        def wrapper(*args,**kwargs):\n            if auth_type == \"file\":\n                name = input(\"Username:\")\n                passwd = input(\"Password:\")\n                if name == \"egon\" and passwd == \"123\":\n                    print(\"auth successfully\")\n                    res = func(*args,**kwargs)\n                    return res\n                else:\n                    print(\"auth error\")\n            elif auth_type == \"sql\":\n                print(\"还他妈不会呢！\")\n        return wrapper\n    return auth\n\n@auth2(auth_type = \"file\")     # index = auth(index)\ndef index():\n    print(\"welcome to index page\")\n\nindex()\n\n@auth2(auth_type = \"sql\")     # index = auth(index)\ndef index2():\n    print(\"welcome to index page\")\n\nindex2()\n\n结果：\nUsername:egon\nPassword:13082171785\nauth successfully\nwelcome to index page\n还他妈不会呢！\n```\n\n#### 装饰器的补充\n\n装饰器需要写到被装饰函数的正上方，并且需要独占一行，因此可以写多个装饰器：\n\n```\n@bbb  #func = bbb(aaa(func))\n@aaa  #func = aaa(func)\ndef func():\n    pass\n```\n\n含参数的多个装饰器\n\n```python\n@ccc(\'c\')  #func = ccc(\'c\')(bbb(\'b\')(aaa(\'a\')(func)))\n@bbb(\'b\')  #func = bbb(\'b\')(aaa(\'a\')(func))\n@aaa(\'a\')  #func = aaa(\'a\')(func)\ndef func():\n    pass\n    \nres = aaa(\'a\')\n@res\nfunc = aaa(\'a\')(func)\n```\n\n打印原函数的注释：\n\n```python\nimport time\nfrom functools import wraps\n\ndef sum_time(func):\n    @wraps(func)\n    def wrapper(*args,**kwargs):\n        start = time.time()\n        res = func(*args,**kwargs)\n        stop = time.time()\n        print(\"run time is %s\" % (stop-start))\n    return wrapper\n\n@sum_time\ndef say_hello():\n    \'\'\'say_hello test\'\'\'\n    time.sleep(2)\n    print(\"hello everyone\")\n\nsay_hello()\nprint(say_hello.__doc__)\n\n结果：\nhello everyone\nrun time is 2.0000414848327637\nsay_hello test\n```\n\n","timestamp":1523777648264},{"name":"06-列表&元组.md","path":"05-Python/01-Python基础/02-2、Python函数部分/06-列表&元组.md","content":"# 列表&元组\n\n> 序列是Python中最基本的数据结构。序列中的每个元素都分配一个数字 - 它的位置，或索引，第一个索引是0，第二个索引是1，依此类推。\n>\n> Python有6个序列的内置类型，但最常见的是列表和元组。序列都可以进行的操作包括索引，切片，加，乘，检查成员。此外，Python已经内置确定序列的长度以及确定最大和最小的元素的方法。列表是最常用的Python数据类型，它可以作为一个方括号内的逗号分隔值出现。列表的数据项不需要具有相同的类型\n\n## 列表\n\n### 列表基本使用\n\n定义一个列表：\n\n```\n>>> a = []\n>>> b = [1,2,3,4]\n>>> c = [1,\'lamber\',[3,4],{5,6}]\n```\n\n列表会去维护一个元素的顺序，因此我们是可以通过索引取到列表内部的元素，索引从0开始，因此第一个元素的索引就是0，第二个元素的索引就是1.\n\n```\n>>> c[0]\n1\n>>> c[1]\n\'lamber\'\n\n我们通过这样的方式调用其实本质上是使用\'__getitem__\'的方法，比如\n>>> a.__getitem__(2)\n\'lamber\'\n```\n\n同时我们可以也可以倒着取元素，最后一个元素就是-1，倒数第二个元素的索引就是-2，以此类推。\n\n```\n>>> c[-1]\nset([5, 6])\n```\n\n不仅如此，还可以根据自己的需要取出列表中的一段来，比如：\n\n```\n>>> a = [\'qimaosen\',\'zhangpeng\',\'lamber\',\'shiyue\']\n>>> a[1:3]\n[\'zhangpeng\', \'lamber\']\n取得内容是索引为1到3的，也就是第二个到第四个元素，但是这个取值有一个特点就是顾头不顾尾，因此\"shiyue\"是取不到的。\n\n>>> a[1:] \n[\'zhangpeng\', \'lamber\', \'shiyue\']\n表示从索引值为1的位置取到最后\n\n>>> a[:2]\n[\'qimaosen\', \'zhangpeng\']\n表示从头取到索引值为2的位置也就是第三个元素，但是根据顾头不顾尾的原则，取到的应该是索引为0和1的。\n\n>>> a[-3:-1]\n[\'shiyue\', \'user1\']\n即使是倒着取值也应该遵循从左向右的顺序，因此这里应该是-3:-1而不是-1:-3。\n\n>>> a = [1,2,3,4,5,6,7,8,9,0]\n>>> a[::2]\n[1, 3, 5, 7, 9]\n设置查找的步长，比如步长为2的话就是查找1,3,5,7,9\n```\n\n### 列表常用的一些方法\n\n- 通过值查找它在列表中的索引值，如果存在返回索引值，不存在会报错\n\n```\n>>> a.index(\'lamber\')\n2\n>>> a.index(\'hahaha\')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: \'hahaha\' is not in list\n```\n\n- 统计列表中元素的个数：\n\n```\n>>> len(a)\n4\n>>> a.__len__()\n4\n\n这两种用法其实本质上是一样的。\n```\n\n- 统计一个元素在列表中出现的次数\n\n```\n>>> a.count(\'lamber\')\n1\n```\n\n- 列表元素的追加\n\n```\n>>> a.append(\'user1\')\n>>> a.append(\'user2\')\n>>> a.append(\'user3\')\n>>> a\n[\'qimaosen\', \'zhangpeng\', \'lamber\', \'shiyue\', \'user1\', \'user2\', \'user3\']\n\n默认是添加到最后，从尾部继续追加。\n```\n\n- 元素的插入\n\n```\n元素的插入是insert方法，不同于append的追加，insert方法我可以指定插入的位置，因此insert方法需要传入两个参数，第一个是要插入的索引位置，第二个是要插入的值。\n\n>>> a\n[\'qimaosen\', \'zhangpeng\', \'lamber\', \'shiyue\', \'user1\', \'user2\', \'user3\']\n>>> a.insert(2,\'the index number is two\')\n>>> a\n[\'qimaosen\', \'zhangpeng\', \'the index number is two\', \'lamber\', \'shiyue\', \'user1\', \'user2\', \'user3\']\n可以看到我们指定插在索引值为2的地方也就是第三个值，结果新插入的值的索引就是2，把原索引值为2的lamber挤到后面去了，其他后面的所有值向后错一个。\n```\n\n- 元素的删除\n\n  - pop\n\n  ```\n  元素的弹出，默认弹出最后一个，返回弹出的值\n  >>> a\n  [\'qimaosen\', \'zhangpeng\', \'the index number is two\', \'lamber\', \'shiyue\', \'user1\', \'user2\', \'user3\']\n  >>> a.pop()\n  \'user3\'\n  >>> a\n  [\'qimaosen\', \'zhangpeng\', \'the index number is two\', \'lamber\', \'shiyue\', \'user1\', \'user2\']\n\n  可以给pop传参数，弹出特定索引位置的值，比如：\n  >>> a\n  [\'qimaosen\', \'zhangpeng\', \'the index number is two\', \'lamber\', \'shiyue\', \'user1\', \'user2\']\n  >>> a.pop(2)\n  \'the index number is two\'\n  >>> a\n  [\'qimaosen\', \'zhangpeng\', \'lamber\', \'shiyue\', \'user1\', \'user2\']\n  ```\n\n  - remove\n\n  ```\n  >>> a\n  [\'qimaosen\', \'zhangpeng\', \'lamber\', \'shiyue\', \'user1\', \'user2\']\n  >>> a.remove(\'lamber\')\n  >>> a\n  [\'qimaosen\', \'zhangpeng\', \'shiyue\', \'user1\', \'user2\']\n\n  这个方法没有返回值\n  ```\n\n  - del\n\n  ```\n  >>> a\n  [\'qimaosen\', \'zhangpeng\', \'shiyue\', \'user1\', \'user2\']\n  >>> del a[0]\n  >>> a\n  [\'zhangpeng\', \'shiyue\', \'user1\', \'user2\']\n\n  del a \n  不接索引的话就是直接删掉整个列表\n  ```\n\n- 列表的修改\n\n```\n最直接的就是找到索引值以后改\n>>> a = [\'zhangpeng\', \'shiyue\', \'user1\', \'user2\']\n>>> a[0] = \'test_user\'\n>>> a\n[\'test_user\', \'shiyue\', \'user1\', \'user2\']\n```\n\n- 清空列表\n\n```\na.clear()  # py3中有，py2中会报错没有这个属性\n\n当然使用test = []也可以清空列表，不过这两种方法是不同的，clear方法是吧原列表的内容给抹掉，但是直接test = []这种方法是重新开辟一块空间挪了一下test列表的指针，日后我们使用的时候，列表的元素肯定不是几个，而是大量的，所以直接赋值为一个空列表要比clear效率高的多，直接赋值一个空列表相当于挪了一下指针，那么没有指针的数据会被定时内存回收的机制回收掉。\n```\n\n- 列表的合并\n\n```\n>>> a = [1,2] \n>>> b = [3,4]\n>>> a.extend(b)\n>>> a\n[1, 2, 3, 4]\n>>> b\n[3, 4]\n\n或者可以使用“+”，实现列表的合并\n>>> a\n[1, 2, 3, 4]\n>>> b\n[3, 4]\n>>> a+b\n[1, 2, 3, 4, 3, 4]\n```\n\n- 列表逆序\n\n```\n>>> a = [1,2,3,4,5]\n>>> a.reverse\n<built-in method reverse of list object at 0x7faca4488950>\n>>> a.reverse()\n>>> a\n[5, 4, 3, 2, 1]\n```\n\n- 列表的排序\n\n```\n>>> a = [1,\'a\',\'Z\',\'%\',\'(\']\n>>> a.sort()\n>>> a\n[1, \'%\', \'(\', \'Z\', \'a\']    # 在python2中可以排序，但是在既有数字又有字符串的情况下是不可以排序的\n```\n\n排序规则是按照ascii表的顺序排的，可以参考如下的ascii表：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-6-9/28261088.jpg)\n\n1. 如果列表中的内容是字符串的话会根据字符串的字母排序，排序依据是ASCII\n2. 如果列表中既有字符串又有数字那么在py3中是无法排序的，但是在py2中可以排。字符串和数字其实没有必然联系，在py3中会报错，显然是更严谨了。\n\n- ennumerate：这是python内部一个内置的函数。这个单词是枚举，列举的意思，对于一个可迭代可遍历的对象enumerate将其组成一个索引序列，利用它可以同时获得索引和值。比如：\n\n```\na = [\"a\",\"b\",\"c\",\"d\"]\nfor index,item in enumerate(a):\n    print(index,item)\n    \n结果：\n0 a\n1 b\n2 c\n3 d\n\nenumerate会根据列表中的元素一个一个写索引，默认从0开始当然也可以指定起始值：\n\na = [\"a\",\"b\",\"c\",\"d\"]\nfor index,item in enumerate(a,2):\n    print(index,item)\n结果：   \n2 a\n3 b\n4 c\n5 d\n```\n\n比如要统计文件行数的时候我们一般的操作是：\n\n```\ncount = len(file.open(\'a.txt\').readlines())\n```\n\n如果文件很大的话那么会很慢，这样我们可以使用enumerate：\n\n```\ncount = -1 \nfor index, line in enumerate(open(filepath,\'r\'))： \n    count += 1\n```\n\n- 列表的join方法：join方法可以将列表按照指定的分隔符连接成字符串：\n\n```\na = [\"a\",\"b\",\"c\",\"d\"]\nprint(\'%\'.join(a))\n\n结果：\na%b%c%d\n```\n\n\n将列表转换为字符串可以使用join方法，不过join方法只能用于元素是字符串的 list；它不进行任何的强制类型转换。对于其他类型需要强制转换为字符串。如果是非字符串会报如下错：\n\n```python\nTypeError: sequence item 0: expected str instance, int found\n```\n\n列表的相乘：\n\n```\n>>> a = [1,2]\n>>> a * 5\n[1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n```\n\n\n\n### 列表推导式\n\n生成一个有10个值的列表：\n\n```\negg_list = []\nfor i in range(10):\n    egg_list.append(\"egg%s\" %i)\nprint(egg_list)\n\n结果：\n[\'egg0\', \'egg1\', \'egg2\', \'egg3\', \'egg4\', \'egg5\', \'egg6\', \'egg7\', \'egg8\', \'egg9\']\n```\n\n使用列表生成式：\n\n```\nl = [ \'狗蛋%s\' %i for i in range(10)]\nprint(l)\n\n结果：\n[\'狗蛋0\', \'狗蛋1\', \'狗蛋2\', \'狗蛋3\', \'狗蛋4\', \'狗蛋5\', \'狗蛋6\', \'狗蛋7\', \'狗蛋8\', \'狗蛋9\']\n```\n\n类似于上面这个格式的就是列表生成式，具体的格式如下：\n\n```\n[expression for item1 in interable1 if condition1\n            for item2 in interable2 if condition2\n            ……\n            for itemN in interableN if conditionN\n]\n```\n\n上面的这种层级关系就类似于：\n\n```\nres = []\nfor item1 in interable1:\n    if condition1:\n        for item2 in iterable2:\n            if condition2\n                ……\n                for itemN in interableN:\n                    if conditionN:\n                        res.append(expression)\n```\n\n举个例子比如：\n\n```\nl = [ \'狗蛋%s\' %i for i in range(10) if i < 5]\nprint(l)\n\n结果：\n[\'狗蛋0\', \'狗蛋1\', \'狗蛋2\', \'狗蛋3\', \'狗蛋4\']\n```\n\n再比如：\n\n```\nl = [1,2,3,4]\ns = \"hello\"\n\nl1 = [(num,s1) for num in l for s1 in s] #(num,s1）,num对应第一个for，s1对应第二个for\nprint(l1)\n\n结果：\n[(1, \'h\'), (1, \'e\'), (1, \'l\'), (1, \'l\'), (1, \'o\'), (2, \'h\'), (2, \'e\'), (2, \'l\'), (2, \'l\'), (2, \'o\'), (3, \'h\'), (3, \'e\'), (3, \'l\'), (3, \'l\'), (3, \'o\'), (4, \'h\'), (4, \'e\'), (4, \'l\'), (4, \'l\'), (4, \'o\')]\n\n就类似于：\nl1 = []\nfor num in l:\n    for s1 in s:\n        t = (num,s1)\n        l1.append(t)\n```\n\n那么找文件关键字中的search就可以简写成：\n\n```\nimport os\ng = os.walk(\"c:\\\\lamber\")\nfile_list = [ \"%s\\\\%s\" %(i[0],j) for i in g for j in i[-1]]\nprint(file_list)\n\n结果:\n[\'c:\\\\lamber\\\\hahah.txt\', \'c:\\\\lamber\\\\a\\\\a1\\\\test1\', \'c:\\\\lamber\\\\a\\\\a1\\\\test2\', \'c:\\\\lamber\\\\b\\\\b2\\\\test2.txt\']\n```\n\n这个东西其实简化了繁杂的东西，节省了代码量。做一个生成一副扑克的例子：\n\n```\n# coding=UTF-8\n\nimport collections\nimport random\n\nCard = collections.namedtuple(\'Card\', [\'rank\', \'suit\'])\nclass FrenchDeck:\n    ranks = [str(n) for n in range(2, 11)] + list(\'JQKA\')\n    suits = \'黑桃 方片 红桃 梅花\'.split()\n    def __init__(self):\n        self._cards = [Card(rank, suit) for suit in self.suits\n        for rank in self.ranks]\n    def __len__(self):\n        return len(self._cards)\n    def __getitem__(self, position):\n        return self._cards[position]\n\ndeck = FrenchDeck()\nprint(deck.__dict__)\nprint(len(deck))  # 查看这幅扑克有多少张\nprint(random.choice(deck)  # 利用random模块的choice方法随便抽一张。\n\n\n结果：\n{\'_cards\': [Card(rank=\'2\', suit=\'黑桃\'), Card(rank=\'3\', suit=\'黑桃\'), Card(rank=\'4\', suit=\'黑桃\'), Card(rank=\'5\', suit=\'黑桃\'), Card(rank=\'6\', suit=\'黑桃\'), Card(rank=\'7\', suit=\'黑桃\'), Card(rank=\'8\', suit=\'黑桃\'), Card(rank=\'9\', suit=\'黑桃\'), Card(rank=\'10\', suit=\'黑桃\'), Card(rank=\'J\', suit=\'黑桃\'), Card(rank=\'Q\', suit=\'黑桃\'), Card(rank=\'K\', suit=\'黑桃\'), Card(rank=\'A\', suit=\'黑桃\'), Card(rank=\'2\', suit=\'方片\'), Card(rank=\'3\', suit=\'方片\'), Card(rank=\'4\', suit=\'方片\'), Card(rank=\'5\', suit=\'方片\'), Card(rank=\'6\', suit=\'方片\'), Card(rank=\'7\', suit=\'方片\'), Card(rank=\'8\', suit=\'方片\'), Card(rank=\'9\', suit=\'方片\'), Card(rank=\'10\', suit=\'方片\'), Card(rank=\'J\', suit=\'方片\'), Card(rank=\'Q\', suit=\'方片\'), Card(rank=\'K\', suit=\'方片\'), Card(rank=\'A\', suit=\'方片\'), Card(rank=\'2\', suit=\'红桃\'), Card(rank=\'3\', suit=\'红桃\'), Card(rank=\'4\', suit=\'红桃\'), Card(rank=\'5\', suit=\'红桃\'), Card(rank=\'6\', suit=\'红桃\'), Card(rank=\'7\', suit=\'红桃\'), Card(rank=\'8\', suit=\'红桃\'), Card(rank=\'9\', suit=\'红桃\'), Card(rank=\'10\', suit=\'红桃\'), Card(rank=\'J\', suit=\'红桃\'), Card(rank=\'Q\', suit=\'红桃\'), Card(rank=\'K\', suit=\'红桃\'), Card(rank=\'A\', suit=\'红桃\'), Card(rank=\'2\', suit=\'梅花\'), Card(rank=\'3\', suit=\'梅花\'), Card(rank=\'4\', suit=\'梅花\'), Card(rank=\'5\', suit=\'梅花\'), Card(rank=\'6\', suit=\'梅花\'), Card(rank=\'7\', suit=\'梅花\'), Card(rank=\'8\', suit=\'梅花\'), Card(rank=\'9\', suit=\'梅花\'), Card(rank=\'10\', suit=\'梅花\'), Card(rank=\'J\', suit=\'梅花\'), Card(rank=\'Q\', suit=\'梅花\'), Card(rank=\'K\', suit=\'梅花\'), Card(rank=\'A\', suit=\'梅花\')]}\n52\nCard(rank=\'4\', suit=\'方片\')\n```\n\n## 元组\n\n列表是可变的，那么元组就可以理解为不可变的列表。但是仅这么概括的话还是有局限性的。因为元组“不仅仅”是不可变的列表，元组还可以被用于没有字段名的记录，正因为元组的有顺序的，因此这个顺序赋予了元组一定的意义，比如：\n\n```\n>>> city, year, pop, chg, area = (\'Tokyo\', 2003, 32450, 0.66, 8014)\n>>> city\n\'Tokyo\'\n>>> year\n2003\n>>> pop\n32450\n>>> chg\n0.66\n>>> area\n8014\n```\n\n我通过一行代码就给五个变量赋了值，这个也叫作元组的拆包。元组拆包可以应用到任何可迭代对象上，唯一的硬性要求是，被可迭代对象中的元素数量必须要跟接受这些元素的元组的空档数一致。除非我们用 * 来表示忽略多余的元素 。\n\n上面的这一段代码也叫作平行赋值，也就是说把一个可迭代对象里的元素，一并赋值到由对应的变量组成的元素中。除了上面的一段代码另外一个很优雅的写法当属不使用中间变量交换两个变量的值\n\n```\n>>> a = \'a\'\n>>> b = \'b\'\n>>> a,b = b,a\n>>> a\n\'b\'\n>>> b\n\'a\'\n```\n\n还可以使用*把一个可迭代对象拆开作为函数的参数传进去：\n\n```\n>>> divmod(20, 8)\n(2, 4)\n>>> t = (20, 8)\n>>> divmod(*t)\n(2, 4)\n>>> quotient, remainder = divmod(*t)\n>>> quotient, remainder\n(2, 4)\n```\n\n占位符的使用：（并不是列表中的所有元素都有用，有时候不需要取到的我们可以使用占位符“_”来取代）\n\n```\n>>> _,filename = os.path.split(\'/usr/local/nginx/conf/nginx.conf\')\n>>> filename\n\'nginx.conf\'\n```\n\n\n\n\n\n","timestamp":1523777648264},{"name":"07-迭代器与生成器.md","path":"05-Python/01-Python基础/02-2、Python函数部分/07-迭代器与生成器.md","content":"# 迭代器\n\n> 什么是迭代？\n>\n> 简单来解释就是更新换代，重复的去执行一个过程，为了更加达到一个接近目标的结果，每一次迭代得到的结果会作为下一次迭代的初始值。python中和迭代有关的其实就是循环，for循环&while循环。针对于有序的，比如列表这种我们是可以通过for循环或者while循环取到的，但是针对于文件，字典这种没有排序的我们就需要用到迭代器了。\n\n## 什么是可迭代的\n\n简单来说就是可以循环的，凡是可迭代的对象都有一个iter的方法：\n\n```python\n比如我定义个字典：\ndic = {\"a\":1,\"b\":2,\"c\":3}\nprint(dic.__iter__())\n\n这个dic.__iter__()其实就是相当于iter(d)。为什么这么说，看一下len的用法：\n\na = \"lamber\"\n\nprint(a.__len__())\nprint(len(a))\n\n这是一样的。因此只要内置了__iter__方法，那么这个对象就叫做可迭代的对象。\n\n那么执行一下：\ndic = {\"a\":1,\"b\":2,\"c\":3}\ndic.__iter__\n\ni = dic.__iter__()\nprint(i.__next__())\nprint(i.__next__())\nprint(i.__next__())\n\n结果：\na\nb\nc\n\n那么这个i就是迭代器，使用__next__方法一个一个的获取，就可以发现把字典里的key打印出来并且是随机的，因为字典是无序的，不依赖下标的。\n```\n\n那么我们用while循环来取一下，就不用打印那么多next了。\n\n```\ndic = {\"a\":1,\"b\":2,\"c\":3}\ndic.__iter__\n\ni = dic.__iter__()\n\nwhile True:\n    print(next(i))\n    \n结果：\na\nTraceback (most recent call last):\nb\n  File \"D:/坚果云同步/Python/Day6/test1.py\", line 12, in <module>\nc\n    print(next(i))\nStopIteration\n```\n\n发现值的确是遍历出来了，但是抛出了一个stopinteration的错误，造成了整个程序的终端，因此我们可以增加一个try，except的判断，如果是这个错误的话直接给break掉。\n\n```\ndic = {\"a\":1,\"b\":2,\"c\":3}\ndic.__iter__\n\ni = dic.__iter__()\n\nwhile True:\n    try:\n        print(next(i))\n    except StopIteration:\n        break\n\n结果：\na\nb\nc\n```\n\n它是不会进行报错的。\n\n之前还用过一个for循环遍历的方法：\n\n```\ndic = {\"a\":1,\"b\":2,\"c\":3}\n\nfor key in dic:\n    print(key)\n```\n\n用这种方式也是可以遍历的，而且不会报错，for循环经典的地方就在于，这个`for key in dic`的这个dic相当于dic.\\_\\_iter\\_\\_的值，然后把这个dic相当于迭代器的值。然后用for循环是遍历的这个迭代器，而且省了try和except。\n\n另外文件本身就是可以迭代的，文件句柄本身就可以支持iter和next方法。\n\n那么为什么要使用迭代器：\n\n优点\n\n- 提供了一种不依赖索引的取值方式，这样就可以遍历那些没有索引的可迭代对象了（字典，集合）\n- 迭代器与列表比较，做成迭代器以后就是内存地址，next一个取一个，同时内存中只有一个内存地址（惰性计算），更节省内存。但是列表的方式的话，列表中的所有索引和值占用内存。\n\n缺点：\n\n- 无法获取迭代器得长度，使用不如列表索引更加灵活。\n- 迭代器是一次性的，只能往后取值，不能倒着取，但是列表你想去哪个下标的就取哪个下标。\n\n```\nl = [1,2,3]\na = l.__iter__()\nprint(next(a))\nprint(next(a))\nprint(next(a))\n\nfor i in a:\n    print(i)\n\n\n结果:\n1\n2\n3\n```\n\n可以发现只有一个123，说明for循环没有输出，可以证明迭代器是一次性的，三次next迭代完成以后下一次就没东西了。for循环也遍历不出值来了。\n\n查看可迭代对象与迭代器对象（需要导入模块）：\n\n```\nfrom collections import Iterable,Iterator\n\na = \"a\"\nc = [1,2,3]\nd = (1,2,3)\ne = {\"a\":1,\"b\":2,\"c\":3}\nf = {1,2,3}\ng = open(\"test1.py\")\n\n##这些类型都是可迭代的对象\na.__iter__()\nc.__iter__()\nd.__iter__()\ne.__iter__()\nf.__iter__()\ng.__iter__()\nprint(isinstance(a,Iterable))\nprint(isinstance(c,Iterable))\nprint(isinstance(d,Iterable))\nprint(isinstance(e,Iterable))\nprint(isinstance(f,Iterable))\nprint(isinstance(g,Iterable))\n\nprint(isinstance(a,Iterator))\nprint(isinstance(c,Iterator))\nprint(isinstance(d,Iterator))\nprint(isinstance(e,Iterator))\nprint(isinstance(f,Iterator))\nprint(isinstance(g,Iterator))\n\n结果：\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n```\n\n# 生成器\n\n生成器和return有什么区别？\n\n生成器就是一个函数，这个函数内包含有yield这个关键字，那么就是一个生成器。含有yield的函数执行到yield就会停止。return只能返回一次函数就彻底结束了，而yield能返回多次值。\n\n```\nfrom collections import Iterator\n\ndef foo():\n    print(\"creator\")\n    yield 1\n\nfoo()\n```\n\n这个调用时没有任何回显的，print的内容也不会被打印出来。那我们来接收一下返回值。看看这到底是一个什么类型：\n\n```python\nfrom collections import Iterator\n\ndef foo():\n    print(\"creator\")\n    yield 1\n\nret = foo()\nprint(isinstance(ret,Iterator))\n\n回显：\nTrue\n```\n\n可以发现这其实就是一个迭代器那么他就可以使用next方法：\n\n```\nfrom collections import Iterator\n\ndef foo():\n    # print(\"creator\")\n    yield 1\n    yield 2\n    yield 3\n    yield 4\n\ng = foo()\nprint(next(g))\nprint(next(g))\nprint(next(g))\nprint(next(g))\n\n结果：\n1\n2\n3\n4\n```\n\n所以之前讲的是一个数据类型的迭代器，现在则是把一个函数变成迭代器。有执行效果而且可以拉去值。把函数做成迭代器这个就叫做生成器。\n\nyield都做了什么：\n\n- yield把函数变成一个生成器，生成器就是一个迭代器，这样就允许我们自定义迭代器了。那么我们可以把这个生成器放到for循环里去了。\n\n```\ndef foo(x):\n    print(\"start count\")\n    while x > 0:\n        yield x\n        x-=1\n    print(\"Done\")\n\ndd = foo(5)\n\nfor v in dd:\n    print(v)\n    \n结果：\nstart count\n5\n4\n3\n2\n1\nDone\n```\n\n## 生成器的应用\n\n使用生成器监控一个文件的更新，类似于linux中的tail：\n\n```\n[lamber@maxiaoyu day2]$ cat tail.py \n#!/usr/bin/python3.6\nimport time\n\ndef tail(file_name):\n    with open(\"test1\",\'r\') as file:\n        file.seek(0,2)\n        while True:\n            line = file.readline()\n            if not line:\n                time.sleep(0.4)   \n                continue\n            else:\n                yield line\na = tail(\'test1\')\n\nfor line in a:\n    print(line,end=\'\')\n```\n\n模拟tail -f test1 | grep error的效果：\n\n```\n[lamber@maxiaoyu day2]$ cat tail.py \n#!/usr/bin/python3.6\nimport time\n\ndef tail(file_name):\n    with open(\"test1\",\'r\') as file:\n        file.seek(0,2)\n        while True:\n            line = file.readline()\n            if not line:\n                time.sleep(0.4)   \n                continue\n            else:\n                yield line\n\n\ndef grep(pattern,lines):\n    for line in lines:\n        if pattern in line:\n            print(\"\\033[45m%s\\033[0m\" % line,end=\'\')\n            \n#调用阶段\na = tail(\'test1\')\nb = grep(\'error\',a)\n\nfor i in b:\n\tprint(i)\n```\n\n### yield的功能总结\n\n- yield把函数变成生成器（本质是迭代器），相当于把`__iter__`和`__next__`封装到了函数内部。\n- yield会保存运行状态，每次next都会停在某一个位置，状态由yield保存\n- 用return返回值能返回一次，而yield可以返回多次\n\n","timestamp":1523777648264},{"name":"08-列表解析与生成器表达式.md","path":"05-Python/01-Python基础/02-2、Python函数部分/08-列表解析与生成器表达式.md","content":"# 生成式表达式\n\n## 生成器表达式\n\n语法（和列表推导式其实是一样的，只不过\"[]\"换成了“()”）：\n\n```\n(expression for item1 in interable1 if condition1\n            for item2 in interable2 if condition2\n            ……\n            for itemN in interableN if conditionN\n)\n```\n\n假说上面的鸡蛋问题，列表生成式是在列表里装了一堆鸡蛋，那么生成器表达式就是给了你一只鸡。\n\n```\nl = (\'狗蛋%s\' %i for i in range(10))\nprint(next(l))\nprint(next(l))\nprint(next(l))\nprint(next(l))\n\n结果：\n狗蛋0\n狗蛋1\n狗蛋2\n狗蛋3\n```\n\n每next一次下一个蛋，生成器就可以用在生成的值很多的情况下。比如有一个很大的文本文件，几个G的大小，我现在要去除掉文件中每一行两边的空格，我就可以使用这个办法：\n\n```\nf = open(\"test1.py\")\nl1 = (line.strip() for line in f)\nl = list(l1)\nprint(l)\n```\n\nlist()方法直接定义就是一个空列表，当然也可以使用list(g)，这里面的g是一个可迭代对象。\n\n## 声明式编程\n\n先来说一个内置函数sum，这个函数是用来求和的。他里面可以跟一个可迭代对象：\n\n```\nl = [1,2,3,4]\nprint(sum(l))\n```\n\n那么同样的我也可以使用sum去统计一个生成器的和，因为生成器本身也是一个可迭代对象。\n\n```\ng = (i for i in range(1,5))\nprint(sum(g))\n```\n\n结果和上面是一样的，那么现在有这么一个需求：\n\n> 有一个文件，里面的内容如下：\n>\n> ```\n> apple 10 3\n> tesla 1000000 1\n> mac 3000 2\n> lenovo 30000 3\n> chicken 10 3\n> ```\n>\n> 第一列是商品名称，第二列是价格，第三列是商品数量。使用声明式编程的方式算出总共花了多少钱。\n\n```\nmoney = []\nwith open(\"b\",\'r\') as f:\n    for line in f:\n        goods = line.strip().split()\n        res = float(goods[-1])*float(goods[-2])\n        money.append(res)\nprint(money)\nprint(sum(money))\n```\n\n使用声明的方式取代上面的代码：\n\n```\nf = open(\"b\",\'r\')\ng = (float(line.strip().split()[-1])*float(line.strip().split()[-2])  for line in f)\nprint(sum(g))\n```\n\n模拟数据库的查询功能。\n\n```\nres = []\nwith open(\'b\') as f:\n    for line in f:\n        l = line.split()\n        # 先定义一个格式\n        dic = {}\n        dic[\'name\'] = l[0]\n        dic[\'price\'] = l[1]\n        dic[\'count\'] = l[2]\n        res.append(dic)\nprint(res)\n\n结果：\n[{\'name\': \'apple\', \'price\': \'10\', \'count\': \'3\'}, {\'name\': \'tesla\', \'price\': \'1000000\', \'count\': \'1\'}, {\'name\': \'mac\', \'price\': \'3000\', \'count\': \'2\'}, {\'name\': \'lenovo\', \'price\': \'30000\', \'count\': \'3\'}, {\'name\': \'chicken\', \'price\': \'10\', \'count\': \'3\'}]\n```\n\n改进\n\n```\nwith open(\"b\") as f:\n    res = (line.split() for line in f)\n    money = ({\'name\':i[0],\'price\':i[1],\'count\':i[2]} for i in res)\n    for i in money:\n        print(i)\n\n结果：\n{\'name\': \'apple\', \'price\': \'10\', \'count\': \'3\'}\n{\'name\': \'tesla\', \'price\': \'1000000\', \'count\': \'1\'}\n{\'name\': \'mac\', \'price\': \'3000\', \'count\': \'2\'}\n{\'name\': \'lenovo\', \'price\': \'30000\', \'count\': \'3\'}\n{\'name\': \'chicken\', \'price\': \'10\', \'count\': \'3\'}\n```\n\n过滤\n\n```\ngoods=[{\'name\':n,\'price\':p,\"count\":c} for n,p,c in g if float(p) > 10000]\n```\n\n","timestamp":1523777648264},{"name":"09-协程函数.md","path":"05-Python/01-Python基础/02-2、Python函数部分/09-协程函数.md","content":"# 协程函数\n\n在函数内，yield语句可以用作出现在赋值运算符右边的表达式，以这种方式使用yield语句的函数称为协程函数，它的执行是为了响应发送给它的值。\n\n```\ndef eator(name):\n    print(\"%s eat food\" %name)\n    food_list = []\n    while True:\n        food = yield food_list\n        print(\"%s is going to eat %s\" %(name,food))\n        food_list.append(food)\n    print(\'Done\')\n\na = eator(\"马晓雨\")\nnext(a)\nprint(a.send(\"包子\"))\nprint(a.send(\"饺子\"))\nprint(a.send(\"拉面\"))\nprint(a.send(\"蛋糕\"))\n\n结果：\n马晓雨 eat food\n马晓雨 is going to eat 包子\n[\'包子\']\n马晓雨 is going to eat 饺子\n[\'包子\', \'饺子\']\n马晓雨 is going to eat 拉面\n[\'包子\', \'饺子\', \'拉面\']\n马晓雨 is going to eat 蛋糕\n[\'包子\', \'饺子\', \'拉面\', \'蛋糕\']\n```\n\n注意上面的程序有一个next，然后才是send。如果没有这个next的话是会报错的。\n\n```\nTypeError: can\'t send non-None value to a just-started generator\n```\n\n意思就是说一个刚开始的生成器是无法使用send方法的。\n\nsend和next有同样的效果，都可以让函数在上次暂停的地方继续走，比如卡在了yield的地方。但是不同的地方在于：\n\n- 如果函数内的yield是表达式形式，那么必须先使用next方法。\n- send在出发下一次代码的执行时，会顺便给yield传一个值。\n\n不过表达式形式的yield经常是会忘记在开始的时候使用next方法，因此我们可以使用一个next方法的装饰器，我们再定义函数的正上方加一个装饰器，那么调用的时候直接send就行了。\n\n```\ndef init(func):\n    def wrapper(*args,**kwargs):\n        res = func(*args,**kwargs)\n        next(res)\n        return res\n    return wrapper\n```\n\n因此使用next()来进行初始化的调用这是必不可少的，调用了next函数以后，程序会卡在yield的地方等待生成器对象的send方法给他发送一个值，传递给send函数的值由协程函数中的yield接收并返回给food，并且语句向下继续执行直到遇到下一个yield卡住。\n\n爬网页练习：\n\n```\nfrom urllib.request import urlopen\n\ndef getweb():\n    while True:\n        url = yield\n        res = urlopen(url).read()\n        print(res)\nhtml = getweb()\nnext(html)\nhtml.send(\"http://www.bilibili.com\")\n```\n\n## 协程函数的一种应用方式\n\n实现遍历文件夹下查找包含某个内容的文件：\n\n```\n文件结构：\nC:\\--lamber\n       |____a\n       |    |___a1\n       |    |    |__test1\n       |    |    |__test2\n       |    |___a2     \n       |____b\n       |    |___b1\n       |    |___b2\n       |         |___test2.txt\n       |____hahah.txt\n```\n\n首先取出所有文件的绝对路径\n\n```\nimport os\n\ng = os.walk(\'C:\\\\lamber\')\n\nfor item in g:\n    print(item)\n\n结果：\n(\'C:\\\\lamber\', [\'a\', \'b\'], [\'hahah.txt\'])\n(\'C:\\\\lamber\\\\a\', [\'a1\', \'a2\'], [])\n(\'C:\\\\lamber\\\\a\\\\a1\', [], [\'test1\', \'test2\'])\n(\'C:\\\\lamber\\\\a\\\\a2\', [], [])\n(\'C:\\\\lamber\\\\b\', [\'b1\', \'b2\'], [])\n(\'C:\\\\lamber\\\\b\\\\b1\', [], [])\n(\'C:\\\\lamber\\\\b\\\\b2\', [], [\'test2.txt\'])\n```\n\n返回的都是元组，元组的第一个元素是文件目录，第二个元素是文件目录下有哪些子文件夹，第三个元素是文件夹下有哪些文件。子文件夹和文件都是以列表的形式保存的，然后使用for循环可以把这个生成器所有的内容都遍历出来。依次会遍历到所有的目录和子目录。那么我们现在要把文件的全路径拼出来：\n\n```\nimport os\n\ng = os.walk(\'C:\\\\lamber\')\n\nfor item in g:\n    for file in item[-1]:\n        file_path = \'%s\\\\%s\' %(item[0],file)\n        print(file_path)\n\n结果：\nC:\\lamber\\hahah.txt\nC:\\lamber\\a\\a1\\test1\nC:\\lamber\\a\\a1\\test2\nC:\\lamber\\b\\b2\\test2.txt\n```\n\n然后查找所有文件中包含“lamber”关键字的文件名：\n\n```\nimport os\nimport time\n\n# 初始化协程函数的装饰器\ndef init(func):\n    def wrapper(*args,**kwargs):\n        res = func(*args,**kwargs)\n        next(res)\n        return res\n    return wrapper\n\n\'\'\'\n流程：\n1-查找到文件\n2-打开文件\n3-查看文件\n4-匹配文件\n5-打印文件名\n\'\'\'\n\n@init\ndef search(target):\n    \'\'\'找到所有文件的绝对路径，那么我找到的这个文件的绝对路径以后要给openfile函数传值\n       给openfile传值完成以后openfile才能够打开。那么如何把search和openfile关联呢？\n       答案其实很简单，就是给openfile send值就可以了，那么给openfile send值的话openfile\n       首先应该是一个协程函数，并且search能获取到openfile的生成器调用send方法才可以。\'\'\'\n    while True:\n        root_dir = yield  # root_dir = \"c:\\\\lamber\"\n        print(\"开始车间工作\")\n        time.sleep(1)\n        g = os.walk(root_dir)\n        for item in g:\n            for file in item[-1]:\n                file_path = \'%s\\\\%s\' % (item[0], file)\n                target.send(file_path)\n\n@init\ndef openfile(target):\n    \'\'\'打开文件以后我们要去查看文件，但是我们要把打开的文件句柄传递过去\n       同时为了在程序的最后获取满足条件的文件，在传递的同时还应该将file_path传递过去\'\'\'\n    while True:\n        file_path = yield\n        print(\"车间工作中：打开传递过来的文件\",file_path)\n        time.sleep(1)\n        with open(file_path) as f:\n            target.send((file_path,f))  # send可以传多个值，但是必须是元组\n\n@init\ndef cat(target):\n    \'\'\'我cat函数读取每一行的时候都要检测关键字是否在这一行里\n       因此我要把读取到的内容传递给grep参数\'\'\'\n    while True:\n        file_path,f=yield\n        print(\"车间持续工作中：针对传递过来的文件逐行的读取\",file_path)\n        time.sleep(1)\n        for line in f:\n            target.send((file_path,line))\n@init\ndef grep(pattern,target):\n    \'\'\'过滤一行内容是否有关键字pattern\'\'\'\n    while True:\n        file_path,line = yield\n        print(\"车间工作中：筛选ing\")\n        time.sleep(1)\n        if pattern in line:\n            target.send(file_path)\n@init\ndef printer():\n    while True:\n        file_path = yield\n        print(\"生产结束，\",file_path,\"文件中中包含对应的关键字\")\n\ng = search(openfile(cat(grep(\"lamber\",printer()))))\ng.send(\"C:\\\\lamber\")\n\n结果：\n开始车间工作\n车间工作中：打开传递过来的文件 C:\\lamber\\hahah.txt\n车间持续工作中：针对传递过来的文件逐行的读取 C:\\lamber\\hahah.txt\n车间工作中：筛选ing\n车间工作中：打开传递过来的文件 C:\\lamber\\a\\a1\\test1\n车间持续工作中：针对传递过来的文件逐行的读取 C:\\lamber\\a\\a1\\test1\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n生产结束， C:\\lamber\\a\\a1\\test1 文件中中包含对应的关键字\n车间工作中：打开传递过来的文件 C:\\lamber\\a\\a1\\test2\n车间持续工作中：针对传递过来的文件逐行的读取 C:\\lamber\\a\\a1\\test2\n车间工作中：筛选ing\n生产结束， C:\\lamber\\a\\a1\\test2 文件中中包含对应的关键字\n车间工作中：筛选ing\n车间工作中：打开传递过来的文件 C:\\lamber\\b\\b2\\test2.txt\n车间持续工作中：针对传递过来的文件逐行的读取 C:\\lamber\\b\\b2\\test2.txt\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n车间工作中：筛选ing\n生产结束， C:\\lamber\\b\\b2\\test2.txt 文件中中包含对应的关键字\n```\n\n\n\n### 面向过程的设计\n\n- 流水线式的设计思想，在设计程序的时候需要把整个流程设计出来，比如画流程图的时候把流程消息整个给简化，让流程更清晰简化程序的复杂度。\n- 但是面向过程的设计也是存在缺陷的，它的针对性很强，有定制性的，比如不能用造汽水的流程去造汽车。环境都是不一样的，整个流水线都要换，因此面向过程的程序设计耦合性是很强的，因此可扩展性是特别差的。因此面向过程是应对与不需要经常变化的软件。比如游戏，企业的OA就是不行的。","timestamp":1523777648264},{"name":"10-内置函数.md","path":"05-Python/01-Python基础/02-2、Python函数部分/10-内置函数.md","content":"# 内置函数\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-5/85846383.jpg)\n\n## 常用内置函数\n\n### abs\n求绝对值，如：abs(-1)，如果输入的是一个向量的话那么会返回这个向量的模\n\n### all\n需要一个可迭代的参数，把可迭代对象变成迭代器赋值给x，如果bool(x)是True的话那么就返回True，如果可迭代对象是空，也返回True。迭代器里面的所有的布尔值都是True才可以。\n\n```\nprint(all(\'\'))\n```\n- sum，求和函数，内部需要一个可迭代对象的参数\n\n- any，接收可迭代对象，如果可迭代对象为空返回false，可迭代对象next出来的值任何一个只要有值为真，那么这个any就返回真。\n\n- bin：把一个10进制整数转换成二进制数。\n\n- bool：判断是否为真，布尔函数\n\n- bytes：把一个字符串转换为字节形式，比如`print(bytes(\'hello\',encoding=\'utf-8\'))`\n\n- callable：是否可被调用，看一个名字（函数）是否可被调用。\n\n- chr()：数字到ascii的对应关系，比如chr(65)，返回对应的字符\n\n- ord()：和chr相对应，输入ord(A)，返回对应的数值。\n\n- classmethod：面向对象讲\n\n- staticmethod：面向对象讲\n\n- property：面向对象讲\n\n- compile：\n\n- complex：复数\n\n  ```\n  x = 1+2j\n  print(x.real)：实部\n  print(x.imag)：虚部\n\n  等价于 ===> x = complex(1-2j)\n\n  补充所有的数据类型：\n  1. int，float，bool：int(1),float(1)\n     print(num is int)  #判断类型以下通用\n     print(isinstance(num,int))   #判断类型以下通用\n  2. str\n     str(1)，可以将整形变成字符串形式，其他形式通用\n  3. list\n     list(interable)，可以将任何可迭代对象变成一个列表。\n  4. tuple\n  5. dict\n     可以使用d = dict(x=1,y=2,z=3)的形式定义字典\n  6. set，集合无序，天然去重。\n  7. frozenset（不可变集合）\n     f = frozenset({1,2,3,4})\n     类似于list和tuple的关系，是不可变得。\n  ```\n\n- delattr：面向对象讲\n\n- hasattr：面向对象讲\n\n- getattr：面向对象讲\n\n- setattr：面向对象讲\n\n### dir：\n内建函数dir是用来查找模块中定义的名字，返回一个有序字符串列表\n```\nimport spam\ndir(spam)\n```\n如果没有参数,dir()列举出当前定义的名字\n\ndir()不会列举出内建函数或者变量的名字，它们都被定义到了标准模块builtin中，可以列举出它们。\n```\nimport builtins\ndir(builtins)\n```\n- help：查看帮助\n\n- divmod：需要传俩值，返回一个元组，第一个值是整除的，`x//y`第二个值是`x%y`。可以用在以后前段的分页阶段。\n\n- enumerate：把一个可迭代对象变成一个迭代器\n\n  ```\n  for i  in enumerate([\'a\',\'b\',\'c\',\'d\']):\n      print(i)\n  结果：\n  (0, \'a\')\n  (1, \'b\')\n  (2, \'c\')\n  (3, \'d\')\n  ```\n\n- eval：把字符串的表达式提取出来运行，比如`str1 = \"print(\'hello\')\"`，使用`eval(str1)`那么就可以运行。\n\n- exec：\n\n- filter：过滤\n\n  ```\n  name_l = [\n      {\'name\':\'egon\',\'age\':18},\n      {\'name\':\'dragonFire\',\'age\':1000},\n      {\'name\':\'gaoluchuan\',\'age\':9000},\n      {\'name\':\'fsw\',\'age\':10000},\n  ]\n  # 左边的值返回时true时才会返回对应的结果\n  filter(lambda d:d[\'age\'] > 100,name_l)\n  ```\n\n  ​\n\n- map：映射，比如把一个列表的数组都做平方操作映射到另外一个新的列表。\n\n  ```python\n  例1：\n  i = [1,2,3,4,5]\n  # map(func,interable)\n  m = map(lambda item:item**2,i)\n  print(list(m))\n\n  例2：\n  name = [\'maxiaoyu\',\'shiyue\',\'maosen\']\n  m = map(lambda str1:str1+\'dafa\',name)\n  print(list(m))\n  ```\n\n  ​\n\n- from functools import reduce：合并\n\n  ```\n  from functools import reduce\n\n  l = list(range(100))\n  print(reduce(lambda x,y:x+y,l))\n\n  reduce的用法reduce(func,interable,init)，默认的init初始值为None。\n  其实迭代器每一次next只会取一个值，那么lambda接收两个值是如何做到的。因为init默认开始值为None，一开始就是1，，那么这个值就会作为下一次的初始值。\n  ```\n\n- hash：使用hash进行字符串校验，字符串改变的话得到的hash值必定改变，在值传递的发送方和接收方都hash最后的值，如果两个值比对是一样的那么证明在传输过程中是未被更改过的，或者传输中发生了丢失。并且hash值的长度固定。hash不能逆推，并且修改很小的一个部分会发生雪崩效应，hash值会发生翻天覆地的变化。\n\n- hex：十进制转16进制\n\n- id：身份验证，查看某个值的身份，并不是内存地址。\n\n  ```\n  id方法的返回值就是对象的内存地址。\n\n  python中会为每个出现的对象分配内存，哪怕他们的值完全相等（注意是相等不是相同）。如执行a=2.0，b=2.0这两个语句时会先后为2.0这个Float类型对象分配内存，然后将a与b分别指向这两个对象。所以a与b指向的不是同一对象：\n  >>> a=2.0\n  >>> b=2.0\n  >>> a is b\n  False\n  >>> a==b\n  True\n  但是为了提高内存利用效率对于一些简单的对象，如一些数值较小的int对象，python采取重用对象内存的办法，如指向a=2，b=2时，由于2作为简单的int类型且数值小，python不会两次为其分配内存，而是只分配一次，然后将a与b同时指向已分配的对象：\n  >>> a=2\n  >>> b=2\n  >>> a is b\n  True\n  如果赋值的不是2而是大的数值，情况就跟前面的一样了:\n\n  >>> a=5555\n  >>> b=5555\n  >>> a is b\n  False\n  >>> id(a)\n  12464372\n  >>> id(b)\n  12464396\n\n  一个简单的结论：解释器在对值很小的int和很短的字符串的时候做了一点小优化，只分配了一个对象，让它们id一样了。\n  ```\n\n- issubclass：面向对象说明\n\n- iter：把一个可迭代对象变成迭代器\n\n- len：统计长度\n\n- locals：局部命名空间\n\n- max：求最大值，比如max(3,2,1)，当然也可以接收可迭代对象的参数，比如：\n\n  ```\n  salary = {\n      \'egon\':3000,\n      \'alex\':100000,\n      \'wupeiqi\':22222,\n      \'yuanhao\':250\n  }\n\n  def get_value(key):\n      return salary[key]\n\n  print(max(salary,key=get_value))\n\n  结果：alex\n  max(salary,key=get_value)\n  max会把一个可迭代对象（salary）变成一个迭代器，next一次就会返回一个key，把这个key作为参数给get_value函数使用，取出对应的值。上面的形式可以让max返回的内容不变，返回对应的key值，但是比较的内容不是key而是get_value的返回结果作为比较的依据。\n\n  如果比较元组的话按照索引逐个比较，比如：\n  max((2,\'a\'),(1,\'b\'))\n  先比较索引为0的，所以(2,\'a\')要大于(1,\'b\')\n  ```\n\n- min：求最小值，参考max。\n\n- zip：拉链，一个对一个，对不上的就对不上了吧。。返回对应的小元组\n\n  ```\n  l = [1,2,3]\n  s = \"maxiaoyu\"\n  print(zip(l,s))\n  for i in zip(l,s):\n      print(i)\n  结果：\n  <zip object at 0x0000005422434388>\n  (1, \'m\')\n  (2, \'a\')\n  (3, \'x\')\n  ```\n\n- sorted：排序，将可迭代对象全部遍历一遍，然后按照asc（升序），默认的，返回一个排序好的列表回来。只要是可迭代的对象，都会先变成迭代器，然后next一步一步取值，如果是字符的话会按照ascii的顺序比较然后返回对应的列表。如果想要逆序的话可以添加一个参数`print(sorted(interble,reverse=True))`。sorted并不修改原可迭代对象内容。\n\n  ```\n  根据工资排序人名：\n  salary = {\n      \'egon\':3000,\n      \'alex\':100000,\n      \'wupeiqi\':22222,\n      \'yuanhao\':250\n  }\n  print(sorted(salary,key=lambda x:salary[x]))\n  ```\n\n- oct：十进制转八进制，逢八进一\n\n- pow：需要传x,y,z三个值，传两个值表示`x**y`，三个值表示`x**y % z`。\n\n- repr：类似于str\n\n- reversed：反转，比如reverse([1,3,5])，这个跟大小无关，单纯的逆序\n\n- round：四舍六入五留双\n\n  ```\n  print(round(3.4))   四舍，小数部分直接扔了就是3\n  print(round(11.3))  同上，11\n  print(round(11.5))  五留双\n  print(round(12.5))  五留双，会留最近的偶数，所以还是12\n  print(round(12.6))  六入，13\n\n  结果：\n  3\n  11\n  12\n  12\n  13\n  ```\n\n- slice：传三个参数，开始、结束、步长\n\n- super：\n\n- vars：不穿参数=locals()，打印局部命名空间的名字。有参数等价于object.\\_\\_dict\\_\\_\n\n- \\_\\_import\\_\\_：有些情况下得到的模块名是字符串的形式，比如字符串类型的time，我现在还想导入time模块。就要用到这个方法了。\n\n  ```\n  s = \'time\'\n  m = __import__(s)\n  print(m)\n  m.sleep(3)\n\n  结果：<module \'time\' (built-in)>\n  ```\n\n## 匿名函数\n\n```\nsalary = {\n    \'egon\':3000,\n    \'alex\':100000,\n    \'wupeiqi\':22222,\n    \'yuanhao\':250\n}\nf = lambda k:salary[k]    ====>不用写名字，k是参数，salarry[k]就是返回值，相当于renturn\nprint(f)\nprint(f(\'egon\'))\nprint(max(salary,key=lambda k:salary[k]))  求工资最大值。\n```\n\n可以使用匿名函数的\n\n1. max\n2. min\n3. sorted\n4. map\n5. reduce\n6. filter\n\n\n匿名函数就是没有函数名，使用lambda表达式定义，lambda是一种快速定义单行表达式的方法。\n\n比如：\n\n```\nr = lambda x,y:x*y\n```\n\nx和y是参数，冒号后面就是return的内容，也就是匿名函数的函数体。匿名函数的优点如下：\n\n- lambda定义的匿名函数省去了函数定义的过程，让代码更加精简\n- 对于一些抽象的，而且并不会被经常使用的函数，有时候给函数起一个名字也是难题，使用lambda不需要考虑函数命名的问题。\n- 使用lambda在某些时候让代码更容易理解。\n\n","timestamp":1523777648264},{"name":"11-递归.md","path":"05-Python/01-Python基础/02-2、Python函数部分/11-递归.md","content":"## 递归\n\n函数体内，再调用函数本身，称之为递归调用！如图看到不断的在函数体内调用自己。（自己内部调用自己）\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-6/68456871.jpg)\n\n调用的时候直接去最里层运行，然后从里向外一层一层的运行完成出来。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-6/96029965.jpg)\n\n比如遍历目录：\n\n一个大问题，可以拆解成多个小问题。同时大问题，与拆分的小问题的解决方案一致！典型需要在调用函数解决大问题时，内部再调用该函数去解决拆分的小问题，就形成的递归调用！\n\n看一个例子：\n\n```\nimport time\ndef func():\n    print(\"递归调用func\")\n    time.sleep(0.5)\n    func()\nfunc()\n```\n\n上面这段代码一会一直不断的调用func，func内部再调用func。然后无限调用下去，那么如果我不设置这个time.sleep的话那么其实运行就会过快，然后报出一个错误：\n\n```\nRecursionError: maximum recursion depth exceeded while calling a Python object\n```\n\n报错信息为，递归错误，已经达到了最大的递归深度，那么我们就知道默认的应该是有一个递归的深度的，那么这个默认的递归深度是多少呢？\n\n```\nimport sys\nprint(sys.getrecursionlimit())\n\n结果：\n1000\n```\n\n结果就是1000，那么递归的每一层的临时数据会放到堆栈里面，因此有多少层都会占用空间的，因此是有这个递归深度的限制的，这个深度是可以调整的，可以使用`sys.setrecursionlimit(10000)`。太大的话递归效率还是很低的。\n\n- 递归必须要用一个明确的结束条件\n- 每次进入更深入的一层递归的时候，问题规模应该比上次递归有所减少。\n- 递归的效率不高，递归层次过多会导致堆栈溢出。在计算机中，函数调用时通过栈这种数据结构实现的。每当进入一个函数调用栈就会加一层栈帧，每当函数返回，栈就会减少一层栈帧，由于栈的大小不是无限的，因此调用次数过多，就会导致栈溢出。\n\n### 使用二分法+递归进行列表查数\n\n```\ndata = [1,3,6,7,9,12,14,16,17,18,20,21,22,23,30,32,33,35]\n\ndef search(num,data):\n    print(data)\n    mid_index = int(len(data)/2)\n    mid_value = data[mid_index]\n    if num > mid_value:\n        # num在列表的右面\n        data = data[mid_index:]\n        search(num,data)\n    elif num < mid_value:\n        # number在列表的左面\n        data = data[:mid_index]\n        search(num,data)\n    else:\n        print(\"find it\")\n        return\nsearch(3,data)\n```\n\n添加对不存在的值的支持：\n\n```\ndata = [1,3,6,7,9,12,14,16,17,18,20,21,22,23,30,32,33,35]\n\ndef search(num,data):\n    print(data)\n    if len(data) > 1:\n        mid_index = int(len(data)/2)\n        mid_value = data[mid_index]\n        if num > mid_value:\n            # num在列表的右面\n            data = data[mid_index:]\n            search(num,data)\n        else:\n            # number在列表的左面\n            data = data[:mid_index]\n            search(num,data)\n    else:\n        if num == data[0]:\n            print(\"find it\")\n            return\n        else:\n            print(\"您查找的值是不存在的\")\nsearch(5,data)\n```\n\n","timestamp":1523777648264},{"name":"12-函数式编程介绍.md","path":"05-Python/01-Python基础/02-2、Python函数部分/12-函数式编程介绍.md","content":"- 精简\n- 不修改状态\n- 模仿数学里的函数式去写的\n\n","timestamp":1523777648264},{"name":"07-元组.md","path":"05-Python/01-Python基础/07-元组.md","content":"元组是不可变的列表，在定义一个元素的元组的时候要注意加一个逗号，因为元组的小括号和数学中的小括号是有歧义的，比如tuple(1)，那么这就不是一个元组而是一个真正的数字1，因此定义的时候应该这么定义`tuple(1,)`这样定义出来的就是一个元组了。\n\n","timestamp":1523777648264},{"name":"08-可变不可变类型.md","path":"05-Python/01-Python基础/08-可变不可变类型.md","content":"## 可变不可变类型\n\n\n\n\n\n## 存储值的多少\n\n一个值\n\n- 数字\n- 字符串\n\n\n\n## 有序无序\n\n\n\n\n\n","timestamp":1523777648264},{"name":"10-Python的编码.md","path":"05-Python/01-Python基础/10-Python的编码.md","content":"# Python的编码\n\n> 如何去理解编码呢？个人的理解，假如◇◇代表的就是问好的意思，这个东西假如说全世界都知道，但是翻译成各国语言之后就是这个样子：中国-->你好、美国-->hello、日本-->こんにちは。也就是说同一种意思针对不同的语言规则所呈现的结果是不一样的，但是意思都是问好，我认为这就是编码\n\n## 编码的历史\n\n### ASCII\n\n早期的编码是从ASCII表开始的。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-6-9/28261088.jpg)\n\n当时美国人用一个字节的后7位就够了，后7位最大能代表127，也就是01111111，具体各个数字代表的内容可以看上面的表，人家除了一些特殊字符外，就是大小写的26个字母还有数字，对于人家来说足够用了。后来对ASCII进行了扩展，将最高位用上了，此时可用范围其实就是到了0~255，前127位还是之前的，后面的内容是为了给拉丁字符扩展出来的。\n\n### GB2312&GBK\n\n1. GB2312：\n2. GBK：\n\n### unicode万国码\n\n此编码涵盖了世界各国可用于电脑通信的书写语言以及一些特殊字符和符号。当然不管是英文还是日文，中文在unicode中都能够找到对应的编码带表示。\n\n## 编码详解\n\n首先所有不管是文本还是什么东西在磁盘（disk）上的存储都是二进制的，不可能是你写一句话就把这一句话保存在磁盘上，而是把这句话对应的二进制数据保存在磁盘上。那么即使是同样一句话，按照不同的编码方式，二进制的展现形式也是不一致的。\n\n### Python2\n\n在py2中，默认的编码是ASCII，因此你在py2中你打中文是会报错的。需要在文件的开头声明应该用什么方式解释这个字符串。\n\n```\n# -*- coding: utf-8 -*-\nb = \"老马\"\n\nprint b\n```\n\npython2的默认解码方式为ASCII，python3中为UTF-8.\n\n```\na = \"马晓雨\"\nprint a\n```\n\n上面这段代码以GBK的编码方式保存的，\n\n","timestamp":1523777648264},{"name":"11-字符串的操作.md","path":"05-Python/01-Python基础/11-字符串的操作.md","content":"## 字符串\n\n字符串的拼接\n\n```\na = \"maxiaoyu\" + \"lamber\"\nprint(a)\n```\n\n这个效率其实并不是很高的，其实效率的高低取决于拼接的次数，比如A+B+C+D+E，字符串属于不可变数据类型，那么A+B会开辟一个空间存储，然后A+B+C开辟一个空间存储，然后A+B+C+D又会开辟一个空间来存储，以此类推。直到最后A+B+C+D+E拼接完成，但是中间拼接的这些内容是没有意义的，因此拼接次数越多效率越低。\n\n##### join\n\n字符串的拼接还可以使用join。\n\n```\na = \" \".join([\"hello\",\"world\"])\nprint(a)\n\nb = \"*\".join([\"a\",\"b\",\"c\",\"d\"])\nprint(b)\n\n结果：\nhello world\na*b*c*d\n```\n\njoin方法会把列表中的内容按照字符串的内容依次的进行拼接。\n\n##### split\n\n和join相反，split会按照指定的分隔符将字符串进行拆分\n\n```\na = \"hello world\".split(\" \")\nfor i in a:\n    print(i)\n    \n结果：\nhello\nworld\n```\n\n指定最大分割数：\n\n```\na = \"hello world\".split(\"l\",1)\nfor i in a:\n    print(i)\n结果：\nhe\nlo world\n```\n\nrsplit是从右侧开始分，maxsplit=-1\n\nsplitlines()，是按照换行符\"\\n\"去分的。每一个\\n分一个这个和split有一个微小的区别，splitlines不会去看字符串最后的\\n，但是split是会计算的，会单独把这个放到列表中。\n\n##### find\n\n查找字符串\n\n```\nprint(\"hello world\".find(\"e\"))\n\n结果：\n1\n```\n\n会返回查找的字符串的索引位置，如果字符串里存在多个要查找的字符串，只会返回第一个查找到的位置，默认从左往右找，如果要从右面查，可以使用rfind，当然也可以指定从什么位置开始找。\n\n```\nprint(\"hello world\".find(\"l\",3))\n```\n\n##### index\n\n返回索引位置，和find很类似，和find不一样的地方是，如果匹配不到的话index方法会报错，但是find找不到的话会返回-1这个数。\n\n```\nprint(\"hello world\".index(\"l\",3))\n```\n\n##### replace\n\n替换方法（replace不会对字符串本身做修改，直接返回新的字符串）\n\n```\nstr.replace(\"old str\",\"new str\")     <-----完全匹配\n```\n\n针对于完全匹配只要有一个错了肯定都不行，那么有完全匹配肯定就有模糊匹配，模糊匹配涉及到了正则表达式。\n\n##### swapcase\n\n大小写替换\n\n##### ljust rjust center\n\n```\na = \"hello world\".center(50,\"*\")\nprint(a)\n\n结果：\n*******************hello world********************\n\nljust：\nhello world***************************************\n\nrjust：\n***************************************hello world\n```\n\n##### format\n\n字符串的格式化输出（%s、%d、%f）\n\n```\nprint(\"hello %s,%s\" % (\"world\",\"again\"))\n\n结果：\nhello world,again\n```\n\n%f定义精度\n\n```\n%.4f  表示精度为4\n```\n\n使用format进行格式化\n\n```\na = \"hello {0},your age is {1}\".format(\"maxiaoyu\",25)\nprint(a)\n\n结果：\nhello maxiaoyu,your age is 25\n\na = \"hello {name},your age is {age}\".format(name=\"lamber\",age=24)\nprint(a)\n```\n\n##### format_map\n\n```\na = \"hello {name},your age is {age}\".format_map({\"name\":\"lamber\",\"age\":24})\nprint(a)\n```\n\n不用于format的地方就是format_map后面跟的是一个字典了。\n\n##### 判断是不是数字\n\n```\nprint(\"1\".isdigit())\nprint(\"壹\".isnumeric())\nprint(\"一\".isnumeric())\nprint(\"200\".isdecimal())\n\n结果:\nTrue\nTrue\nTrue\nTrue\n```\n\n其实在这三个方法区别不是很大只不过isnumeric更有针对性，isnumeric可以判定中文的“一”和大写的“壹”，比其他两个多这么点功能。\n\n##### capitalize&title\n\n首字母大写（仅仅是第一个单词）\n\n```\nprint(\"hello world\".capitalize())\n\n结果：\nHello world\n\nprint(\"hello world\".title())\n\n结果：\nHello World\n```\n\n##### upper&lower\n\n```\nprint(\"heLlo WoRld\".upper())\nprint(\"heLlo WoRld\".lower())\n\n结果：\nHELLO WORLD\nhello world\n```\n\n##### expendtabs\n\n扩展tab键，默认占用4个空格，这是linux里面，使用\\t表示tab键。\n\n```\nprint(\"heLlo\\tWoRld\")\nprint(\"heLlo\\tWoRld\".expandtabs(20))\n\n结果：\nheLlo\tWoRld\nheLlo               WoRld\n```\n\n##### identifier（基本不用）\n\n判断是否是一个合法的变量。\n\n##### isprintable（基本不用）\n\n是否可打印，字符串可打印，\\t&\\n这种是不可打印的\n\n##### zfill\n\n```\nprint(\"lamber\".zfill(20))\n\n00000000000000lamber\n```\n\n","timestamp":1523777648264},{"name":"13-文件操作.md","path":"05-Python/01-Python基础/13-文件操作.md","content":"# 针对文件的操作\n\n- 打开文件\n  - open()，通过操作系统去调用打开文件。\n- 操作文件\n  - read()、write()\n- 关闭文件\n  - close()\n\n## 文件打开流程的概述\n\n```\nfile1 = open(\"test1\")\nfile2 = open(\"test2\")\n\nprint(file1)\nprint(file2)\n\n结果：\n<_io.TextIOWrapper name=\'test1\' mode=\'r\' encoding=\'cp936\'>\n<_io.TextIOWrapper name=\'test2\' mode=\'r\' encoding=\'cp936\'>\n```\n\n返回的内容是一个文件对象，要想处理文件首先就得有一个文件的句柄。比如炒菜有铁锅，铁锅有个手柄可以控制这个锅，操作文件也是一样的，因此控制文件一样也需要一个句柄来进行操控。\n\n使用open方法打开以后，我们再使用这个句柄去调用read函数。那么现在我准备两个文本文档，test1.txt是使用GBK编码保存的，test2.txt是使用UTF-8的编码方式保存的。那么系统在读取文件的时候会按照系统默认的编码规则去解码成unicode。\n\n```\n<_io.TextIOWrapper name=\'test1.txt\' mode=\'r\' encoding=\'cp936\'>\n<_io.TextIOWrapper name=\'test2.txt\' mode=\'r\' encoding=\'cp936\'>\n```\n\n我们查到以后可以发现在windows的pycharm中默认的解码方式是cp936，cp936其实就是GBK。那么我们以GBK的的编码方式保存的文件，按照GBK的编码规则解码成unicode是没问题的，但是我们以UTF-8的编码方式保存的文件按照GBK的编码规则解码成unicode肯定就是报错的了。\n\n```\nfile1 = open(\"test1.txt\")\nfile2 = open(\"test2.txt\")\n\nprint(file1)\nprint(file2)\n\ndata1 = file1.read()\ndata2 = file2.read()\n\nprint(data1)\nprint(data2)\n\n结果：\nC:\\Users\\马晓雨\\AppData\\Local\\Programs\\Python\\Python36\\python.exe D:/坚果云同步/Python/Day3/file.py\nTraceback (most recent call last):\n  File \"D:/坚果云同步/Python/Day3/file.py\", line 8, in <module>\n<_io.TextIOWrapper name=\'test1.txt\' mode=\'r\' encoding=\'cp936\'>\n    data2 = file2.read()\nUnicodeDecodeError: \'gbk\' codec can\'t decode byte 0xb4 in position 18: illegal multibyte sequence\n<_io.TextIOWrapper name=\'test2.txt\' mode=\'r\' encoding=\'cp936\'>\n```\n\n反过来同样的内容在linux上新建一个文件查看\n\n```\n[lamber@maxiaoyu day1]$ ./file.py \n<_io.TextIOWrapper name=\'test1\' mode=\'r\' encoding=\'UTF-8\'>\n```\n\n这样就可以看出来了，windows上默认的是GBK的规则，linux上默认的是UTF-8的规则。为了解决这个问题。我们可以指定它的默认规则。\n\n```\nfile2 = open(\"test2.txt\",encoding=\"UTF-8\")\n```\n\n这个样子就不会报错了。这个是在读取文件的时候需要注意的一个点。\n\n最后要对文件进行关闭，如果没有使用close的话最后会默认关闭，但是为了避免出现额外的问题，我们要加上close方法的。\n\n## 文件的操作\n\n### 读取某一些字符\n\n```\ndata1 = file1.read(5)\n```\n\n（py3）这里的这个5读取的是字符而不是字节。但是python2中不是这样的，python2中是按字节来读的，比如一个汉字占用3个字节，它没读完的话就会显示乱码。\n\n并且指针的操作是连续的。\n\n```\nfile1 = open(\"test1.txt\")\nfile2 = open(\"test2.txt\",encoding=\"UTF-8\")\n\ndata1 = file1.read(5)\ndata2 = file1.read(5)\n\nprint(data1)\nprint(data2)\n\n结果：\n堺雅人，1\n973年1\n```\n\n也就是说data2是接着data1的结果接着读的。这是按照字符来读取。\n\n逐行读取：\n\n```\nfile1 = open(\"test1.txt\")\nfile2 = open(\"test2.txt\",encoding=\"UTF-8\")\n\ndata1 = file1.readline()\ndata2 = file1.readlines()\n\nprint(data1)\nprint(data2)\n\n结果：\n堺雅人，1973年10月14日出生于兵库县神户市，籍贯宫崎县宫崎市。\n\n[\'演员、配音演员，1994年于早稻田大学肄业。\\n\', \'2004年出演NHK大河剧《新选组》，饰演新选组总长山南敬助。\\n\', \'2008年出演NHK大河剧《笃姬》中第十三代将军德川家定。\\n\', \'2010年首度主演电视剧《JOKER 不被原谅的搜查官》，同年主演电影《金色梦乡》。\']\n```\n\nreadline会去读取文件中的一行，那么这个一行的判定标准是什么，其实就是换行符\\n，每一个用换行符\\n隔开的就是一行。对应的还有一个readlines方法，这个readlines方法不同于readline只读取一行，它会读取整个文件，然后把每一行作为一个元素放到列表里。并且也适用于前面说到的指针问题，我上面先用readline读了一行，那么readlines是接着我上面读的内容继续往下读取的而不是从头开始的。\n\n并且从上面的内容可以看到两个print之间有一个空行，原因是因为print默认就自带一个换行符。因此可以使用strip方法给去掉：\n\n```\nfor line in data2:\n    print(line.strip())\n```\n\n但是不管是readline还是readlines在实际生产中不要用。因为readlines的每一行都要放到内存，如果文件很大，那么就会吃掉很多内存。因此可以直接就使用这个文件句柄就可以。\n\n```\nfile1 = open(\"test1.txt\")\nfor line in file1:\n    print(line.strip())\n```\n\n使用文件句柄的时候会一条一条的去操作，并不会把所有的内容扔到内存里，可以达到优化内存的操作。\n\n**判断f的操作句柄是否为一个可读文件**\n\n```\nfile.readable()\n```\n\n### 写操作\n\n```\nfile1 = open(\"test1.txt\",mode=\"w\")\nfile1.write(\"hello\")\n```\n\n在设置文件句柄的时候，有一个mode，默认的是r，这个是可读的，不可写。如果想要执行写操作需要把mode改成w才能进行写操作，那么此时就是只能写不能读。\n\n这个写操作属于重定向，会清空原来的内容，再把要写的内容添加进去。我们可以直接去查看test1.txt的内容发现我们的hello的确是添加进去了。因此对于这个write的操作，在设置文件句柄的时候，即使文件不存在也不会报错，不存在的话就会创建文件。并把我们要添加的内容添加进去。\n\n```\nfile1 = open(\"test3.txt\",mode=\"w\",encoding= \"UTF-8\")\nfile1.write(\"创建新文件test3.txt\")\n```\n\n这里的encoding的时候在读取文件的时候是磁盘到unicode的解码方式，现在写文件是unicode要编码成什么字节码。\n\n追加内容：\n\n```\nfile1 = open(\"test3.txt\",mode=\"a\",encoding= \"UTF-8\")\nfile1.write(\"\\n我是追加的内容\\n\")\n```\n\n调用write方法的时候其实并不是立即写入的而是临时保存在缓存中，直到遇到了close方法（不管是手动写的还是最后系统给加上的）。因为如果数据每一次都是立即写入到磁盘的话那么时间是很长的。做一个简单的测试：\n\n```\nimport time\n\nfile1 = open(\"test4.txt\",mode=\"a\",encoding= \"UTF-8\")\nfile1.write(\"延迟测试内容\\n\")\n\ntime.sleep(100)\n\nfile1.close()\n```\n\n可以发现不存在的test4.txt文件会被立即创建，但是内容并不会马上写入，会一直等待直到sleep100秒后才会写入内容。\n\n当然如果要立刻写入到磁盘的话也是有方法的。使用flush方法。\n\n```\nimport time\n\nfile1 = open(\"test5.txt\",mode=\"a\",encoding= \"UTF-8\")\nfile1.write(\"延迟测试内容\\n\")\nfile1.flush()\n\ntime.sleep(100)\n\nfile1.close()\n```\n\n内容会被立即刷到test5.txt中去，这个flush可以用来做进度条。\n\n```\nimport sys\n\nsys.stdout.write(\"标准输出\")\n\n结果：\n标准输出\n```\n\nsys模块是一个跟系统相关的模块，sys.stdout相当于f = open(\"file1\")，也是一个文件句柄，stdout是一个和写相关的，这里写一个内容就会被输出到屏幕，其实print就是按照stdout这个来做的。\n\n```python\n进度条：\nimport sys\nimport time\n\nfor i in range(100)\n\tsys.stdout.write(\"*\")\n\ttime.sleep(0.5)\n```\n\n不覆盖的写入：\n\n```\nfile1 = open(\"test\",mode=x,encoding=\"UTF-8\")\n```\n\nwritelines会把后面列表的内容遍历的写进去。\n\n```\nfile.writelines([\"a\",\"b\"……])\n```\n\ntruncate方法\n\n```\nfile.truncate(n)\n```\n\n这里的n代表的是光标的位置，truncate可以进行阶段，把你光标以前的内容都截断出来，后面都不要。truncate这是一个修改文件的过程，因此truncate要在写模式下生效。\n\n**可读可写模式**\n\n- r+（追加写）\n- w+（首先清空原来的内容，清掉以后再写）\n- a+\n\nw+\n\n```\nfile = open(\"test1.txt\",mode=\"w+\",encoding=\"UTF-8\")\nfile.write(\"maxiaoyu\")\ndata = file.read()\nprint(data)\n```\n\n这段内容用的模式是w+的，所以写之前会把之前的所有内容清空再写，但是这个程序是没有输出的，因为写完以后光标是在最后的，那么再读是读不到内容的，因此我们需要一个方法去调整光标的位置，这个方法就是seek（）\n\n```python\nfile = open(\"test1.txt\",mode=\"w+\",encoding=\"UTF-8\")\nfile.write(\"maxiaoyu\")\nfile.seek(0)\nprint(file.read())\n\n结果：\nmaxiaoyu\n```\n\n这个seek里面的数字是按照字节移动的，不是按照字符，和python3中的read是不一样的。seek的用法为seek(A,B)，B表示从哪个位置开始进行便宜，B=0的时候是从头开始，B=2是从结尾便宜，B=1表示从当前位置开始偏移。还有一个关于光标的方法是tell方法，tell方法可以打印光标的位置。\n\n```python\nfile = open(\"test1.txt\",mode=\"r+\",encoding=\"UTF-8\")\nfile.seek(-3,2)\nprint(file.tell())\nprint(file.read())\n\n结果：\nTraceback (most recent call last):\n  File \"D:/坚果云同步/Python/Day3/file2.py\", line 2, in <module>\n    file.seek(-3,2)\nio.UnsupportedOperation: can\'t do nonzero end-relative seeks\n```\n\n在python3中，是不允许在非二进制打开的情况下倒着查看文件的。那我们以二进制方式打开。\n\n```\nfile = open(\"test1.txt\",mode=\"rb+\",encoding=\"UTF-8\")\nfile.seek(-3,2)\nprint(file.tell())\nprint(file.read())\n\n\n结果：\nTraceback (most recent call last):\n  File \"D:/坚果云同步/Python/Day3/file2.py\", line 1, in <module>\n    file = open(\"test1.txt\",mode=\"rb+\",encoding=\"UTF-8\")\nValueError: binary mode doesn\'t take an encoding argument\n```\n\n报错显示二进制模式下不能使用encoding参数，那么我们把encoding拿掉。\n\n```\nfile = open(\"test1.txt\",mode=\"rb+\")\nfile.seek(-3,2)\nprint(file.tell())\nprint(file.read())\n\n结果：\n11\nb\'\\xe9\\x9b\\xa8\'\n```\n\n这样就能够打印出来了，不过是以二进制字节码的形式打印的。解码一下就可以查看了。\n\n```\nfile = open(\"test1.txt\",mode=\"rb+\")\nfile.seek(-3,2)\nprint(file.tell())\ndata1 = file.read().decode(\"UTF-8\")\nprint(str(data1))\n\n结果：\n11\n雨\n```\n\nwb+\n\n```\n\n```\n\n**a+**\n\n```\nfile = open(\"test1.txt\",mode=\"a+\",encoding=\"UTF-8\")\nfile.seek(0)\nprint(file.tell())\ndata1 = file.read()\nprint(data1)\n\n结果：\n0\nhello马晓雨\n```\n\na+模式其实就是最佳，那么最佳完了以后的指针肯定在最后的位置，如果不调整seek的话read方法是什么都读不出来的。因此我用seek函数把光标调整到0位置，就可以正常读取了。那么我们如果读一部分然后再写呢？\n\n```\nfile = open(\"test1.txt\",mode=\"a+\",encoding=\"UTF-8\")\nfile.read(3)\nfile.write(\"我是插入的数据\")\n\nprint(file.read())\n\n结果：\nlo马晓雨我是插入的数据\n```\n\n通过实际操作我们发现这个write其实是不受到光标的影响，都是在后面添加。主要是原因是之前我存了“hello马晓雨”这个数据，那么再磁盘中就开辟出来一段数据空间，这是固定存储好的，那么我们现在要把插入的数据查到之前的字符串中间是不可能的。\n\n\n\n**seek的用途**\n\n比如文件的上传和下载中的断点续传。\n\n\n\n### with\n\n之前说到的close方法用来关闭打开的文件，如果没有使用close方法的话那么最后也会关闭，但是最后关闭实在整个程序执行完了以后会关闭，如果在此之前还有一堆操作的话那么就有可能会存在一些问题。\n\n因此避免开发忘记，可以使用一种with的方法进行替换\n\n```\nwith open(\"test1.txt\") as f:\n    f.read()\n```\n\n使用这种替代方式的好处就是有了层级的关系，将代码块提炼出来了。这样如果我想要执行别的操作我也不用close，只要退出当前控制块就是退出当前的层级，自然也就退出了这个打开的文件。\n\n\n\n## 文件操作\n\n#### 文件查询小练习\n\n一个haproxy的配置文件\n\n```shell\nglobal\n\t\tlog 127.0.0.1 local2\n\t\tdaemon\n\t\tmaxconn 256\n\t\tlog 127.0.0.1 local2 info\ndefaults\n\t\tlog global\n\t\tmode http \n\t\ttimeout connect 5000ms\n\t\ttimeout client 50000ms\n\t\ttimeout server 50000ms\n\t\toption  dontlognull\n\nlisten stats :8888\n\t\tstats enable\n\t\tstats uri\t\t/admin\n\t\tstats auth\t\tadmin:1234\n\nfrontend oldboy.org\n\t\tbind 0.0.0.0:80\n\t\toption httplog\n\t\toption httpclose\n\t\toption forwardfor\n\t\tlog global\n\t\tacl www hdr_reg(host) -i www.oldboy.org\n\t\tuse_backend www.oldboy.org if www\n\nbackend www.oldboy1.org\n\t\tserer 10.10.0.10 10.10.0.10 weight 9999 maxconn 333333333333\n\t\tserver 10.10.10.1 10.10.10.1 weight 22 maxconn 2000\n\t\tserver 2.2.2.4 2.2.2.4 weight 20 maxconn\nbackend www.oldboy2.org\n\t\tserver 3.3.3.3 3.3.3.3 weight 20 max conn 3000\nbackend www.oldboy20.org\n\t\tserver 10.10.0.10 10.10.0.10 weight 9999 maxconn 333333333333\n```\n\n#### 查询功能\n\n用户输入后端域名可以把负载的后端对应的服务器显示出来。\n\n```python\ndomain = input(\"Please input the domain name: \").strip()\nflag = False\nserver = []\nwith open(\"haproxy.cfg\",encoding=\"UTF-8\") as f:\n    for line in f:\n        if line.startswith(\"backend\") and domain in line:\n            flag = True\n            continue\n        if line.startswith(\"backend\") and flag:\n            break\n        if flag:\n            server.append(line.strip())\n    for i in server:\n        print(i)\n```\n\n本练习比较重要的就是设置标志位\n\n#### 文件的修改\n\n进度条优化\n\n```python\nimport sys\nimport time\n\nfor i in range(100):\n    s = \"\\r %d %% %s\"% (i,\"#\"*i)\n    sys.stdout.write(s)\n    sys.stdout.flush()\n\n    time.sleep(0.5)\n```\n\n![](http://omk1n04i8.bkt.clouddn.com/17-6-27/33341003.jpg)\n\n关于\\r&\\n的一个说明。\n\n**1、\\n 软回车**：\n\n在Windows 中表示换行且回到下一行的最开始位置。相当于Mac OS 里的 \\r 的效果。\n在Linux、unix 中只表示换行，但不会回到下一行的开始位置。\n**2、\\r 软空格：**\n\n在Linux、unix 中*表示返回到当行的最开始位置。*\n\n在Mac OS 中表示换行且返回到下一行的最开始位置，相当于Windows 里的 \\n 的效果。\n\n\n\n硬盘级别上是没有文件修改一说的，但是再内存中可以。所以修改文件就是读源文件的内容往新文件里去写，这样就节省内存空间，但是多占用了硬盘空间。\n\n\n\n\n\n","timestamp":1523777648264},{"name":"14-字典.md","path":"05-Python/01-Python基础/14-字典.md","content":"#  字典\n\n键值对，字典的查询效率高于列表，列表的效率是线性的。\n- 键是唯一的，键必须是不可变数据类型\n- 字典是无序的\n\n\n为什么字典是无序的？\n\n> 浅层次的理解就是，列表是靠下标定位数据，但是字典是靠键定位数据。因此字典无需再维护顺序。只要有键，能找到对应的值就行。存储下标还要占用额外的空间。\n\n上面说到键是唯一的，那么我在一个字典里写两个一样的键会报错么？当然不会报错的，只不过后面的键会把前面的键覆盖掉，比如：\n\n```\nnames = {\"name\":\"maxiaoyu\",\"name\":\"lamber\"}\nprint(names[\"name\"])\n\n结果：\nlamber\n```\n\n\n\n\n## 字典的增删改查\n\n\n```\nname = {\n    \"user1\": {\"name\":\"user1\",\"age\":14,\"sex\":\"male\"},\n    \"user2\": {\"name\":\"user2\",\"age\":15,\"sex\":\"famale\"},\n    \"user3\": {\"name\":\"user3\",\"age\":16,\"sex\":\"male\"},\n    \"user4\": {\"name\":\"user4\",\"age\":17,\"sex\":\"famale\"},\n    \"user5\": {\"name\":\"user5\",\"age\":18,\"sex\":\"male\"},\n    \"user6\":[\"maxiaoyu\"]\n}\n```\n\n\n### 增\n\n\n```\nname[\"user6\"].append(1)\nprint(name)\n\n结果：\n{\'user1\': {\'name\': \'user1\', \'age\': 14, \'sex\': \'male\'}, \'user2\': {\'name\': \'user2\', \'age\': 15, \'sex\': \'famale\'}, \'user3\': {\'name\': \'user3\', \'age\': 16, \'sex\': \'male\'}, \'user4\': {\'name\': \'user4\', \'age\': 17, \'sex\': \'famale\'}, \'user5\': {\'name\': \'user5\', \'age\': 18, \'sex\': \'male\'}, \'user6\': [\'maxiaoyu\', 1]}\n```\n\n\n```\nname[\"user7\"] = {\"name\":\"user7\",\"age\":23,\"sex\":\"male\"}\nprint(name)\n\n\n结果：\n{\'user1\': {\'name\': \'user1\', \'age\': 14, \'sex\': \'male\'}, \'user2\': {\'name\': \'user2\', \'age\': 15, \'sex\': \'famale\'}, \'user3\': {\'name\': \'user3\', \'age\': 16, \'sex\': \'male\'}, \'user4\': {\'name\': \'user4\', \'age\': 17, \'sex\': \'famale\'}, \'user5\': {\'name\': \'user5\', \'age\': 18, \'sex\': \'male\'}, \'user6\': [\'maxiaoyu\'], \'user7\': {\'name\': \'user7\', \'age\': 23, \'sex\': \'male\'}}\n```\n\n### 删\n\n\n```\nnames.pop(key,None)\n```\npop就是弹出，根据对应的键值弹出，后面的None指的是当没有这个键值的时候返回none，如果不设置这个none的话就会报错的。\n\nnames.popitem()\n\n随机删除一个。\n\ndel names[key]\n\nnames.clear()\n\n\n### 改\n\n\n```\nname[\"user1\"][\"name\"] = \"lamber\"\nprint(name[\"user1\"][\"name\"])\n```\n\n### 查\n\n\n```\nprint(names)\n\n结果：\n\n{\'user1\': {\'name\': \'user1\', \'age\': 14, \'sex\': \'male\'}, \'user2\': {\'name\': \'user2\', \'age\': 15, \'sex\': \'famale\'}, \'user3\': {\'name\': \'user3\', \'age\': 16, \'sex\': \'male\'}, \'user4\': {\'name\': \'user4\', \'age\': 17, \'sex\': \'famale\'}, \'user5\': {\'name\': \'user5\', \'age\': 18, \'sex\': \'male\'}, \'user6\': [\'maxiaoyu\']}\n```\n\n\n\n查看某一个key的值\n```\nprint(names[key])\n```\n\n\n\n使用get方法，如果key不存在不会报错，会返回一个none\n```\nprint(names.get(key))\n```\n\n快速判断字典里有没有一个key，会返回一个布尔值，true or false\n\n```\nprint(key in names)\n```\n\n字典的循环：\n\n\n```\nfor i in names:\n    print(i,names[i])\n```\n\n这种方式不要用，效率低很多。\n```\nfor k,v in names.items():\n    print(k,v)\n    \nuser1 {\'name\': \'user1\', \'age\': 14, \'sex\': \'male\'}\nuser2 {\'name\': \'user2\', \'age\': 15, \'sex\': \'famale\'}\nuser3 {\'name\': \'user3\', \'age\': 16, \'sex\': \'male\'}\nuser4 {\'name\': \'user4\', \'age\': 17, \'sex\': \'famale\'}\nuser5 {\'name\': \'user5\', \'age\': 18, \'sex\': \'male\'}\nuser6 [\'maxiaoyu\']\n```\n\n\n列出所有的key\n```\nprint(names.keys())\n\n\ndict_keys([\'user1\', \'user2\', \'user3\', \'user4\', \'user5\', \'user6\'])\n\n```\n\n列出所有的value：\n\n\n```\nprint(names.values())\n\ndict_values([{\'name\': \'user1\', \'age\': 14, \'sex\': \'male\'}, {\'name\': \'user2\', \'age\': 15, \'sex\': \'famale\'}, {\'name\': \'user3\', \'age\': 16, \'sex\': \'male\'}, {\'name\': \'user4\', \'age\': 17, \'sex\': \'famale\'}, {\'name\': \'user5\', \'age\': 18, \'sex\': \'male\'}, [\'maxiaoyu\']])\n```\n\n\n字典的更新：\n\n```\ndict1 = {\n    \"user1\": {\"name\":\"user1-1\",\"age\":14,\"sex\":\"male\"},\n    \"user2\": {\"name\":\"user2\",\"age\":11,\"sex\":\"famale\"},\n    \"user3\": {\"name\":\"user3\",\"age\":15,\"sex\":\"male\"},\n}\n\ndict2 = {\n    \"user1\": {\"name\":\"user1-2\",\"age\":14,\"sex\":\"male\"},\n    \"user4\": {\"name\":\"user4\",\"age\":14,\"sex\":\"male\"},\n    \"user5\": {\"name\":\"user5\",\"age\":14,\"sex\":\"male\"},\n}\n\ndict1.update(dict2)\nprint(dict1)\n\n\n结果：\n{\'user1\': {\'name\': \'user1-2\', \'age\': 14, \'sex\': \'male\'}, \'user2\': {\'name\': \'user2\', \'age\': 11, \'sex\': \'famale\'}, \'user3\': {\'name\': \'user3\', \'age\': 15, \'sex\': \'male\'}, \'user4\': {\'name\': \'user4\', \'age\': 14, \'sex\': \'male\'}, \'user5\': {\'name\': \'user5\', \'age\': 14, \'sex\': \'male\'}}\n```\n其实就是没有的给加上，有的给更新为参数内的字典。比如dic2\n\nfromkeys：\n\n\n```\na = {}\na = a.fromkeys([1,2,3],\"value\")\nprint(a)\n\n结果：\n{1: \'value\', 2: \'value\', 3: \'value\'}\n```\n使用fromkeys，把前面的一个列表做为一个key，然后后面的值作为value。如果不写的话那么就是None。\n\nget方法：\n\n```\nnames = {\"name\":\"maxiaoyu\",\"age\":\"15\"}\na = names.get(\"name\",None)\nprint(a)\n\n结果：\nmaxiaoyu\n```\n\n使用get方法，如果有name这个键那么a就是name对应的value，如果不存在不会报错，会设置为None。\n\n","timestamp":1523777648264},{"name":"001-__class__.md","path":"05-Python/02-面向对象编程/002-2、OOP中双下方法汇总/001-__class__.md","content":"# \\_\\_class\\_\\_\n\n获取已知对象的类：对象.\\_\\_class\\_\\_\n\n```python\n>>> a = \'hahaha\'\n>>> a.__class__\n<type \'str\'>\n>>> b = 1\n>>> b.__class__\n<type \'int\'>\n>>> c = [1,2,3]\n>>> c.__class__\n<type \'list\'>\n>>> d = {1,2,3}\n>>> d.__class__\n<type \'set\'>\n>>> e = 1.2\n>>> e.__class__\n<type \'float\'>\n>>> f = {\'name\':\'lamber\'}\n>>> f.__class__\n<type \'dict\'>\n```\n\n那么类的类又是什么呢？\n\n```\n>>> f.__class__.__class__\n<type \'type\'>\n```\n\n其实就是type。\n\n\n","timestamp":1523777648264},{"name":"002-__name__ & __main__.md","path":"05-Python/02-面向对象编程/002-2、OOP中双下方法汇总/002-__name__ & __main__.md","content":"# \\_\\_name\\__ & \\_\\_main\\_\\_\n\n`__name__`：是一个变量，是用来标识系统模块的名字的一个系统变量。这里分两种情况：假如当前模块是主模块（也就是调用其他模块的模块），那么此模块名字就是\\_\\_main\\_\\_，通过if判断这样就可以执行“\\_\\_main\\_\\_:”后面的主函数内容；假如此模块是被import的，则此模块名字为文件名字（不加后面的.py），通过if判断这样就会跳过“\\_\\_main\\_\\_:”后面的内容。\n\n通过上面方式，python就可以分清楚哪些是主函数，进入主函数执行；并且可以调用其他模块的各个函数等等。因此可以实现文件在不同的场景执行不同的代码就可以用这个功能来实现。一般被当做脚本去执行的时候也就是直接运行这个py文件的时候用\n\n```python\nif __name__ = \'__main__\':\n    xxxxxxxx\n```\n\n这样就ok了。如果作为模块被导入到其他的文件的时候上面的条件不成立就会执行if下面的语句。\n\n\n\n","timestamp":1523777648264},{"name":"003-__new__.md","path":"05-Python/02-面向对象编程/002-2、OOP中双下方法汇总/003-__new__.md","content":" \\_\\_new\\_\\_ 是在\\_\\_init\\_\\_之前被调用的特殊方法\n \\_\\_new\\_\\_是用来创建对象并返回之的方法\n 而\\_\\_init\\_\\_只是用来将传入的参数初始化给对象\n 你很少用到\\_\\_new\\_\\_，除非你希望能够控制对象的创建","timestamp":1523777648264},{"name":"004-__setattr__,__delattr__,__getattr__.md","path":"05-Python/02-面向对象编程/002-2、OOP中双下方法汇总/004-__setattr__,__delattr__,__getattr__.md","content":"```\nclass Foo:\n    x=1\n    def __init__(self,y):\n        self.y=y\n\n    def __getattr__(self, item):\n        print(\'----> from getattr:你找的属性不存在\')\n\n\n    def __setattr__(self, key, value):\n        print(\'----> from setattr\')\n        # self.key=value #这就无限递归了,你好好想想\n        # self.__dict__[key]=value #应该使用它\n\n    def __delattr__(self, item):\n        print(\'----> from delattr\')\n        # del self.item #无限递归了\n        self.__dict__.pop(item)\n\n#__setattr__添加/修改属性会触发它的执行\nf1=Foo(10)\nprint(f1.__dict__) # 因为你重写了__setattr__,凡是赋值操作都会触发它的运行,你啥都没写,就是根本没赋值,除非你直接操作属性字典,否则永远无法赋值\nf1.z=3\nprint(f1.__dict__)\n\n#__delattr__删除属性的时候会触发\nf1.__dict__[\'a\']=3#我们可以直接修改属性字典,来完成添加/修改属性的操作\ndel f1.a\nprint(f1.__dict__)\n\n#__getattr__只有在使用点调用属性且属性不存在的时候才会触发\nf1.xxxxxx\n```\n\n","timestamp":1523777648264},{"name":"003-面向对象的程序设计.md","path":"05-Python/02-面向对象编程/003-面向对象的程序设计.md","content":"### 面向过程和面向对象\n\n#### 面向过程\n\n- 流程的，需要把整个过程给考虑出来，整个流水线，从开始到最后都要预测好。\n\n#### 面向对象\n\n- ​\n\n比如说英雄联盟，每一个英雄就是一个对象，开发者无法控制某一个阶段人物到多少级，打多少钱。\n\n什么时候使用面向对象？\n\n需要数据和逻辑分离的时候就可以使用，面向过程的数据和逻辑是耦合的。\n\n还有一种用法是作为模版约束。约束用户的属性和行为\n\n### 类和对象\n\n#### 类\n\n盖伦共同的特征：\n\n- 属于一个阵营叫德玛西亚\n\n```\nclass Garen:\n    camp = \"德玛西亚\"\n    def attack(self):\n        print(\'attack\')\n```\n\n实例化会自动触发类内部init方法的执行\n\n#### 关于类\n\n```\nclass garen:\n    camp = \"德玛西亚\"\n    def attack(self):\n        print(\"attack\")\nprint(garen)\nprint(int)\n\n结果：\n<class \'__main__.garen\'>\n<class \'int\'>\n```\n\n其实不管是int还是garen，大家都是类。那么如何使用类：两种用法，一种是实例化，比如`obj = garen()`，第二种是引用名字，通过xx.xx的方式引用。实例可以去引用名字，使用“.”可以用类的变量，绑定方法，实例名.实例自己变量名（init方法中定义的）\n\n```\ngaren.camp = xxxx\ngaren.attack(xxx)  #使用类的方法\n```\n\n\\_\\_init\\_\\_方法\n\n```\nclass garen:\n    camp = \"德玛西亚\"\n    def __init__(self,nickname):\n        self.nickname = nickname\n    def attack(self):\n        print(\"attack\")\n```\n\n实例化会自动触发类里面的\\_\\_init\\_\\_方法。\n\n```\nclass garen:\n    camp = \"德玛西亚\"\n    def __init__(self,nickname):\n        self.nickname = nickname\n    def attack(self):\n        print(\"attack\")\n\ng1 = garen(\"我上去就是一个大保健\")\nprint(g1.nickname)\n\n结果：\n我上去就是一个大保健\n```\n\n其中init方法中的self.nick = nickname其实就是相当于g1.nick = \"我上去就是一个大保健\"。self被替换成对象g1.\n\n```\nprint(g1.attack)\n\n结果：\n<bound method garen.attack of <__main__.garen object at 0x0000002ADAB50828>>\n```\n\n把garen的方法绑定给实例化后的g1了。如果我直接调用类的attack方法的话其实就是调用了一个方法，而且必须给self传值：\n\n```\nprint(garen.attack())\n\n结果：\nTypeError: attack() missing 1 required positional argument: \'self\'\n```\n\n但是如果我用g1这个实力去调用的话就不会，因为是绑定方法，调用的时候会把g1这个实例传给self。因此不会报错。其实在实例化的就是做了这样一个操作：\n\n```\ng1 = garen(\'xxx\') ===>   garen.__init__(g1,\'xxx\')\n```\n\n但是类去调用类自己内部的函数就没有给self主动传值的功能。\n\n\n\n对象：\n\n共有的特征，类--->归纳对象相同的特征，\n\n私有的特征\n\n先定义类，然后再实例化出来对象。\n\n\n\n比如学生类：\n\n```\n共同的特征举例：共同的国籍\n独有的特征举例：ID、名字、性别、省市\n共同的技能举例：\n\n```\n\n定义学生类：\n\n```\nclass Student:\n    country=\'China\'\n    def __init__(self,ID,NAME,SEX,PROVINCE):\n        self.id=ID\n        self.name=NAME\n        self.sex=SEX\n        self.province=PROVINCE\n    def search_score(self):\n        print(\"tell score\")\n\ns1 = Student(\'123\',\'cobila\',\'female\',\'shanxi\')\n实例化的过程并不是将返回值赋值给s1，返回值应该为None。\n```\n\n\n\n在python3中统一了类与类型的概念，类就是类型，比如int，str，list，tuple这些类型其实就是一个class。\n\n在py3当中，所有的类都是新式类，没有经典类和新式类的区分，但是再py2当中新式类的定义方式有所不同。\n\n```\n大前提：\n1.只有在python2中才分新式类和经典类，python3中统一都是新式类\n2.新式类和经典类声明的最大不同在于,所有新式类必须继承至少一个父类\n3.所有类甭管是否显式声明父类，都有一个默认继承object父类（讲继承时会讲，先记住）\n在python2中的区分\n经典类：\nclass 类名:\n    pass\n\n经典类：\nclass 类名(父类):\n    pass\n\n在python3中，上述两种定义方式全都是新式类,py3中的新式类，你可以写继承自谁你也可以不写继承自谁，不写的话默认继承一个object类。但是再py2中的话你不写继承自谁那就是一个空，这就是python2和python3的区别，查看继承自哪个类，可以使用：\n\n类名.__bases__来查看\n```\n\n类的使用：\n\n- 实例化\n- 属性引用（属性是特征+技能）\n\n查看类的名称空间\n\n```\nprint(garen.__dict__)\n\n{\'__module__\': \'__main__\', \'camp\': \'德玛西亚\', \'__init__\': <function garen.__init__ at 0x0000005DAA173A60>, \'attack\': <function garen.attack at 0x0000005DAA173AE8>, \'__dict__\': <attribute \'__dict__\' of \'garen\' objects>, \'__weakref__\': <attribute \'__weakref__\' of \'garen\' objects>, \'__doc__\': None}\n```\n\n查看对象的名称空间\n\n```\nprint(g1.__dict__)\n\n{\'nickname\': \'我上去就是一个大保健\'}\n```\n\n对象的名称空间相当于局部的，比如我要找g1的camp，在g1的名称空间没找到，就回去类下面找，一层一层向外找，类里面就有camp，就会返回对应的值，没有就会报错没有这儿attribute（属性）。\n\n绑定方法的核心在于绑定，唯一绑定到一个确定的对象身上。接下来看一下对象之间的交互：\n\n```\nclass garen:\n    def __init__(self,nickname,attack=100,life=1000):\n        self.nickname = nickname\n        self.attack = attack\n        self.life = life\n    def attack_hero(self,enemy):\n        enemy.life -= self.attack\n\nclass riven:\n    def __init__(self,nickname,attack=100,life=1000):\n        self.nickname = nickname\n        self.attack = attack\n        self.life = life\n    def attack_hero(self,enemy):\n        enemy.life -= self.attack\n\ngaren1 = garen(\'塑料5第一盖伦\')\nriven1 = riven(\'王者5第一瑞文\')\nriven1.attack_hero(garen1)\nprint(garen1.life)\n\n结果：\n900\n```\n\n瑞文砍了盖伦一刀，生命值减少100.结果就是900了。\n\n### 如何基于面向对象开发软件\n\n\n\n### 继承\n\n```\nclass father1:\n    pass\nclass father2:\n    pass\nclass son1(father1):\n    pass\nclass son2(father2):\n    pass\nclass son3:\n    pass\nprint(son1.__bases__)\nprint(son2.__bases__)\nprint(son3.__bases__)\n\n结果：\n(<class \'__main__.father1\'>,)\n(<class \'__main__.father2\'>,)\n(<class \'object\'>,)\n```\n\n来看下面一个例子：\n\n```\nclass animal:\n    def __init__(self,name,age,):\n        self.name = name\n        self.age = age\n    def walk(self):\n        pass\n    def say(self):\n        pass\nclass people(animal):\n    pass\nclass pig(animal):\n    pass\nclass dog(animal):\n    pass\n```\n\n可以看到people，pig，dog类都继承了父类animal类，他们都是动物，但是却不是一个物种，这就是同一种实物的不同表现形式（形态），这就是多态。继承多个父类的话在括号中多个类之间用逗号隔开。\n\n```\nclass animal:\n    def __init__(self,name,age,):\n        self.name = name\n        self.age = age\n    def walk(self):\n        print(\'%s is walking\' %self.name)\n    def say(self):\n        pass\nclass people(animal):\n    pass\nclass pig(animal):\n    pass\nclass dog(animal):\n    pass\np1 = people(\'卢锡安\',50)\nprint(p1.name,p1.age)\np1.walk()\n\n\n结果：\n卢锡安 50\n卢锡安 is walking\n```\n\npeople类什么都没定义，但是依然可以接受name和age的参数，因为people是继承了animal类，那么people就拥有animal类的属性，因此继承解决了一定的重用性的问题。\n\n那么既然子类能够继承，能够继承一样的东西那么必然就有不一样的东西，如果都一模一样那要分什么子类父类，一个类不就够了。就因为每一个子类都有独特的不一样的地方因此独特的属性就需要独立去定义，这个就需要派生，派生出新的属性（因此派生要继承一个父类，还要有自己独特的特点，也就是父类没有的，这就是派生出自己新的东西）。\n\n那么如何在复用父类的一些方法的同时派生新的内容？\n\n```\nclass hero:\n    def __init__(self,nickname,attack,life):\n        self.nickname = nickname\n        self.attack = attack\n        self.life = life\n    def attack_hero(self):\n        print(\'%s 正在调用hero的attack方法\' % self.nickname)\n\nclass garen(hero):\n    camp = \'Demacia\'\n    def attack_hero(self):\n        hero.attack_hero(self)\n        print(\"attack from class garen\")\n\ng1 = garen(\"草丛伦\",100,1000)\ng1.attack_hero()\n\n结果：\n草丛伦 正在调用hero的attack方法\nattack from class garen\n```\n\n比如我在garen类中的attack_hero方法中我要复用父类的attack_hero的方法，我就直接调用hero.attack_hero就可以，然后如果要派生新的方法的话我就再添加新的内容就可以了。当然也可以复用父类的init方法：\n\n```\nclass hero:\n    def __init__(self,nickname,attack,life):\n        self.nickname = nickname\n        self.attack = attack\n        self.life = life\n    def attack_hero(self):\n        print(\'%s 正在调用hero的attack方法\' % self.nickname)\n\nclass garen(hero):\n    camp = \'Demacia\'\n    def __init__(self,nickname,attack,life,script):\n        hero.__init__(self,nickname,attack,life)\n        self.script = script\n    def attack_hero(self):\n        hero.attack_hero(self)\n        print(\"attack from class garen\")\n\ng1 = garen(\"草丛伦\",100,1000,\'人在塔在\')\ng1.attack_hero()\nprint(g1.script)\n\n结果：\n草丛伦 正在调用hero的attack方法\nattack from class garen\n人在塔在\n```\n\n## 组合\n\n> 首先和继承区分一下，继承是什么是什么，比如人是动物，阿猫阿狗也是动物，这叫继承，从属关系。那么组合是有的关系，比如学生报名选课，老师教课，两者之间都和这个课程有关系，但是他们并不属于课程，课程也不属于他们。又比如盖伦属于英雄类，这就是继承的体现，盖伦要出装备，瑞文也要出装备，装备是要重用的部分，但是装备并不属于任何一个类，不属于盖伦类，也不属于瑞文类。这个东西是没有办法继承的。其实说白了就是针对不同情况的代码重用采取的不同的处理方法。\n\n```\nclass teacher:\n    def __init__(self,name,sex,course):\n        self.name = name\n        self.sex = sex\n        self.course = course\nclass course:\n    def __init__(self,name,price,peroid):\n        self.name = name\n        self.price = price\n        self.peroid = peroid\nt1 = teacher(\'egon\',\'male\',course(\'python\',\'15800\',7))\nclass student:\n    def __init__(self,name,sex,course):\n        self.name = name\n        self.sex = sex\n        self.course = course\n\n\nprint(t1.course)\nprint(t1.course.name)\nprint(t1.course.price)\nprint(t1.course.peroid)\n\nc1 = course(\'python\',15800,7)\ns1 = student(\'maxiaoyu\',\'男\',c1)\n\nprint(s1.course)\nprint(s1.course.name)\nprint(s1.course.price)\nprint(s1.course.peroid)\n\n结果：\n<__main__.course object at 0x00000002D51F0A20>\npython\n15800\n7\n<__main__.course object at 0x00000002D51F0C18>\npython\n15800\n7\n```\n\n## 接口\n\n> python里面没有接口的概念，在父类里面定义接口的概念但是不具体实现。具体的实现在子类，目的就是为了实现归一化的设计。比如，文本文件可以读，调用的方法是read，块设备文件也可以读取，方法也是read，虽然方法都是read但是内部根据子类的设计实现方式不一样，具体的读取方式也是不同的。比如你去驾校是去学开车，而不是去学习开奥迪怎么开，学特斯拉怎么开。\n\n```\nclass animal:\n    def run(self):\n        pass\n    def speak(self):\n        pass\nclass people(animal):\n    def run(self):\n        print(\"人正在走\")\n    def speak(self):\n        print(\"人说话\")\n\nclass pig(animal):\n    def run(self):\n        print(\'猪在走\')\n    def speak(self):\n        print(\"哦哦哦\")\n\npeople1 = people()\npig1 = pig()\n\npeople1.run()\npig1.run()\n\n结果：\n人正在走\n猪在走\n```\n\n那么按照上面的代码的逻辑其实这个animal模拟的接口类其实是没有价值的。即使注释掉代码还是可以正常执行也不会报错。我不能做到让你子类必须继承父类，即使不继承也不会报错。那么针对这个情况我们可以使用raise进行主动抛出异常，如果子类没有对父类（接口模拟类）进行继承和派生自己的内容就会报错，如下的代码：\n\n```\nclass animal:\n    def run(self):\n        raise AttributeError(\"子类必须实现\")\n    def speak(self):\n        raise AttributeError(\"子类必须实现\")\nclass people(animal):\n    # def run(self):\n        # print(\"人正在走\")\n    def speak(self):\n        print(\"人说话\")\n\nclass pig(animal):\n    def run(self):\n        print(\'猪在走\')\n    def speak(self):\n        print(\"哦哦哦\")\n\npeople1 = people()\npig1 = pig()\n\npeople1.run()\npig1.run()\n\n结果：\nTraceback (most recent call last):\n  File \"D:/坚果云同步/Python/Day8（面向对象）/模拟接口.py\", line 21, in <module>\n    people1.run()\n  File \"D:/坚果云同步/Python/Day8（面向对象）/模拟接口.py\", line 3, in run\n    raise AttributeError(\"子类必须实现\")\nAttributeError: 子类必须实现\n```\n\n我people类中没派生出新的run方法，那么肯定就是原生的继承自animal的run方法，那么就会直接这个raise的主动错误的抛出。不过这个方法太low了，因此就涉及到下面一个内容，抽象类。\n\n```\nimport abc\n# abc abstract class\n\nclass animal(metaclass=abc.ABCMeta):\n    @abc.abstractmethod\n    def run(self):\n        pass\n    @abc.abstractmethod\n    def speak(self):\n        pass\nclass people(animal):\n    # def run(self):\n        # print(\"人正在走\")\n    # def speak(self):\n    #     print(\"人说话\")\n    pass\n\n\np1 = people()\np1.run()\n\n结果：\nTraceback (most recent call last):\n  File \"D:/坚果云同步/Python/Day8（面向对象）/模拟接口.py\", line 19, in <module>\n    p1 = people()\nTypeError: Can\'t instantiate abstract class people with abstract methods run, speak\n```\n\n我引入一个模块叫abc，abc是abstract class的缩写，按照上述的写法写完了以后你会发现如果子类没有重新定义继承的函数就会报错，当然这个报错只会在你实例化的时候报错，如果你不实例化的话那是不会报错的。或者实例化后你自己重新定义了继承的方法那也不会报错的。那么这个animal类就是抽象类。\n\n那么为什么叫抽象类呢？平常的类就是属性（技能+变量）的结合体，抽象类的本质还是类，与普通类的区别在于加了装饰器的函数，子类必须实现他们。\n\n","timestamp":1523777648264},{"name":"004-继承深入.md","path":"05-Python/02-面向对象编程/004-继承深入.md","content":"## 继承原理的实现\n\n### 继承的顺序\n\n- python3中：\n\n单继承的话，找属性的时候先会找子类本身，如果子类没有的话会去父类找。不过多继承的情况下又是如何呢？\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-17/51486523.jpg)\n\n```\n# 如下A继承自object，在py3中其实写不写无所谓，但是在py2中就代表的就是新式类\n# 这样写的目的就是不管在py2中还是在py3中代表的都是新式类。\nclass A(object):\n    def test(self):\n        print(\'from A\')\n\nclass B(A):\n    def test(self):\n        print(\'from B\')\n\nclass C(A):\n    def test(self):\n        print(\'from C\')\n\nclass D(B):\n    def test(self):\n        print(\'from D\')\n\nclass E(C):\n    def test(self):\n        print(\'from E\')\n\nclass F(D,E):\n    # def test(self):\n    #     print(\'from F\')\n    pass\nf1=F()\nf1.test()\n\nprint(F.__mro__) #只有新式才有这个属性可以查看线性列表，经典类没有这个属性\n\n#新式类继承顺序:F->D->B->E->C->A->object(广度优先)\n- 如果继承的最终只有一个头，也就是单分支，会把每一条路都走完了然后再找到最后的头。\n- 如果有多个头，那么就单独走完每个头。\n```\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-17/14617092.jpg)\n\n>经典类继承顺序:F->D->B->A->E->C（深度优先）\n- python3中统一都是新式类\n- python2中才分新式类与经典类\n\npython中super的用法，之前提到在子类中调用父类的方法可以像如下这样调用：\n\n```\nclass father():\n    def aaa(self,name):\n        self.name = name\n        print(\'aaa\',name)\n\nclass son(father):\n    def __init__(self,name):\n        father.aaa(self,name)\n        pass\n```\n\n上面的例子中就是在子类中调用父类的方法，次数self就需要显式调用，要明确的把self写上的。现在可以使用super的方法去调用：\n\n```\n\n```\n\nsuper()方法生成的是一个对象，它所代表的就是父类的，那么super.\\_\\_init\\_\\_调用的就是绑定方法。没必要传递self，因此以后调用父类方法的时候直接super().方法名。在python2中需要\n\n```\nsuper(自己的类名,self).父类的方法名(a,b,c)\n```\n\nsuper只能用于新式类，并且代码中如果有涉及到中文注释要在开头声明coding的头部。因此以后要去调用父类需要重用的功能直接使用super就好了。并且python3兼容python2的写法。\n\n### 多态和多态性\n\n多态性：定义统一的接口，通过传入不同类型的值，调用逻辑都一样，但是执行结果是不一样的。\n\n多态指的是同一种事物的多种形态，是通过继承实现的。\n\nsuper的用法。\n\n经典类和新式类有什么区别\n\n### 封装\n\n- 层面一：什么都不用干，比如定义一个类，生成一个对象。\n\n如何进行属性的隐藏：\n\n```\nclass A:\n    __x = 1\n    def test(self):\n        print(\'test A\')\n\nprint(A.__x)\n\n上面的执行是会报错的：\nAttributeError: type object \'A\' has no attribute \'__x\'\n```\n\n来具体看一下A里面的内容：\n\n```\n{\'__module__\': \'__main__\', \'_A__x\': 1, \'test\': <function A.test at 0x000000A69B503A60>, \'__dict__\': <attribute \'__dict__\' of \'A\' objects>, \'__weakref__\': <attribute \'__weakref__\' of \'A\' objects>, \'__doc__\': None}\n```\n\n发现x的属性为\\_A\\_\\_x，那么再调用一次试试：\n\n```\nclass A:\n    __x = 1\n    def test(self):\n        print(\'test A\')\n\n\nprint(A._A__x)\n\n结果：1\n```\n\n那么对应的方法也是`_classname__namespace`这样的。这种语法只在定义的时候才会有变形的效果，如果类或者对象已经产生了，再去定义一个的话就不会有变形的效果了。但是再定义阶段的内部可以直接调用，咋写的就咋调用。\n\n```\nclass A:\n    def __fa(self):\n        print(\'from A\')\n    def test(self):\n        self.__fa()\nclass B(A):\n    def __fa(self):\n        print(\'from B\')\n\nb = B()\nb.test()\n\n结果：from A\n\n分析：\n当在用封装的时候，比如类A和类B，虽然其中都定义了方法，但是再定义完成以后调用的时候他们的本质其实已经是不一样的了。其中A类的__fa方法是_A__fa，B类的是_B__fa。那么分析b对象在调用test()方法的时候，b首先会找自己本身，b本身没有会找B类，B类没有找父类A类，A类里面有，A类中的test方法里调用了self的__fa()方法，其实也就是\"b._A__fa()\"，因此只会返回from A\n```\n\n- 层面二：\n\n#### property\n\nproperty是一种特殊的属性，访问它时会执行一段功能（函数）然后返回值。并且被property装饰过的内容会优于其他的属性去查找。\n\n> 例一：BMI指数（bmi是计算而来的，但很明显它听起来像是一个属性而非方法，如果我们将其做成一个属性，更便于理解）成人的BMI数值：\n>\n> 过轻：低于18.5\n>\n> 正常：18.5-23.9\n>\n> 过重：24-27\n>\n> 肥胖：28-32\n>\n> 非常肥胖, 高于32\n>\n> 　　体质指数（BMI）=体重（kg）÷身高^2（m）\n>\n> 　　EX：70kg÷（1.75×1.75）=22.86\n\n```\nclass BMI:\n    def __init__(self,name,age,height,weight):\n        self.name = name\n        self.age = age\n        self.height = height\n        self.weight = weight\n    @property\n    def bodyindex(self):\n        return self.weight/(self.height**2)\n\np1=BMI(\'maxiaoyu\',26,1.81,89)\nprint(p1.bodyindex)\n```\n\n如果再调用p1.bodyinde()的话会报错：\n\n```\nTypeError: \'float\' object is not callable\n```\n\n再来看一下property的用法\n\n```\nclass people:\n    def __init__(self,name):\n        self.__Name = name\n    def name(self):\n        return self.__Name\np = people(\'maxiaoyu\')\nprint(p.name())\n```\n\n将people类中的Name属性封装一下，那么在外部如果不使用`_people__Name`的形式的话那就是访问不到的。那么如果想使用平常的方式取到的话那么那么需要定义一个方法给return一个值回来，于是我们定义个一个name方法用来返回接收到的名字。但是在调用的时候可能别人并不知道name是一个方法，因此这里也可以使用到property：\n\n```\nclass people:\n    def __init__(self,name):\n        self.__Name = name\n    @property\n    def name(self):\n        return self.__Name\np = people(\'maxiaoyu\')\nprint(p.name)\n```\n\n不过这个name本身无法进行修改，比如你用p.name=xxx是肯定会报错的，因为这个name的实质其实是一个函数，函数的返回值=另外一个值本身就是有问题的。那么这里可以用到另外一个方法，`方法名.setter`，这里的方法名是被property修饰过的方法。\n\n```\nclass people:\n    def __init__(self,name):\n        self.__Name = name\n    @property\n    def name(self):\n        return self.__Name\n    @name.setter\n    def name(self,value):\n        if not isinstance(value,str):\n            raise TypeError(\'名字必须为字符串类型\')\n        self.__Name = value\np = people(\'maxiaoyu\')\np.name = \"lamber\"\nprint(p.name)\n\n结果：lamber\n```\n\n添加删除的功能：\n\n```\nclass people:\n    def __init__(self,name):\n        self.__Name = name\n    @property\n    def name(self):\n        return self.__Name\n    @name.setter\n    def name(self,value):\n        if not isinstance(value,str):\n            raise TypeError(\'名字必须为字符串类型\')\n        self.__Name = value\n    @name.deleter\n    def name(self):\n    \tdel self.__Name\n```\n\n#### 静态方法，staticmethod\n\n非绑定方法。就需要设置staticmethod，这个方法就是给类用的，不和对象进行绑定。\n\n```\nimport time\nclass Date:\n    def __init__(self,year,month,day):\n        self.year = year\n        self.month = month\n        self.day = day\n    @staticmethod\n    def now():\n        t = time.localtime()\n        return Date(t.tm_year,t.tm_mon,t.tm_mday)\n    @staticmethod\n    def tomorrow():\n        t = time.localtime(time.time() + 86400)\n        return Date(t.tm_year, t.tm_mon, t.tm_mday)\n\ndate_now = Date.now()\nprint(date_now.__dict__)\n```\n\n#### classmethod\n\n类的绑定方法，会把类自动当做第一个参数传给绑定到类的方法，虽然是给类用的，当然对象也是可以用的。但是自动传的值始终是类的。\n\n`__str__`的用法，它是定义在类的内部，必须返回一个字符串类型，当打印由这个类产生的对象的时候会触发执行。即使平常我们不写这个`__str__`，它也会执行。\n\n```\nclass A:\n    def __init__(self,name,age):\n        self.name = name\n        self.age = age\n    def __str__(self):\n        return \"name %s;age %s\" %(self.name,self.age)\na = A(\'lamber\',13)\nprint(a)\n\n结果：\nname lamber;age 13\n```\n\n示例：\n\n```\nimport time\nclass Date:\n    def __init__(self,year,month,day):\n        self.year = year\n        self.month = month\n        self.day = day\n    @classmethod\n    def now(cls):\n        t = time.localtime()\n        obj = cls(t.tm_year, t.tm_mon, t.tm_mday)\n        return obj\n    @classmethod\n    def tomorrow(cls):\n        t = time.localtime(time.time() + 86400)\n        return cls(t.tm_year, t.tm_mon, t.tm_mday)\n\nclass eurodate(Date):\n    def __str__(self):\n        return \'haha\'\n\ne = eurodate.now()\nprint(e)\n```\n\n\n\n\n\n","timestamp":1523777648264},{"name":"005-反射.md","path":"05-Python/02-面向对象编程/005-反射.md","content":"## isinstance(obj,cls) & issubclass(sub,super)\n\n- isinstance(\'aaa\',str)\n\n查看是不是子类\n\n```python\nclass A:\n    pass\nclass B(A):\n    pass\n\nprint(B.__bases__)\nprint(issubclass(B,A))\n\n结果：\n(<class \'__main__.A\'>,)\nTrue\n```\n\n## 反射\n\n反射又称为自省，python中面向对象的反射表示通过字符串的形式操作对象相关属性，python中的一切事物都是对象（都可以使用反射）。\n\n### hasattr\n\n判断object中有没有一个name字符串对应的方法或属性\n\n\n```\nclass People:\n    country = \'China\'\n    def __init__(self,name):\n        self.name = name\np = People(\'lamber\')\nprint(hasattr(p,\'country\'))\n\nTrue\n```\n\n### getattr\n\n获取到一个对象的某个属性\n\n```\nclass People:\n    country = \'China\'\n    def __init__(self,name):\n        self.name = name\n    def walk(self):\n        print(\'%s is walking\' %self.name)\np = People(\'lamber\')\n\nprint(getattr(p,\'country\'))\nf = getattr(p,\'walk\')\nprint(f)\nf()\n\nprint(getattr(p,\'hehe\',\'您找的属性并不存在\'))\n如果要找的属性不存在的话那么getattr的第三个参数回作为默认的返回值返回。\n```\n\n或者我们可以先用hasattr判断一下是否存在然后再用getattr去操作。\n\n### setattr\n\n```\nsetattr(p,\'sex\',\'male\')\nprint(p.__dict__)\n\n结果：\n{\'name\': \'lamber\', \'sex\': \'male\'}\n```\n\n### delattr\n\n```\nsetattr(p,\'sex\',\'male\')\nprint(p.__dict__)\ndelattr(p,\'name\')\nprint(p.__dict__)\n\n\n结果\n{\'name\': \'lamber\', \'sex\': \'male\'}\n{\'sex\': \'male\'}\n```\n\n#### 小结\n\n上面的四种属性，同样适用于类。\n\n### 反射当前模块成员\n\n```\nimport sys\n\ndef s1():\n    print(\'s1\')\ndef s2():\n    print(\'s2\')\n\n# 在当前位置获取当前模块\nprint(__name__)\nthis_module = sys.modules[__name__]\nprint(this_module)\nprint(hasattr(this_module,\'s1\'))\nprint(getattr(this_module,\'s2\'))\n```\n\n#### 反射的应用\n\n\n\n### attr系列\n\n- `__setattr__`：一碰到给对象设置属性就会触发。对应三个参数，self、key、value\n\n```\nclass Foo:\n    def __init__(self,name):\n        self.name = name\n    def __setattr__(self, key, value):\n        if not isinstance(value,str):\n            raise TypeError(\'Value must be str type\')\n        self.__dict__[key]=value\n\nf1 = Foo(\'lamber\')\nf1.sex = \'male\'\nprint(f1.__dict__)\n\n结果：{\'name\': \'lamber\', \'sex\': \'male\'}\n```\n\n- `__getattr__`：普通的调用并不会触发getattr，只有在调用不存在的属性的时候才会调用getattr\n\n```\nclass Foo:\n    def __init__(self,x):\n        self.name = x\n    def __getattr__(self, item):\n        print(item)\nf1 = Foo(\'lamber\')\nprint(f1.hahaha)\n\n结果：\nhahaha\nNone\n```\n\n- `__delattr__`：在调用del删除方法的时候会触发调用\n\n````\nclass Foo:\n    def __init__(self,name):\n        self.name = name\n    def __setattr__(self, key, value):\n        if not isinstance(value,str):\n            raise TypeError(\'Value must be str type\')\n        self.__dict__[key]=value\n    def __delattr__(self, item):\n        del self.__dict__[item]\n       #self.__dict__.pop(item)\n\nf1 = Foo(\'lamber\')\nf1.sex = \'male\'\ndel f1.sex\nprint(f1.__dict__)\n\n结果：{\'name\': \'lamber\'}\n````\n\n### 定制自己的数据类型\n\n基于继承的原理定制自己的数据类型，继承标准类型：\n\n```\n# 比如定制一个数字列表，只能存数字不能存别的。\nclass List(list):\n    def append(self,p_object):\n        if not isinstance(p_object,int):\n            raise TypeError(\'must be int\')\n        super().append(p_object)\n    def insert(self, index: int,object):\n        if not isinstance(object,int):\n            raise TypeError(\'must be int\')\n        super().insert(index,object)\n\nl1 = List([1,2,3,4])\nl1.insert(0,2333)\nprint(l1)\n```\n\n当不能使用继承的时候，来模拟一个日志记录的功能。\n\n```\nimport time\n\nclass Open:\n    def __init__(self,filepath,mode=\'r\',encoding=\'utf-8\'):\n        self.filepath = filepath\n        self.mode = mode\n        self.encoding = encoding\n        self.x = open(filepath,mode=mode,encoding=encoding)\n    def write(self,line):\n        t = time.strftime(\'%Y-%m-%d %X\')\n        self.x.write(\'%s %s\' %(t,line))\nf = Open(\'a.txt\',\'w\')\nf.write(\'hahaha\\n\')\nf.write(\'hahaha\\n\')\nf.write(\'hahaha\\n\')\n```\n\n查看a.txt的内容：\n\n```\n2017-07-25 16:25:01 hahaha\n2017-07-25 16:25:01 hahaha\n2017-07-25 16:25:01 hahaha\n```\n\n在无法使用继承的情况下添加文件操作的其他方法(授权的实现)：\n\n```python\nimport time\n\nclass Open:\n    def __init__(self,filepath,mode=\'r\',encoding=\'utf-8\'):\n        self.filepath = filepath\n        self.mode = mode\n        self.encoding = encoding\n        self.x = open(filepath,mode=mode,encoding=encoding)\n    def write(self,line):\n        t = time.strftime(\'%Y-%m-%d %X\')\n        self.x.write(\'%s %s\' %(t,line))\n    def __getattr__(self, item):\n        return getattr(self.x,item)\nfile1 = Open(\'a.txt\',\'r\')\nres = file1.read()\nprint(res)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","timestamp":1523777648264},{"name":"006-深复制和浅赋值.md","path":"05-Python/02-面向对象编程/006-深复制和浅赋值.md","content":"# 浅copy和深copy\n\n## 浅：copy.copy \n\n```\n>>> import copy\n>>> a = [1,2,3]\n>>> b = copy.copy(a)\n>>> id(a)\n139823673812320\n>>> id(b)\n139823673942600\n```\n\n通过上面的例子其实可以发现a和b其实是两个列表，之所以说是浅复制是因为copy.copy方法仅仅是复制了列表的一个框。以及内部引用的值的内存地址。\n\n```\n>>> print(id(a[0]),id(a[1]),id(a[2]))\n(29535336, 29535312, 29535288)\n>>> print(id(b[0]),id(b[1]),id(b[2]))\n(29535336, 29535312, 29535288)\n```\n\n发现a和b内的值的内存地址是一样的，那么我们就可以理解为下面这个图。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-26/46611517.jpg)\n\n那么如果我改a的话其实b是不会受到影响的，比如我改a[0]，相当于a的第一个元素指向另外的一个内存地址。\n\n```\n>>> a[0] = 4\n>>> a\n[4, 2, 3]\n>>> b\n[1, 2, 3]\n```\n\n图例类似于下图：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-7-26/33931495.jpg)\n\n`b = list(a)`和`b = copy.copy(a)`是一个效果。\n\n因此浅copy我可以理解为虽然复制了a这个对象，但是对象中的元素依然是引用的。\n\nhttp://www.cnblogs.com/Eva-J/p/5534037.html\n\nhttp://blog.csdn.net/u010367506/article/details/31736033\n\nhttp://python.jobbole.com/82294/\n\nhttp://www.cnblogs.com/mcznhaha/p/4820068.html","timestamp":1523777648264},{"name":"007-新式类比经典类.md","path":"05-Python/02-面向对象编程/007-新式类比经典类.md","content":"## 新式类和经典类的区别\n\n新式类要求类必须继承一个类，如果没有继承的话那么默认就是继承的object类，你可以认为object类是万类之源，说是类的祖宗不为过。只不过在python2中允许不继承任何类，那么这个类就是经典类，python2要想创建一个新之类，那么必须有所继承，没继承的时候也要显式的写上继承object类，不过在python3中就不需要那么麻烦了，因为python3全是新式类，如果你不写的话隐式的会为你继承object类。\n\n- 在python2中分为新式类和经典类，在python3中全部都为新式类。\n- 在python2中新式类是显式的，python3中是默认是隐式的\n\n```\n# 比如如下一个类：\nclass A:\n    pass\n这个类如果再python2中就是经典类，但是在python3中就是新式类，因为在python3中，新式类是隐式的，python3中的\"class A\"相当于python2中的class A(object)的，因此在python2中如果要定义新式类的话应该按照如下的方式进行定义：\n\nclass A(object):\n\tpass\n如果python2中没有显式的继承object类的话那么就是经典类\n```\n\n- 在涉及到多继承的时候遍历搜索的方式不一样。经典类是深度优先遍历搜索，新式类是广度优先遍历搜索。\n- 新式类对象可以直接通过`__class__`属性获取自身类型:type\n- 新式类增加了`__slots__`内置属性, 可以把实例属性的种类锁定到__slots__规定的范围之中\n- 新式类增加了·`__getattribute__`方法\n\n## 那么新式类的优势是什么？\n\n","timestamp":1523777648264},{"name":"008-面向对象总结.md","path":"05-Python/02-面向对象编程/008-面向对象总结.md","content":"# 面向对象编程汇总\n\n>面向对象的编程是一种编程的设计思想，不同于面向过程的编程，面向过程的编程可以理解为一条流水线，流程中的每一个环节都设计好了，考虑的很周全。相对来讲因为流程清晰降低了程序的复杂度，但是换个角度来说可迁移性和可扩展性相对来说就很低了。比如杀猪的生产线不能生产手机，同样生产手机的生产线不能造汽车。\n>\n>可以说面向过程的关注点是过程，也就是流水线的每一个部分我们用什么方法去实现，而面向对象的编程是关注的对象。过程已经不再是面向对象关注的重点，而且很多情况下你根本无法预先知道过程是什么样子的。比如英雄联盟，一场十个英雄对战，谁什么时间点什么操作，谁能拿mvp，谁杀人数最多，经济最好……这个东西其实都是未知的，无法预测的，只有你打了你才会知道。我们只需要关注具体每个英雄具有什么操作，什么技能就好了。\n\n## 1、相关内容介绍\n\n### 1.1 类&对象\n\n什么是类？类可以理解为一类实体特征的集合，比如人类、狗类、猫类等等。这些类里面包含了这一类事物的共同的特征和技能。那么什么是对象呢？对象就是一个类的对照出来的实体，比如一只狗，不管他是什么狗（金毛，二哈还是柴犬还是狮子狗），重要的是这里有一只狗，它是属于狗这个类的。这就是对象，一个真真正正实际存在的实例，个体。\n\n在面向对象的程序设计过程当中我们可以把自己理解为造物主，我们定义了狗类，猫类，人类等等这些具有共同特征的大类，我们可以把这个类理解创造实体的蓝图或者是模子，通过这个模子我们创造出一个一个的实体，也就是我们所说的对象，这个过程叫做实例化。\n\n在python中一切皆为对象，并且在python3中统一了类和类型的概念，类型就是类。\n\n那么说了这么多举个例子，英雄联盟里有一百大几的英雄，我们就可以认为每一个英雄就是一个类，比如艾希类，盖伦类，瑞文类等等。每一个英雄类都有自己的特征和继承，比如英雄的名字，所属的阵营，英雄的语音，被动技能+QWER这四个技能。那么打匹配的时候下路对线你可以选艾希adc对面也可以选艾希adc，你们的艾希都是属于艾希这一个类的，不可能你比对面少个w技能还是少个r技能，你们所选到的英雄都是一个真实存在的艾希，这个就是通过艾希这个类实例化而得到的类的实体。至于之后的谁输谁赢那就看谁的操作比较菜了，这两个对象交互的过程其实是未知的，不可预测的。","timestamp":1523777648264},{"name":"009-slots与迭代器协议.md","path":"05-Python/02-面向对象编程/009-slots与迭代器协议.md","content":"\n```\nclass Foo:\n    def __init__(self,name):\n        self.name = name\n    def __getitem__(self, item):\n        return self.__dict__[item]\n    def __setitem__(self, key, value):\n        self.__dict__[key] = value\n    def __delitem__(self, key):\n        self.__dict__.pop(key)\nf = Foo(\'lamber\')\nprint(f.name)\nf[\'age\'] = 25\nprint(f.__dict__)\ndel f[\'age\']\nprint(f.__dict__)\nprint(f[\'name\'])\n\n结果：\nlamber\n{\'name\': \'lamber\', \'age\': 25}\n{\'name\': \'lamber\'}\nlamber\n```\n\n其实`__getitem__ __setitem__ __delitem__`的方法就是以字典的形式进行添加，查询，删除对象中的属性。因此也就是对应不同的操作值的形式调用的get，set，del方法不同。要进行区分。\n\n## slots\n\n- \\_\\_slots\\_\\_是什么:是一个类变量,变量值可以是列表,元祖,或者可迭代对象,也可以是一个字符串(意味着所有实例只有一个数据属性)\n- 引子:使用点来访问属性本质就是在访问类或者对象的\\_\\_dict\\_\\_属性字典(类的字典是共享的,而每个实例的是独立的)\n- 为何使用\\_\\_slots\\_\\_:字典会占用大量内存,如果你有一个属性很少的类,但是有很多实例,为了节省内存可以使用\\_\\_slots\\_\\_取代实例的\\_\\_dict\\_\\_。当你定义\\_\\_slots\\_\\_后,\\_\\_slots\\_\\_就会为实例使用一种更加紧凑的内部表示。实例通过一个很小的固定大小的数组来构建,而不是为每个实例定义一个字典,这跟元组或列表很类似。在\\_\\_slots\\_\\_中列出的属性名在内部被映射到这个数组的指定小标上。使用\\_\\_slots\\_\\_一个不好的地方就是我们不能再给实例添加新的属性了,只能使用在\\_\\_slots\\_\\_中定义的那些属性名。\n- 注意事项:\\_\\_slots\\_\\_的很多特性都依赖于普通的基于字典的实现。另外,定义了\\_\\_slots\\_\\_后的类不再 支持一些普通类特性了,比如多继承。大多数情况下,你应该只在那些经常被使用到 的用作数据结构的类上定义\\_\\_slots\\_\\_比如在程序中需要创建某个类的几百万个实例对象 。关于\\_\\_slots\\_\\_的一个常见误区是它可以作为一个封装工具来防止用户给实例增加新的属性。尽管使用\\_\\_slots\\_\\_可以达到这样的目的,但是这个并不是它的初衷。更多的是用来作为一个内存优化工具。\n\n```\nclass People:\n    __slots__ = [\'x\']\n    # x = 1\n    # def __init__(self,name):\n    #     self.name = name\n    # def run(self):\n    #     pass\n\nprint(People.__dict__)\np1 = People\n\n结果：\n{\'__module__\': \'__main__\', \'__slots__\': [\'x\'], \'x\': <member \'x\' of \'People\' objects>, \'__doc__\': None}\n\np1 = People()\nprint(p1.__dict__)\n\n结果：\nAttributeError: \'People\' object has no attribute \'__dict__\'\n```\n\n通过上面的例子可以看出，使用了\\_\\_slots\\_\\_方法的类，在实例化的时候，生成的对象并不会创建命名空间，因此也就不会产生`__dict__`这个字典。属性只能设置slots里面定义的属性，非定义的属性会报错。也就是说我们只能设置x属性。\n\n```\np1.x = 1\nprint(p1.x)\n\n结果：1\n```\n\n小结：类里面加`__slots__`方法\n\n- 不会为对象产生命名空间（没有dict），节省空间\n- 只允许设置slots里设置的值，因此节省内存的同时限制可以设置的属性。因此可以限制这种类生成的对象具有一致的属性。\n\nslots用来产生固定属性，但是并且需要多个对象的情况下。\n\n## __next\\_\\_和\\_\\_iter\\_\\_实现迭代器协议\n\n```\nfrom collections import Iterator,Iterable\nclass Foo:\n    def __init__(self,start):\n        self.start = start\n    def __iter__(self):\n        return self\n    def __next__(self):\n        if self.start > 10:\n            raise StopIteration\n        n = self.start\n        self.start+=1\n        return n\nf = Foo(0)\nprint(isinstance(f,Iterable))\nprint(isinstance(f,Iterator))\nprint(f.__next__())\nprint(f.__next__())\nprint(f.__next__())\nprint(f.__next__())\nprint(f.__next__())\nprint(f.__next__())\nprint(f.__next__())\n```\n\n模拟一个range\n\n```\nclass Range:\n    def __init__(self,start,stop):\n        self.start = start\n        self.stop = stop\n    def __iter__(self):\n        return self\n    def __next__(self):\n        if self.start == self.stop:\n            raise StopIteration\n        n = self.start\n        self.start += 1\n        return n\nfor i in Range(0,5):\n    print(i)\n```\n\n### 析构函数\n\n`__del__`\n\n在对象被销毁的时候就会触发析构函数。因此可以在析构函数里加上self.句柄.close来关闭掉打开的文件。\n\n### 上下文管理协议\n\n```\nclass Foo:\n    def __enter__(self):\n        print(\'enter\')\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\'exit\')\n        print(\'exc_type\',exc_type)\n        print(\'exc_val\',exc_val)\n        print(\'exc_tb\',exc_tb)\n\nwith Foo():\n    print(\'with foo的子代码块\')\n    \n结果：\nenter\nwith foo的子代码块\nexit\nexc_type None\nexc_val None\nexc_tb None\n\nwith Foo(): 就相当于res = Foo().__enter__()\nenter的返回值就是with foo() as obj中的obj\n\n当抛出异常的时候\n\nclass Foo:\n    def __enter__(self):\n        print(\'enter\')\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\'exit\')\n        print(\'exc_type\',exc_type)\n        print(\'exc_val\',exc_val)\n        print(\'exc_tb\',exc_tb)\n\nwith Foo() as obj:\n    print(\'with foo的子代码块\')\n    raise NameError(\'name undefined\')\n\n\n结果：\nC:\\Users\\马晓雨\\AppData\\Local\\Programs\\Python\\Python36\\python3.exe D:/坚果云同步/Python/Day11/模拟range.py\nTraceback (most recent call last):\nenter\nwith foo的子代码块\n  File \"D:/坚果云同步/Python/Day11/模拟range.py\", line 26, in <module>\nexit\nexc_type <class \'NameError\'>\nexc_val name undefined\nexc_tb <traceback object at 0x000000D5FAB84908>\n    raise NameError(\'name undefined\')\nNameError: name undefined\n\n一旦抛出异常，后面的代码就不会运行了，也就是意味着with的子代码块运行完了，然后就会触发exit方法。当然如果再exit里面return一个true就不会抛出异常了。\n\nclass Open:\n    def __init__(self,filepath,mode,encoding=\'utf-8\'):\n        self.filepath = filepath\n        self.mode = mode\n        self.encoding = encoding\n        self.f = open(filepath,mode=mode,encoding=encoding)\n    def write(self,line):\n        self.f.write(line)\n    def __getattr__(self,item):\n        return getattr(self.f,item)\n    def __enter__(self):\n        return self\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.f.close()\n       #return True\n\nwith Open(\'a.txt\',\'w\') as write_file: # write_file = Open(\'a.txt\',\'w\')\n    write_file.write(\'test\\n\')\n```\n\n### \\_\\_call\\_\\_\n\n在类中加上call方法以后，那么对象加小括号也可以了，也就是说实例化后的对象加括号也可以变成一个可调用对象。\n\n#### 应用\n\ntype叫元类，是用来控制产生类的。\n\n通过type就可以自己去定制类的产生了。\n\n### 自定制元类\n\n","timestamp":1523777648264},{"name":"010-模块和包.md","path":"05-Python/02-面向对象编程/010-模块和包.md","content":"一个py文件就是一个模块\n\n一个py文件除了可以执行（执行的时候叫脚本文件）之外，还可以供他人使用。\n\n模块分为自定义模块，内建模块（比如sys），第三方的模块（第三方开源）\n\n导入分为两种\n\n- import：import的时候不要加py的后缀名，\n\n导入模块会干三件事：\n\n1. 创建NameSpace，用来存放导入的模块中定义的名字\n2. 基于刚刚创建的名称空间执行xxx.py.如果有同名的全局变量，在导入之前定义的会被覆盖\n3. 创建模块名spam，指向刚刚创建的名称空间。调用的时候直接spam.xxx\n\n- from xxx import xxx\n\n\n\n","timestamp":1523777648264},{"name":"011-元类(1).md","path":"05-Python/02-面向对象编程/011-元类(1).md","content":"# 元类\n\n> Stack Overflow上有一个关于元类的很好的回复，我这就不班门弄斧了，直接上文章吧。\n\n## 类的介绍\n\n### 类也是对象\n\n在理解元类之前，你需要先掌握Python中的类。Python中类的概念借鉴于Smalltalk，这显得有些奇特。在大多数编程语言中，类就是一组用来描述如何生成一个对象的代码段。在Python中这一点仍然成立：\n\n```python\n>>> class ObjectCreator(object):\n…       pass\n…\n>>> my_object = ObjectCreator()\n>>> print my_object\n<__main__.ObjectCreator object at 0x8974f2c>\n```\n\n但是，Python中的类还远不止如此。类同样也是一种对象。是的，没错，就是对象。只要你使用关键字class，Python解释器在执行的时候就会创建一个对象。下面的代码段：\n\n```python\n>>> class ObjectCreator(object):\n…       pass\n…\n```\n\n将在内存中创建一个对象，名字就是ObjectCreator。**这个对象（类）自身拥有创建对象（类实例）的能力，而这就是为什么它是一个类的原因。**但是，它的本质仍然是一个对象，于是乎你可以对它做如下的操作：\n\n- 你可以将它赋值给一个变量\n- 你可以拷贝它\n- 你可以为它增加属性\n- 你可以将它作为函数参数进行传递\n\nExample follows：\n\n```python\n>>> print ObjectCreator     # 你可以打印一个类，因为它其实也是一个对象\n<class \'__main__.ObjectCreator\'>\n>>> def echo(o):\n…       print o\n…\n>>> echo(ObjectCreator)                 # 你可以将类做为参数传给函数\n<class \'__main__.ObjectCreator\'>\n>>> print hasattr(ObjectCreator, \'new_attribute\')\nFasle\n>>> ObjectCreator.new_attribute = \'foo\' #  你可以为类增加属性\n>>> print hasattr(ObjectCreator, \'new_attribute\')\nTrue\n>>> print ObjectCreator.new_attribute\nfoo\n>>> ObjectCreatorMirror = ObjectCreator # 你可以将类赋值给一个变量\n>>> print ObjectCreatorMirror()\n<__main__.ObjectCreator object at 0x8997b4c>\n```\n\n### **动态地创建类**\n\n因为类也是对象，你可以在运行时动态的创建它们，就像其他任何对象一样。首先，你可以在函数中创建类，使用class关键字即可。\n\n```python\n>>> def choose_class(name):\n…       if name == \'foo\':\n…           class Foo(object):\n…               pass\n…           return Foo     # 返回的是类，不是类的实例\n…       else:\n…           class Bar(object):\n…               pass\n…           return Bar\n…\n>>> MyClass = choose_class(\'foo\')\n>>> print MyClass              # 函数返回的是类，不是类的实例\n<class \'__main__\'.Foo>\n>>> print MyClass()            # 你可以通过这个类创建类实例，也就是对象\n<__main__.Foo object at 0x89c6d4c>\n```\n\n但这还不够动态，因为你仍然需要自己编写整个类的代码。由于类也是对象，所以它们必须是通过什么东西来生成的才对。当你使用class关键字时，Python解释器自动创建这个对象。但就和Python中的大多数事情一样，Python仍然提供给你手动处理的方法。还记得内建函数type吗？这个古老但强大的函数能够让你知道一个对象的类型是什么，就像这样：\n\n```python\n>>> print type(1)\n<type \'int\'>\n>>> print type(\"1\")\n<type \'str\'>\n>>> print type(ObjectCreator)\n<type \'type\'>\n>>> print type(ObjectCreator())\n<class \'__main__.ObjectCreator\'>\n```\n\n这里，type有一种完全不同的能力，它也能动态的创建类。type可以接受一个类的描述作为参数，然后返回一个类。（我知道，根据传入参数的不同，同一个函数拥有两种完全不同的用法是一件很傻的事情，但这在Python中是为了保持向后兼容性）\n\ntype可以像这样工作：\n\n```\ntype(类名, 父类的元组（针对继承的情况，可以为空），包含属性的字典（名称和值）)\n```\n\n比如下面的代码：\n\n```\n>>> class MyShinyClass(object):\n…       pass\n```\n\n可以手动像这样创建：\n\n```\n>>> MyShinyClass = type(\'MyShinyClass\', (), {})  # 返回一个类对象\n>>> print MyShinyClass\n<class \'__main__.MyShinyClass\'>\n>>> print MyShinyClass()  #  创建一个该类的实例\n<__main__.MyShinyClass object at 0x8997cec>\n```\n\n你会发现我们使用“MyShinyClass”作为类名，并且也可以把它当做一个变量来作为类的引用。类和变量是不同的，这里没有任何理由把事情弄的复杂。\n\ntype 接受一个字典来为类定义属性，因此\n\n```\n>>> class Foo(object):\n…       bar = True\n```\n\n可以翻译为：\n\n```\n>>> Foo = type(\'Foo\', (), {\'bar\':True})\n```\n\n并且可以将Foo当成一个普通的类一样使用：\n\n```Python\n>>> print Foo\n<class \'__main__.Foo\'>\n>>> print Foo.bar\nTrue\n>>> f = Foo()\n>>> print f\n<__main__.Foo object at 0x8a9b84c>\n>>> print f.bar\nTrue\n```\n\n当然，你可以向这个类继承，所以，如下的代码：\n\n```Py\n>>> class FooChild(Foo):\n…       pass\n```\n\n就可以写成：\n\n```python\n>>> FooChild = type(\'FooChild\', (Foo,),{})\n>>> print FooChild\n<class \'__main__.FooChild\'>\n>>> print FooChild.bar   # bar属性是由Foo继承而来\nTrue\n```\n\n最终你会希望为你的类增加方法。只需要定义一个有着恰当签名的函数并将其作为属性赋值就可以了。\n\n```python\n>>> def echo_bar(self):\n…       print self.bar\n…\n>>> FooChild = type(\'FooChild\', (Foo,), {\'echo_bar\': echo_bar})\n>>> hasattr(Foo, \'echo_bar\')\nFalse\n>>> hasattr(FooChild, \'echo_bar\')\nTrue\n>>> my_foo = FooChild()\n>>> my_foo.echo_bar()\nTrue\n```\n\n你可以看到，在Python中，类也是对象，你可以动态的创建类。这就是当你使用关键字class时Python在幕后做的事情，而这就是通过元类来实现的。\n\n## 什么是元类\n\n元类就是用来创建类的“东西”。你创建类就是为了创建类的实例对象，不是吗？但是我们已经学习到了Python中的类也是对象。好吧，元类就是用来创建这些类（对象）的，元类就是类的类，你可以这样理解 为：\n\n```python\nMyClass = MetaClass()\nMyObject = MyClass()\n```\n\n你已经看到了type可以让你像这样做：\n\n```python\nMyClass = type(\'MyClass\', (), {})\n```\n\n这是因为函数type实际上是一个元类。type就是Python在背后用来创建所有类的元类。现在你想知道那为什么type会全部采用小写形式而不是Type呢？好吧，我猜这是为了和str保持一致性，str是用来创建字符串对象的类，而int是用来创建整数对象的类。type就是创建类对象的类。你可以通过检查\\_\\_class\\_\\_属性来看到这一点。Python中所有的东西，注意，我是指所有的东西——都是对象。这包括整数、字符串、函数以及类。它们全部都是对象，而且它们都是从一个类创建而来。\n\n```python\n>>> age = 35\n>>> age.__class__\n<type \'int\'>\n>>> name = \'bob\'\n>>> name.__class__\n<type \'str\'>\n>>> def foo(): pass\n>>>foo.__class__\n<type \'function\'>\n>>> class Bar(object): pass\n>>> b = Bar()\n>>> b.__class__\n<class \'__main__.Bar\'>\n```\n\n现在，对于任何一个\\_\\_class\\_\\_的\\_\\_class\\_\\_属性又是什么呢？\n\n```python\n>>> a.__class__.__class__\n<type \'type\'>\n>>> age.__class__.__class__\n<type \'type\'>\n>>> foo.__class__.__class__\n<type \'type\'>\n>>> b.__class__.__class__\n<type \'type\'>\n```\n\n因此，元类就是创建类这种对象的东西。如果你喜欢的话，可以把元类称为“类工厂”（不要和工厂类搞混了:D） type就是Python的内建元类，当然了，你也可以创建自己的元类。\n\n### **__metaclass__****属性**\n\n你可以在写一个类的时候为其添加\\_\\_metaclass\\_\\_属性。\n\n```python\nclass Foo(object):\n\t__metaclass__ = something…\n[…]\n```\n\n如果你这么做了，Python就会用元类来创建类Foo。小心点，这里面有些技巧。你首先写下class Foo(object)，但是类对象Foo还没有在内存中创建。Python会在类的定义中寻找\\_\\_metaclass\\_\\_属性，如果找到了，Python就会用它来创建类Foo，如果没有找到，就会用内建的type来创建这个类。把下面这段话反复读几次。当你写如下代码时 :\n\n```python\nclass Foo(Bar):\n    pass\n```\n\nPython做了如下的操作：\n\nFoo中有\\_\\_metaclass\\_\\_这个属性吗？如果是，Python会在内存中通过\\_\\_metaclass\\_\\_创建一个名字为Foo的类对象（我说的是类对象，请紧跟我的思路）。如果Python没有找到\\_\\_metaclass\\_\\_，它会继续在Bar（父类）中寻找\\_\\_metaclass\\_\\_属性，并尝试做和前面同样的操作。如果Python在任何父类中都找不到\\_\\_metaclass\\_\\_，它就会在模块层次中去寻找\\_\\_metaclass\\_\\_，并尝试做同样的操作。如果还是找不到\\_\\_metaclass\\_\\_,Python就会用内置的type来创建这个类对象。\n\n现在的问题就是，你可以在\\_\\_metaclass\\_\\_中放置些什么代码呢？答案就是：可以创建一个类的东西。那么什么可以用来创建一个类呢？type，或者任何使用到type或者子类化type的东东都可以。\n\n### **自定义元类**\n\n元类的主要目的就是为了当创建类时能够自动地改变类。通常，你会为API做这样的事情，你希望可以创建符合当前上下文的类。假想一个很傻的例子，你决定在你的模块里所有的类的属性都应该是大写形式。有好几种方法可以办到，但其中一种就是通过在模块级别设定\\_\\_metaclass\\_\\_。采用这种方法，这个模块中的所有类都会通过这个元类来创建，我们只需要告诉元类把所有的属性都改成大写形式就万事大吉了。\n\n幸运的是，\\_\\_metaclass\\_\\_实际上可以被任意调用，它并不需要是一个正式的类（我知道，某些名字里带有‘class’的东西并不需要是一个class，好好理解下，这很有帮助）。所以，我们这里就先以一个简单的函数作为例子开始。\n\n```python\n# 元类会自动将你通常传给‘type’的参数作为自己的参数传入\ndef upper_attr(future_class_name, future_class_parents, future_class_attr):\n    \'\'\'返回一个类对象，将属性都转为大写形式\'\'\'\n    #  选择所有不以\'__\'开头的属性\n    attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith(\'__\'))\n    # 将它们转为大写形式\n    uppercase_attr = dict((name.upper(), value) for name, value in attrs)\n \n    # 通过\'type\'来做类对象的创建\n    return type(future_class_name, future_class_parents, uppercase_attr)\n \n__metaclass__ = upper_attr  #  这会作用到这个模块中的所有类\n \nclass Foo(object):\n    # 我们也可以只在这里定义__metaclass__，这样就只会作用于这个类中\n    bar = \'bip\'\n```\n\n```python\nprint hasattr(Foo, \'bar\')\n# 输出: False\nprint hasattr(Foo, \'BAR\')\n# 输出:True\n \nf = Foo()\nprint f.BAR\n# 输出:\'bip\'\n```\n\n现在让我们再做一次，这一次用一个真正的class来当做元类。\n\n```python\n# 请记住，\'type\'实际上是一个类，就像\'str\'和\'int\'一样\n# 所以，你可以从type继承\nclass UpperAttrMetaClass(type):\n    # __new__ 是在__init__之前被调用的特殊方法\n    # __new__是用来创建对象并返回之的方法\n    # 而__init__只是用来将传入的参数初始化给对象\n    # 你很少用到__new__，除非你希望能够控制对象的创建\n    # 这里，创建的对象是类，我们希望能够自定义它，所以我们这里改写__new__\n    # 如果你希望的话，你也可以在__init__中做些事情\n    # 还有一些高级的用法会涉及到改写__call__特殊方法，但是我们这里不用\n    def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr):\n        attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith(\'__\'))\n        uppercase_attr = dict((name.upper(), value) for name, value in attrs)\n        return type(future_class_name, future_class_parents, uppercase_attr)\n```\n\n但是，这种方式其实不是OOP。我们直接调用了type，而且我们没有改写父类的\\_\\_new\\_\\_方法。现在让我们这样去处理:\n\n```python\n    def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr):\n        attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith(\'__\'))\n        uppercase_attr = dict((name.upper(), value) for name, value in attrs)\n \n        # 复用type.__new__方法\n        # 这就是基本的OOP编程，没什么魔法\n        return type.__new__(upperattr_metaclass, future_class_name, future_class_parents, uppercase_attr)\n```\n\n你可能已经注意到了有个额外的参数upperattr_metaclass，这并没有什么特别的。类方法的第一个参数总是表示当前的实例，就像在普通的类方法中的self参数一样。当然了，为了清晰起见，这里的名字我起的比较长。但是就像self一样，所有的参数都有它们的传统名称。因此，在真实的产品代码中一个元类应该是像这样的：\n\n```python\nclass UpperAttrMetaclass(type):\n    def __new__(cls, name, bases, dct):\n        attrs = ((name, value) for name, value in dct.items() if not name.startswith(\'__\')\n        uppercase_attr  = dict((name.upper(), value) for name, value in attrs)\n        return type.__new__(cls, name, bases, uppercase_attr)\n```\n\n如果使用super方法的话，我们还可以使它变得更清晰一些，这会缓解继承（是的，你可以拥有元类，从元类继承，从type继承）\n\n```python\nclass UpperAttrMetaclass(type):\n    def __new__(cls, name, bases, dct):\n        attrs = ((name, value) for name, value in dct.items() if not name.startswith(\'__\'))\n        uppercase_attr = dict((name.upper(), value) for name, value in attrs)\n        return super(UpperAttrMetaclass, cls).__new__(cls, name, bases, uppercase_attr)\n```\n\n就是这样，除此之外，关于元类真的没有别的可说的了。使用到元类的代码比较复杂，这背后的原因倒并不是因为元类本身，而是因为你通常会使用元类去做一些晦涩的事情，依赖于自省，控制继承等等。确实，用元类来搞些“黑暗魔法”是特别有用的，因而会搞出些复杂的东西来。但就元类本身而言，它们其实是很简单的：\n\n1. 拦截类的创建\n2. 修改类\n3. 返回修改之后的类\n\n**为什么要用metaclass类而不是函数?**\n\n由于\\_\\_metaclass\\_\\_可以接受任何可调用的对象，那为何还要使用类呢，因为很显然使用类会更加复杂啊？这里有好几个原因：\n\n- 意图会更加清晰。当你读到UpperAttrMetaclass(type)时，你知道接下来要发生什么。\n- 你可以使用OOP编程。元类可以从元类中继承而来，改写父类的方法。元类甚至还可以使用元类。\n- 你可以把代码组织的更好。当你使用元类的时候肯定不会是像我上面举的这种简单场景，通常都是针对比较复杂的问题。将多个方法归总到一个类中会很有帮助，也会使得代码更容易阅读。\n- 你可以使用\\_\\_new\\_\\_, \\_\\_init\\_\\_以及\\_\\_call\\_\\_这样的特殊方法。它们能帮你处理不同的任务。就算通常你可以把所有的东西都在\\_\\_new\\_\\_里处理掉，有些人还是觉得用\\_\\_init\\_\\_更舒服些。\n- 哇哦，这东西的名字是metaclass，肯定非善类，我要小心！\n\n## **究竟为什么要使用元类？**\n\n现在回到我们的大主题上来，究竟是为什么你会去使用这样一种容易出错且晦涩的特性？好吧，一般来说，你根本就用不上它：\n\n“元类就是深度的魔法，99%的用户应该根本不必为此操心。如果你想搞清楚究竟是否需要用到元类，那么你就不需要它。那些实际用到元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类。”  —— Python界的领袖 Tim Peters\n\n元类的主要用途是创建API。一个典型的例子是Django ORM。它允许你像这样定义：\n\n```\nclass Person(models.Model):\n    name = models.CharField(max_length=30)\n    age = models.IntegerField()\n```\n\n但是如果你像这样做的话：\n\n```python\nguy  = Person(name=\'bob\', age=\'35\')\nprint guy.age\n```\n\n这并不会返回一个IntegerField对象，而是会返回一个int，甚至可以直接从数据库中取出数据。这是有可能的，因为models.Model定义了\\_\\_metaclass\\_\\_， 并且使用了一些魔法能够将你刚刚定义的简单的Person类转变成对数据库的一个复杂hook。Django框架将这些看起来很复杂的东西通过暴露出一个简单的使用元类的API将其化简，通过这个API重新创建代码，在背后完成真正的工作。\n\n## END\n\n首先，你知道了类其实是能够创建出类实例的对象。好吧，事实上，类本身也是实例，当然，它们是元类的实例。\n\n```python\n>>>class Foo(object): pass\n>>> id(Foo)\n142630324\n```\n\nPython中的一切都是对象，它们要么是类的实例，要么是元类的实例，除了type。type实际上是它自己的元类，在纯Python环境中这可不是你能够做到的，这是通过在实现层面耍一些小手段做到的。其次，元类是很复杂的。对于非常简单的类，你可能不希望通过使用元类来对类做修改。你可以通过其他两种技术来修改类：\n\n- [Monkey patching](http://en.wikipedia.org/wiki/Monkey_patch)\n- class decorators\n\n当你需要动态修改类时，99%的时间里你最好使用上面这两种技术。当然了，其实在99%的时间里你根本就不需要动态修改类 :D\n\n","timestamp":1523777648264},{"name":"012-异常处理.md","path":"05-Python/02-面向对象编程/012-异常处理.md","content":"## 异常介绍\n\n异常就是程序运行时发生错误的信号，在python中,错误触发的异常如下：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-1/22612195.jpg)\n\n### 异常种类\n\n在python中不同的异常可以用不同的类型（python中统一了类与类型，类型即类）去标识，不同的类对象标识不同的异常，一个异常标识一种错误：\n\n```\nAttributeError 试图访问一个对象没有的属性，比如foo.x，但是foo没有属性x\nIOError 输入/输出异常；基本上是无法打开文件\nImportError 无法引入模块或包；基本上是路径问题或名称错误\nIndentationError 语法错误（的子类） ；代码没有正确对齐，缩进错误\nIndexError 下标索引超出序列边界，比如当x只有三个元素，却试图访问x[5]\nKeyError 试图访问字典里不存在的键\nKeyboardInterrupt Ctrl+C被按下\nNameError 使用一个还未被赋予对象的变量\nSyntaxError Python代码非法，代码不能编译(个人认为这是语法错误，写错了）\nTypeError 传入对象类型与要求的不符合\nUnboundLocalError 试图访问一个还未被设置的局部变量，基本上是由于另有一个同名的全局变量，\n导致你以为正在访问它\nValueError 传入一个调用者不期望的值，即使值的类型是正确的\n```\n\n更多异常：\n\n```\nArithmeticError\nAssertionError\nAttributeError\nBaseException\nBufferError\nBytesWarning\nDeprecationWarning\nEnvironmentError\nEOFError\nException\nFloatingPointError\nFutureWarning\nGeneratorExit\nImportError\nImportWarning\nIndentationError\nIndexError\nIOError\nKeyboardInterrupt\nKeyError\nLookupError\nMemoryError\nNameError\nNotImplementedError\nOSError\nOverflowError\nPendingDeprecationWarning\nReferenceError\nRuntimeError\nRuntimeWarning\nStandardError\nStopIteration\nSyntaxError\nSyntaxWarning\nSystemError\nSystemExit\nTabError\nTypeError\nUnboundLocalError\nUnicodeDecodeError\nUnicodeEncodeError\nUnicodeError\nUnicodeTranslateError\nUnicodeWarning\nUserWarning\nValueError\nWarning\nZeroDivisionError\n```\n\n## 异常处理\n\n### 什么是异常处理？\n\npython解释器检测到错误，触发异常（也允许程序员自己触发异常）\n\n程序员编写特定的代码，专门用来捕捉这个异常（这段代码与程序逻辑无关，与异常处理有关）\n\n如果捕捉成功则进入另外一个处理分支，执行你为其定制的逻辑，使程序不会崩溃，这就是异常处理\n\n### 为何要进行异常处理\n\npython解析器去执行程序，检测到了一个错误时，触发异常，异常触发后且没被处理的情况下，程序就在当前异常处终止，后面的代码不会运行，谁会去用一个运行着突然就崩溃的软件。\n\n所以你必须提供一种异常处理机制来增强你程序的健壮性与容错性 \n\n### 如何进行异常处理\n\n首先须知，异常是由程序的错误引起的，语法上的错误跟异常处理无关，必须在程序运行前就修正。\n\n#### 通过if判断来进行异常处理\n\n- if判断式的异常处理只能针对某一段代码，对于不同的代码段的相同类型的错误你需要写重复的if来进行处理。\n- 在你的程序中频繁的写与程序本身无关，与异常处理有关的if，就像是在你的代码中到处拉屎。可读性极其的差\n- 千万不要妄下定论if不能用来异常处理。如果你不服，那你想想在没有学习try...except之前，你的程序难道就没有异常处理，而任由其崩溃么\n\n```\ndef test():\n    print(\'test running\')\nchoice_dic={\n    \'1\':test\n}\nwhile True:\n    choice=input(\'>>: \').strip()\n    if not choice or choice not in choice_dic:continue #这便是一种异常处理机制啊\n    choice_dic[choice]()\n```\n\n#### 使用try...except..来进行异常处理\n\n##### 1、基本使用\n\n```\n语法：\ntry:\n    被检测的代码块\nexcept 异常类型：\n    try中一旦检测到异常，就执行这个位置的逻辑\n    \n示例代码：\n    \nf=open(\'a.txt\')\ng=(line.strip() for line in f)\n\'\'\'\nnext(g)会触发迭代f，依次next(g)就可以读取文件的一行行内容，无论文件a.txt有多大，同一时刻内存中只有一行内容。\n提示：g是基于文件句柄f而存在的，因而只能在next(g)抛出异常StopIteration后才可以执行f.close()\n\'\'\'\n\nf=open(\'a.txt\')\n\ng=(line.strip() for line in f)\nfor line in g:\n    print(line)\nelse:\n    f.close()\n    \n\ntry:\n    f=open(\'a.txt\')\n    g=(line.strip() for line in f)\n    print(next(g))\n    print(next(g))\n    print(next(g))\n    print(next(g))\n    print(next(g))\nexcept StopIteration:\n    f.close()\n```\n\n##### 2、异常类只能用来处理指定的异常情况，如果非指定异常则无法处理。\n\n```\n# 未捕获到异常，程序直接报错\n \ns1 = \'hello\'\ntry:\n    int(s1)\nexcept IndexError as e:\n    print e\n```\n\n##### 3、针对多个异常类型我们可以写多个分支\n\n```\ns1 = \'hello\'\ntry:\n    int(s1)\nexcept IndexError as e:\n    print(e)\nexcept KeyError as e:\n    print(e)\nexcept ValueError as e:\n    print(e)\n```\n\n##### 4、万能异常(Exception)，可以捕获任意异常类型的异常。\n\n```python\ns1 = \'hello\'\ntry:\n    int(s1)\nexcept Exception as e:\n    print(e)\n```\n\n你可能会说既然有万能异常，那么我直接用上面的这种形式就好了，其他异常可以忽略\n\n你说的没错，但是应该分两种情况去看\n\n1.如果你想要的效果是，无论出现什么异常，我们统一丢弃，或者使用同一段代码逻辑去处理他们，那么骚年，大胆的去做吧，只有一个Exception就足够了。\n\n```\ns1 = \'hello\'\ntry:\n    int(s1)\nexcept Exception,e:\n    \'丢弃或者执行其他逻辑\'\n    print(e)\n\n#如果你统一用Exception，没错，是可以捕捉所有异常，但意味着你在处理所有异常时都使用同一个逻辑去处理（这里说的逻辑即当前expect下面跟的代码块）\n```\n\n2.如果你想要的效果是，对于不同的异常我们需要定制不同的处理逻辑，那就需要用到多分支了。当然也可以在多分支后来一个exception\n\n```\ns1 = \'hello\'\ntry:\n    int(s1)\nexcept IndexError as e:\n    print(e)\nexcept KeyError as e:\n    print(e)\nexcept ValueError as e:\n    print(e)\nexcept Exception as e:\n    print(e)\n```\n\n##### 5、异常的其他结构\n\n```\ns1 = \'hello\'\ntry:\n    int(s1)\nexcept IndexError as e:\n    print(e)\nexcept KeyError as e:\n    print(e)\nexcept ValueError as e:\n    print(e)\n#except Exception as e:\n#    print(e)\nelse:\n    print(\'try内代码块没有异常则执行我\')\nfinally:\n    print(\'无论异常与否,都会执行该模块,通常是进行清理工作\') \n```\n\nelse在try内代码执行正常的时候才会执行else里面的逻辑。如果try里面的代码块有异常的话那么就会执行对应的except的了。\n\n那么finally其实就是不管你有没有异常都会执行finally下面的代码块，一般用于清理工作，那么什么是清理工作呢。比如客户端链接远端服务器，然后客户端崩了相当于tcp链接异常被关掉了，但是server端还为client端保存着这个已经无意义的tcp链接，这就是占用无用的资源，因此需要finally这种清理的操作来进行资源的释放。\n\n##### 6、主动抛出异常，raise\n\n```\n#_*_coding:utf-8_*_\n__author__ = \'Linhaifeng\'\n\ntry:\n    raise TypeError(\'类型错误\')\nexcept Exception as e:\n    print(e)\n```\n\n##### 7、自定义异常\n\n其实上面不管是TypeError还是什么属性不存在，他们的本质其实都是类，他们的父类是BaseException，如下：\n\n```\nprint(TypeError.__bases__) # (<class \'Exception\'>,)\n```\n\n因此我们也可以自己自定义一个错误异常类，继承BaseException就可以了。\n\n```\n#_*_coding:utf-8_*_\n\nclass EgonException(BaseException):\n    def __init__(self,msg):\n        self.msg=msg\n    def __str__(self):\n        return self.msg\n\ntry:\n    raise EgonException(\'类型错误\')\nexcept EgonException as e:\n    print(e) \n```\n\n##### 8、断言\n\n```\n# assert 条件\n \nassert 1 == 1\nassert 1 == 2\n\n等价于：\nif not 1 == 1:\n    raise AssertionError\n```\n\n在开发程序的时候，与其让它在运行的时候崩溃，不如在他出现错误条件的时候就崩溃返回错误这是断言的一个用法。\n\n首先什么时候应该使用断言，没有特定的规则，断言应该用于：\n\n- 防御型的编程\n- 运行时检查程序逻辑\n- 检查约定\n- 程序常量\n- 检查文档\n\n针对断言的内容可以参考以下几篇文章：\n\n[Python中不尽如人意的断言](http://www.cnblogs.com/cicaday/p/python-assert.html)\n\n[Python使用断言的最佳时机](https://www.oschina.net/translate/when-to-use-assert)\n\n[Python常用断言](http://www.jianshu.com/p/eea0b0e432da)\n\n##### 9、try..except的方式比较if的方式的好处\n\ntry..except这种异常处理机制就是取代if那种方式，让你的程序在不牺牲可读性的前提下增强健壮性和容错性\n\n异常处理中为每一个异常定制了异常类型（python中统一了类与类型，类型即类），对于同一种异常，一个except就可以捕捉到，可以同时处理多段代码的异常（无需‘写多个if判断式’）减少了代码，增强了可读性 \n\n使用try..except的方式\n\n1. 把错误处理和真正的工作分开来\n2. 代码更易组织，更清晰，复杂的工作任务更容易实现；\n3. 毫无疑问，更安全了，不至于由于一些小的疏忽而使程序意外崩溃了；\n\n##### 10、if判断和try...except...的选择\n\n- if本身就可以来处理异常，只不过if的方式，对于不同代码段的同一种异常，需要重复写多分支的if，而这段多分支if与真正的工作无关，写多了你的程序可读性就会及其的差。\n- try..except的方式，只是python提供给你一种特定的语法结构去做这件事，对于不同代码的同一种异常，python为你定制了一中类型，一个expect就可以捕捉到\n\n## 什么时候该使用异常处理\n\n有的同学会这么想，学完了异常处理后，好强大，我要为我的每一段程序都加上try...except，干毛线去思考它会不会有逻辑错误啊，这样就很好啊，多省脑细胞===》2B青年欢乐多\n\ntry...except应该尽量少用，因为它本身就是你附加给你的程序的一种异常处理的逻辑，与你的主要的工作是没有关系的\n这种东西加的多了，会导致你的代码可读性变差\n\n而且异常处理本就不是你2b逻辑的擦屁股纸，只有在有些异常无法预知的情况下，才应该加上try...except，其他的逻辑错误应该尽量修正","timestamp":1523777648264},{"name":"013-模块导入.md","path":"05-Python/02-面向对象编程/013-模块导入.md","content":"## 模块\n\n### 1、什么是模块\n\n常见的场景：一个模块就是一个包含了python定义和声明的文件，文件名就是模块名字加上.py的后缀。\n\n但其实import加载的模块分为四个通用类别：　\n\n- 使用python编写的代码（.py文件）\n- 已被编译为共享库或DLL的C或C++扩展\n- 包好一组模块的包\n- 使用C编写并链接到python解释器的内置模块\n\n### 2、为何要使用模块\n\n如果你退出python解释器然后重新进入，那么你之前定义的函数或者变量都将丢失，因此我们通常将程序写到文件中以便永久保存下来，需要时就通过python test.py方式去执行，此时test.py被称为脚本script。\n\n随着程序的发展，功能越来越多，为了方便管理，我们通常将程序分成一个个的文件，这样做程序的结构更清晰，方便管理。这时我们不仅仅可以把这些文件当做脚本去执行，还可以把他们当做模块来导入到其他的模块中，实现了功能的重复利用。\n\n### 3、如何去使用模块\n\n可以使用import去导入模块，比如`import spam`没有py后缀名的。那么导入的过程中都做了什么呢？\n\n```\n#spam.py\nprint(\'from the spam.py\')\n\nmoney=1000\n\ndef read1():\n    print(\'spam->read1->money\',money)\n\ndef read2():\n    print(\'spam->read2 calling read\')\n    read1()\n\ndef change():\n    global money\n    money=0\n```\n\n那么import spam都做了哪些事情\n\n- 第一件事：创建NameSpace，用来存放spam.py中定义的名字。\n- 第二件事：基于刚才创建的NameSpace执行spam.py，因此会执行spam里面的print语句，因此我们可以看到是有输出的。\n- 第三件事：创建模块名，指向刚刚创建的名称空间。创建完成以后我们就可以使用“模块名.属性”的方法来找指定的内容了。\n\n当然导入模块只能导入一次，假如同一个模块你在一个文件里导入了很多次，但是其实只会有一次的效果。不会重复运行。\n\n我们可以通过sys模块的modules查看当前都加载了什么模块。\n\n```\nimport spam\nimport sys\nprint(sys.modules)\n```\n\n给导入的模块起一个别名(别名只在当前位置有用)：\n\n```\nimport spam as x\n```\n\n在下面的情况下别名是很有作用的：\n\n```\nif file_format == \'xml\':\n    import xmlreader as reader\nelif file_format == \'csv\':\n    import csvreader as reader\ndata=reader.read_date(filename)\n```\n\n我这边只有reader就好了，不用管你是xml还是csv。\n\n当然我们也可以在一行内导入多个模块，多个模块用逗号隔开，但是不推荐这么做。\n\n### 4、from ... import ...\n\n假如我们要使用spam模块里的money，只能使用spam.money，直接调用money会调用本地py的。那么如果要直接用该咋办，那么可以使用from  import的导入方式。具体的我们可以看一下下面的例子：\n\n```\n#spam.py\nprint(\'from the spam.py\')\n\nmoney=1000\n\ndef read1():\n    print(\'spam->read1->money\',money)\n\ndef read2():\n    print(\'spam->read2 calling read\')\n    read1()\n\ndef change():\n    global money\n    money=0\n```\n\n在模拟测试的py文件中导入这个spam：\n\n```\nfrom spam import money\n\nmoney = \"not from spam\"\n\nprint(money)\n\n结果：\nfrom the spam.py\nnot from spam\n```\n\n我们可以发现这个money其实还是当前定义的，但是我把money注释掉以后再看：\n\n```\n结果：\nfrom the spam.py\n1000\n```\n\n我们就可以直接光明正大的使用单独的money了，但是如果单单是import的话，那么只能打印spam.money，直接打印money会报错的。\n\n综合来讲，其实import和from import差不多都会进行上面说到的三个步骤，但是form import和import的第三步骤的操作有所不同，import是创建模块名指向导入模块创建的命名空间，from不会创建模块名，因此可以直接使用。\n\nfrom import也支持起别名\n\n```\nfrom spam import read1 as read\n```\n\n这个别名是给模块里的属性的别名而不是模块的别名，一个是方便管理再有一个就是避免冲突的问题。当然from import也支持导入多行，加一个括号就好了：\n\n```python\nfrom spam import (read1,read2,money)\n```\n\n也可以使用通配符导入所有（不建议这样去导入，因为导入的内容过多的时候就有可能和当前位置的namespace造成冲突）：\n\n```python\nfrom spam import *\n```\n\n不过我们还可以在被导入的模块里添加一句：\n\n```python\n__all__ = [\'money\',\'read1\'] \n```\n\n这样在需要导入的模块里再进行from spam import \\*的时候导入的内容就是上面这个列表里标识的内容了而不是所有的命名空间的内容了。\n\npython的模块不支持重载，如果在最开始的时候进行导入了，并且途中进行更改再导入是不会生效的，因为针对同一个模块，后续的再次导入只不过是指向了第一次的地址。因此除非你重新运行一遍，否则是不会生效的。\n\n### 模块的搜索路径\n\npython解释器在启动时会自动加载一些模块，可以使用sys.modules查看\n\n在第一次导入某个模块时（比如spam），会先检查该模块是否已经被加载到内存中（当前执行文件的名称空间对应的内存），如果有则直接引用\n\n如果没有，解释器则会查找同名的内建模块，如果还没有找到就从sys.path给出的目录列表中依次寻找spam.py文件。\n\n**所以总结模块的查找顺序是：内存中已经加载的模块->内置模块->sys.path路径中包含的模块**\n\n```python\nimport sys\ndir_list = sys.path   # sys.path其实就是一个列表\nfor dir in dir_list:\n    print(dir)\n\n结果：\nD:\\坚果云同步\\Python\\Day12\nD:\\坚果云同步\\Python\nC:\\Users\\马晓雨\\AppData\\Local\\Programs\\Python\\Python36\\python36.zip\nC:\\Users\\马晓雨\\AppData\\Local\\Programs\\Python\\Python36\\DLLs\nC:\\Users\\马晓雨\\AppData\\Local\\Programs\\Python\\Python36\\lib\nC:\\Users\\马晓雨\\AppData\\Local\\Programs\\Python\\Python36\nC:\\Users\\马晓雨\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\n```\n\n需要特别注意的是：我们自定义的模块名不应该与系统内置模块重名。虽然每次都说，但是仍然会有人不停的犯错。\n\n在初始化后，python程序可以修改sys.path,路径放到前面的优先于标准库被加载。\n\n```\nimport sys\nsys.path.append(\'/a/b/c/d\')\nsys.path.insert(0,\'/x/y/z\') #排在前的目录，优先被搜索\n```\n\n注意：搜索时按照sys.path中从左到右的顺序查找，位于前的优先被查找，sys.path中还可能包含.zip归档文件和.egg文件，python会把.zip归档文件当成一个目录去处理.\n\n```python\n#首先制作归档文件：zip module.zip foo.py bar.py\n\nimport sys\nsys.path.append(\'module.zip\')\nimport foo,bar\n\n#也可以使用zip中目录结构的具体位置\nsys.path.append(\'module.zip/lib/python\')\n\n#windows下的路径不加r开头，会语法错误\nsys.path.insert(0,r\'C:\\Users\\Administrator\\PycharmProjects\\a\')\n```\n\n至于.egg文件是由setuptools创建的包，这是按照第三方python库和扩展时使用的一种常见格式，.egg文件实际上只是添加了额外元数据(如版本号，依赖项等)的.zip文件。\n\n需要强调的一点是：只能从.zip文件中导入.py，.pyc等文件。使用C编写的共享库和扩展块无法直接从.zip文件中加载（此时setuptools等打包系统有时能提供一种规避方法），且从.zip中加载文件不会创建.pyc或者.pyo文件，因此一定要事先创建他们，来避免加载模块使性能下降。\n\n官网的解释如下\n\n> ##### 官网链接：\n>\n> https://docs.python.org/3/tutorial/modules.html#the-module-search-path\n>\n> 搜索路径：当一个命名为spam的模块被导入时    解释器首先会从内建模块中寻找该名字    找不到，则去sys.path中找该名字sys.path从以下位置初始化    \n>\n> 1 执行文件所在的当前目录    \n>\n> 2 PTYHONPATH（包含一系列目录名，与shell变量PATH语法一样）    \n>\n> 3 依赖安装时默认指定的\n>\n> 注意：在支持软连接的文件系统(Linux)中，执行脚本所在的目录是在软连接之后被计算的，换句话说，包含软连接的目录不会被添加到模块的搜索路径中在初始化后，我们也可以在python程序中修改sys.path,执行文件所在的路径默认是sys.path的第一个目录，在所有标准库路径的前面。这意味着，当前目录是优先于标准库目录的，需要强调的是：我们自定义的模块名不要跟python标准库的模块名重复，除非你是故意的，傻叉。","timestamp":1523777648264},{"name":"014-包.md","path":"05-Python/02-面向对象编程/014-包.md","content":"## 包\n\n### 编译python文件\n\n为了提高加载模块的速度，强调强调强调：提高的是加载速度而绝非运行速度。python解释器会在\\_\\_pycache\\_\\_目录中下缓存每个模块编译后的版本，格式为：module.version.pyc。通常会包含python的版本号。例如，在CPython3.3版本下，spam.py模块会被缓存成\\_\\_pycache\\_\\_/spam.cpython-33.pyc。这种命名规范保证了编译后的结果多版本共存。(只有模块导入的时候才会有这个cache文件，也就是pyc文件)\n\nPython检查源文件的修改时间与编译的版本进行对比，如果过期就需要重新编译。这是完全自动的过程。并且编译的模块是平台独立的，所以相同的库可以在不同的架构的系统之间共享，即pyc是一种跨平台的字节码，类似于JAVA或.NET,是由python虚拟机来执行的，但是pyc的内容跟python的版本相关，不同的版本编译后的pyc文件不同，2.5编译的pyc文件不能到3.5上执行，并且pyc文件是可以反编译的，因而它的出现仅仅是用来提升模块的加载速度的。\n\n**python解释器在以下两种情况下不检测缓存**\n\n- 如果是在命令行中被直接导入模块，则按照这种方式，每次导入都会重新编译，并且不会存储编译后的结果（python3.3以前的版本应该是这样）\n\n```python\npython -m spam.py\n```\n\n- 如果源文件不存在，那么缓存的结果也不会被使用，如果想在没有源文件的情况下来使用编译后的结果，则编译后的结果必须在源目录下\n\n```python\nsh-3.2# ls\n__pycache__ spam.py\nsh-3.2# rm -rf spam.py \nsh-3.2# mv __pycache__/spam.cpython-36.pyc ./spam.pyc\nsh-3.2# python3 spam.pyc \nspam\n```\n\n提示：\n\n1. 模块名区分大小写，foo.py与FOO.py代表的是两个模块\n2. 你可以使用-O或者-OO转换python命令来减少编译模块的大小\n\n```\n1 -O转换会帮你去掉assert语句\n2 -OO转换会帮你去掉assert语句和__doc__文档字符串\n3 由于一些程序可能依赖于assert语句或文档字符串，你应该在在确认需要的情况下使用这些选项。\n```\n\n3. 在速度上从.pyc文件中读指令来执行不会比从.py文件中读指令执行更快，只有在模块被加载时，.pyc文件才是更快的\n4. 只有使用import语句是才将文件自动编译为.pyc文件，在命令行或标准输入中指定运行脚本则不会生成这类文件，因而我们可以使用compieall模块为一个目录中的所有模块创建.pyc文件\n\n```\n模块可以作为一个脚本（使用python -m compileall）编译Python源\n \npython -m compileall /module_directory 递归着编译\n如果使用python -O -m compileall /module_directory -l则只一层\n \n命令行里使用compile()函数时，自动使用python -O -m compileall\n \n详见：https://docs.python.org/3/library/compileall.html#module-compileall\n```\n\n### 包描述\n\n新建Python pacakage就是新建了一个包，其实就是一个文件夹，但是这个文件夹有一个`__init__.py`的文件。大包下面还可以有小包。包其实就是一种使用\'包名字.模块名\'的方式来组织python模块名称空间的一种方式。\n\n```\nglance/                   #Top-level package\n├── __init__.py           #Initialize the glance package\n├── api                   #Subpackage for api\n│   ├── __init__.py\n│   ├── policy.py\n│   └── versions.py\n├── cmd                   #Subpackage for cmd\n│   ├── __init__.py\n│   └── manage.py\n└── db                    #Subpackage for db\n    ├── __init__.py\n    └── models.py\n```\n\n导入包：\n\n```\nimport glance.api.policy\n\n那么在使用这个policy的时候也要把包的前缀写全了。\n比如：glance.api.policy.get()\n\n如果不要这么一堆前缀的话就是用from导入\nfrom glance.api.policy import get\nfrom glance.api import policy\n注意就是使用from的方法的话，import后面必须是一个明确的东西不能带点。\n是模块就是模块，是属性就是属性\n还可以使用import *的方法，比如：\nfrom glance.api import *\n在导入包的时候只会执行包下面的init文件，并且import后面如果不明确指明什么内容是不会明确导入具体模块的，因此我们仍然不能找到api包下面的模块的namespace，针对这个问题我们可以在api包下面的init文件中定一个一个__all__，然后将模块的名字写入：\n__all__ = [\'policy\',\'versions\']\n那么这样在导入的时候就没问题了，那么取的内容就可以从__all__中去取了。\n那么from import的方式可以使用__all__，那么直接import的方式该怎么办？直接import的话其实是不回去找__all__这个特殊变量的。而且没有import *这么个用法。这个时候就要在api的init文件中使用绝对导入了。\n```\n#### 绝对导入和相对导入\n\n我们的最顶级包glance是写给别人用的，然后在glance包内部也会有彼此之间互相导入的需求，这时候就有绝对导入和相对导入两种方式：\n\n- 绝对导入：以glance作为起始\n- 相对导入：用.或者..的方式最为起始（只能在一个包中使用，不能用于不同目录内）\n\n例如：我们在glance/api/version.py中想要导入glance/cmd/manage.py\n\n```\n在glance/api/version.py\n\n#绝对导入\nfrom glance.cmd import manage\nmanage.main()\n\n#相对导入。这个导入是不能够作为单独的文件去运行的，在其他文件中调用的时候才生效。\nfrom ..cmd import manage\nmanage.main()\n\n.    ：当前路径\n..   ：上级路径\n```\n\n测试结果：注意一定要在于glance同级的文件中测试\n\n```\nfrom glance.api import versions \n```\n\n注意：在使用pycharm时，有的情况会为你多做一些事情，这是软件相关的东西，会影响你对模块导入的理解，因而在测试时，一定要回到命令行去执行，模拟我们生产环境，你总不能拿着pycharm去上线代码吧！！！\n\n**特别需要注意的是：可以用import导入内置或者第三方模块（已经在sys.path中），但是要绝对避免使用import来导入自定义包的子模块(没有在sys.path中)，应该使用from... import ...的绝对或者相对导入,且包的相对导入只能用from的形式。**\n\n#### 单独导入包\n\n单独导入包名称时不会导入包中所有包含的所有子模块，如\n\n```\n#在与glance同级的test.py中\nimport glance\nglance.cmd.manage.main()\n\n\'\'\'\n执行结果：\nAttributeError: module \'glance\' has no attribute \'cmd\'\n\n\'\'\' \n```\n\n解决办法：\n\n```\n#glance/__init__.py\nfrom . import cmd\n\n#glance/cmd/__init__.py\nfrom . import manage\n```\n\n执行：\n\n```\n#在于glance同级的test.py中\nimport glance\nglance.cmd.manage.main()\n```\n\n千万别问：\\_\\_all\\_\\_不能解决吗，\\_\\_all\\_\\_是用于控制from...import * ，fuck\n\n了解：包的分发\n\nhttps://packaging.python.org/distributing/\n\n那么导入的过程中的都做了什么？\n\n> 导入包的时候就会执行包下面的init文件。不过导入包的时候也就是仅仅执行了包下面的init文件。\n\n\n- 无论是import形式还是from...import形式，凡是在导入语句中（而不是在使用时）遇到带点的，都要第一时间提高警觉：这是关于包才有的导入语法\n- 包是目录级的（文件夹级），文件夹是用来组成py文件（包的本质就是一个包含\\_\\_init\\_\\_.py文件的目录）\n- import导入文件时，产生名称空间中的名字来源于文件，import 包，产生的名称空间的名字同样来源于文件，即包下的\\_\\_init\\_\\_.py，导入包本质就是在导入该文件\n\n**强调：**\n\n      　　1. 在python3中，即使包下没有\\_\\_init\\_\\_.py文件，import 包仍然不会报错，而在python2中，包下一定要有该文件，否则import 包报错\n\n      　　2. 创建包的目的不是为了运行，而是被导入使用，记住，包只是模块的一种形式而已，包即模块\n\n\n包A和包B下有同名模块也不会冲突，如A.a与B.a来自俩个命名空间\n\n**注意事项**\n\n- 关于包相关的导入语句也分为import和from ... import ...两种，但是无论哪种，无论在什么位置，在导入时都必须遵循一个原则：*凡是在导入时带点的，点的左边都必须是一个包*，否则非法。可以带有一连串的点，如item.subitem.subsubitem,但都必须遵循这个原则。\n- 对于导入后，在使用时就没有这种限制了，点的左边可以是包,模块，函数，类(它们都可以用点的方式调用自己的属性)。\n- 对比import item 和from item import name的应用场景：如果我们想直接使用name那必须使用后者。\n- 需要注意的是from后import导入的模块，必须是明确的一个不能带点，否则会有语法错误，如：from a import b.c是错误语法\n\n\n以后导入的时候可以如何进行导入呢？\n\n```\nbase_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(base_dir)\n```\n\n### 软件开发规范\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-3/90893096.jpg)\n\n```\n#=============>bin目录：存放执行脚本\n#start.py\nimport sys,os\n\nBASE_DIR=os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(BASE_DIR)\n\nfrom core import core\nfrom conf import my_log_settings\n\nif __name__ == \'__main__\':\n    my_log_settings.load_my_logging_cfg()\n    core.run()\n\n#=============>conf目录：存放配置文件\n#config.ini\n[DEFAULT]\nuser_timeout = 1000\n\n[egon]\npassword = 123\nmoney = 10000000\n\n[alex]\npassword = alex3714\nmoney=10000000000\n\n[yuanhao]\npassword = ysb123\nmoney=10\n\n#settings.py\nimport os\nconfig_path=r\'%s\\%s\' %(os.path.dirname(os.path.abspath(__file__)),\'config.ini\')\nuser_timeout=10\nuser_db_path=r\'%s\\%s\' %(os.path.dirname(os.path.dirname(os.path.abspath(__file__))),\\\n                     \'db\')\n\n\n#my_log_settings.py\n\"\"\"\nlogging配置\n\"\"\"\n\nimport os\nimport logging.config\n\n# 定义三种日志输出格式 开始\n\nstandard_format = \'[%(asctime)s][%(threadName)s:%(thread)d][task_id:%(name)s][%(filename)s:%(lineno)d]\' \\\n                  \'[%(levelname)s][%(message)s]\' #其中name为getlogger指定的名字\n\nsimple_format = \'[%(levelname)s][%(asctime)s][%(filename)s:%(lineno)d]%(message)s\'\n\nid_simple_format = \'[%(levelname)s][%(asctime)s] %(message)s\'\n\n# 定义日志输出格式 结束\n\nlogfile_dir = r\'%s\\log\' %os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # log文件的目录\n\nlogfile_name = \'all2.log\'  # log文件名\n\n# 如果不存在定义的日志目录就创建一个\nif not os.path.isdir(logfile_dir):\n    os.mkdir(logfile_dir)\n\n# log文件的全路径\nlogfile_path = os.path.join(logfile_dir, logfile_name)\n\n# log配置字典\nLOGGING_DIC = {\n    \'version\': 1,\n    \'disable_existing_loggers\': False,\n    \'formatters\': {\n        \'standard\': {\n            \'format\': standard_format\n        },\n        \'simple\': {\n            \'format\': simple_format\n        },\n    },\n    \'filters\': {},\n    \'handlers\': {\n        #打印到终端的日志\n        \'console\': {\n            \'level\': \'DEBUG\',\n            \'class\': \'logging.StreamHandler\',  # 打印到屏幕\n            \'formatter\': \'simple\'\n        },\n        #打印到文件的日志,收集info及以上的日志\n        \'default\': {\n            \'level\': \'DEBUG\',\n            \'class\': \'logging.handlers.RotatingFileHandler\',  # 保存到文件\n            \'formatter\': \'standard\',\n            \'filename\': logfile_path,  # 日志文件\n            \'maxBytes\': 1024*1024*5,  # 日志大小 5M\n            \'backupCount\': 5,\n            \'encoding\': \'utf-8\',  # 日志文件的编码，再也不用担心中文log乱码了\n        },\n    },\n    \'loggers\': {\n        #logging.getLogger(__name__)拿到的logger配置\n        \'\': {\n            \'handlers\': [\'default\', \'console\'],  # 这里把上面定义的两个handler都加上，即log数据既写入文件又打印到屏幕\n            \'level\': \'DEBUG\',\n            \'propagate\': True,  # 向上（更高level的logger）传递\n        },\n    },\n}\n\n\ndef load_my_logging_cfg():\n    logging.config.dictConfig(LOGGING_DIC)  # 导入上面定义的logging配置\n    logger = logging.getLogger(__name__)  # 生成一个log实例\n    logger.info(\'It works!\')  # 记录该文件的运行状态\n\nif __name__ == \'__main__\':\n    load_my_logging_cfg()\n\n#=============>core目录：存放核心逻辑\n#core.py\nimport logging\nimport time\nfrom conf import settings\nfrom lib import read_ini\n\nconfig=read_ini.read(settings.config_path)\nlogger=logging.getLogger(__name__)\n\ncurrent_user={\'user\':None,\'login_time\':None,\'timeout\':int(settings.user_timeout)}\ndef auth(func):\n    def wrapper(*args,**kwargs):\n        if current_user[\'user\']:\n            interval=time.time()-current_user[\'login_time\']\n            if interval < current_user[\'timeout\']:\n                return func(*args,**kwargs)\n        name = input(\'name>>: \')\n        password = input(\'password>>: \')\n        if config.has_section(name):\n            if password == config.get(name,\'password\'):\n                logger.info(\'登录成功\')\n                current_user[\'user\']=name\n                current_user[\'login_time\']=time.time()\n                return func(*args,**kwargs)\n        else:\n            logger.error(\'用户名不存在\')\n\n    return wrapper\n\n@auth\ndef buy():\n    print(\'buy...\')\n\n@auth\ndef run():\n\n    print(\'\'\'\n    1 购物\n    2 查看余额\n    3 转账\n    \'\'\')\n    while True:\n        choice = input(\'>>: \').strip()\n        if not choice:continue\n        if choice == \'1\':\n            buy()\n\n\n\nif __name__ == \'__main__\':\n    run()\n\n#=============>db目录：存放数据库文件\n#alex_json\n#egon_json\n\n#=============>lib目录：存放自定义的模块与包\n#read_ini.py\nimport configparser\ndef read(config_file):\n    config=configparser.ConfigParser()\n    config.read(config_file)\n    return config\n\n#=============>log目录：存放日志\n#all2.log\n[2017-07-29 00:31:40,272][MainThread:11692][task_id:conf.my_log_settings][my_log_settings.py:75][INFO][It works!]\n[2017-07-29 00:31:41,789][MainThread:11692][task_id:core.core][core.py:25][ERROR][用户名不存在]\n[2017-07-29 00:31:46,394][MainThread:12348][task_id:conf.my_log_settings][my_log_settings.py:75][INFO][It works!]\n[2017-07-29 00:31:47,629][MainThread:12348][task_id:core.core][core.py:25][ERROR][用户名不存在]\n[2017-07-29 00:31:57,912][MainThread:10528][task_id:conf.my_log_settings][my_log_settings.py:75][INFO][It works!]\n[2017-07-29 00:32:03,340][MainThread:12744][task_id:conf.my_log_settings][my_log_settings.py:75][INFO][It works!]\n[2017-07-29 00:32:05,065][MainThread:12916][task_id:conf.my_log_settings][my_log_settings.py:75][INFO][It works!]\n[2017-07-29 00:32:08,181][MainThread:12916][task_id:core.core][core.py:25][ERROR][用户名不存在]\n[2017-07-29 00:32:13,638][MainThread:7220][task_id:conf.my_log_settings][my_log_settings.py:75][INFO][It works!]\n[2017-07-29 00:32:23,005][MainThread:7220][task_id:core.core][core.py:20][INFO][登录成功]\n[2017-07-29 00:32:40,941][MainThread:7220][task_id:core.core][core.py:20][INFO][登录成功]\n[2017-07-29 00:32:47,222][MainThread:7220][task_id:core.core][core.py:20][INFO][登录成功]\n[2017-07-29 00:32:51,949][MainThread:7220][task_id:core.core][core.py:25][ERROR][用户名不存在]\n[2017-07-29 00:33:00,213][MainThread:7220][task_id:core.core][core.py:20][INFO][登录成功]\n[2017-07-29 00:33:50,118][MainThread:8500][task_id:conf.my_log_settings][my_log_settings.py:75][INFO][It works!]\n[2017-07-29 00:33:55,845][MainThread:8500][task_id:core.core][core.py:20][INFO][登录成功]\n[2017-07-29 00:34:06,837][MainThread:8500][task_id:core.core][core.py:25][ERROR][用户名不存在]\n[2017-07-29 00:34:09,405][MainThread:8500][task_id:core.core][core.py:25][ERROR][用户名不存在]\n[2017-07-29 00:34:10,645][MainThread:8500][task_id:core.core][core.py:25][ERROR][用户名不存在]\n```\n\n","timestamp":1523777648264},{"name":"01-1、Python中的上下文.md","path":"05-Python/02-面向对象编程/030-小知识点总结/01-1、Python中的上下文.md","content":"# Python中的上下文\n\n> 关于上下文，知乎上有一句通俗易懂的话。每一段程序都有很多外部变量。只有像Add这种简单的函数才是没有外部变量的。一旦你的一段程序有了外部变量，这段程序就不完整，不能独立运行。你为了使他们运行，就要给所有的外部变量一个一个写一些值进去。这些值的集合就叫上下文。\n>\n> 换种说法，上下文其实就是代码在执行过程中的一个完整性，比如调用数据库打开一个连接，那么从引用进行开启到最后使用完毕进行关闭应该是一个完整的过程。简单来说就是代码块执行前准备，代码块执行后收拾。\n\n## 需求的产生\n\n在正常的管理各种系统资源(文件、锁定和连接)，在涉及到异常时通常是个棘手的问题。异常很可能导致控制流跳过负责释放关键资源的语句。例如打开一个文件进行操作时，如果意外情况发生（磁盘已满、特殊的终端信号让其终止等），就会抛出异常，这样可能最后的文件关闭操作就不会执行。如果这样的问题频繁出现，则可能耗尽系统资源。\n\n是的，这样的问题并不是不可避免。在没有接触到上下文管理器之前，我们可以用`“try/finally”`语句来解决这样的问题。或许在有些人看来，“try/finally”语句显得有些繁琐。上下文管理器就是被设计用来简化“try/finally”语句的，这样可以让程序更加简洁。\n\n## 上下文的使用场景\n\n### 资源的创建和释放场景\n\n上下文管理器的常用于一些资源的操作，需要在资源的获取与释放相关的操作，一个典型的例子就是数据库的连接，查询，关闭处理。先看如下一个例子：\n\n```python\nclass Database(object):\n \n    def __init__(self):\n        self.connected = False\n \n    def connect(self):\n        self.connected = True\n \n    def close(self):\n        self.connected = False\n \n    def query(self):\n        if self.connected:\n            return \'query data\'\n        else:\n            raise ValueError(\'DB not connected \')\n \ndef handle_query():\n    db = Database()\n    db.connect()\n    print \'handle --- \', db.query()\n    db.close()\n \ndef main():\n    handle_query()\n \nif __name__ == \'__main__\':\n    main()\n```\n\n上述的代码很简单，针对`Database`这个数据库类，提供了`connect` `query` 和`close` 三种常见的db交互接口。客户端的代码中，需要查询数据库并处理查询结果。当然这个操作之前，需要连接数据库（db.connect()）和操作之后关闭数据库连接（ db.close()）。上述的代码可以work，可是如果很多地方有类似handle_query的逻辑，连接和关闭这样的代码就得copy很多遍，显然不是一个优雅的设计。\n\n#### 使用with语句进行优化\n\nPython提供了With语句语法，来构建对资源创建与释放的语法糖。给Database添加两个魔法方法：\n\n```python\nclass Database(object):\n \n    ...\n \n    def __enter__(self):\n        self.connect()\n        return self\n \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n```\n\n然后修改handle_query函数如下：\n\n```python\ndef handle_query():\n    with Database() as db:\n        print \'handle ---\', db.query()\n```\n\n在Database类实例的时候，使用with语句。一切正常work。比起装饰器的版本，虽然多写了一些字符，但是代码可读性变强了。\n\nWith 语句仅能工作于支持上下文管理协议(context management protocol)的对象。也就是说只有内建了”上下文管理”的对象才能和 with 一起工作。Python内置了一些支持该协议的对象，如下所列是一个简短列表：\n\n- file\n- decimal.Context\n- thread.LockType\n- threading.Lock\n- threading.RLock\n- threading.Condition\n- threading.Semaphore\n- threading.BoundedSemaphore\n\n由以上列表可以看出，file 是已经内置了对上下文管理协议的支持。所以我们可以用下边的方法来操作文件：\n\n```python\nwith open(\'/etc/passwd\', \'r\') as f:\n    for eachLine in f:\n        # ...do stuff with eachLine or f...\n```\n\n上边的代码试图打开一个文件,如果一切正常,把文件对象赋值给 f。然后用迭代器遍历文件中的每一行,当 完成时,关闭文件。无论是在这一段代码的开始,中间,还是结束时发生异常,会执行清理的代码,此 外文件仍会被自动的关闭。\n\n\n\n\n\n## 上下文管理协议\n\n实现了上下文协议的函数/对象即为上下文管理器。对于迭代器协议是实现了`__iter__`方法。上下文管理协议则是`__enter__`和`__exit__`。比如：\n\n```python\nfilename = \'my_file.txt\'\nmode = \'w\' # Mode that allows to write to the file\nwriter = open(filename, mode)\n\nclass PypixOpen(object):\n    def __init__(self, filename, mode):\n        self.filename = filename\n        self.mode = mode\n\n    def __enter__(self):\n        self.openedFile = open(self.filename, self.mode)\n        return self.openedFile\n\n    def __exit__(self, *unused):\n        self.openedFile.close()\n\n# Script starts from here\n\nwith PypixOpen(filename, mode) as writer:\n    writer.write(\"Hello World from our new Context Manager!\")\n```\n\n`PypixOpen` 实现了`__enter__`和`__exit__`这两个上下文管理器协议，当PypixOpen调用/实例化的时候，则创建了上下文管理器。类似于实现迭代器协议类调用生成迭代器一样。\n\n- __enter__: 该方法进入运行时上下文环境，并返回自身或另一个与运行时上下文相关的对象。返回值会赋给 as 从句后面的变量，as 从句是可选的。\n- __exit__: 该方法退出当前运行时上下文并返回一个布尔值，该布尔值标明了“如果 with_suit 的退出是由异常引发的，该异常是否须要被忽略”。如果 __exit__() 的返回值等于 False，那么这个异常将被重新引发一次；如果 __exit__() 的返回值等于 True，那么这个异常就被无视掉，继续执行后面的代码。\n\nWith 语句的实际执行流程是这样的：\n\n```python\nwith context_expr [as var]:\n    with_suite\n\n1. 执行 context_exp 以获取上下文管理器\n2. 加载上下文管理器的 __exit__() 方法以备稍后调用\n3. 调用上下文管理器的 __enter__() 方法\n4. 如果有 as var 从句，则将 __enter__() 方法的返回值赋给 var\n5. 执行子代码块 with_suit\n6. 调用上下文管理器的 __exit__() 方法，如果 with_suit 的退出是由异常引发的，那么该异常的 type、value 和 traceback 会作为参数传给 __exit__()，否则传三个 None\n7. 如果 with_suit 的退出由异常引发，并且 __exit__() 的返回值等于 False，那么这个异常将被重新引发一次；如果 __exit__() 的返回值等于 True，那么这个异常就被无视掉，继续执行后面的代码\n```","timestamp":1523777648264},{"name":"99-python模块汇总.md","path":"05-Python/02-面向对象编程/99-python模块汇总.md","content":"\n## 模块用法汇总\n\n### Collections模块\n\n### Sys模块\n\nsys模块主要是和解释器打交道的\n\n\n- sys.argv           命令行参数List，第一个元素是程序本身路径，实现从程序外部向程序传递参数\n\n\n```\n[lamber@maxiaoyu day2]$ cat item.py \n#!/usr/bin/python3.6\nimport sys\n\nprint(sys.argv[0])\nprint(sys.argv[1])\nprint(sys.argv[2])\nprint(sys.argv[3])\n\n[lamber@maxiaoyu day2]$ ./item.py a b c\n./item.py\na\nb\nc\n第一个元素就是这个运行的脚本本身，返回程序的本身路径，其他的几个会返回额外传递的参数\n这个其实和linux的shell脚本挺像的，可以在执行脚本的时候传递$1,$2……这些。\n```\n\n\n- sys.exit(n)        退出程序，正常退出时exit(0)，参数不为0表示异常退出。\n- sys.version        获取Python解释程序的版本信息\n- sys.maxint         最大的Int值，python3中这个东西已经取消了。在py3中当int足够大的时候会自动转换为长整型\n- sys.path           返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值，首先会找自己所在的目录，然后会找python安装路径下的各个路径，最后找到site-packages\n\n\n```\nimport sys\n\nprint(sys.path)\n\n[\'D:\\\\坚果云同步\\\\Python\\\\Day9\', \'D:\\\\坚果云同步\\\\Python\', \'C:\\\\Users\\\\马晓雨\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\python36.zip\', \'C:\\\\Users\\\\马晓雨\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\DLLs\', \'C:\\\\Users\\\\马晓雨\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\lib\', \'C:\\\\Users\\\\马晓雨\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\', \'C:\\\\Users\\\\马晓雨\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\lib\\\\site-packages\']\n```\n\n\n- sys.platform       返回操作系统平台名称，比如win32，linux2.\n\n\n\n\n\n\n","timestamp":1523777648264},{"name":"00-socket.md","path":"05-Python/03-网络编程初窥/00-socket.md","content":"静态方法：与类无关，不能访问类里的任何属性和方法\n\n类方法：只能访问类变量\n\n属性@property：把一个方法变成一个静态属性：\n\n- flight.status\n- @status.setter\n- @status.delter\n\n反射\n\n- getattr(obj,str)\n- setattr(obj,str,val)\n- hasattr(obj,str)\n- delattr(obj,str)\n\n模块的动态加载，`__import__`但是官方的建议是使用importlib\n\n```\nimport importlib\nimportlib.import_module(\'lib.aa\')\n```\n\n# socket\n\n## 什么是socket\n\n> 网络上的两个程序通过一个双向的通信连接实现数据的交换，这个连接的一端称为一个socket。\n>\n> 建立网络通信连接至少要一对端口号(socket)。socket本质是编程接口(API)，对TCP/IP的封装，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口；HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。\n>\n> Socket的英文原义是“孔”或“插座”。作为BSD UNIX的[进程通信](https://baike.baidu.com/item/%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1)机制，取后一种意思。通常也称作\"[套接字](https://baike.baidu.com/item/%E5%A5%97%E6%8E%A5%E5%AD%97)\"，用于描述IP地址和端口，是一个通信链的句柄，可以用来实现不同虚拟机或不同计算机之间的通信。在Internet上的[主机](https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA)一般运行了多个服务软件，同时提供几种服务。每种服务都打开一个Socket，并绑定到一个端口上，不同的端口对应于不同的服务。Socket正如其英文原意那样，像一个多孔插座。一台主机犹如布满各种插座的房间，每个插座有一个编号，有的插座提供220伏交流电， 有的提供110伏交流电，有的则提供有线电视节目。 客户软件将插头插到不同编号的插座，就可以得到不同的服务。\n\n### 服务端和客户端的职能\n\n#### server端需要做什么：\n\n- 持续稳定的提供服务\n- 要绑定一个唯一的地址，允许客户端可以明确的找到\n\n看下面的例子来理解建立socket的步骤：\n\n**Server**(以打电话为例子)\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport socket\n\n# 买个电话(sock_stream基于流的套接字就是tcp的，DGRAM：datagram,就是基于UDP的)\nphone = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n\n# 买个电话要插电话卡，有手机号(server端的ip和端口号)\nphone.bind((\'127.0.0.1\',8080))\n\n# 开机\nphone.listen(5) # 服务端最大可以挂起的连接数\n\n# 开始监听客户端的请求，也就是等电话,服务端会卡在这里。\nconn,addr = phone.accept()\n\nprint(\'电话线路\',conn)\nprint(\'客户端的手机号\',addr)\n\n# 从自己的缓存里收1024字节，这个是上限，也就是说一次最多能收1024，如果\n# 发过来一个1个那就收一个，但是超过1024最多只能拿1024.官方建议不要超过8K（8192）\n# 因此针对这个问题我们一次收一点分多次接收\ndata = conn.recv(1024)  # 收消息\nprint(\'客户端发过来的消息\',data)\n\nconn.send(data.upper())\n\nconn.close()\n\nphone.close()\n```\n\n**Client**\n\n```\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport socket\nphone = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nphone.connect((\'127.0.0.1\',8080))\nphone.send(\'hello\'.encode(\'utf-8\'))\n\ndata = phone.recv(1024)\nprint(data)\nphone.close()\n```\n\n首先运行服务端然后再运行客户端：\n\nServer端的回显：\n\n```\n电话线路 <socket.socket fd=412, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=(\'127.0.0.1\', 8080), raddr=(\'127.0.0.1\', 5204)>\n客户端的手机号 (\'127.0.0.1\', 5204)\n客户端发过来的消息 b\'hello\'\n```\n\n客户端的回显：\n\n```\nb\'HELLO\'\n```\n\n##### 小结\n\n**server端要想建立一个socker需要以下几个步骤：**\n\n- 首先建立一个socket对象，声明地址簇和协议类型\n\n  ```\n  - 地址簇（family adress）\n    - AF.INET: ipv4\n    - AF.INET6: ipv6\n    - AF.UNIX: local\n  - 协议类型（socket protocol type）\n    - sock.SOCK_STREAM：tcp\n    - sock.DGRAM：udp\n  ```\n\n- 要给服务端一个唯一的地址和端口来提供服务的访问\n\n- 绑定完成以后开始启用（listen），listen(n)，n可以是任意数字，这个其实代表的是可以放在缓存区的链接数量，就好比你月初月末给中国移动打电话，接线员总是有限的，用户是远大于接线员的，你可以拨进去转人工服务，但是你未必能立即获得到服务是一个道理，人不够的时候就提示你坐席繁忙请稍后。在这里也是一样的。当然这里的这个数是不能写死的，要写到配置文件里面去控制。\n\n- 监听客户端的请求（accept），服务端会卡在这个地方\n\n```\nconn,addr = server.accept() #conn是链接的实例化对象，addr记录客户端地址\n```\n\n- 接收客户端的消息\n- 给客户端回复消息\n- 关闭与客户端的链接\n- 关闭服务端socket\n\n**client端的话也无外乎几个步骤：**\n\n- 建立一个socket对象，声明地址簇和协议类型\n- 我要链接的服务器的地址和端口\n- 给服务端发消息\n- 接收服务端消息\n- 关闭客户端socket\n\n### 针对上面的程序做一下小优化\n\n- 当客户端退出的时候服务端也会被干掉\n\n服务端应该提供的是持续的稳定的服务，但是现在的话只要客户端被断开以后服务端也会被强制reset（因为conn对象被干掉了），这是不符合要求的。为了避免这个问题我们加一个try …… except，因为客户端什么时候断开链接是不可控的。\n\n```python\nwhile True: # 通信循环\n    try:# 应对windows系统\n        # 如果再linux上的话客户端断掉并不会干掉server\n        # server会一直收空，然后发也是空\n        # 陷入死循环\n        data = conn.recv(1024)  # 收消息\n        if not data: break # 应对linux系统\n        print(\'客户端发过来的消息\',data)\n        conn.send(data.upper())\n    except Exception:\n        print(\'链接已被关闭\')\n        break\n\nconn.close()\n```\n\n因此加上一个try except，异常类型是用万能异常来捕捉。这样在windows上就没问题了，但是再linux上有问题，linux的server端程序并不会崩掉，而是recv会无限次数的接收空值，相当于一个死循环，为了避免这个问题，因此我们可以加一个判断，如果接收的是空的那么就跳出通信循环的逻辑。\n\n但是跳出是可以正常跳出了，但是此时server端的还是正常的结束掉了，这依然不符合要求，因此在通讯循环的基础上需要套一个链接的循环，你这个客户端关闭了要允许我接收其他客户端的链接：\n\n```python\nwhile True: # 链接循环\n    conn,addr = phone.accept()\n\n    print(\'电话线路\',conn)\n    print(\'客户端的手机号\',addr)\n\n    while True: # 通信循环\n        try:# 应对windows系统\n            # 如果再linux上的话客户端断掉并不会干掉server\n            # server会一直收空，然后发也是空\n            # 陷入死循环\n            data = conn.recv(1024)  # 收消息\n            if not data: break # 应对linux系统\n            print(\'客户端发过来的消息\',data)\n            conn.send(data.upper())\n        except Exception:\n            print(\'链接已被关闭\')\n            break\n\n    conn.close()\n\nphone.close()\n```\n\n- 当客户端键入空值的时候会被卡住！\n\n***为什么会被卡住，首先说不管是客户端还是服务端，send和receive去实现网络间沟通的原理其实很简单，都是和本地缓存中收发的。***因为不管是send还是receive其实最后都是要通过电脑的网卡进行数据的收发，网卡是硬件是通过操作系统去调用的，其实我们编写的程序无外乎就是调用操作系统，让操作系统去进行数据的收发，我们的send是发给操作系统，receive也是从操作系统的缓存中去取，这是数据的收发。\n\n服务端为了能够对客户端发过来的消息进行持续性的接收，应该设置一个循环，因此通讯部分代码可以加到一个循环里。\n\n```python\nwhile True: # 通信循环\n        data = conn.recv(1024)  # 收消息\n        if not data: break # 应对linux系统\n        print(\'客户端发过来的消息\',data)\n        conn.send(data.upper())\n```\n\n客户端也是\n\n```python\nwhile True:\n    msg = input(\'>> \')\n    phone.send(msg.encode(\'utf-8\'))\n    # 如果输入为空的话，服务端会一直在recv这里，不会给客户端send\n    # 客户端没收到，在自己系统的缓存里找也找不到就会卡主。\n    data = phone.recv(1024)\n    # print(data)\n# phone.close()\n```\n\n那么如果输入空的话就会卡住，为什么会卡住？因为服务端本身会一直卡在recv的阶段目的就是为了随时接受客户端的消息，客户端发了一个空，服务端啥也没收到也就不会返回任何值，于是客户端就永远的卡在了recv这个步骤。为了避免这个问题其实加一个判断就可以了，修改如下：\n\n```python\nwhile True:\n    msg = input(\'>> \')\n    if not msg:continue\n    phone.send(msg.encode(\'utf-8\'))\n    # 如果输入为空的话，服务端会一直在recv这里，不会给客户端send\n    # 客户端没收到，在自己系统的缓存里找也找不到就会卡主。\n    data = phone.recv(1024)\n    print(data)\n# phone.close()\n```\n\n### 使用socket模拟ssh\n\nserver端：\n\n```python\n#!/usr/bin/python3.6\nprint(\'=====模拟ssh小程序=====\')\nimport socket \nimport subprocess\n\n# to make a new socket obj\nnew_ssh = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nnew_ssh.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n# Bind Addr&Port\n# new_ssh.setsockopt(socket.SOL_SOCKET)\nnew_ssh.bind((\'23.110.64.224\',8888))\n\n# start the socket\nnew_ssh.listen(10)\n\n# start to listen\nwhile True:\n    conn,addr = new_ssh.accept()\n    print(\'当前客户端地址为\',addr)\n    while True:\n        try:\n            data = conn.recv(1024)\n            if not data: break\n            print(\'客户端输入的命令为：\',data.decode(\'utf-8\'))\n            s_data = subprocess.Popen(data.decode(\'utf-8\'),\n                                      shell=True,\n                                      stdout = subprocess.PIPE,\n                                      stderr = subprocess.PIPE)\n                conn.send(s_data.stdout.read())\n                conn.send(s_data.stderr.read())\n        except Exception:\n            print(\'当前客户端链接已被关闭\')\n            break\n    conn.close()\nnew_ssh.close()\n```\n\nclient\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport socket\nphone = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nphone.connect((\'23.110.64.224\',8888))\n\nwhile True:\n    msg = input(\'>> \')\n    if not msg:continue\n    phone.send(msg.encode(\'utf-8\'))\n    # 如果输入为空的话，服务端会一直在recv这里，不会给客户端send\n    # 客户端没收到，在自己系统的缓存里找也找不到就会卡主。\n    data = phone.recv(1024).decode(\'utf-8\')\n    data2 = data.replace(\'\\n\', \'\\r\\n\')\n    print(data2)\n# phone.close()\n```\n\n### 粘包现象\n\n首先明确一点就是只有tcp会出现粘包现象，udp是不会出现的。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-17/42296147.jpg)\n\n首先说为什么只有TCP会出现粘包的现象：\n\n1. 首先tcp是面向流的，可靠地。因此，发送端为了将多个发往接收端的包更有效的发到对方使用了Nagle算法进行优化，将多次间隔较小并且数据量小的数据合并成一个大的数据块然后进行封包，这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。 即面向流的通信是无消息保护边界的，比如下面这个例子:\n\n   ```python\n   服务端\n   #!/usr/bin/python3.6\n   # -*- coding: utf-8 -*-\n   # author:maxiaoyu\n   import socket\n\n   address = (\'127.0.0.1\',2333)\n\n   s = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n\n   s.bind(address)\n\n   s.listen(10)\n\n   conn,addr = s.accept()\n\n   data1 = conn.recv(1024)\n   data2 = conn.recv(1024)\n\n   print(data1)\n   print(data2)\n\n   客户端：\n   #!/usr/bin/python3.6\n   # -*- coding: utf-8 -*-\n   # author:maxiaoyu\n   import socket\n\n   c = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n   address = (\'127.0.0.1\',2333)\n   c.connect(address)\n\n   c.send(\'Hello World\'.encode(\'utf-8\'))\n   c.send(\'hehehehe\'.encode(\'utf-8\'))\n   ```\n\n   客户端发了两次分别发了一个‘Hello World’和一个\'hehehehe\'，因为间隔短并且数据量小因此被合并到一起发送了，那么接收的结果其实算作一次的，结果如下：\n\n   ```python\n   b\'Hello Worldhehehehe\'\n   b\'\'\n   ```\n\n   第二次啥都没有输出，因为客户端的自然结束导致服务端的链接失效也自然程序退出。但是我们想要两次send的内容分别单次输出，因为tcp流式的特点和nagle的算法优化机制把两次的数据给合并了。服务端只是接收到了一股数据流，但是并没有明确的界点去判定哪个是第一段哪个是第二段。所谓粘包问题主要还是因为接收方不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。这样就可以能造成需要分开传输的小数据一股脑全灌到一条消息里去，一条超过指定接收大小的数据接收不全，积压在本地的缓存中，下次执行其他命令的时候就会把之前的积压的消息一起发过来会造成混淆，比如下面这个例子：\n\n   ```python\n   >> ipconfig\n\n   Windows IP 配置\n   以太网适配器 以太网:\n\n      媒体状态  . . . . . . . . . . . . : 媒体已断开连接\n   中间略……\n\n      连接特定的 DNS 后缀 . . . . . . . : lhwork.net\n      本地链接 IPv6 地址. . . . . . . . : fe80::82b:a6f3:b7b2\n   >> ls\n   :e775%11\n      IPv4 地址 . . . . . . . . . . . . : 10.239.63.48\n      子网掩码  . . . . . . . . . . . . : 255.255.255.0\n      默认网关. . . . . . . . . . . . . : 10.239.63.254\n\n   以太网适配器 蓝牙网络连接:\n\n      媒体状态  . . . . . . . . . . . . : 媒体已断开连接\n      连接特定的 DNS 后缀 . . . . . . . : \n\n   >> ls\n   \'ls\' 不是内部或外部命令，也不是可运行的程序\n   或批处理文件。\n   ```\n\n   我在上面输入第一个ls的时候就应该报错不是可运行程序了，结果回显的内容是第一条命令ipconfig的剩下没取完的内容，这就是问题的所在。因此，发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一个TCP段。若连续几次需要send的数据都很少，通常TCP会根据优化[算法](http://lib.csdn.net/base/datastructure)把这些数据合成一个TCP段后一次发送出去，这样接收方就收到了粘包数据。\n\n   当然粘包现象在客户端和服务端都是有可能出现的，原理一样，比如我服务端接收两次数据，第一次接收1K，第二次接收1024K，那么第一个字节接受了，后面的一堆又都粘在一起了。\n\n2. 那么为什么UDP并不会出现粘包？因为UDP不是基于流的。UDP是无连接的，面向消息的，提供高效率服务。不会使用块的合并优化算法, 由于UDP支持的是一对多的模式，所以接收端的skbuff(套接字缓冲区）采用了链式结构来记录每一个到达的UDP包，在每个UDP包中就有了消息头（消息来源地址，端口等信息），这样，对于接收端来说，就容易进行区分处理了。 **即面向消息的通信是有消息保护边界的。**\n\n3. tcp是基于数据流的，于是收发的消息不能为空，这就需要在客户端和服务端都添加空消息的处理机制，防止程序卡住，而udp是基于数据报的，即便是你输入的是空内容（直接回车），那也不是空消息，udp协议会帮你封装上消息头。udp的recvfrom是阻塞的，一个recvfrom(x)必须对一个一个sendinto(y),收完了x个字节的数据就算完成,若是y>x数据就丢失，这意味着udp根本不会粘包，但是会丢数据，不可靠。tcp的协议数据不会丢，没有收完包，下次接收，会继续上次继续接收，己端总是在收到ack时才会清除缓冲区内容。数据是可靠的，但是会粘包\n\n#### 造成粘包的原因可以归结如下：\n\n- 发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据了很小，会合到一起，产生粘包【nagle算法】）\n- 接收方不及时接收缓冲区的包，造成多个包接收（客户端发送了一段数据，服务端只收了一小部分，服务端下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包） \n\n#### 粘包的处理办法\n\n知道了粘包的产生原因，那么接下来对粘包进行一下处理\n\n##### 1. 比较简单的解决办法\n\n问题的根因就是tcp流式的特点无法界定起始位置，那么我们在发数据之前让接收端直到我要发的数据长度是多长就可以了。\n\n```python\nserver端：\n\nimport socket,subprocess\nip_port=(\'127.0.0.1\',8080)\ns=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\ns.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\ns.bind(ip_port)\ns.listen(5)\n\nwhile True:\n    conn,addr=s.accept()\n    print(\'客户端\',addr)\n    while True:\n        msg=conn.recv(1024)\n        if not msg:break\n        res=subprocess.Popen(msg.decode(\'utf-8\'),\n                             shell=True,\n                             stdin=subprocess.PIPE,\n                             stderr=subprocess.PIPE,\n                             stdout=subprocess.PIPE)\n        err=res.stderr.read()\n        if err:\n            ret=err\n        else:\n            ret=res.stdout.read()\n        data_length=len(ret)\n        conn.send(str(data_length).encode(\'utf-8\'))\n        data=conn.recv(1024).decode(\'utf-8\')\n        if data == \'recv_ready\':\n            conn.sendall(ret)\n    conn.close()\n    \n\nclient端\n\nimport socket,time\ns=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nres=s.connect_ex((\'127.0.0.1\',8080))\n\nwhile True:\n    msg=input(\'>>: \').strip()\n    if len(msg) == 0:continue\n    if msg == \'quit\':break\n\n    s.send(msg.encode(\'utf-8\'))\n    length=int(s.recv(1024).decode(\'utf-8\'))\n    s.send(\'recv_ready\'.encode(\'utf-8\'))\n    send_size=0\n    recv_size=0\n    data=b\'\'\n    while recv_size < length:\n        data+=s.recv(1024)\n        recv_size+=len(data)\n\n\n    print(data.decode(\'utf-8\'))\n```\n\n##### 2.  通过封装包头解决粘包问题\n\n包头应该有什么？\n\n- 固定长度\n- 对将要发送数据的描述信息\n\n\n这里用到了一个新的struct模块，我们可以用struct的方法把一段字符打包成固定长度的二进制数据。优化后的程序如下：\n\n###### 服务端\n\n```python\n#!/usr/bin/python3.6\nprint(\'=====模拟ssh小程序=====\')\nimport socket\nimport subprocess\nimport struct\n\n# to make a new socket obj\nnew_ssh = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nnew_ssh.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n# Bind Addr&Port\n# new_ssh.setsockopt(socket.SOL_SOCKET)\nnew_ssh.bind((\'127.0.0.1\',8888))\n\n# start the socket\nnew_ssh.listen(10)\n\n# start to listen\nwhile True:\n    conn,addr = new_ssh.accept()\n    print(\'当前客户端地址为\',addr)\n    while True:\n        try:\n            data = conn.recv(1024)\n            if not data: break\n            print(\'客户端输入的命令为：\',data.decode(\'utf-8\'))\n            s_data = subprocess.Popen(data.decode(\'utf-8\'),\n                                      shell=True,\n                                      stdout = subprocess.PIPE,\n                                      stderr = subprocess.PIPE)\n            # 首先从管道里把标准输出和标准错误输出取出来\n            out_res = s_data.stdout.read()\n            err_res = s_data.stdout.read()\n            # 数据的长度是二者之和\n            data_size = len(out_res) + len(err_res)\n\n            # 发送报头，把数据长度封装为固定长度为4字节的报头\n            conn.send(struct.pack(\'i\',data_size))\n            # 发送数据部分\n            conn.send(out_res)\n            conn.send(err_res)\n        except Exception:\n            print(\'当前客户端链接已被关闭\')\n            break\n    conn.close()\n# new_ssh.close()\n```\n\n###### 客户端\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport socket\nimport struct\nphone = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nphone.connect((\'127.0.0.1\',8888))\n\nwhile True:\n    msg = input(\'>> \')\n    if not msg:continue\n    phone.send(msg.encode(\'utf-8\'))\n    # 接收报文头，大小是我们定义好的4个字节。\n    head = phone.recv(4)\n    # struct.unpack解包，用data_size接收解包后的长度信息\n    data_size = struct.unpack(\'i\',head)[0]\n\n    # 收数据，首先定义接收了多少和接收的数据都是空。\n    recv_size = 0\n    recv_data = b\'\'\n    # 当接收的大小比传过来的大小小的时候那么就持续接收\n    while recv_size < data_size:\n        # 当然最大接收1024，但是不一定就是1024，可以比1024小\n        data = phone.recv(1024)\n        # 因为可以比1024小，因此size不能直接加1024，而是要加data的长度\n        recv_size += len(data)\n        recv_data += data\n    # 全部循环完了以后然后再打印数据即可呢\n    print(recv_data.decode(\'gbk\'))\n# phone.close()\n```\n\n当然使用这种方法一般来说是没有问题的，但是struct.pack中的format类型是有大小限制的，我们不能保证后面的data_size是多少。比如i（int）整形可以表示的最大data_size为 `-2147483648 <= number <= 2147483647`也就是2的32次幂对半劈，中间有一个0所以右侧是2147483647.但是这个数据能表示的毕竟是有限的，当上传文件的时候几个G甚至是几个T都是有可能的。\n\n##### 3. 自定制json报头解决问题\n\n之前说到的报头一个是要带着数据的长度，再有一个数据的描述信息，文件大小，文件名，文件哈希值等等，而且直接自定义报头的话可以传输的文件大小是有限制的，我们可以使用一个字典来尝试去解决。\n\n```python\n>>> head_len = {\'filename\':\'a.txt\',\'hash\':None,\'data_size\':1231231231231313131231123131323}\n>>> head_bytes = json.dumps(head_len).encode(\'utf-8\')\n>>> len(head_bytes)\n81\n>>> head = struct.pack(\'i\',len(head_bytes))\n>>> head\nb\'Q\\x00\\x00\\x00\'\n```\n\n上面这个字典所代表的data_size已经很大了，要远大于自定义报头的方式，修改后的代码如下：\n\n```python\n#!/usr/bin/python3.6\nprint(\'=====模拟ssh小程序=====\')\nimport socket\nimport subprocess\nimport struct\nimport json\n\n# to make a new socket obj\nnew_ssh = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nnew_ssh.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n# Bind Addr&Port\n# new_ssh.setsockopt(socket.SOL_SOCKET)\nnew_ssh.bind((\'127.0.0.1\',8888))\n\n# start the socket\nnew_ssh.listen(10)\n\n# start to listen\nwhile True:\n    conn,addr = new_ssh.accept()\n    print(\'当前客户端地址为\',addr)\n    while True:\n        try:\n            data = conn.recv(1024)\n            if not data: break\n            print(\'客户端输入的命令为：\',data.decode(\'utf-8\'))\n            s_data = subprocess.Popen(data.decode(\'utf-8\'),\n                                      shell=True,\n                                      stdout = subprocess.PIPE,\n                                      stderr = subprocess.PIPE)\n            out_res = s_data.stdout.read()\n            err_res = s_data.stderr.read()\n            # 首先算出数据大小\n            data_size = len(out_res) + len(err_res)\n            # 用一个字典来存储文件头大小和描述信息，我们可以任意的添加key\n            head_dic = {\'data_size\':data_size}\n            # 要传输的内容是字节码，先用json序列化成字典形式的字符串，然后encode成字节码\n            head_bytes = json.dumps(head_dic).encode(\'utf-8\')\n\n            # 1、发送报头的长度，先用struct打包一下，将这个报头的长度压缩成4个字节\n            conn.send(struct.pack(\'i\',len(head_bytes)))\n            # 2、发送报头\n            conn.send(head_bytes)\n            # 3、发送数据部分\n            conn.send(out_res)\n            conn.send(err_res)\n        except Exception:\n            print(\'当前客户端链接已被关闭\')\n            break\n    conn.close()\n# new_ssh.close()\n```\n\n客户端的：\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport socket\nimport struct\nimport json\nphone = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nphone.connect((\'127.0.0.1\',8888))\n\nwhile True:\n    msg = input(\'>> \')\n    if not msg:continue\n    phone.send(msg.encode(\'utf-8\'))\n    \n    # 接收报头长度\n    head_struct = phone.recv(4)\n    # 接收到的内容是一个元组，我们取第一个，这里取到的值是包头实际的大小\n    head_len = struct.unpack(\'i\',head_struct)[0]\n\n    # 接收报文头，我知道报头多大了我就接收一下报头\n    head_bytes = phone.recv(head_len)\n    # 接收到的内容是字节码，先解码转换成json格式的字符串\n    head_json = head_bytes.decode(\'utf-8\')\n    # 把json字符串还原成字典\n    head_dic = json.loads(head_json)\n    # 取到字典中的data_size的key获取到真实的数据内容的大小。\n    data_size = head_dic[\'data_size\']\n\n\n    # 收数据\n    recv_size = 0\n    recv_data = b\'\'\n    while recv_size < data_size:\n        data = phone.recv(1024)\n        recv_size += len(data)\n        recv_data += data\n\n    print(recv_data.decode(\'gbk\'))\n\n# phone.close()\n```\n\n\n\n\n\n","timestamp":1523777648264},{"name":"01-socketserver.md","path":"05-Python/03-网络编程初窥/01-socketserver.md","content":"# SocketServer\n\n## SocketServer实现并发\n\n### SockerServer源码分析\n\n基于tcp的套接字，关键就是两个循环，一个链接循环，一个通信循环\n\nsocketserver模块中分两大类：server类（解决链接问题）和request类（解决通信问题）\n\n#### Server类\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-21/42116814.jpg)\n\n#### request 类\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-21/48099336.jpg)\n\n#### 继承关系\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-21/22563251.jpg)\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-21/44908269.jpg)\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-21/82065533.jpg)\n\n```\n\n                             +------------+\n                             | BaseServer |\n                             +------------+\n                                   |\n                                   v\n                             +-----------+        +------------------+\n                             | TCPServer |------->| UnixStreamServer |\n                             +-----------+        +------------------+\n                                   |\n                                   v\n                             +-----------+        +--------------------+\n                             | UDPServer |------->| UnixDatagramServer |\n                             +-----------+        +--------------------+\n```\n\n服务端改为支持并发：\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport socketserver\n\n\nclass FtpServer(socketserver.BaseRequestHandler):\n    def handle(self):\n        print(self)\n        print(self.request)\n        while True:\n            data = self.request.recv(1024)\n            self.request.send(data.upper())\n\n\nif __name__ == \'__main__\':\n    obj = socketserver.ThreadingTCPServer((\'127.0.0.1\',8080),FtpServer)\n    obj.serve_forever() # 链接循环\n```\n\n以下述代码为例，分析socketserver源码：\n\n```python\nobj = socketserver.ThreadingTCPServer((\'127.0.0.1\',8080),FtpServer)\nobj.serve_forever()\n```\n\n查找属性的顺序：ThreadingTCPServer->ThreadingMixIn->TCPServer->BaseServer\n\n1. 实例化得到obj，那么我们实例化必将触发初始化函数`__init__`的运行，那么看一下ThreadingTCPServer都干了啥。\n\n   ```python\n   class ThreadingTCPServer(ThreadingMixIn, TCPServer): pass\n   ```\n\n   可以发现这个类就是继承了一个ThreadingMixIN和一个TCPServer，然后啥都没干，他其实就是作为一个桥梁的作用把两个父类给架起来来了，通过这个类实例化得到的对象可以调用两个父类的方法\n\n2. 经过查找ThreadingMixIn类里也没有构造方法，那么再去找父类，找到TCPServer中是有构造方法的：\n\n   ```python\n   class TCPServer(BaseServer):\n\n       # 定义地址集，这里定义成一个属性\n       address_family = socket.AF_INET\n       # 定义socket类型，默认基于流式的就是TCP\n       socket_type = socket.SOCK_STREAM\n       # listen的个数，同时允许有几个等待的队列里面。\n       request_queue_size = 5\n       # 是否允许地址的重用\n       allow_reuse_address = False\n\n       def __init__(self, server_address, RequestHandlerClass, bind_and_activate=True):\n           \"\"\"Constructor.  May be extended, do not override.\"\"\"\n           BaseServer.__init__(self, server_address, RequestHandlerClass)\n           self.socket = socket.socket(self.address_family,\n                                       self.socket_type)\n           if bind_and_activate:\n               try:\n                   self.server_bind()\n                   self.server_activate()\n               except:\n                   self.server_close()\n                   raise\n   ```\n\n   这个其实就是我们之前构造一个socket的过程，只不过现在以面向对象的形式体现了。在构造方法里还调用了基类的构造方法，其中基类的构造方法如下：\n\n   ```python\n    def __init__(self, server_address, RequestHandlerClass):\n        \"\"\"Constructor.  May be extended, do not override.\"\"\"\n        self.server_address = server_address\n        self.RequestHandlerClass = RequestHandlerClass\n        self.__is_shut_down = threading.Event()\n        self.__shutdown_request = False\n   ```\n\n   那么根据基类的构造方法，对象肯定是有server_address和RequestHandlerClass的属性的，基类的init方法仅仅是做了一个赋值的操作。RequestHandlerClass就是我们之前写到的FtpServer类。\n\n   `self.socket`就是对象构造的的socket对象，和之前一样，给socket.socket传一个地址集的参数，一个socket类型的参数。如果`bind_and_activate`激活的话那么就执行server_bind方法和server_activate的方法。\n\n3. 按照继承关系在TCPServer类中找到了server_bind和server_activate的方法如下：\n\n   ```python\n   def server_bind(self):\n\n       if self.allow_reuse_address:\n           self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n       self.socket.bind(self.server_address)\n       self.server_address = self.socket.getsockname()\n\n   def server_activate(self):\n\n       self.socket.listen(self.request_queue_size)\n   ```\n\n   其实就是执行了我们bind的过程。activate函数就是之前讲到的手机开机，设置listen方法的监听个数。\n\n4. 我们说每一个服务员要进行循环的利用，不是一次性的，以你我们调用了`obj.serverforever`这样一个方法。这个循环方法是在BaseServer下定义的，源代码如下：\n\n   ```python\n   def serve_forever(self, poll_interval=0.5):\n\n       self.__is_shut_down.clear()\n       try:\n           with _ServerSelector() as selector:\n               selector.register(self, selectors.EVENT_READ)\n\n               while not self.__shutdown_request:\n                   ready = selector.select(poll_interval)\n                   if ready:\n                       self._handle_request_noblock()\n\n                   self.service_actions()\n       finally:\n           self.__shutdown_request = False\n           self.__is_shut_down.set()\n   ```\n\n   在while循环中调用了一个`_handle_request_noblock()`的方法，那么这个方法做了什么？这个方法也是在BaseServer中的，代码如下：\n\n   ```python\n   def _handle_request_noblock(self):\n     \n       try:\n           # request其实就是conn这条连接，client_address就是客户端的地址。\n           request, client_address = self.get_request()\n       except OSError:\n           return\n       if self.verify_request(request, client_address):\n           try:\n               self.process_request(request, client_address)\n           except Exception:\n               self.handle_error(request, client_address)\n               self.shutdown_request(request)\n           except:\n               self.shutdown_request(request)\n               raise\n       else:\n           self.shutdown_request(request)\n   ```\n\n   在如上的这个函数中，对象调用了一个get_request的方法，看一下get_request方法：\n\n   ```\n   def get_request(self):\n\n       return self.socket.accept()\n   ```\n\n   函数很简单就是调用了socket的accept的方法，其实就是开始请求了。那么上面的内容也就好理解了，`request,client_address = self.get_request`。其中request就是conn，client_address就是客户端的地址。然后对象调用了process_request方法将连接request和客户端的地址传给了这个函数，看一下这个方法写的啥：\n\n   ```python\n   def process_request_thread(self, request, client_address):\n\n       try:\n           self.finish_request(request, client_address)\n       except Exception:\n           self.handle_error(request, client_address)\n       finally:\n               self.shutdown_request(request)\n   def process_request(self, request, client_address):\n       \"\"\"Start a new thread to process the request.\"\"\"\n       t = threading.Thread(target = self.process_request_thread,\n                            args = (request, client_address))\n       t.daemon = self.daemon_threads\n       t.start()\n   ```\n\n   上述操作就是开启了多线程应对并发，开一个线程就执行一次这个函数。target指向一个函数为process_request_thread，这个函数在源码中就在process_request的正上方。这个目标函数执行了finish_request函数，来看一下finsh_requst写的啥，这个函数是在BaseServer里写到的。\n\n   ```python\n   def finish_request(self, request, client_address):\n       \"\"\"Finish one request by instantiating RequestHandlerClass.\"\"\"\n       self.RequestHandlerClass(request, client_address, self)\n   ```\n\n   这个函数其实就是调用了RequestHandlerClass其实这个就是我们写的那个FtpServer的那个类，我们把客户端的信息传递给了我们自己定义的类。传递了一个连接，一个客户端地址，一个obj对象本身，那么其实操作一顿绕了一圈最终就是用我们创建的Ftpserver来实例化了对象。相当于`FtpServer(request,client_address,self)`这个样子。那么实例化就要找FtpServer下的构造方法，但是我们没写，那么就要找他的父类的构造方法了。源代码如下：\n\n   ```\n   class BaseRequestHandler:\n\n       def __init__(self, request, client_address, server):\n           self.request = request\n           self.client_address = client_address\n           # 这个server就是obj本身\n           self.server = server\n           self.setup()\n           try:\n               self.handle()\n           finally:\n               self.finish()\n   ```\n\n   这个FtpServer的对象调用了一个handle方法，但是这个handle我们看到的是pass，因此在一开始定义类的时候我们一定要写一个handle的方法\n\n#### 源码分析总结：\n\n基于tcp的socketserver我们自己定义的类中的\n\n1. 　　self.server即套接字对象\n2. 　　self.request即一个链接\n3. 　　self.client_address即客户端地址\n\n基于udp的socketserver我们自己定义的类中的\n\n1. 　　self.request是一个元组（第一个元素是客户端发来的数据，第二部分是服务端的udp套接字对象），如(b\'adsf\', <socket.socket fd=200, family=AddressFamily.AF_INET, type=SocketKind.SOCK_DGRAM, proto=0, laddr=(\'127.0.0.1\', 8080)>)\n2. 　　self.client_address即客户端地址","timestamp":1523777648264},{"name":"02-FTPserver.md","path":"05-Python/03-网络编程初窥/02-FTPserver.md","content":"","timestamp":1523777648264},{"name":"04-Socket小结.md","path":"05-Python/03-网络编程初窥/04-Socket小结.md","content":"# Socket\n\n## 常用Socket小功能\n\n- socket.gethostname()，返回所在主机或者本地主机的名字。\n\n  ```\n  >>> socket.gethostname()\n  \'maxiaoyu\'\n  ```\n\n- socket.gethostbyname()，接收hostname返回IP。\n\n  ```\n  >>> socket.gethostbyname(\'bbs.dcgamer.top\')\n  \'47.94.132.15\'\n  ```\n\n- ip地址格式转换：如果要使用低层网络函数，有时普通的字符串形式的IP地址并不是很有用，需要把它们转换成打包后的32位二进制格式。 \n\n  ```\n  # ip地址格式打包\n  >>> packed = socket.inet_aton(\'192.168.1.1\')\n  >>> packed\n  \'\\xc0\\xa8\\x01\\x01\'\n  >>> unpacked = socket.inet_ntoa(packed)\n  >>> unpacked\n  \'192.168.1.1\'\n  ```\n\n- 调用socket库中的getservbyport()函数来获取服务的名字。调用这个函数时可以根据情况决定是否提供协议名，第一个参数是端口号，第二个是协议名。 \n\n  ```\n  >>> socket.getservbyport(9002,\'tcp\')\n  \'dynamid\'\n  >>> socket.getservbyport(53,\'udp\')  \n  \'domain\'\n  >>> socket.getservbyport(8080,\'tcp\')\n  \'webcache\'\n  ```\n\n- 编写低层网络应用时，或许需要处理通过电缆在两台设备之间传送的低层数据。在这种操作中，需要把主机操作系统发出的数据转换成网络格式，或者做逆向转换，因为这两种数据的表示方式不一样。 函数名中的n表示网络； h表示主机； l表示长整形； s表示短整形，即16位。 \n\n  ```python\n  import socket\n\n  def convert_integer():\n      data = 1234\n      # 32-bit\n      print(\"Original: %s => Long host byte order: %s, Network byte order: %s\"\\%(data, socket.ntohl(data), socket.htonl(data)))\n      # 16-bit\n      print(\"Original: %s => Short host byte order: %s, Network byte order:%s\"\\%(data, socket.ntohs(data), socket.htons(data)))\n  if __name__ == \'__main__\':\n      convert_integer()\n      \n  结果如下：\n  $ python 1_5_integer_conversion.py\n  Original: 1234 => Long host byte order: 3523477504, Network byte order: 3523477504\n  Original: 1234 => Short host byte order: 53764, Network byte order: 53764\n  ```\n\n- 获取套接字的超时时间，创建一个套接字对象实例，调用gettimeout()方法获取默认的超时时间，调用\n  settimeout()方法设定一个超时时间。传给settimeout()方法的参数可以是秒数（非负浮点数）也可以是None。这个方法在处理阻塞式套接字操作时使用。如果把超时时间设为None，则禁用了套接字操作的超时检测。 这种操作在开发服务器应用时很有用。 \n\n  ```python\n  >>> sock = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n  >>> print(sock.gettimeout())\n  None\n  >>> sock.settimeout(10)\n  >>> sock.gettimeout()       \n  10.0\n  ```\n\n- socket的错误处理\n\n  ```python\n\n  ```\n\n  ​","timestamp":1523777648264},{"name":"05-GIL.md","path":"05-Python/03-网络编程初窥/05-GIL.md","content":"","timestamp":1523777648264},{"name":"06-06、进程&线程.md","path":"05-Python/03-网络编程初窥/06-06、进程&线程.md","content":"# 进程&线程\n\n参考文章：http://www.cnblogs.com/yuanchenqi/articles/6755717.html\n\n## 进程线程介绍\n\n**CPU的切换的条件：**\n\n- 出现了IO操作\n- 达到了规定的时间片\n\n#### 什么是进程？\n\n进程就是一个程序在一个数据集上的一次动态执行过程，进程是一种运行状态。进程一般由程序、数据集、进程控制块三部分组成。我们编写的程序用来描述进程要完成哪些功能以及如何完成；数据集则是程序在执行过程中所需要使用的资源；进程控制块用来记录进程的外部特征，描述进程的执行变化过程，系统可以利用它来控制和管理进程，它是系统感知进程存在的唯一标志，简单来说进程控制块会保存进程的运行状态。\n\n进程是一个资源管理或者是资源调度单位，我们可以理解为一个容器，真正跑的是容器里的线程（最小执行单位）。\n\n##### 并发\n\ncpu不断切换去操作不同的任务的这种情况叫做并发。\n\n##### 并行\n\n多个任务分别交给多个cpu去同时执行这个叫并行。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-22/98205600.jpg)\n\n进程和线程的关系：\n\n- 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程（主线程）。\n- 资源分配给进程，同一进程的所有线程共享该进程的所有资源。\n- CPU分给线程，即真正在CPU上运行的是线程。\n\n#### 同步异步\n\n在计算机领域，同步就是指一个进程在执行某个请求的时候，若该请求需要一段时间才能返回信息，那么这个进程将会一直等待下去，直到收到返回信息才继续执行下去（比如recv收到为空的时候会一直卡住）；异步是指进程不需要一直等下去，而是继续执行下面的操作，不管其他进程的状态。当有消息返回时系统会通知进程进行处理，这样可以提高执行的效率。举个例子，打电话时就是同步通信，发短息时就是异步通信。\n\n## Threading模块\n\npython可以实现多进程的并行，但是不支持多线程的并行。Python的多线程会由于Python的GIL锁，导致同一时刻，同一进程只有有一个线程被运行。\n\n首先看下面一段代码：\n\n```python\nimport threading\nimport time\n\n\ndef listen():\n    print(\'听歌\')\n    time.sleep(3)\n\ndef blog():\n    print(\'blog\')\n    time.sleep(3)\n\nlisten()\nblog()\n```\n\n定义了两个函数一个是听歌，另外一个是写博客，每一个函数都有自己sleep的时间，先运行听歌的话那么下面的blog函数就得等着听歌的运行完了才行。但是从实际来讲，听歌和学博客本身就没有什么制约关系，我完全可以一边听歌一边写博客。\n\n```\nimport threading\nimport time\n\n\ndef listen():\n    print(\'开始听歌啦~~~~\')\n    time.sleep(3)\n    print(\'不听拉~~~~\')\n\ndef blog():\n    print(\'开始写博客拉****\')\n    time.sleep(3)\n    print(\'写博客结束拉****\')\n\n# t = threading.Thread(target = fun_name,args = ())\nt1 = threading.Thread(target = listen)\nt2 = threading.Thread(target = blog)\n\nt1.start()\nt2.start()\n\nprint(\'end\')\n```\n\n现在我们调用threading模块下的Thread类去创建线程，类需要传递两个内容，第一个是target，这个target指的是我要创建一个线程，这个线程要去运行哪个内容，我们要运行listen听歌的函数，直接把函数名穿进去，如果需要传参数的话就在后面加一个args传递参数，这里没用到就不加了。\n\n类实例化产生的就是对象，我们分别使用t1和t2来接收这俩对象。调用对象的start方法就可以执行。那么上述代码的执行结果是什么呢？\n\n![](http://omk1n04i8.bkt.clouddn.com/17-8-22/14015806.jpg)\n\n从上面的图可以看到其实开始听歌，写博客，end是同一时间出现的，那么这个是怎么做到的呢。\n\n我们运行py文件会有一个主进程，在主进程内部会开启一个主线程，上一则例子中运行听歌和写博客都是在主线程中运行的，因此会依次等待两个函数运行完毕。\n\n不过第二则例子我们利用了threading，从主线程下面又派生出两个子线程分别去对照完成听歌和写博客两件事情，可以看到开始运行的一开始的时候，开始听课，开始写博客和end一起出来的，但是实际上来说他们是并发执行的，而不是并行，并且谁先谁后并不是绝对的，只不过我先调用了t1的start方法，因此时间上稍稍早了一点。实际上他们是要去竞争的。那么结束的时候也是三秒以后结束的，而不是等待6s。\n\n### 使用自定义类的方式实现多线程\n\n实现继承Thread类的方法实现自定义自己的类，关键就是重写一个run方法：\n\n```python\nimport threading\nimport time\n\n\nclass MyThread(threading.Thread):\n\n    def __init__(self):\n        threading.Thread.__init__(self)\n\n    def run(self):\n        print(\'running ~~~\')\n        time.sleep(3)\n        print(\'running over\')\n\nt1 = MyThread()\nt2 = MyThread()\n\nt1.start()\nt2.start()\n\nprint(\'end\')\n```\n\n### Thread类的实例方法\n\n#### join()和setdaemon\n\n```python\n# join()：在子线程完成运行之前，这个子线程的父线程将一直被阻塞。\n\n# setDaemon(True)：\n        \'\'\'\n   将线程声明为守护线程，必须在start() 方法调用之前设置，如果不设置为守护线程程序会被无限挂起。\n   当我们在程序运行中，执行一个主线程，如果主线程又创建一个子线程，主线程和子线程 就分兵两路，分别运行，那么当主线程完成想退出时，会检验子线程是否完成。如果子线程未完成，则主线程会等待子线程完成后再退出。但是有时候我们需要的是只要主线程完成了，不管子线程是否完成，都要和主线程一起退出，这时就可以 用setDaemon方法啦\n   说白了就是我不等你了子线程了，只要主线程完成了你们都跟着一起完事\'\'\'\n\n\nimport threading\nfrom time import ctime,sleep\nimport time\n\ndef Music(name):\n\n        print (\"Begin listening to {name}. {time}\".format(name=name,time=ctime()))\n        sleep(3)\n        print(\"end listening {time}\".format(time=ctime()))\n\ndef Blog(title):\n\n        print (\"Begin recording the {title}. {time}\".format(title=title,time=ctime()))\n        sleep(5)\n        print(\'end recording {time}\'.format(time=ctime()))\n\n\nthreads = []\n\n\nt1 = threading.Thread(target=Music,args=(\'FILL ME\',))\nt2 = threading.Thread(target=Blog,args=(\'aaa\',))\n\nthreads.append(t1)\nthreads.append(t2)\n\nif __name__ == \'__main__\':\n\n    #t2.setDaemon(True) # 设置t2为daemon的时候，t1会正常执行完，也就是3s过后程序结束，打印4行\n    \"\"\"\n    1 Begin listening to FILL ME. Sat Jan 14 14:17:09 2017\n    2 Begin recording the aaa Sat Jan 14 14:17:09 2017\n    3 all over Sat Jan 14 14:17:09 2017       #先打印这三条\n    4 \n    5 end listening Sat Jan 14 14:17:12 2017  #等待3秒，再打印这条；t1结束后，主线程也结束了。   \n    \"\"\"\n\n    for t in threads:\n\n        #t.setDaemon(True) #注意:一定在start之前设置，设置完了以后会立即打印三行然后结束\n        t.start() # 这个执行子线程t也是由主线程来操作的。\n\n        #t.join()\n\n    #t1.join()\n    #t2.join()    #  考虑这三种join位置下的结果？\n\n    print (\"all over %s\" %ctime())\n    \n关于Daemon的描述：\n\ndaemon\nA boolean value indicating whether this thread is a daemon thread (True) or not (False). This must be set before start() is called, otherwise RuntimeError is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main thread default to daemon = False.\n\nThe entire Python program exits when no alive non-daemon threads are left.\n\n当daemon被设置为True时，如果主线程退出，那么子线程也将跟着退出，\n\n反之，子线程将继续运行，直到正常退出。简单的理解如下：\nDaemon：程序直到不存在非守护线程时退出。\n```\n\n其他方法：\n\n```python\nThread实例对象的方法\n  # isAlive(): 返回线程是否活动的。\n  # getName(): 返回线程名。\n  # setName(): 设置线程名。\n\nthreading模块提供的一些方法：\n  # threading.currentThread(): 返回当前的线程变量。\n  # threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。\n  # threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。结果 为1的时候说明只有一个主线程没有子线程。\n```\n\n### 小结：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-13/72029660.jpg)\n\n\n\n\n\n","timestamp":1523777648264},{"name":"07-07、小谈GIL.md","path":"05-Python/03-网络编程初窥/07-07、小谈GIL.md","content":"## GIL(全局解释器锁)\n\n- 参考资料：http://cenalulu.github.io/python/gil-in-python/\n\n> 定义：\n>\n> In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython’s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.)\n\nPython中的线程是操作系统的原生线程，Python虚拟机使用一个全局解释器锁（Global Interpreter Lock）来互斥线程对Python虚拟机的使用。为了支持多线程机制，一个基本的要求就是需要实现不同线程对共享资源访问的互斥，所以引入了GIL。\nGIL：在一个线程拥有了解释器的访问权之后，其他的所有线程都必须等待它释放解释器的访问权，即使这些线程的下一条指令并不会互相影响。\n在调用任何Python C API之前，要先获得GIL\nGIL缺点：多处理器退化为单处理器；优点：避免大量的加锁解锁操作\n\n### GIL的影响\n\n无论你启多少个线程，你有多少个cpu, Python在执行一个进程的时候会淡定的在同一时刻只允许一个线程运行。\n所以，python是无法利用多核CPU实现多线程的。\n这样，python对于计算密集型的任务开多线程的效率甚至不如串行(没有大量切换)，但是，对于IO密集型的任务效率还是有显著提升的。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-13/66476109.jpg)\n\n#### 在Python中哪一种多线程的程序表现较好？\n\n上面说到由于GIL这一把锁，同一时刻的一个进程下只允许一个一个线程去使用CPU，达不到并行的效果。当线程遇到IO操作的时候（或者达到规定的时间片）就会让出cpu让其他的线程去使用cpu，直到IO结束才会继续调用cpu资源。这样的操作使得Python更适合IO密集型，而计算密集型在多个线程的时候会处于并发的状态，当一个线程计算一半的时候将CPU资源分配给其他的线程计算，上一个计算的结果还需要保存起来，占用资源，另外多个线程计算在切换的过程中是消耗资源的，并且计算的效率并没有提升反而有下降，故并不建议用python多线程运行计算密集型的代码。\n\n> ##### IO密集型（IO bound）和CPU密集型（CPU bound）：\n>\n> I/O bound 指的是系统的CPU效能相对硬盘/内存的效能要好很多，此时，系统运作，大部分的状况是 CPU 在等 I/O (硬盘/内存) 的读/写，此时 CPU Loading 不高。\n> CPU bound 指的是系统的 硬盘/内存 效能 相对 CPU 的效能 要好很多，此时，系统运作，大部分的状况是 CPU Loading 100%，CPU 要读/写 I/O (硬盘/内存)，I/O在很短的时间就可以完成，而 CPU 还有许多运算要处理，CPU Loading 很高。\n\n结论：\n\n- IO密集型：Python多线程是有意义的\n- 计算密集型：Python多线程没多大用，反而会更慢，没串行来的快。\n\n## 多线程性能测试\n\n- 多核也就是多个CPU\n  - cpu越多，提高的是计算的性能\n  - 如果程序是IO操作的时候（多核和单核是一样的），再多的cpu也没有意义。\n\n- 实现并发\n  第一种：一个进程下，开多个线程\n  第二种：开多个进程\n\n- 多进程：\n   优点：可以利用多核\n   缺点：开销大\n\n- 多线程\n   优点：开销小\n   缺点：不可以利用多核\n\n- 多进程和多进程的应用场景\n   - 计算密集型：也就是计算多，IO少。如果是计算密集型，就用多进程（如金融分析等）\n   - IO密集型：也就是IO多，计算少。如果是IO密集型的，就用多线程（一般遇到的都是IO密集型的）\n\n### 计算密集型\n\n```python\n# 计算密集型的要开启多进程\nfrom  multiprocessing import Process\nfrom threading import Thread\nimport time\ndef work():\n    res = 0\n    for i in range(10000000):\n        res+=i\nif __name__ == \'__main__\':\n    l = []\n    start = time.time()\n    for i in range(4):\n        p = Process(target=work)  #1.9371106624603271  #可以利用多核（也就是多个cpu）\n        # p  = Thread(target=work)  #3.0401737689971924\n        l.append(p)\n        p.start()\n    for p in l:\n        p.join()\n    stop = time.time()\n    print(\'%s\'%(stop-start))\n```\n\n### IO密集型\n\n```python\n# I/O密集型要开启多线程\nfrom multiprocessing import Process\nfrom threading import Thread\nimport time\ndef work():\n    time.sleep(3)\nif __name__ == \'__main__\':\n    l = []\n    start = time.time()\n    for i in range(400):\n        # p = Process(target=work)  #34.9549994468689   #因为开了好多进程，它的开销大，花费的时间也就长了\n        p = Thread(target=work) #2.2151265144348145  #当开了多个线程的时候，它的开销小，花费的时间也小了\n        l.append(p)\n        p.start()\n    for i in l :\n        i.join()\n    stop = time.time()\n    print(\'%s\'%(stop-start))\n```\n\n","timestamp":1523777648264},{"name":"08-08、互斥锁.md","path":"05-Python/03-网络编程初窥/08-08、互斥锁.md","content":"## 同步锁\n\n### 不加锁\n\n首先先来看下面的一段代码：\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\n\nimport time\nimport threading\n\ndef subNum():\n    \"\"\"\n    定义个方法，这个方法是用来持续的\n    :return: \n    \"\"\"\n    # 在每个线程中都获取这个全局变量\n    global num\n    num-=1\n\n    # temp=num\n    # time.sleep(0.1)\n    # num =temp-1  # 对此公共变量进行-1操作\n\nnum = 100  #设定一个共享变量\n\nthread_list = []\n\nfor i in range(100):\n    t = threading.Thread(target=subNum)\n    t.start()\n    thread_list.append(t)\nprint(len(thread_list))\n\nfor t in thread_list: #等待所有线程执行完毕\n    t.join()\nprint(len(thread_list))\n\nprint(\'Result: \', num)\n```\n\n设置一个共享变量num=100，函数subNum就是获取到这个全局变量然后做-1的操作。先使用上面这种方式去执行一遍观察结果：\n\n```python\n100\n100\nResult:  0\n```\n\n发现100被减到0了，上述的程序其实就是生成了100个线程去依次执行减1操作，所以结果肯定是0.那么换一种形式：\n\n```python\nimport time\nimport threading\n\ndef subNum():\n    \"\"\"\n    定义个方法，这个方法是用来持续的\n    :return: \n    \"\"\"\n    # 在每个线程中都获取这个全局变量\n    global num\n    # num-=1\n\n    temp=num\n    time.sleep(0.001)\n    num =temp-1  # 对此公共变量进行-1操作\n\nnum = 100  #设定一个共享变量\n\nthread_list = []\n\nfor i in range(100):\n    t = threading.Thread(target=subNum)\n    t.start()\n    thread_list.append(t)\nprint(len(thread_list))\n\nfor t in thread_list: #等待所有线程执行完毕\n    t.join()\nprint(len(thread_list))\n\nprint(\'Result: \', num)\n```\n\n其中主要的变化是将`num-=1`替换成了如下的三行：\n\n```python\n    temp=num\n    time.sleep(0.001)\n    num =temp-1  # 对此公共变量进行-1操作\n```\n\n上面这三行的操作其实和`num -= 1`没什么区别，只不过借助一个中间变量。不过重点不在这里，重点是我们这里sleep了0.001s。之前说线程发生切换取决于以下两个条件：\n\n- 遇到了IO操作（IO操作远远的要慢于CPU操作）\n- 达到了规定的时间片\n\n这里使用time.sleep睡了这么一小会就相当于IO操作，因此就会发生线程的切换，那么对于第一个线程来说，他执行了temp = num的操作完了以后就在那sleep等着了，没有进行进一步操作，而是让出CPU。此时发生线程切换，下一个线程也会执行temp = num的操作，然后开始睡，切换到下一个线程，以此类推。\n\n在第一个线程还没醒过来的时候切换的线程大家拿到的temp全是100，然后第一个线程睡醒了，继续参与到CPU的竞争中来，然后执行-1的操作，直到执行完为止，也不会真正的剪掉几个1.有些线程拿到的temp就是100，有些是99，有一些是98。因此我们最后执行的结果其实是不确定的，可能是九十几，也有可能是八十几，取决于你的cpu的速度。\n\n但是我们如果把sleep的时间设置为0.1s的话那么肯定就是99，因为0.1s对于cpu来说实在是太长了，也就是100个线程拿到的temp全是100，然后减完了全是99然后赋值给num。因此最后就是99.\n\n如果上面的不好理解的话，那么就用银行账户来做比喻。\n\n![img](http://omk1n04i8.bkt.clouddn.com/17-3-25/93569127-file_1490441344049_2169.jpg)\n\n如果上面这张图的例子看懂了的话，那么上面的例子应该就可以看懂了。不加锁的话，那么在存钱操作（减1操作）执行完之前，大家拿到的当前余额都是1000元（temp都是100，或者是99等等），这就是不加锁的问题。\n\n### 加锁\n\n有了上面的经验，我们就知道，我们需要对共享的资源进行锁保护，加锁的方式很简单。\n\n- 首先创建一把互斥锁\n\n  ```python\n  # 主要Lock的L大写\n  lock = threading.Lock()\n  ```\n\n- 将这把锁加载需要“锁住”的位置。\n\n  ```python\n  lock.acquire()\n  temp=num\n  time.sleep(0.001)\n  num =temp-1  # 对此公共变量进行-1操作\n  lock.release()\n  ```\n\n此时的结果就肯定是可以把num减到0了，不过思考这么一个问题，这样和串行的执行的区别是什么？加了这把锁意味着就要一个一个线程去执行，和join是一个效果。\n\n但是join针对是一个整体，比如我在线程里去调用了subNum这个函数，假如里面有一个print(\'ok\')。\n\n```python\nprint(\'ok\')\nlock.acquire()\ntemp=num\ntime.sleep(0.1)\nnum =temp-1  # 对此公共变量进行-1操作\nlock.release()\n```\n\n那么使用join会将这个print语句也按照串行的去执行。但是加锁的话我们可以指定用锁把哪一段锁住，那么print这一段不需要进行锁保护，那么我们就不需要进行加锁，他就可以允许线程去并发执行了，这就是加锁和串行的区别。简单的概括一下就是互斥锁可以根据自己的需求去设定加锁和解锁的位置，因此要比单线程的join()的效率更高。因为互斥锁的使用很简单，因此你加锁和解锁的位置要是不对的话很可能会造成死锁的现象，为了解决死锁的问题，又出现了迭代锁。迭代锁起到了线程串行的作用，因此不会导致thread_safe即线程安全的问题。\n\n#### 关于这把互斥锁\n\n这把锁是用户级别的锁，是用来保证共享数据一致性的一种手段，不要和GIL的这一把大锁搞混了。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-13/23266726.jpg)\n\n既然用户程序已经自己有锁了，那为什么C python还需要GIL呢？加入GIL主要的原因是为了降低程序的开发的复杂度，比如现在的你写python不需要关心内存回收的问题，因为Python解释器帮你自动定期进行内存回收，你可以理解为python解释器里有一个独立的线程，每过一段时间它起wake up做一次全局轮询看看哪些内存数据是可以被清空的，此时你自己的程序 里的线程和 py解释器自己的线程是并发运行的，假设你的线程删除了一个变量，py解释器的垃圾回收线程在清空这个变量的过程中的clearing时刻，可能一个其它线程正好又重新给这个还没来及得清空的内存空间赋值了，结果就有可能新赋值的数据被删除了，为了解决类似的问题，python解释器简单粗暴的加了锁，即当一个线程运行时，其它人都不能动，这样就解决了上述的问题，这可以说是Python早期版本的遗留问题。（摘自--http://www.cnblogs.com/liuyang1987/p/6292321.html#commentform）","timestamp":1523777648264},{"name":"09-09、死锁和递归锁&信号量.md","path":"05-Python/03-网络编程初窥/09-09、死锁和递归锁&信号量.md","content":"# 死锁&递归锁&信号量\n\n所谓死锁，是指两个或两个以上的进程或线程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程，示例代码如下：\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\n\nimport threading\nimport time\n\n# 定义两把互斥锁\nmutexA = threading.Lock()\nmutexB = threading.Lock()\n\nclass MyThread(threading.Thread):\n\n    def __init__(self):\n        threading.Thread.__init__(self)\n\n    def run(self):\n        self.fun1()\n        self.fun2()\n\n    def fun1(self):\n\n        mutexA.acquire()  # 如果锁被占用,则阻塞在这里,等待锁的释放\n        print (\"I am %s , get res: %s---%s\" %(self.name, \"ResA\",time.time()))\n        mutexB.acquire()\n        print (\"I am %s , get res: %s---%s\" %(self.name, \"ResB\",time.time()))\n        mutexB.release()\n        mutexA.release()\n\n\n    def fun2(self):\n\n        mutexB.acquire()\n        print (\"I am %s , get res: %s---%s\" %(self.name, \"ResB\",time.time()))\n        time.sleep(0.2)\n\n        mutexA.acquire()\n        print (\"I am %s , get res: %s---%s\" %(self.name, \"ResA\",time.time()))\n        mutexA.release()\n\n        mutexB.release()\n\nif __name__ == \"__main__\":\n\n    print(\"start---------------------------%s\"%time.time())\n\n    for i in range(0, 10):\n        my_thread = MyThread()\n        my_thread.start()\n```\n\n执行结果如下：\n\n```python\nstart---------------------------1505195825.0121815\nI am Thread-1 , get res: ResA---1505195825.0698388\nI am Thread-1 , get res: ResB---1505195825.0703418\nI am Thread-1 , get res: ResB---1505195825.0703418\nI am Thread-2 , get res: ResA---1505195825.0703418\n```\n\n**解析：**当第一线程去执行fun1的时候，会依次占用A锁，占用B锁，释放B锁，释放A锁，然后再去执行fun2，在执行fun2的时候首先会占用B锁，但是此时发现了一个sleep，我们说线程切换到条件有两个，其一是达到了规定的时间片，其二是遇到了IO操作，time.sleep无异于IO操作，因此第二个线程就会开始依次执行fun1和fun2，在执行fun1的时候第二个线程会占用A锁，然后紧接着当他要占用B锁的时候发现B锁没有被释放，然后线程2就会等着，但是当第一个线程睡完了这0.2秒的时候发现锁A又被占用了，因此第一个线程会等着锁A被释放。这两个线程互相的去等待彼此需要的锁被释放就卡在这里了。也就是我们只能看到如上的4条结果，如果没有外力干涉，那么它会一直卡在这里。\n\n简单的复现了一下死锁产生的现象，如下为死锁产生的四个必要的条件：\n\n- 互斥条件：一个资源每次只能被一个进程使用。\n- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。\n- 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。\n- 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。\n\nPython解决这种死锁问题的方案是使用递归锁，递归锁和互斥锁不一样的地方是，互斥锁只能调用一次，而且调用一次必须释放才能再次利用，但是递归锁则不用。代码修改如下，递归锁使用的是Rlock()的方法：\n\n```python\nimport threading\nimport time\n\n# mutexA = threading.Lock()\n# mutexB = threading.Lock()\n\nrlock = threading.RLock()\n\nclass MyThread(threading.Thread):\n\n    def __init__(self):\n        threading.Thread.__init__(self)\n\n    def run(self):\n        self.fun1()\n        self.fun2()\n\n    def fun1(self):\n        rlock.acquire()  # 如果锁被占用,则阻塞在这里,等待锁的释放\n\n        print (\"I am %s , get res: %s---%s\" %(self.name, \"ResA\",time.time()))\n\n        rlock.acquire()\n        print (\"I am %s , get res: %s---%s\" %(self.name, \"ResB\",time.time()))\n        rlock.release()\n        rlock.release()\n\n\n    def fun2(self):\n        rlock.acquire()\n        print (\"I am %s , get res: %s---%s\" %(self.name, \"ResB\",time.time()))\n        time.sleep(0.2)\n\n        rlock.acquire()\n        print (\"I am %s , get res: %s---%s\" %(self.name, \"ResA\",time.time()))\n        rlock.release()\n\n        rlock.release()\n\nif __name__ == \"__main__\":\n\n    print(\"start---------------------------%s\"%time.time())\n\n    for i in range(0, 5):\n        my_thread = MyThread()\n        my_thread.start()\n```\n\n程序返回的结果：\n\n```python\nstart---------------------------1505199544.7603152\nI am Thread-1 , get res: ResA---1505199544.760816\nI am Thread-1 , get res: ResB---1505199544.760816\nI am Thread-1 , get res: ResB---1505199544.760816\nI am Thread-1 , get res: ResA---1505199544.961564\nI am Thread-2 , get res: ResA---1505199544.961564\nI am Thread-2 , get res: ResB---1505199544.961564\nI am Thread-2 , get res: ResB---1505199544.961564\nI am Thread-2 , get res: ResA---1505199545.1627228\nI am Thread-4 , get res: ResA---1505199545.1627228\nI am Thread-4 , get res: ResB---1505199545.1627228\nI am Thread-4 , get res: ResB---1505199545.1627228\nI am Thread-4 , get res: ResA---1505199545.3631237\nI am Thread-3 , get res: ResA---1505199545.3631237\nI am Thread-3 , get res: ResB---1505199545.3631237\nI am Thread-3 , get res: ResB---1505199545.3631237\nI am Thread-3 , get res: ResA---1505199545.563327\nI am Thread-5 , get res: ResA---1505199545.563327\nI am Thread-5 , get res: ResB---1505199545.563327\nI am Thread-5 , get res: ResB---1505199545.563327\nI am Thread-5 , get res: ResA---1505199545.7639341\n```\n\n递归锁会去维护一个计数器，这个计数器（counter）会去记录acquire的次数，从而可以使得资源被acquire多次，直到一个线程所有的acquire都被release，其他的线程才能获得资源。简单的分析一下：\n\n**分析：**\n\n线程1依次去执行fun1和fun2，在fun2的位置会sleep，但是此时counter=0，因此其他线程不会强占，因此我们还在结果里看到线程1是顺序的执行了4次的print语句释放后然后才是线程2去顺序的执行4次，以此类推。说白了这个递归锁的counter控制了资源的单独使用，在counter递减为0之前其他线程不允许强占。\n\nRlock允许的是同一线程中，同一把锁被多次acquire，但是lock互斥锁是不支持这种操作的。如果使用RLock，那么acquire和release必须成对出现，即调用了n次acquire，必须调用n次的release才能真正释放所占用的琐。说回来，其实这又变成了串行的去执行了，但是涉及到公共数据了以后肯定是串行的去执行的。\n\n### 信号量（Semaphore）\n\n信号量其实也是一把锁，这把锁允许多个工作单位同时执行任务，但是不能超过设置的限制。信号量管理一个内置的计数器，每当调用acquire()时内置计数器-1；调用release() 时内置计数器+1；计数器不能小于0；当计数器为0时，acquire()将阻塞线程直到其他线程调用release()。Semaphore与进程池看起来类似，但是是完全不同的概念。\n\n- 进程池：Pool(4)，最大只能产生四个进程，而且从头到尾都只是这四个进程，不会产生新的。\n- 信号量：信号量是产生的一堆进程/线程，即产生了多个任务都去抢那一把锁\n\n看个例子：\n\n```python\nimport threading\nimport time\n\nsemaphore = threading.Semaphore(5) # 设置为5表示同时能有5个线程进去\n\n\ndef func():\n    if semaphore.acquire():\n        print(threading.currentThread().getName() + \' get semaphore\')\n        time.sleep(2)\n        semaphore.release()\n\n\nfor i in range(20):\n    t1 = threading.Thread(target=func)\n    t1.start()\n```\n\n`semaphore = threading.Semaphore(5)`设置为5的话表示同时能有五个线程进去，其实这个就相当于停车位，一个停车场只有五个空位，先扔进去五辆车都占上，这五个车都停留2s，有人出去了，才允许有人进来，在锁内的五个线程是并发执行的，因此看到的结果是五个五个的打印，开始是thread1~5，后来是6~10.\n\n### 定时器Timer\n\n指定n秒后执行某操作\n\n```python\nfrom threading import Timer\ndef func(n):\n    print(\'hello,world\',n)\nt = Timer(3,func,args=(123,))  #等待三秒后执行func函数，因为func函数有参数，那就再传一个参数进去\nt.start()\n```\n\n\n\n","timestamp":1523777648264},{"name":"10-10、线程Queue.md","path":"05-Python/03-网络编程初窥/10-10、线程Queue.md","content":"# 线程Queue\n\n>Queue is especially useful in threaded programming when information must be exchanged safely between multiple threads.\n\n#### queue列队的三种模式及构造函数\n\n1、先进先出模式 （谁先进去，谁先出来）   ---->class queue.Queue(maxsize)\n\n2、先进后出模式  （先进去的，最后出来）  ---->class queue.LifoQueue(maxsize)\n\n3、优先级模式    （优先级越低，先出来）   ---->class queue.PriorityQueue(maxsize)\n\nQueue是线程安全的，同时只有一个线程去取数据，能够保证数据的安全。\n\n```python\n创建一个“队列”对象\n\nimport Queue\nq = Queue.Queue(maxsize = 10)\n# Queue.Queue类即是一个队列的同步实现。队列长度可为无限或者有限。可通过Queue的构造函数的可选参数.maxsize来设定队列长度。如果maxsize小于1就表示队列长度无限。\n\n将一个值放入队列中\nq.put(10)\n# 调用队列对象的put()方法在队尾插入一个项目。put()有两个参数，第一个item为必需的，为插入项目的值；第二个block为可选参数，默认为1。如果队列当前为空且block为1，put()方法就使调用线程暂停,直到空出一个数据单元。如果block为0，put方法将引发Full异常，告诉你队列空了，不能取了。\n\n将一个值从队列中取出\nq.get()\n# 调用队列对象的get()方法从队头删除并返回一个项目。可选参数为block，默认为True。如果队列为空且block为True，get()就使调用线程暂停，直至有项目可用。如果队列为空且block为False，队列将引发Empty异常。\n```\n\n### 先进先出\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-14/90869551.jpg)\n\n#### 示例1\n\n```python\n#先进先出 （原则：谁先进去，谁就先出来）\nimport queue  #线程 队列\n\nq=queue.Queue() #先进先出\nq.put(12)\nq.put(\"hello\")\nq.put({\"name\":\"yuan\"})\n\nwhile 1:\n    data=q.get()\n    print(data)\n    print(\"-----------\")\n```\n\n执行结果：\n\n```python\n12            #他是第1个进去的，所以他先出来\n-----------\nhello\n-----------\n{\'name\': \'yuan\'}\n-----------\n```\n\n#### 示例2\n\n```python\nimport queue  #队列，解决多线程问题  （注意：python2.7 Queue的首字母是大写的）\n\n\n# q=queue.Queue(3) #1、设置3就是满了，默认（FIFO 先进先出 ） #先进后出（手枪弹夹，后压进去的，先出来）\nq=queue.Queue()  \nq.put(12)  \nq.put(\"hello\")\nq.put({\"name\":\"yuan\"})\n\nq.put(34)\n# q.put(34,False) #2、blook=True,如果改成Flase,提示你满了，会报错，但不会卡在这里，如果为True就会卡住，等你get走了我再塞进去。\n\n\nwhile 1:\n    data=q.get()  #1、会卡着，等值进来\n    # data=q.get(block=False)  #3、队列为空\n    print(data)\n    print(\"-----------\")\n```\n\n### 先进后出\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-14/96633032.jpg)\n\n```python\n#先进后出\nimport queue\n\nq=queue.LifoQueue()  #先进后出\n\nq.put(12)\nq.put(\"hello\")\nq.put({\"name\":\"yuan\"})\n\nwhile 1:\n    data=q.get()  #卡着，等值进来，\n    print(data)\n    print(\"-----------\")\n```\n\n结果：\n\n```python\n{\'name\': \'yuan\'}\n-----------\nhello\n-----------\n12\n-----------\n```\n\n### 基于优先级的\n\n```python\n#优先级\nimport queue\n\nq=queue.PriorityQueue()  #优先级\n\nq.put([3,12])\nq.put([2,\"hello\"])  #2先出来，按优化级  级别是：2--->3--->4 从级到高\nq.put([4,{\"name\":\"yuan\"}])\n\nwhile 1:\n    data=q.get() # 都取出来以后卡在这里\n    print(data[1])\n    print(\"-----------------------\")\n```\n\n根据规则，优先级越低越先出来，所以结果如下：\n\n```python\nhello\n-----------------------\n12\n-----------------------\n{\'name\': \'yuan\'}\n-----------------------\n```\n\n## join与task_done方法\n\n```python\njoin() 阻塞进程，直到所有任务完成，需要配合另一个方法task_done。\n\n    def join(self):\n        with self.all_tasks_done:\n            while self.unfinished_tasks:\n                self.all_tasks_done.wait()\n\ntask_done() 表示某个任务完成。每一条get语句后需要一条task_done。如果队列没取完，也会卡住\n\n\nimport queue\nq = queue.Queue(5)\nq.put(10)\nq.put(20)\nprint(q.get())\nq.task_done()\nprint(q.get())\nq.task_done()\n\nq.join()\n\nprint(\"ending!\")\n\n此包中的常用方法(q = Queue.Queue()):\n\nq.qsize()  返回队列的大小\nq.empty()  如果队列为空，返回True,反之False\nq.full()   如果队列满了，返回True,反之False\nq.full 与 maxsize 大小对应\nq.get([block[, timeout]])  获取队列，timeout等待时间\nq.get_nowait()      相当q.get(False)\n非阻塞 q.put(item)   写入队列，timeout等待时间\nq.put_nowait(item)  相当q.put(item, False)\nq.task_done()  在完成一项工作之后，q.task_done() 函数向任务已经完成的队列发送一个信号\nq.join()       实际上意味着等到队列为空，再执行别的操作\n```\n\n","timestamp":1523777648264},{"name":"11-11、Event.md","path":"05-Python/03-网络编程初窥/11-11、Event.md","content":"# Event\n\n线程的一个关键特性是每个线程都是独立运行且状态不可预测。如果程序中的其他线程需要通过判断某个线程的状态来确定自己下一步的操作,这时线程同步问题就 会变得非常棘手。为了解决这些问题,我们需要使用threading库中的Event对象。 对象包含一个可由**线程**设置的信号标志,它允许线程等待某些事件的发生。在 初始情况下,Event对象中的信号标志被设置为假。如果有线程等待一个Event对象, 而这个Event对象的标志为假,那么这个线程将会被一直阻塞直至该标志为真。一个线程如果将一个Event对象的信号标志设置为真,它将唤醒所有等待这个Event对象的线程。如果一个线程等待一个已经被设置为真的Event对象,那么它将忽略这个事件, 继续执行\n\n```python\nevent.isSet()：返回event的状态值；\nevent.wait()：如果 event.isSet()==False将阻塞线程；\nevent.set()： 设置event的状态值为True，所有阻塞池的线程激活进入就绪状态， 等待操作系统调度；\nevent.clear()：恢复event的状态值为False。\n```\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-12/55828543.jpg)\n\n可以考虑一种应用场景（仅仅作为说明），例如，我们有多个线程从Redis队列中读取数据来处理，这些线程都要尝试去连接Redis的服务，一般情况下，如果Redis连接不成功，在各个线程的代码中，都会去尝试重新连接。如果我们想要在启动时确保Redis服务正常，才让那些工作线程去连接Redis服务器，那么我们就可以采用threading.Event机制来协调各个工作线程的连接操作：主线程中会去尝试连接Redis服务，如果正常的话，触发事件，各工作线程会尝试连接Redis服务。来看模拟的示例：\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\n\nimport threading\nimport time\nimport logging\n\n# 定义logging模块的配置\nlogging.basicConfig(level=logging.DEBUG, format=\'(%(threadName)-10s) %(message)s\',)\n\ndef worker(event):\n    logging.debug(\'Waiting for redis ready...\')\n    event.wait()\n    logging.debug(\'redis ready, and connect to redis server and do some work [%s]\', time.ctime())\n    time.sleep(1)\n\ndef main():\n    readis_ready = threading.Event()\n    t1 = threading.Thread(target=worker, args=(readis_ready,), name=\'t1\')\n    t1.start()\n\n    t2 = threading.Thread(target=worker, args=(readis_ready,), name=\'t2\')\n    t2.start()\n\n    logging.debug(\'first of all, check redis server, make sure it is OK, and then trigger the redis ready event\')\n    time.sleep(3) # simulate the check progress\n    readis_ready.set()\n\nif __name__==\"__main__\":\n    main()\n```\n\n先来看看运行结果：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-12/2741344.jpg)\n\n**分析：**\n\n我们定义了一个worker函数，这个函数在执行的时候会卡在event.wait()这里，event.wait()会去判断`event.isSet()==False`是否是成立的，因为默认就是False的，因此条件会成立，event.wait也会如期的卡住。\n\n再来看main方法，main方法是我们在运行脚本的时候会默认会执行官的一个方法，我们这main方法里起了两个线程去运行这个worker函数，将redis_ready这个event作为参数传递进去，然后睡3s，此时调用event的set方法，将event设置为True。此时之前卡住的部分就会继续运行下去，可以看到上面的动图，worker在卡了3s后继续运行了。\n\n#### 现在变更一下需求：\n\nthreading.Event的wait方法还接受一个超时参数，默认情况下如果事件一直没有发生，wait方法会一直阻塞下去，而加入这个超时参数之后，如果阻塞时间超过这个参数设定的值之后，wait方法会返回。对应于上面的应用场景，如果Redis服务器一致没有启动，我们希望子线程能够打印一些日志来不断地提醒我们当前没有一个可以连接的Redis服务，我们就可以通过设置这个超时参数来达成这样的目的，改一下worker函数：\n\n```python\ndef worker(event):\n    logging.debug(\'Waiting for redis ready...\')\n    while not event.isSet():\n        event.wait(2)\n        logging.debug(\'redis is not ready,still waiting.......\')\n    logging.debug(\'redis ready, and connect to redis server and do some work [%s]\', time.ctime())\n    time.sleep(1)\n```\n\n我们把wait的动作放到一个while循环里，如果说在wait规定的2s内，这个event仍然是false的话那么就向下执行，然而向下执行则是会继续循环执行，就打到了一种不断的打印日志的效果。","timestamp":1523777648264},{"name":"12-12、进程对象Process.md","path":"05-Python/03-网络编程初窥/12-12、进程对象Process.md","content":"# 进程对象Process\n\n## Multiprocessing多进程模块\n\nMultiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency,effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.\n\n由于GIL的存在，python中的多线程其实并不是真正的多线程，如果想要充分地使用多核CPU的资源，在python中大部分情况需要使用多进程。\n\nmultiprocessing包是Python中的多进程管理包。与threading.Thread类似，它可以利用multiprocessing.Process对象来创建一个进程。该进程可以运行在Python程序内部编写的函数。该Process对象与Thread对象的用法相同，也有start(), run(), join()的方法。此外multiprocessing包中也有Lock/Event/Semaphore/Condition类 (这些对象可以像多线程那样，通过参数传递给各个进程)，用以同步进程，其用法与threading包中的同名类一致。所以，multiprocessing的很大一部份与threading使用同一套API，只不过换到了多进程的情境。来看下面这个例子：\n\n```python\n# Process类调用\n\nfrom multiprocessing import Process\nimport time\ndef f(name):\n    # 这个函数的功能就是打印一个字符串睡一秒\n    print(\'hello\', name,time.ctime())\n    time.sleep(1)\n\nif __name__ == \'__main__\':\n    p_list=[]\n    for i in range(3):\n        p = Process(target=f, args=(\'alvin:%s\'%i,))\n        p_list.append(p)\n        p.start()\n    for i in p_list:\n        i.join()  # 如果不加进程的话主进程会先结束，会先打印end。\n    print(\'end\')\n\n# 和Thread使用自定义类的方式去调用\nfrom multiprocessing import Process\nimport time\n\nclass MyProcess(Process):\n    def __init__(self):\n        super(MyProcess, self).__init__()\n        # self.name = name\n\n    def run(self):\n\n        print (\'hello\', self.name,time.ctime())\n        time.sleep(1)\n\n\nif __name__ == \'__main__\':\n    p_list=[]\n    for i in range(3):\n        p = MyProcess()\n        p.start()\n        p_list.append(p)\n\n    for p in p_list:\n        p.join()\n\n    print(\'end\')\n```\n\n输出结果：\n\n```python\nhello alvin:0 Wed Sep 13 14:29:51 2017\nhello alvin:1 Wed Sep 13 14:29:51 2017\nhello alvin:2 Wed Sep 13 14:29:51 2017\nend   # 三行一起输入然后停一秒结束打印end\n```\n\n这样就是三个进程一起去执行这个函数，这样的执行是一种并行的结果，不是并发，因为这个是多进程，是可以把任务给多个处理核心一起去处理，真正的实现并行。来看一个例子：\n\n```python\nfrom multiprocessing import Process\nimport os\nimport time\n\ndef info(name):\n    # 定义一个函数打印父进程id和进程id\n    print(\"name:\",name)\n    print(\'parent process:\', os.getppid())\n    print(\'process id:\', os.getpid())\n    print(\"------------------\")\n    time.sleep(1)\n\n\nif __name__ == \'__main__\':\n\n    info(\'main process line\')\n    # 开启两个进程运行\n    p1 = Process(target=info, args=(\'alvin\',))\n    p2 = Process(target=info, args=(\'egon\',))\n    p1.start()\n    p2.start()\n\n    p1.join()\n    p2.join()\n\n    print(\"ending\")\n```\n\n运行结果：\n\n```python\nname: main process line\nparent process: 12252   # pycharm的进程号\nprocess id: 14232       # python.exe的进程号，这才是主进程的进程号\n------------------\nname: alvin\nparent process: 14232\nprocess id: 11100       # python.exe的进程号（相当于开了一个子进程）\n------------------\nname: egon\nparent process: 14232\nprocess id: 16744       # python.exe的进程号（相当于开了一个子进程）\n------------------\nending\n```\n\n### 多进程的使用方法\n\n**构造方法：**\n\nProcess([group [, target [, name [, args [, kwargs]]]]])\n\n- group: 线程组，目前还没有实现，库引用中提示必须是None； \n- target: 要执行的方法； \n- name: 进程名； \n- args/kwargs: 要传入方法的参数。\n\n**实例方法：**\n\n- is_alive()：返回进程是否在运行。\n- join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的timeout（可选参数）。\n- start()：进程准备就绪，等待CPU调度\n- run()：strat()调用run方法，如果实例进程时未制定传入target，这star执行t默认run()方法\n- terminate()：不管任务是否完成，立即停止工作进程\n\n**属性：**\n\n- daemon：和线程的setDeamon功能一样\n- name：进程名字。\n- pid：进程号。\n\n","timestamp":1523777648264},{"name":"13-13、协程简介.md","path":"05-Python/03-网络编程初窥/13-13、协程简介.md","content":"# 协程\n\n协程，又称微线程，纤程。英文名Coroutine。一句话说明什么是线程：协程是一种用户态的轻量级线程。**协程的特点是自己来切换而不是有操作系统来进行切换了**。协程中yeild起到了保存程序状态的作用。\n\n协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：\n\n协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。\n\n- 由于协程是单线程，因此不用再切换\n- 不再有任何锁的概念。\n\n下面的例子涉及到了生产者和消费者的简单模型，关于生产者和消费者相关的内容可以查看下面的链接：[生产者与消费者模型简介](http://wiki.dcgamer.top/?file=007-Python/15-15%E3%80%81%E7%AE%97%E6%B3%95/01-%E7%BC%96%E7%A8%8B%E6%80%9D%E7%BB%B4/00-%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B)\n\n看一下下面的这个例子：\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\n\nimport time\n\n\"\"\"\n传统的生产者-消费者模型是一个线程写消息，一个线程取消息，通过锁机制控制队列和等待，但一不小心就可能死锁。\n如果改用协程，生产者生产消息后，直接通过yield跳转到消费者开始执行，待消费者执行完毕后，切换回生产者继续生产，效率极高。\n\"\"\"\n\n\n# 注意到consumer函数是一个generator（生成器）:\n# 任何包含yield关键字的函数都会自动成为生成器(generator)对象\n\ndef consumer():\n    r = \'\'\n    while True:\n        # 3、consumer通过yield拿到消息，处理，又通过yield把结果传回；\n        #    yield指令具有return关键字的作用。然后函数的堆栈会自动冻结(freeze)在这一行。\n        #    当函数调用者的下一次利用next()或generator.send()或for-in来再次调用该函数时，\n        #    就会从yield代码的下一行开始，继续执行，再返回下一次迭代结果。通过这种方式，迭代器可以实现无限序列和惰性求值。\n        n = yield r\n        if not n:\n            return\n        print(\'[CONSUMER] ←← Consuming %s...\' % n)\n        time.sleep(1)\n        r = \'200 OK\'\n\n\ndef produce(c):\n    # 1、首先调用c.next()启动生成器\n    next(c)\n    n = 0\n    while n < 5:\n        n = n + 1\n        print(\'[PRODUCER] →→ Producing %s...\' % n)\n        # 2、然后，一旦生产了东西，通过c.send(n)切换到consumer执行；\n        cr = c.send(n)\n        # 4、produce拿到consumer处理的结果，继续生产下一条消息；\n        print(\'[PRODUCER] Consumer return: %s\' % cr)\n    # 5、produce决定不生产了，通过c.close()关闭consumer，整个过程结束。\n    c.close()\n\n\nif __name__ == \'__main__\':\n    # 6、整个流程无锁，由一个线程执行，produce和consumer协作完成任务，所以称为“协程”，而非线程的抢占式多任务。\n    c = consumer()\n    produce(c)\n```\n\n执行结果如下：\n\n```python\n[PRODUCER] →→ Producing 1...\n[CONSUMER] ←← Consuming 1...\n[PRODUCER] Consumer return: 200 OK\n[PRODUCER] →→ Producing 2...\n[CONSUMER] ←← Consuming 2...\n[PRODUCER] Consumer return: 200 OK\n[PRODUCER] →→ Producing 3...\n[CONSUMER] ←← Consuming 3...\n[PRODUCER] Consumer return: 200 OK\n[PRODUCER] →→ Producing 4...\n[CONSUMER] ←← Consuming 4...\n[PRODUCER] Consumer return: 200 OK\n[PRODUCER] →→ Producing 5...\n[CONSUMER] ←← Consuming 5...\n[PRODUCER] Consumer return: 200 OK\n```\n\n**解析：**\n\n- 当执行如上的程序的时候，我们会得到一个生成器c，将这个生成器传递给produce函数。\n- produce函数是我们用来模拟生产者的一个函数，在produce函数中，调用next方法启动生成器，然后执行send方法传递一个n给consumer，send方法会使consumer在yield卡住的地方继续向下运行，同时将n传递给yield\n- consumer执行完毕以后，通过while循环，继续卡在yield处，同时返回一个`200 OK`赋值给produce的cr，回到produce函数，继续执行循环。\n\n上面这个过程可以说是一个并发的过程，但是执行过程仍然是串行的，相当于我生产者生产一个包子，等你消费者吃完了，我再去生产下一个。吃包子的过程（time.sleep）相当于IO操作，虽然我们通过yeild实现了并发，但是每一个consumer操作还是停留了1s，我们需要的并发是不去等待你这个吃的过程（停留的这1s）也就是说单单只使用yeild是无法检测到系统级别的IO操作的，需要更底层的方式去检测，因此我们可以使用将这些功能封装好的包。\n\n## greenlet\n\ngreenlet机制的主要思想是：生成器函数或者协程函数中的yield语句挂起函数的执行，直到稍后使用next()或send()操作进行恢复为止。可以使用一个调度器循环在一组生成器函数之间协作多个任务。greentlet是python中实现我们所谓的\"Coroutine(协程)\"的一个基础库.\n\n```python\nfrom greenlet import greenlet\n \ndef t1():\n    print (12)\n    gr2.switch()\n    print (34)\n    gr2.switch()\n \ndef t2():\n    print (56)\n    gr1.switch()\n    print (78)\n \ngr1 = greenlet(t1)\ngr2 = greenlet(t2)\ngr1.switch()\n```\n\n一个“greenlet”是一个独立的小微线程。可以把它想象成一个堆栈，栈底是初始功能，而栈顶是当前greenlet的暂停位置。你可以通过创建多个这样的堆栈，然后在它们之间的跳跃执行。跳转不是绝对的：一个greenlet必须选择跳转到一个已经选择好的greenlet，这将导致前者挂起，后者恢复。 greenlets之间跳转被称为切换(switch)。\n\n当你创建一个greenlet，它得到一个初始的空栈;当你第一次切换到它，它开始运行指定的函数，比如可以调用其他函数，切换出greenlet等。当最终栈底函数结束时,greenlet的堆栈再次变成空，greenlet也就dead了。 greenlets也会因为一个未捕获的异常而dead。\n\n比如首先调用的gr1.switch()，gr1开始运行执行的函数t1，首先会打印12，然后gr2.switch()调用gr2这个greenlet，他会去执行指定的函数t2，打印56，此时gr1就停止了，当t2执行到了gr1.switch()的时候，t1被重新激活，执行34，同理又跳转到t2打印78.当栈底函数结束了以后，greenlet也就dead了，因此上面这个脚本执行的结果是：\n\n```python\n12\n56\n34\n78\n```\n\n不过上面这个很蛋疼，切换全是我们手动的，木有意义啊，因此我们可以使用greenlet上层封装的库\n\n### 基于greenlet的框架\n\n#### 使用gevent模块实现协程\n\nPython通过yield提供了对协程的基本支持，但是不完全。而第三方的gevent为Python提供了比较完善的协程支持。gevent是第三方库，通过greenlet实现协程，其基本思想是：当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。\n\n由于切换是在IO操作时自动完成，所以gevent需要修改Python自带的一些标准库，这一过程在启动时通过monkey patch完成：\n\n```python\nimport gevent\nimport time\n\ndef foo():\n    print(\"running in foo\")\n    gevent.sleep(2) # 为什么不用time.sleep，因为调度者不是cpu而是程序设计者\n    print(\"switch to foo again\")\n\ndef bar():\n    print(\"switch to bar\")\n    gevent.sleep(5)\n    print(\"switch to bar again\")\n\nstart=time.time()\n\ngevent.joinall(\n    [gevent.spawn(foo),\n    gevent.spawn(bar)]\n)\n\nprint(time.time()-start)\n```\n\n执行结果：\n\n```python\nrunning in foo\nswitch to bar\nswitch to foo again\nswitch to bar again\n5.002115249633789\n```\n\n当然，实际代码里，我们不会用gevent.sleep()去切换协程，而是在执行到IO操作时，gevent自动切换，代码如下：\n\n```python\nfrom gevent import monkey\nmonkey.patch_all()\nimport gevent\nfrom urllib import request\nimport time\n\ndef f(url):\n    print(\'GET: %s\' % url)\n    resp = request.urlopen(url)# 网络IO\n    data = resp.read()\n    print(\'%d bytes received from %s.\' % (len(data), url))\n\nstart=time.time()\n\ngevent.joinall([  # 启动这个函数使用join\n        gevent.spawn(f, \'https://itk.org/\'),  # 通过gevent.spawn运行的函数，要传递的参数\n        gevent.spawn(f, \'https://www.github.com/\'),\n        gevent.spawn(f, \'https://zhihu.com/\'),\n])\n\n# f(\'https://itk.org/\')\n# f(\'https://www.github.com/\')\n# f(\'https://zhihu.com/\')\n\nprint(time.time()-start)\n```\n\n执行结果：\n\n```python\nGET: https://itk.org/\nGET: https://www.github.com/\nGET: https://zhihu.com/\n11664 bytes received from https://zhihu.com/.\n12323 bytes received from https://itk.org/.\n55997 bytes received from https://www.github.com/.\n4.451509475708008\n```\n\n结果我们会发现，三个GET请求一起才出现，然后根据IO时延的不同下面三个依次出现了。","timestamp":1523777648264},{"name":"14-14、阻塞型IO和非阻塞性IO.md","path":"05-Python/03-网络编程初窥/14-14、阻塞型IO和非阻塞性IO.md","content":"# 阻塞和非阻塞型IO\n\n同步（synchronous） IO和异步（asynchronous） IO，阻塞（blocking） IO和非阻塞（non-blocking）IO分别是什么，到底有什么区别？这个问题其实不同的人给出的答案都可能不同，比如wiki，就认为asynchronous IO和non-blocking IO是一个东西。这其实是因为不同的人的知识背景不同，并且在讨论这个问题的时候上下文(context)也不相同。所以，为了更好的回答这个问题，先限定一下本文的上下文。\n本文讨论的背景是Linux环境下的network IO。 \n\nStevens在文章中一共比较了五种IO Model：\n\n- ​    blocking IO（阻塞性IO，当遇到IO请求的时候，没有返回就一直卡在这里）\n- ​    nonblocking IO（非阻塞型IO）\n- ​    IO multiplexing（IO多路复用，监听多个链接）\n- ​    signal driven IO（异步IO）\n- ​    asynchronous IO（驱动信号模型）\n\n由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。\n再说一下IO发生时涉及的对象和步骤。\n对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：\n\n-  等待数据准备 (Waiting for the data to be ready，比如socket.accept的过程)\n-  将数据从内核拷贝到进程中 (Copying the data from the kernel to the process，比如系统将内核态的数据转到用户态)\n\n记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。\n\n## blocking IO （阻塞IO-同步IO）\n\n在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-14/32375165.jpg)\n\n当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了，也就是全程阻塞。\n\n## non-blocking IO（非阻塞IO-同步IO）\n\nlinux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-14/85044755.jpg)\n\n从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，用户进程其实是需要不断的主动询问kernel数据好了没有。\n\n **注意：**\n\n在网络IO时候，非阻塞IO也会进行recvform系统调用，检查数据是否准备好，与阻塞IO不一样，”非阻塞将大的整片时间的阻塞分成N多的小的阻塞, 所以进程不断地有机会 ‘被’ CPU光顾”。即每次recvform系统调用之间，cpu的权限还在进程手中，这段时间是可以做其他事情的，也就是说非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。这个过程通常被称之为轮询。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。\n\n **举个例子：**\n\n排队买票相当于阻塞性的，排不到你你也没办法上别的地方去干别的，你跑了别人就把你的位置占了。但是银行叫号就和排队不一样了，你来了取个号，反正排不到你你可以去干别的，吃个饭，还是干点别的啥都可以，它本质上并没有卡住你让你什么都干不了，这就是好比非阻塞型的IO。\n\n**那么非阻塞性IO有什么优缺点？**\n\n- 缺点：多次的系统调用会消耗更多的资源，任务完成的响应延迟增大了；而且数据不是实时的了，比如你干别的事情的时候数据可能已经到了。这会导致整体数据吞吐量的降低。\n- 优点：不被阻塞以后我就可以去干点别的了，这是比阻塞型更优的地方。也就是 “后台” 可以有多个任务在同时执行\n\n示例代码：\n\n```python\nimport time\nimport socket\nsk = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n# sk.setsockopt\nsk.bind((\'127.0.0.1\',6667))\nsk.listen(5)\nsk.setblocking(False) # 设置为false以后就是非阻塞的了\nwhile True:\n    try:\n        print (\'waiting client connection .......\')\n        connection,address = sk.accept()   # 进程主动轮询\n        print(\"+++\",address)\n        client_messge = connection.recv(1024)\n        print(str(client_messge,\'utf8\'))\n        connection.close()\n    except Exception as e: # 没有客户端链接来的时候会返回一个error\n        print (e)\n        time.sleep(4)      # 在没有新连接来的时候我们可以干别的，比如sleep，而不是卡住。\n```\n\n操作结果：\n\n```python\nwaiting client connection .......\n[WinError 10035] 无法立即完成一个非阻止性套接字操作。\nwaiting client connection .......\n[WinError 10035] 无法立即完成一个非阻止性套接字操作。\nwaiting client connection .......\n[WinError 10035] 无法立即完成一个非阻止性套接字操作。\n………………\n…………\n……      # 每4s打印两行，这就是我们取完号以后出去玩的过程。\n```\n\n## IO multiplexing（IO多路复用-同步IO）\n\n IO multiplexing这个词可能有点陌生，但是如果我说select，epoll，大概就都能明白了。有些地方也称这种IO方式为event driven IO。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。之前的两个IO模型，wait for data的过程是socket.accept去做的，在多路复用这一块，不是accept去做这个事情了，而是select去做。简单的来说就是拆成了两步，select去负责它的流程如图：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-14/39496141.jpg)\n\n当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。\n这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）\n在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。\n\n```\n套接字对象到底是谁？\n其实就是fd，也就是文件描述符，关于文件描述符：\n1-是一个非零整数，不会变\n2-收发数据的时候，对于接收端而言，数据先到内核空间，然后copy到用户空间，同时，内核空间数据清除。\n\n全程阻塞\n```\n\n\n\n\n\n## **Asynchronous I/O（异步IO）**\n\nlinux下的asynchronous IO其实用得很少。先看一下它的流程：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-14/9398560.jpg)\n\n用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。因此，异步IO的特点就是**全程无阻塞**。","timestamp":1523777648264},{"name":"15-15、Selectors.md","path":"05-Python/03-网络编程初窥/15-15、Selectors.md","content":"# Selectors模块\n\nselectors是基于select模块进行封装实现的一个IO多路复用\n\n\n\nIO多路复用的实现机制：\n\n- win：select\n- linux：select、poll、epoll\n\nselect的缺点，\n\n- 每一次调用select都会把用户缓冲区的fd挪到内核缓冲区，这样消耗很大，导致效率下降\n- 遍历所有的内核空间的fd，判断是否有数据访问。（最重要的问题）\n- 最大连接数（1024），预值。\n\npoll做了什么改进：\n\n- 将最大连接数进行了改进，改为了无限制。\n\nepoll做了什么改进：\n\n- select的拷贝fd的过程在epoll分成了三个函数去完成。创建一个epoll句柄（第一个），将所有的fd拷贝到内核区，但是只需要拷贝一次。\n- 回调函数（某一个函数或者某一个动作成功完成之后，会触发的函数）去解决遍历的问题，它为所有的fd绑定一个回调函数，当这个fd发生变动（有数据访问）以后就触发回调函数，把这个fd放到一个链表里去。（交试卷的问题）\n- 函数判断链表是否为空\n- 最大连接数进行了改进\n\n```python\nimport selectors\nimport socket\n\nsel = selectors.DefaultSelector()\n\ndef accept(sock, mask):\n    conn, addr = sock.accept()  # Should be ready\n    print(\'accepted\', conn, \'from\', addr)\n    conn.setblocking(False)\n    sel.register(conn, selectors.EVENT_READ, read)\n\ndef read(conn, mask):\n    data = conn.recv(1000)  # Should be ready\n    if data:\n        print(\'echoing\', repr(data), \'to\', conn)\n        conn.send(data)  # Hope it won\'t block\n    else:\n        print(\'closing\', conn)\n        sel.unregister(conn)\n        conn.close()\n\nsock = socket.socket()\nsock.bind((\'localhost\', 1234))\nsock.listen(100)\nsock.setblocking(False)\nsel.register(sock, selectors.EVENT_READ, accept)\n\nwhile True:\n    events = sel.select()\n    for key, mask in events:\n        callback = key.data\n        callback(key.fileobj, mask)\n```\n\n","timestamp":1523777648264},{"name":"16-16、线程池.md","path":"05-Python/03-网络编程初窥/16-16、线程池.md","content":"# \n\n","timestamp":1523777648264},{"name":"20-20、socket编程小结.md","path":"05-Python/03-网络编程初窥/20-20、socket编程小结.md","content":"# 小结\n\nTCP和UDP之间的区别：\n\n```\n1 TCP是流式的，UDP发送的是报文，udp会封装消息报头。\n2 tcp是可靠的，udp是不可靠的，因为tcp是面向链接的，udp是不面向链接的\n```\n\n多线程多进程应用\n\n```\n首先说进程和线程，进程是一个资源单位，线程是一个调度单位，进程的资源是独立的，而线程的资源是可以共享的，那么多进程就有一个问题就是多进程势必户进行资源的占用。\n\nCPython中有一个问题就是GIL锁，GIL锁在同一时刻只可以允许一个进程中的一个线程出去去使用cpu，因此即使使用多线程，但是同一时刻，一个进程中还是只能有一个线程去使用cpu。那么多进程是可以并行处理问题的，所以说多进程的一个有段就是可以利用多核。\n\n二者的适用范围：\n- 多进程：适用于计算密集型，处理器使用频繁但是IO操作少。比如金融分析\n- 多线程：适用于IO密集型，处理器使用不是那么频繁的操作\n```\n\n黏包问题怎么解决\n\n````\n# 起因\n因为tcp的数据是流式的，因此多张图发送从用户空间转到系统空间所有的内容都连在一起了，在另一端接收的时候只会接收指定的长度receive(length)，因此有可能接收的长度有一个数据和另外一个数据黏在一起了。\n# 解决办法\n避免黏包的问题，主要还是要知道一个完整的数据的头和尾，以及文件的长度，我知道文件长度是多少了，我就可以指定接收多少的长度把这个长度接收完了那么这就是这个文件。方法其一就是已知长度接收长度，另外一种方法就是封装一个报头，其中包含文件的长度，以及其他信息，然后将报头压缩，在接收端接收的时候先把报头读取出来，然后就知道文件该接受多少了。\n````\n\n线程与协程（切换机制）\n\n```\n首先从切换执行者的角度说明：\n线程的切换者：处理器（CPU）\n协程的切换者：程序开发人员，人为的去控制\n\n线程切换的时机：\n- 达到了规定的使用时间片\n- 遇到了IO操作\n\n协程首先就是一个线程，所以不涉及到切换的问题。这个是用户态的，协程拥有自己的寄存器上下文和栈，在切换的时候可以将上下文保存到其他的位置，切换回来的时候可以进行状态的恢复，可以进行人为的控制。\n```\n\n四个IO机制\n\n```\n1.阻塞性IO\n一个同步的过程，如果没接收到对应的数据的话，用户态的数据会一直卡住持续等待。\n2.非阻塞性IO\n将一直等待给换成多次轮训去询问是否有数据，如果没有数据就返回一个error，也就是将一个持续的等待分成了多次的系统调用。这个调用期间cpu的使用权限是在进程手里的，因此还可以处理其他的内容，就好比排队办业务和叫号办业务的区别。\n3.IO多路复用\n将IO数据传输的整个过程拆为两部分，其中一个部分是由select去监听数据，select可以监听多个链接。\n4.异步IO\n用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。因此，异步IO的特点就是全程无阻塞。\n```\n\n锁的问题：\n\n```\n一般遇到有锁的问题大多是因为有资源数据共享的问题。要保证数据的一致性，一般会在处理数据的线程上加一把锁，加锁期间其他人需要进行锁等待，待处理完成以后进行锁释放，其他人才可以正常使用。\n这个就是说到的互斥锁。当然锁是会出现死锁问题的，比如一个资源在请求一个资源的时候对已经获得的资源并不进行释放。这就可能产生死锁的问题。\n```\n\n","timestamp":1523777648264},{"name":"01-01、Pymysql.md","path":"05-Python/04-Python操作DB/01-01、Pymysql.md","content":"# Pymsql\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport pymysql\n\n# 连接数据库成功\nconn = pymysql.connect(host=\'localhost\',user=\'root\',password=\'\',database=\'exe\')\n## 创建一个取数据的工具(把手)\ncursor = conn.cursor()\nsql = \'select * from student\'\ncursor.execute(sql)\n# 取一条，取出来就是一条记录，这是一个元组。\nret = cursor.fetchone()\nprint(ret)\n\n# 关闭数据库链接\ncursor.close()\nconn.close()\n\n\"\"\"\n一定不要自己去拼凑sql语句，防止sql注入（uuu\' or 1=1 --）\n\n占位符可以采用多种形式，支持字典，列表。\ncursor.execute(sql,user,pwd)\ncursor.execute(sql,[user,pwd])\ncursor.execute(sql,{\'user\':user,\'pass\':pwd})\n\npymysql会自己做参数\n\"\"\"\n```\n\n**使用pymysql进行<u>*增删改*</u>的时候要提交，不然不会更新到数据库：**\n\n```mysql\nconn.commit()    # 放在excute之后\n```\n\n当然在插入的时候我们可以选择多条插入，一般executemany只适用于insert：\n\n```mysql\ncursor.executemany(sql,[(\'egon\',\'11\'),(\'lamber\',\'22\'),])\n```\n\n不管是execute还是executemany都会有一个返回值，这个返回值表示的是受影响的行数。这个受影响的行数增删改查都有的。\n\n关于查询操作，数据库的fetchone操作其实也是很类似文件的读取，也是存在一个指针点的，我们可以“seek”到某一个位置，不过在pymysql里他不叫seek它叫做scroll\n\n```python\ncursor.scroll(1,mode=\'relative\')  # 根据当前的位置相对位移\ncursor.scroll(1,mode=\'absolute\')  # 根据绝对位置定位\n```\n\nfetchone一次取一个，那么肯定就有对应的一次取多个的。\n\n```python\ncursor.fetchmany(n)   # n是一次取几条，一般不用这中办法\n```\n\n一般要不就是取一条，要不就是取所有的，一般看场景，比如用户认证的时候肯定就是单用户认证，这个时候fetchone就足够了。这个fetchall是取所有的查到的数据。fetchall拿到的是一个元组，元组里面套小元组。\n\n```python\ncursor.fetchall()\n```\n\n但是元组对应的只是各个字段的值，假如不看字段定义我们并不知道取出来的值对应的是什么关系，当然这个是可以修改的\n\n```python\ncursor = conn.cursor(cursor=pymysql.cursors.DictCursor)\n```\n\n返回的结果就是列表里面套字典了。\n\n如果获取最后查入数据的那条自增id呢？当然不关你是插入多条还是插入一条，只返回最后那条的id\n\n```mysql\ncursor.lastrowid    # 不带括号哦，就是一个属性值。\n```\n\n练习：\n\n\n\n","timestamp":1523777648264},{"name":"02-02、ORM框架.md","path":"05-Python/04-Python操作DB/02-02、ORM框架.md","content":"# ORM框架（SQLAlchemy）\n\n> ORM（关系对象映射），其实这个就是代替我们去对数据库进行操作的，sql语句有一套规则，ORM这个也是有一个规则，它将sql的增删改查等等以面向对象的形式去操作数据库，我们只需要去了解ORM的这一套规则，就可以间接的去操作数据库了。ORM的相关规则简化了直接操作数据库的相关规则。ORM同样也支持原生的SQL\n\n作用：\n\n- 提供简单的规则\n- 自动转换成SQL语句\n\nORM框架有两类：\n\n1. DB first：手动创建库和表，通过orm框架自动生成类\n2. code first：手动创建类和数据库，通过orm框架创建表（SQLAlchemy属于codefirst）\n\n![](http://omk1n04i8.bkt.clouddn.com/17-10-11/32720243.jpg)\n\n安装：\n\n```python\npip3 install SQLAlchemy\n```\n\nSQLAlchemy内部使用 Engine/ConnectionPooling/Dialect 进行数据库操作，Engine使用ConnectionPooling连接数据库，然后再通过Dialect执行SQL语句。\n\n```python\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"mysql+pymysql://root:123@127.0.0.1:3306/t1\", max_overflow=5)\n  \n# 执行SQL\n# cur = engine.execute(\n#     \"INSERT INTO hosts (host, color_id) VALUES (\'1.1.1.22\', 3)\"\n# )\n  \n# 新插入行自增ID\n# cur.lastrowid\n  \n# 执行SQL\n# cur = engine.execute(\n#     \"INSERT INTO hosts (host, color_id) VALUES(%s, %s)\",[(\'1.1.1.22\', 3),(\'1.1.1.221\', 3),]\n# )\n  \n  \n# 执行SQL\n# cur = engine.execute(\n#     \"INSERT INTO hosts (host, color_id) VALUES (%(host)s, %(color_id)s)\",\n#     host=\'1.1.1.99\', color_id=3\n# )\n  \n# 执行SQL\n# cur = engine.execute(\'select * from hosts\')\n# 获取第一行数据\n# cur.fetchone()\n# 获取第n行数据\n# cur.fetchmany(3)\n# 获取所有数据\n# cur.fetchall()\n```\n\n其中`create_engine()`是用来初始化数据库链接的，SQLAlchemy本身无法操作数据库，其必须以来pymsql等第三方插件，Dialect用于和数据API进行交流，根据配置文件的不同调用不同的数据库API，从而实现对数据库的操作.SQLAlchemy用一个字符串表示连接信息：\n\n```\n\'数据库类型+数据库驱动名称://用户名:口令@机器地址:端口号/数据库名\' max_overflow=5\n```\n\nExample：\n\n```\nMySQL-Python\n    mysql+mysqldb://<user>:<password>@<host>[:<port>]/<dbname>\n   \npymysql\n    mysql+pymysql://<username>:<password>@<host>/<dbname>[?<options>]\n   \nMySQL-Connector\n    mysql+mysqlconnector://<user>:<password>@<host>[:<port>]/<dbname>\n   \ncx_Oracle\n    oracle+cx_oracle://user:pass@host:port/dbname[?key=value&key=value...]\n   \n更多详见：http://docs.sqlalchemy.org/en/latest/dialects/index.html\n```\n\n其中max_overflow是有sqlalchemy来控制的最大连接数。\n\n- 创建数据表\n- 操作数据行\n\n## 建表\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy import Column, Integer, String, ForeignKey, UniqueConstraint, Index\nfrom sqlalchemy.orm import sessionmaker, relationship\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"mysql+pymysql://root:@127.0.0.1:3306/ormtest?charset=utf8\", max_overflow=5)\nBase = declarative_base()\n\n# create single table\nclass Users(Base):     # 建表的类必须继承Base\n    __tablename__ = \'users\'   # 表名\n    id = Column(Integer, primary_key=True,autoincrement=True)\n    name = Column(String(32),nullable=True,default=\'default\',index=True) \n    extra = Column(String(16),unique=True)\n    # string指代char和varchar，interger指代int类型。\n    __table_args__ = (\n        UniqueConstraint(\'id\', \'name\', name=\'uix_id_name\'), # 联合唯一\n        Index(\'ix_id_name\', \'name\', \'extra\'),  # 第一个位置是索引名，后面才是索引字段\n    )\n\n    \n# 一对多\nclass Favor(Base):\n    __tablename__ = \'favor\'\n    nid = Column(Integer, primary_key=True)\n    caption = Column(String(50), default=\'red\', unique=True)\n \n \nclass Person(Base):\n    __tablename__ = \'person\'\n    nid = Column(Integer, primary_key=True)\n    name = Column(String(32), index=True, nullable=True)\n    favor_id = Column(Integer, ForeignKey(\"favor.nid\"))   # 外键\n \n \n# 多对多\nclass Group(Base):\n    __tablename__ = \'group\'\n    id = Column(Integer, primary_key=True)\n    name = Column(String(64), unique=True, nullable=False)\n    port = Column(Integer, default=22)\n \n \nclass Server(Base):\n    __tablename__ = \'server\'\n \n    id = Column(Integer, primary_key=True, autoincrement=True)\n    hostname = Column(String(64), unique=True, nullable=False)\n \n \nclass ServerToGroup(Base):\n    __tablename__ = \'servertogroup\'\n    nid = Column(Integer, primary_key=True, autoincrement=True)\n    server_id = Column(Integer, ForeignKey(\'server.id\'))\n    group_id = Column(Integer, ForeignKey(\'group.id\'))\n\n\ndef init_db():\n    Base.metadata.create_all(engine) # create_all创建所有表\n\n\ndef drop_db():\n    Base.metadata.drop_all(engine)   # drop_all删除所有表，看你调用什么了\n\ninit_db()\n```\n\n针对不同的数据可以引入不同的数据类型，比如Integer、String，ForeignKey，UniqueConstraint等等。这里的String指代的是char和varchar，如果你想用varchar可以单独引入CHAR和VARCHAR。如果我们需要其他的类型直接引入就可以了。\n\n## 数据行操作\n\n```python\nengine = create_engine(\"mysql+pymysql://maxiaoyu:13082171785@192.168.171.10:3306/ormtest?charset=utf8\", max_overflow=5)\nSession = sessionmaker(bind=engine)\nsession = Session()\nsession.close()\n```\n\n添加数据行\n\n```python\nobj1 = Users(name=\'localuser1\',extra=\'user1\') # 生成一行数据\nsession.add(obj1) # 将对象(一行数据)，添加到表中\n```\n\n多行添加\n\n```python\nobjs = [\n    Users(name=\'testuser1\',extra=\'普通用户\'),\n    Users(name=\'testuser2\',extra=\'白金用户\')\n]\nsession.add_all(objs)   # 可以提交多行，使用add_all进行添加\n```\n\n查询数据\n\n```python\nIn [12]: print session.query(Users)\nSELECT users.id AS users_id, users.name AS users_name, users.extra AS users_extra \nFROM users\n```\n\n查询数据默认使用的是session.query，后面括号里接的是对应的模型类。当我们直接运行的是session.query(Users)的时候我们发现它输出的是查询的sql语句，那么如果我们要把所有的都查出来该如何操作呢？\n\n```python\nIn [14]: session.query(Users).all()\nOut[14]: \n[<__main__.Users at 0x2a74090>,\n <__main__.Users at 0x2a74dd0>,\n <__main__.Users at 0x2a74e90>]\n```\n\n在上述的查询语句后面加一个`all()`方法即可，对应查出来的每一行数据是一个对象，当前我这个数据表里有三条数据，因此我查到的就是三个数据对象。因为每一条数据就是一个对象嘛~。\n\n如果我们想取第一条的话，那么就是可以将all方法换成first方法，这样就是拿的查到的第一个（排序按照数据库默认排序）\n\n```python\nIn [16]: a = session.query(Users).first()\n\nIn [17]: a.name\nOut[17]: u\'localuser1\'\n```\n\nwhere条件过滤\n\n```python\nIn [27]: print(session.query(Users).filter(Users.id > 2))\nSELECT users.id AS users_id, users.name AS users_name, users.extra AS users_extra \nFROM users \nWHERE users.id > %(id_1)s\n\nuser_list = session.query(Users.name,Users.extra).filter(Users.id ==3)\n```\n\n删除：\n\n```python\nIn [28]: session.query(Users).filter(Users.id == 1).delete()\nOut[28]: 1\n```\n\n修改：\n\n```python\nIn [29]: session.query(Users).filter(Users.id ==2).update({\'name\':\'黑金用户\'})\nOut[29]: 1\n\nIn [30]: session.query(Users).filter(Users.id ==2).first().name\nOut[30]: \'黑金用户\'\n  \n# 在原来的基础上设置值，这种在原来的基础上设置值的方案必须开synchronize_session=False\nIn [31]: session.query(Users).filter(Users.id ==2).update({Users.name:Users.name\n    ...: +\'lalala\'},synchronize_session=False)\nOut[31]: 1\n\nIn [32]: session.query(Users).filter(Users.id ==2).first().name\nOut[32]: \'黑金用户lalala\'\n\n# 要保证相加减的字段是数字类型的，比如使用字符串+1这种就会报错的\nIn [34]: session.query(Users).filter(Users.id ==2).update({\'id\':Users.id+33},syn\n    ...: chronize_session=\"evaluate\")\nOut[34]: 1\n```\n\n查询深入：\n\n```python\nret = session.query(Users).filter_by(name=\'alex\')\n# filter_by 内部调用filter，我们可以使用字典的形式去传递，那么再filter_by的内部就是相当于**kwargs去接收，然后再去转换成表达式\n\nret = session.query(Users).filter(Users.id > 1, Users.name == \'eric\').all()\n# 默认条件是and的关系哦。\n\n# between的使用：\nret = session.query(Users).filter(Users.id.between(1, 3), Users.name == \'eric\').all()\n\n# in\nret = session.query(Users).filter(Users.id.in_([1,3,4])).all()\n# not in，波浪号表示非，否的意思\nret = session.query(Users).filter(~Users.id.in_([1,3,4])).all()\n\n# 内部查询\nret = session.query(Users).filter(Users.id.in_(session.query(Users.id).filter_by(name=\'eric\'))).all()\n\n# 默认是and，如果是or的话需要单独引入\nfrom sqlalchemy import and_, or_\n\nret = session.query(Users).filter(and_(Users.id > 3, Users.name == \'eric\')).all()\nret1 = session.query(Users).filter(or_(Users.id < 2, Users.name == \'eric\')).all()\nret2 = session.query(Users).filter(\n    or_( # 整体每个部分是and\n        Users.id < 2,\n        and_(Users.name == \'eric\', Users.id > 3), # 这一部分是and\n        Users.extra != \"\"\n    )).all()\n\n# 通配符，这里的通配符支持mysql中like的通配符用法\nret1 = session.query(Users).filter(Users.name.like(\'e%\')).all()\nret2 = session.query(Users).filter(~Users.name.like(\'e%\')).all()\n\n# limit\nret = session.query(Users)[1:2]\n\n# 排序\nret = session.query(Users).order_by(Users.name.desc()).all()\nret = session.query(Users).order_by(Users.name.desc(), Users.id.asc()).all()\n\n\n# 分组\nfrom sqlalchemy.sql import func\n# 这里引入的func指的是mysql的内置函数，比如min，max，avg这种\nret = session.query(Users).group_by(Users.extra).all()\nret = session.query(\n    func.max(Users.id),\n    func.sum(Users.id),\n    func.min(Users.id)).group_by(Users.name).all()\n\nret = session.query(\n    func.max(Users.id),\n    func.sum(Users.id),\n    func.min(Users.id)).group_by(Users.name).having(func.min(Users.id) >2).all()\n\n# 连表\n## select * from users,favor where users.id = favor.id;\n## 相当于inner join,None不会显示（这个相当于带条件的笛卡尔积）\nret = session.query(Users, Favor).filter(Users.id == Favor.nid).all()\n## inner join，推荐大家使用join，默认会找到外键并进行关联，因此没有设置外键的话，会进行报错。\nret = session.query(Person).join(Favor).all()\n## left join，right join就是换一下顺序就可以了。\nret = session.query(Person).join(Favor, isouter=True).all()\n\n\n# 组合\nq1 = session.query(Users.name).filter(Users.id > 2)\nq2 = session.query(Favor.caption).filter(Favor.nid < 2)\nret = q1.union(q2).all()\n\nq1 = session.query(Users.name).filter(Users.id > 2)\nq2 = session.query(Favor.caption).filter(Favor.nid < 2)\nret = q1.union_all(q2).all()\n\n# 临时表&子查询\n## select * from b where id in (xx,xx,xx)\nquery = session.query(UserType).filter(UserType.id.in_(session.query(xxx).all()))\n\n## select * from (select * from tb) as B，如果一条语句要作为子查询要在末尾加上subquery()才可以被使用，否则是会报错的。\nquery1 = session.query(UserType).filter(UserType.id>2).subquery()\nquery2 = session.query(query1).all()\n\n## select id ,(select * from users) from usertype；也要加subquery。但是这样的计算的是笛卡尔积。\nresult = session.query(UserType.id,session.query(Users).subquery()).all()\n## select id ,(select * from users where users.id==xxx) from usertype；\nresult = session.query(UserType.id,session.query(Users).filter(Users.id==UserType.id).subquery()).all()\n\n\n\n\n```\n\n便利的功能\n\n","timestamp":1523777648264},{"name":"00-参考内容.md","path":"05-Python/07-Tkinter/00-参考内容.md","content":"https://zhuanlan.zhihu.com/p/22619896?refer=passer","timestamp":1523777648264},{"name":"01-Tkinter.md","path":"05-Python/07-Tkinter/01-Tkinter.md","content":"# TKinter\n\n### Laber and Button\n\n一个简单的小窗口\n\n```python\nimport tkinter as tk\n\n\"\"\"\n1、定义window窗口和窗口的一些属性。\n2、书写窗口内容\n3、执行window.mainloop让窗口活起来\n\"\"\"\n# 定义一个窗口\nwindow = tk.Tk()\n# 定义一些窗口的属性\nwindow.title(\'my first window\')\nwindow.geometry(\'200x200\')\n\n# 用一个标签描述窗口内容\nwindow_lable = tk.Label(window,\n                        text=\'这里是测试的内容\',  # 标签内容\n                        bg=\'green\',  # 背景颜色\n                        font=(\'Arial\', 12),  # 字体\n                        width=15, height=2  # 标签长宽\n                        )\nwindow_lable.pack()  # 固定窗口位置\n\n# 让整个window活起来\nwindow.mainloop()\n```\n\n为窗口添加button，让窗口中的内容随着button的点击而变化：\n\n```python\nimport tkinter as tk\n\n# 定义一个窗口\nwindow = tk.Tk()\n# 定义一些窗口的属性\nwindow.title(\'my first window\')\nwindow.geometry(\'200x200\')\n\non_hit = False  # 默认的情况下on_hit=False\n\n\ndef hit_me():\n    global on_hit\n    if not on_hit:\n        on_hit = True   # 从False变为true\n        var.set(\'you hit me\')\n    else:\n        on_hit = False\n        var.set(\'\')     # 设置文字内容为空\n\n\n# 用一个标签描述窗口内容\nvar = tk.StringVar()   # 这是文字变量存储器，用来存储动态变更的文字\nwindow_lable = tk.Label(window,\n                        textvariable=var,  # 使用文本变量替换text，可以变化\n                        bg=\'green\',  # 背景颜色\n                        font=(\'Arial\', 12),  # 字体\n                        width=15, height=2  # 标签长宽\n                        )\nwindow_lable.pack()  # 固定窗口位置\n\n\n# 制作button按钮\nb = tk.Button(window,\n              text=\'点我\',    # 显示在按钮上的文字\n              width=15, height=2,\n              command=hit_me)   # 点击按钮的时候执行的命令\nb.pack()   # 固定按钮的位置\n\n\n# 让整个window活起来\nwindow.mainloop()\n```\n\n","timestamp":1523777648264},{"name":"01-CMDB简介.md","path":"05-Python/09-项目/01-01、CMDB/01-CMDB简介.md","content":"","timestamp":1523777648264},{"name":"02-高级配置文件设计.md","path":"05-Python/09-项目/01-01、CMDB/02-高级配置文件设计.md","content":"","timestamp":1523777648264},{"name":"03-可插拔式插件的设计.md","path":"05-Python/09-项目/01-01、CMDB/03-可插拔式插件的设计.md","content":"","timestamp":1523777648264},{"name":"001-001-使用YAML作为项目的配置.md","path":"05-Python/11-最佳实践/001-001-使用YAML作为项目的配置.md","content":"# 使用YAML来编写项目的配置文件\n\n> 但凡是项目里肯定少不了配置文件，那么编写配置文件的方法有很多种，你可以用字典来保存，然后通过json模块的交互来获取到对应的信息，不过这样很麻烦，你还可以通过configParser来书写配置文件。当然还有一种方法，那就是使用YAML，YAML是专门用来编写配置文件的语言，非常简洁和强大。要比JSON方便的多。\n\n## 简介\n\nYAML 语言（发音 /ˈjæməl/ ）的设计目标，就是方便人类读写。它实质上是一种通用的数据串行化格式。安装的YAML相关的模块的话很简单的，直接pip安装即可。\n\n```python\npip install PyYaml\n```\n\nYAML的基本语法规则如下：\n\n>- 大小写敏感\n>- 和python类似，使用缩进来表示层级关系\n>- 缩进不允许使用tab，只能使用空格\n>- 缩进几个空格不重要，只要相同层级的元素左侧对齐即可\n\n\n\n\n\n\n\n","timestamp":1523777648264},{"name":"002-002-VirtualEnv.md","path":"05-Python/11-最佳实践/002-002-VirtualEnv.md","content":"# VirtualEnv\n\n> 使用virtualenv进行科学管理我们的项目\n\n## 安装Virtualenv\n\n```shell\n# 看好你使用的环境，我是给python3使用，因此调用的也就是pip3去进行安装\npip(3) install virtualenv\n\n# 直接使用virtualenv project_name就可以进行创建虚拟环境了。\nmkdir ~/testvirtualenv\ncd ~/testvirtualenv\nvirtualenv env1\n```\n\n## 安装VirtualenvWrapper\n\nVirtualenvwrapper是virtualenv的扩展包，可以更好的管理我们创建的虚拟环境\n\n```shell\npip(3) install virtualenvwrapper\n```\n\n指定一个虚拟环境的目录，我是在自己的家目录下新建一个了一个python路径来进行项目管理\n\n```shell\n➜  python > pwd\n/Users/lamber/python\n```\n\n在使用virtualenvwrapper之前要运行virtualenvwrapper.sh这个脚本，并且要进行环境变量的设置，因此我们要把下面的脚本内容放到`~/.bashrc`由于我用的是zsh于是就在`~/.zshrc`中添加了如下的两句内容：\n\n```shell\n# About virtualenvwrapper\nVIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python3\nif [ -f /usr/local/bin/virtualenvwrapper.sh ]; then\n   export WORKON_HOME=$HOME/python\n   source /usr/local/bin/virtualenvwrapper.sh\nfi\n```\n\n然后重载一下即可，主要是设置virtualenvwrapper是给那个python版本使用的，不然可能会出现无法导入virtualenvwrapper模块的问题。\n\n## 创建虚拟环境\n\n```shell\nmkvirtualenv env1\n```\n\n创建成功后，当前路径前面就会有(env1)的字样。\n\n## 常用小功能\n\n- 列出当前的虚拟环境\n\n  ```shell\n  lsvirtualenv -b\n  ```\n\n- 切换虚拟环境\n\n  ```shell\n  workon env1\n  ```\n\n- 查看环境里安装了哪些包\n\n  ```shell\n  lssitepackages\n  ```\n\n- 进入当前环境\n\n  ```shell\n  cdvirtualenv\n\n  # 示例\n  (env1) ➜  python > cdvirtualenv\n  (env1) ➜  env1 >\n  (env1) ➜  env1 > ll\n  total 8\n  drwxr-xr-x  21 lamber  staff   672B  2  8 14:55 bin\n  drwxr-xr-x   3 lamber  staff    96B  2  8 14:55 include\n  drwxr-xr-x   3 lamber  staff    96B  2  8 14:55 lib\n  -rw-r--r--   1 lamber  staff    60B  2  8 14:55 pip-selfcheck.json\n  ```\n\n- 进入当前环境的site-packages：\n\n  ```shell\n  cdsitepackages\n  cdsitepackages pip\n  ```\n\n- 复制虚拟环境\n\n  ```shell\n  cpvirtualenv env1 env3   # cpvirtualenv source destination\n  ```\n\n- 退出虚拟环境\n\n  ```shell\n  deactivate\n  ```\n\n- 删除虚拟环境\n\n  ```shell\n  ➜  ~ > rmvirtualenv env2\n  Removing env2...\n  ```\n\n## Tip\n\n创建一个干净的环境\n\n```shell\n$ mkvirtualenv --no-site-packages env343\n```\n\n指定虚拟环境使用的python版本\n\n```shell\n$ mkvirtualenv -p  /usr/local/bin/python3  env343\n```\n\n","timestamp":1523777648264},{"name":"00-生产者与消费者模型.md","path":"05-Python/12-扩展阅读/01-编程思维/00-生产者与消费者模型.md","content":"# 生产者与消费者模型（待修改）\n\n**首先考虑两个问题**\n\n- 生产者消费者模型，旨在解决什么问题？\n- 在现有的场景哪些会用到生产者和消费者模型？\n\n先看一下下面这个图：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-13/5137196.jpg)\n\n厨师A和B是生产者，生产包子。顾客相当于消费者，吃包子。做一个假设，如果厨师做包子的速度远远比顾客吃包子的速度要快，有这样一种情况，厨师等顾客吃完一个包子后再做下一个包子（这时我们说厨师与顾客的耦合度高，即厨师做包子与顾客吃包子是紧密相连的），这样显然效率会很低，现实情况中也不可能是这样，因为一旦顾客多时，厨师就有可能忙不过来了。\n\n因此可以尝试这样解决，不管顾客有没有吃完包子，厨师也继续做包子，但此时是先把包子放在一个包子柜台中，等顾客有需要时再去包子柜台拿包子。如此一来，厨师和顾客的耦合度就变低了，即厨师做包子并不取决于顾客是否把包子吃完，这样的话效率显然就会高多。厨师（生产者）只需要关心你这柜台里还有没有包子，他不关心具体的消费者，对于厨师（生产者）来说他甚至不知道有没有顾客（消费者）的存在。对于顾客（消费者）来说，他也不需要关心厨师，更不需要关心厨师有几个，他只需要关心这个柜子里面还有没有包子让他吃就够了。这就是一种松耦合的模型，因此，第一个问题，生产者和消费者模型是为了复用和解耦。那么现有场景中，消息队列就会用到这个模型，比如[ActiveMQ](https://baike.baidu.com/item/ActiveMQ)。\n\n生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列（柜台）来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力，回到这个例子：\n\n- **类比分析1：**厨师和顾客相当于是两个线程（假设线程A和线程B），厨师做的包子即相当于是线程A执行后的结果，而线程B的执行需要利用线程A的执行结果，并且，线程A的执行速度比线程B的执行速度要快。\n- **类比分析2：**厨师不会等顾客吃完包子后再做下一个包子，即线程A也不会等线程B使用线程A的执行结果后再去执行下一次功能相同的线程A2，否则程序运行效率会很低。\n- **类比分析3：**厨师把做好的包子放在包子柜台里，顾客吃完一个包子后再去包子柜台取，线程A把执行结果存放在消息队列中，然后再执行下一个功能相同的线程A2，线程B在消息队列中取胜线程A的执行结果，然后再执行下一个功能相同的线程B2，如此类推。\n\n\n```python\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\n\n#生产者消费者模型（生产者先执行，再吃包子。）\n\nimport time,random\nimport queue,threading\n\nq = queue.Queue()\n\ndef Producer(name):\n  count = 0\n  while count <10:\n    print(\"making........\")\n    time.sleep(random.randrange(3)) #产生一个随机数（1-2秒之间）\n    q.put(count)\n    print(\'Producer %s has produced %s baozi..\' %(name, count))\n    count +=1\n    print(\"ok......\")\n\ndef Consumer(name):\n  count = 0\n  while count <10:\n    time.sleep(random.randrange(4))  #产生一个随机数（1-3秒之间）\n    if not q.empty():\n        data = q.get()\n        print(\'\\033[32;1mConsumer %s has eat %s baozi...\\033[0m\' %(name, data))\n    else:\n        print(\"-----no baozi anymore----\")\n        count +=1\n\np1 = threading.Thread(target=Producer, args=(\'A君\',))\nc1 = threading.Thread(target=Consumer, args=(\'B君\',))\n\np1.start()\nc1.start()\n```\n\n执行结果：\n\n```python\nmaking........\nProducer A君 has produced 0 baozi..\nok......\nmaking........\nProducer A君 has produced 1 baozi..\nok......\nmaking........\nConsumer B君 has eat 0 baozi...\nConsumer B君 has eat 1 baozi...\nProducer A君 has produced 2 baozi..\nok......\nmaking........\nConsumer B君 has eat 2 baozi...\nProducer A君 has produced 3 baozi..\nok......\nmaking........\nProducer A君 has produced 4 baozi..\nok......\nmaking........\nConsumer B君 has eat 3 baozi...\nConsumer B君 has eat 4 baozi...\nProducer A君 has produced 5 baozi..\nok......\nmaking........\nProducer A君 has produced 6 baozi..\nok......\nmaking........\nProducer A君 has produced 7 baozi..\nok......\nmaking........\nProducer A君 has produced 8 baozi..\nok......\nmaking........\nProducer A君 has produced 9 baozi..\nok......\nConsumer B君 has eat 5 baozi...\nConsumer B君 has eat 6 baozi...\nConsumer B君 has eat 7 baozi...\nConsumer B君 has eat 8 baozi...\nConsumer B君 has eat 9 baozi...\n-----no baozi anymore----\n-----no baozi anymore----\n-----no baozi anymore----\n-----no baozi anymore----\n-----no baozi anymore----\n-----no baozi anymore----\n-----no baozi anymore----\n-----no baozi anymore----\n-----no baozi anymore----\n-----no baozi anymore----\n```\n\n","timestamp":1523777648264},{"name":"01-图解http--1.md","path":"05-Python/12-扩展阅读/02-图解HTTP读书笔记/01-图解http--1.md","content":"\n\n了解HTTP之前首先要了解TCP/IP协议簇，HTTP是建立在TCP/IP协议簇的基础上工作的，首先TCP/IP≠TCP+IP，这是一个协议簇，或者叫协议栈。这是一个协议的集合，它反映了网络中信息传递的过程，由上层协议到底层协议，再有底层到上层。我们需要研究的HTTP就属于其中应用层的协议。\n\n**TCP/IP四层结构如下：**\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-30/51016336.jpg)\n\n","timestamp":1523777648264},{"name":"00-Python的数据类型.md","path":"05-Python/12-扩展阅读/03-流畅的Python读书笔记/00-Python的数据类型.md","content":"","timestamp":1523777648264},{"name":"01-01、数据结构和算法.md","path":"05-Python/12-扩展阅读/04-Python CookBook/01-01、数据结构和算法.md","content":"# 数据结构和算法\n\n元组（列表）的解包：\n\n```python\nIn [1]: s = \"Hello\"\n\nIn [2]: a,b,c,d,e=s\n\nIn [3]: print(a,b,c,d,e)\nH e l l o\n\n# 如果说有不想要的内容可以使用单下划线\'_\'来作为占位符使用。\na,_,c,d,e = s\n```\n\n解包多个值：\n\n```python\n>>> *trailing, current = [10, 8, 7, 1, 9, 5, 10, 3]\n# 返回的值总是一个列表，即使有0个元素。\n>>> trailing\n[10, 8, 7, 1, 9, 5, 10]\n>>> current\n3\n```\n\n","timestamp":1523777648264},{"name":"01-Chapter1.md","path":"05-Python/12-扩展阅读/05-Django_By_Example/01-Chapter1.md","content":"# Chapter 1\n\n>第一章：https://zhuanlan.zhihu.com/p/27323301\n\n\n\n","timestamp":1523777648264},{"name":"98-Python代码风格（PEP8）.md","path":"05-Python/98-Python代码风格（PEP8）.md","content":"# PEP 8 Style Guide for Python code\n\n风格指南是关于一致性的。风格指南的一致性很重要。 一个项目的一致性更重要。 一个模块或功能内的一致性是最重要的。 \n但是，我们应该知道何时需要不一致 - 有时风格指南的建议不适用。 如果由此疑惑的话，应当遵从自己的判断。或者你可以看看其他的例子，决定什么看起来最好。并且不要犹豫去问问题！ \n特别是：不要只是为了符合这个PEP 8建议而破坏向后兼容性！\n\n下面有些其他的原因可以让我们忽略特定指导原则： \n\n- 当使用了这个指南导致代码可读性很差，甚至是使用过PEP 8的人去读依旧很差。 \n- 为了与原有的代码风格保持一致，也可以不遵循PEP 8（可能是出于历史原因），当然还有一种可能是原有代码的风格是乱的，这样的话也可以趁着这个机会整理一下之前混乱的风格。 \n- 代码风格问题出现的比指南还要早，而且已经没有什么必要再修改。 \n- 当代码需要与不支持风格指南推荐功能的旧版本的Python保持兼容时。\n\n## 代码的布局\n\n### 缩进\n\n一次缩进建议使用4个空格。\n\n有的时候连续的一行要写很长，在pycharm中有一条竖线，当你写了很长的时候你就会看到这个竖线，这个是python官方建议不超过的长度，因此针对这个问题应该使用适当的缩进来增强代码的可读性。\n\n在分界线处对齐：\n\n```python\nfoo = long_function_name(var_one, var_two,\n                         var_three, var_four)\n```\n\n使用更多的缩进与其他部分区分开，var_one和var_four与print()缩进不同\n\n```\ndef long_function_name(\n        var_one, var_two, var_three,\n        var_four):\n    print(var_one)\n```\n\n悬挂式缩进时应该另起一行\n\n```\nfoo = long_function_name(\n    var_one, var_two,\n    var_three, var_four)\n```\n\n\n\n## 模块引用风格\n\n- 模块名称要短、使用小写，并避免使用特殊符号，比如点(.)和问号(?)。如 `my.spam.py` 这样的名字是必须不能用的！该方式命名将妨碍Python的模块查找功能。\n\n- 不推荐在模块名中使用下划线，在模块名称中使用其他字符（空格或连字号）将阻止导入（-是减法运算符），因此请尽量保持模块名称简单，也无需分开单词。最重要的是，不要使用下划线命名空间，而是使用子模块。\n\n  ```\n  # OK\n  import library.plugin.foo\n  # not OK\n  import library.foo_plugin\n  ```\n\n- ​\n\n\n## PEP8报错建议汇总\n\n### trailing whitespace\n\n```\n语句后面不要尾随空格，看看你的代码行位是不是带了空格\n```\n\n\n\n\n\n\n\n\n## 日常作业整改意见汇总\n\n- 能不操作文件和数据库就不要操作，尽量去放在内存中去处理，而且打开的文件句柄一定要记得关闭，不关闭是要被开除的。\n- 函数名字不要大写开头\n- 方法之间要空一行，没有用的方法不要体现在你的代码中。空文件和大部分注释掉的内容不要提交\n- 变量名不要大写，函数名可以使用下划线，但是首字母不要大写，类名的首字母大写不建议下划线。类的方法之间空一行，类之间，函数之间空两行。\n- 导入其他模块的类或者方法直接导入类就行了，不要使用module.class的方式","timestamp":1523777648264},{"name":"99-Python报错统计.md","path":"05-Python/99-Python报错统计.md","content":"# Python报错提示整理\n\n##### 1、non-default argument follows default argument\n\n- 就是说我把含有默认值的参数放在了不含默认值的参数的前面\n\n\n##### 2、not all arguments converted during string formatting\n\n这个问题是在字符串格式化输出的时候出现的问题，格式化字符串中的%s或者%d与实际给的参数对应不上了，问题发生在打印socket的地址的时候传的是一个元组而不是单个。\n\n```python\nlogger().warning(\'当前的客户端地址为：%s，端口号为：%s\' % self.client_address)\n```\n\nself.client_address其实就是(\'127.0.0.1\',8080)。\n\n","timestamp":1523777648264}]