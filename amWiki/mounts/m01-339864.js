if(typeof AWPageMounts=='undefined'){AWPageMounts={}};AWPageMounts['m01']=[{"name":"01-简单命令-1.md","path":"01-Linux运维/00-常用命令/01-常用简单命令/01-简单命令-1.md","content":"# 常用命令的简单说明\r\n>这里留存一部分常用命令的简单说明，这种命令日常应用挺多，但是实际上能用到的功能寥寥可数，因此用一篇文档陈列在这里。\r\n\r\n***\r\n\r\n## 命令传送门\r\n>1. [命令传送门](#命令传送门 \"命令传送门\")\r\n\t1. [1.cat](#1.cat \"1.cat\")\r\n\t1. [2.tac](#2.tac \"2.tac\")\r\n\t1. [3.ls](#3.ls \"3.ls\")\r\n\t1. [4.cd](#4.cd \"4.cd\")\r\n\t1. [5.more](#5.more \"5.more\")\r\n\t1. [6.less](#6.less \"6.less\")\r\n\t1. [7.head](#7.head \"7.head\")\r\n\t1. [8.tail](#8.tail \"8.tail\")\r\n\t1. [9.file](#9.file \"9.file\")\r\n\t1. [10.diff](#10.diff \"10.diff\")\r\n\r\n### 1.cat\r\n> 查看文件用的命令，这也是使用的最多的查看文件的命令\r\n\r\ncat的常见参数：\r\n- n 输出行号\r\n- b 对于空行并不标出行号  \r\n\r\n比如：\r\n\r\n```\r\n[root@db02 ~]# cat test.txt\r\nroot:x:0:0:root:/root:/bin/bash\r\nbin:x:1:1:bin:/bin:/sbin/nologin\r\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\r\n\r\nadm:x:3:4:adm:/var/adm:/sbin/nologin\r\n\r\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\r\n```\r\n查看文档的时候输出行号\r\n\r\n```\r\n[root@db02 ~]# cat -n test.txt\r\n     1  root:x:0:0:root:/root:/bin/bash\r\n     2  bin:x:1:1:bin:/bin:/sbin/nologin\r\n     3  daemon:x:2:2:daemon:/sbin:/sbin/nologin\r\n     4\r\n     5  adm:x:3:4:adm:/var/adm:/sbin/nologin\r\n     6\r\n     7  lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\r\n```\r\n针对空行不输出行号：\r\n\r\n```\r\n[root@db02 ~]# cat -b test.txt  \r\n     1  root:x:0:0:root:/root:/bin/bash\r\n     2  bin:x:1:1:bin:/bin:/sbin/nologin\r\n     3  daemon:x:2:2:daemon:/sbin:/sbin/nologin\r\n\r\n     4  adm:x:3:4:adm:/var/adm:/sbin/nologin\r\n\r\n     5  lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\r\n```\r\n### 2.tac\r\n>和cat相反，cat是正向查看，tac就是反向查看，工作中用的不是很多，但是要知道有这么一个功能。\r\n### 3.ls\r\n>ls=list，其实就是列出来的意思，平常的使用中就是查看目录中列出来的文件。\r\n\r\nls的常用参数\r\n\r\n```\r\n-a：显示所有档案及目录（ls内定将档案名或目录名称为“.”的视为影藏，不会列出）；\r\n-A：显示除影藏文件“.”和“..”以外的所有文件列表；\r\n-l：与“-C”选项功能相反，所有输出信息用单列格式输出，不输出为多列；\r\n-F：在每个输出项后追加文件的类型标识符，具体含义：“*”表示具有可执行权限的普通文件，“/”表示目录，“@”表示符号链接，“|”表示命令管道FIFO，“=”表示sockets套接字。当文件为普通文件时，不输出任何标识符；\r\n-b：将文件中的不可输出的字符以反斜线“”加字符编码的方式输出；\r\n-c：与“-lt”选项连用时，按照文件状态时间排序输出目录内容，排序的依据是文件的索引节点中的ctime字段。与“-l”选项连用时，则排序的一句是文件的状态改变时间；\r\n-d：仅显示目录名，而不显示目录下的内容列表。显示符号链接文件本身，而不显示其所指向的目录列表；\r\n-i：显示文件索引节点号（inode）。一个索引节点代表一个文件； --file-type：与“-F”选项的功能相同，但是不显示“*”；\r\n-k：以KB（千字节）为单位显示文件大小；\r\n-l：以长格式显示目录下的内容列表。输出的信息从左到右依次包括文件名，文件类型、权限模式、硬连接数、所有者、组、文件大小和文件的最后修改时间等； -m：用“,”号区隔每个文件和目录的名称； -n：以用户识别码和群组识别码替代其名称；\r\n-r：以文件名反序排列并输出目录内容列表； -s：显示文件和目录的大小，以区块为单位； -t：用文件和目录的更改时间排序；\r\n-L：如果遇到性质为符号链接的文件或目录，直接列出该链接所指向的原始文件或目录；\r\n-R：递归处理，将指定目录下的所有文件及子目录一并处理；\r\n-t：按照时间顺序显示\r\n-r：逆序显示\r\n```\r\n以长格式来显示文件（或者我们可以直接简写ll=ls -l）,-h参数会把大小转换为人可读的形式：\r\n\r\n```\r\n[root@db02 ~]# ls -lh\r\ntotal 63M\r\n-rw-------. 1 root root 1.2K Feb  2 00:40 anaconda-ks.cfg\r\ndrwxr-xr-x  2 root root 4.0K Feb 28 16:49 bash_scripts\r\ndrwxr-xr-x  2 root root 4.0K Mar 26 18:23 exercise\r\n-rw-r--r--. 1 root root  22K Feb  2 00:40 install.log\r\n-rw-r--r--. 1 root root 5.8K Feb  2 00:38 install.log.syslog\r\n-rw-r--r--  1 root root  388 Mar 24 15:59 maxiaoyu.txt\r\n-rw-r--r--  1 root root  638 Apr  2 16:07 mysql_master_slave.sh\r\n-rw-------  1 root root    0 Mar  5 17:11 nohup.out\r\n\r\n```\r\n按照时间顺序显示出来：\r\n\r\n```\r\n[root@db02 ~]# ls -lt\r\ntotal 63936\r\n-rw-r--r--  1 root root      185 Apr  2 16:12 test.txt\r\n-rw-r--r--  1 root root      638 Apr  2 16:07 mysql_master_slave.sh\r\ndrwxr-xr-x  2 root root     4096 Mar 26 18:23 exercise\r\n-rw-r--r--  1 root root      388 Mar 24 15:59 maxiaoyu.txt\r\n-rw-------  1 root root        0 Mar  5 17:11 nohup.out\r\ndrwxr-xr-x  2 root root     4096 Feb 28 16:49 bash_scripts\r\n-rw-rw-r--  1 root root 41925772 Feb 27 20:24 percona-xtrabackup-24-debuginfo-2.4.6-2.el6.x86_64.rpm\r\n-rw-rw-r--  1 root root 15194300 Feb 27 20:24 percona-xtrabackup-test-24-2.4.6-2.el6.x86_64.rpm\r\n-rw-rw-r--  1 root root  8278704 Feb 27 20:24 percona-xtrabackup-24-2.4.6-2.el6.x86_64.rpm\r\ndrwxr-xr-x. 3 root root     4096 Feb  3 08:49 python\r\n-rw-------. 1 root root     1139 Feb  2 00:40 anaconda-ks.cfg\r\n-rw-r--r--. 1 root root    22179 Feb  2 00:40 install.log\r\n-rw-r--r--. 1 root root     5890 Feb  2 00:38 install.log.syslog\r\n```\r\n倒序显示：\r\n\r\n```\r\n[root@db02 ~]# ls -ltr\r\ntotal 63936\r\n-rw-r--r--. 1 root root     5890 Feb  2 00:38 install.log.syslog\r\n-rw-r--r--. 1 root root    22179 Feb  2 00:40 install.log\r\n-rw-------. 1 root root     1139 Feb  2 00:40 anaconda-ks.cfg\r\ndrwxr-xr-x. 3 root root     4096 Feb  3 08:49 python\r\n-rw-rw-r--  1 root root  8278704 Feb 27 20:24 percona-xtrabackup-24-2.4.6-2.el6.x86_64.rpm\r\n-rw-rw-r--  1 root root 15194300 Feb 27 20:24 percona-xtrabackup-test-24-2.4.6-2.el6.x86_64.rpm\r\n-rw-rw-r--  1 root root 41925772 Feb 27 20:24 percona-xtrabackup-24-debuginfo-2.4.6-2.el6.x86_64.rpm\r\ndrwxr-xr-x  2 root root     4096 Feb 28 16:49 bash_scripts\r\n-rw-------  1 root root        0 Mar  5 17:11 nohup.out\r\n-rw-r--r--  1 root root      388 Mar 24 15:59 maxiaoyu.txt\r\ndrwxr-xr-x  2 root root     4096 Mar 26 18:23 exercise\r\n-rw-r--r--  1 root root      638 Apr  2 16:07 mysql_master_slave.sh\r\n-rw-r--r--  1 root root      185 Apr  2 16:12 test.txt\r\n```\r\n### 4.cd\r\n>cd,全名change directory，即切换目录的意思。平常的用法也就是来回切换目录的，有一个用法是cd -，这个命令的意思是切换到刚才的目录，这个刚才的目录和一个变量有关即“$OLDPWD”。\r\n### 5.more\r\n>more命令也是可以查看文件内容的一个命令，但是不同于cat的地方是针对打的文件，一屏幕显示不完的不会一气全部都打印出来，而是允许你翻页，甚至允许你一行一行的看。\r\n\r\n常用参数：\r\n- 空格：向下翻页（一屏）\r\n- b：小写的b键，可以上翻页\r\n- h：小写的h按键可以查看帮助\r\n- 回车：一行一行的向下翻\r\n- =：查看当前行号\r\n- /：斜杠后面接关键字，可以实现搜索的功能。\r\n- z：向下滚动一屏\r\n\r\n我想十行十行的查看：\r\n\r\n```\r\n[root@db02 ~]# more -10 /etc/services\r\n# /etc/services:\r\n# $Id: services,v 1.48 2009/11/11 14:32:31 ovasik Exp $\r\n#\r\n# Network services, Internet style\r\n# IANA services version: last updated 2009-11-10\r\n#\r\n# Note that it is presently the policy of IANA to assign a single well-known\r\n# port number for both TCP and UDP; hence, most entries here have two entries\r\n# even if the protocol doesn\'t support UDP operations.\r\n# Updated from RFC 1700, ``Assigned Numbers\'\' (October 1994).  Not all ports\r\n```\r\n### 6.less\r\n>和more类似，但是比more更好用\r\n\r\n- 上下左右（方向键）：\r\n- -N：显示行号\r\n\r\n### 7.head\r\n同样是查看文件的命令，只不过就是查看方式不一样罢了，这个默认就是默认显示文件的前十行\r\n\r\n- head -3 filename：查看文件的前3行，这种写法是简写的，原始写法是head -n 3 filename\r\n- head -n -3 filename：在行数前面加一个-，表示我显示所有，但是除了最后三行。\r\n\r\n### 8.tail\r\n>这个用法和head挺类似的，head是从前往后看，tail是从后往前看。但是tail命令还有一个监控文件的功能\r\n\r\n- -f：监控一个文件的动态变化，比如我们可以用来监控日志文件。\r\n- -F：和f一样的功能，但是-F可以监控不存的文件，意思就是加入我要监控的一个文件不存在，那么我会告诉你这个文件不存在但是我不会报错，我会继续监控，然后如果我创建了这个文件那么就可以开始监控了。\r\n\r\n### 9.file\r\n>file命令的作用是确定文件的类型，当你不确定某个文件到底是什么类型的文件的时候你就可以使用file命令来来确定\r\n\r\n```\r\n[root@db02 ~]# file /bin/ls     \r\n/bin/ls: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.18, stripped\r\n[root@db02 ~]# file ./test.txt\r\n./test.txt: ASCII text\r\n```\r\n\r\n### 10.diff\r\n> diff命令在最简单的情况下，比较给定的两个文件的不同。如果使用“-”代替“文件”参数，则要比较的内容将来自标准输入。diff命令是以逐行的方式，比较文本文件的异同处。如果该命令指定进行目录的比较，则将会比较该目录中具有相同文件名的文件，而不会对其子目录文件进行任何比较操作。\r\n\r\n这里仅仅记录最简单的用法：\r\n\r\n```\r\ndiff filename1 filename2\r\n\r\n[root@db02 ~]# diff test.txt test2.txt         \r\ndiff: test2.txt: No such file or directory\r\nYou have new mail in /var/spool/mail/root\r\n[root@db02 ~]# diff test.txt test.txt2\r\n1c1\r\n< root:x:0:0:root:/root:/bin/bash\r\n---\r\n> lamber:x:0:0:root:/root:/bin/bash\r\n4c4\r\n< line 4\r\n---\r\n>\r\n6a7\r\n> this is test.txt2\r\n```\r\n其中，字母\"a\"、\"d\"、\"c\"分别表示添加、删除及修改操作。而\"n1\"、\"n2\"表示在文件1中的行号，\"n3\"、\"n4\"表示在文件2中的行号。\r\n","timestamp":1541470330295},{"name":"02-iptables.md","path":"01-Linux运维/00-常用命令/02-iptables.md","content":"# Iptables\n\n## 了解防火墙\n\n关闭两项功能：\n\n1、selinux，ids（生产中也是关闭的）\n\n2、iptables（生产中看情况，内网关闭外网打开）\n\n大并发的情况下不能开iptables，影响性能，采用硬件防火墙。\n\n/var/log/messages 出现`kernel：nf_conntrack：table full，dropping packet.`该如何解决这个问题（参考下面的解决方案）\n\n上述结果会让业务访问很慢\n\n大流量下重启 CentOS6 上的 iptables 应注意 [nf_conntrack table full](<http://www.bitbi.biz/blog/2013/06/03/e5a4a7e6b581e9878fe4b88be9878de590af-centos6-e4b88ae79a84-iptables-e5ba94e6b3a8e6848f-nf_conntrack-table-full/>)：\n\n```shell\nnet.netfilter.nf_conntrack_max = 25000000\nnet.netfilter.nf_conntrack_max = 25000000\nnet.netfilter.nf_conntrack_tcp_timeout_established = 180\nnet.netfilter.nf_conntrack_tcp_timeout_time_wait = 120\nnet.netfilter.nf_conntrack_tcp_timeout_close_wait = 60\nnet.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120\n```\n\n安全优化：\n\n1、尽可能不给服务器配置外网IP，可以通过代理转发.\n\n2、并发不是特别大情况在外网IP的环境，开启防火墙\n\n其他：http://edu.51cto.com/course/course_id-772.html\n\n防火墙介绍：\n\niptables又称为Netfilter，其实原名就是Netfilter只不过人们习惯上叫iptables。它是一款开源的开放的基于包过滤的防火墙工具，它强大，灵活，可以对流入和流出服务器的数据包进行很精细的控制，特别是它可以在一台非常低的硬件配置下跑的非常好。Iptables工作在OSI七层的二层，三层，四层。如果重新编译内核，Iptables也可以支持7层控制（squid+Iptables）\n\n","timestamp":1541470330295},{"name":"001-Tomcat基础部署.md","path":"01-Linux运维/01-常用服务/01-Tomcat/001-Tomcat基础部署.md","content":"# Tomcat基础部署\n\n## 统一用户\n\n```\n[root@web01 tools]# useradd -u 601 tomcat\n[root@web01 tools]# passwd tomcat\nChanging password for user tomcat.\nNew password: \nBAD PASSWORD: it is based on a dictionary word\nBAD PASSWORD: is too simple\nRetype new password: \npasswd: all authentication tokens updated successfully.\n[root@web01 tools]# id tomcat\nuid=601(tomcat) gid=601(tomcat) groups=601(tomcat)\n```\n\n## 部署JDK和Tomcat\n\n\n```\n[root@web01 tools]# tar xf jdk-8u121-linux-x64.tar.gz \n[root@web01 tools]# mv jdk1.8.0_121/ /usr/local/\n[root@web01 tools]# ln -s /usr/local/jdk1.8.0_121/ /usr/local/jdk\n[root@web01 tools]# tar xf apache-tomcat-8.5.13.tar.gz \n[root@web01 tools]# mv apache-tomcat-8.5.13 /usr/local/\n[root@web01 tools]# ln -s /usr/local/apache-tomcat-8.5.13/ /usr/local/tomcat\n```\n\n### 设置环境变量\n\n```\nexport JAVA_HOME=/usr/local/jdk\nexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH\nexport CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar\nexport TOMCAT_HOME=/usr/local/tomcat/\n\n添加到profile文件中\n[root@web01 local]# source /etc/profile\n```\n\n确认tomcat的版本号：\n\n```\n[tomcat@lamber tomcat]$ ./bin/version.sh \nUsing CATALINA_BASE:   /usr/local/tomcat\nUsing CATALINA_HOME:   /usr/local/tomcat\nUsing CATALINA_TMPDIR: /usr/local/tomcat/temp\nUsing JRE_HOME:        /usr/local/jdk\nUsing CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar\nServer version: Apache Tomcat/8.5.16\nServer built:   Jun 21 2017 17:01:09 UTC\nServer number:  8.5.16.0\nOS Name:        Linux\nOS Version:     2.6.32-042stab093.5\nArchitecture:   amd64\nJVM Version:    1.8.0_121-b13\nJVM Vendor:     Oracle Corporation\n```\n\n## 启动tomcat\n\n\n```\n[root@web01 ~]# chown -R tomcat.tomcat /usr/local/jdk /usr/local/tomcat/\n[root@web01 ~]# su - tomcat\n[tomcat@web01 ~]$ java -version\njava version \"1.8.0_121\"\nJava(TM) SE Runtime Environment (build 1.8.0_121-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)\n```\n注意所有的web服务器在初始化的时候一定要修改ulimit\n\n```\n[tomcat@web01 ~]$ /usr/local/tomcat/bin/startup.sh \nUsing CATALINA_BASE:   /usr/local/tomcat\nUsing CATALINA_HOME:   /usr/local/tomcat\nUsing CATALINA_TMPDIR: /usr/local/tomcat/temp\nUsing JRE_HOME:        /usr/local/jdk\nUsing CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar\nTomcat started.\n\n[tomcat@web01 ~]$ netstat -lntup | grep 8080\n(Not all processes could be identified, non-owned process info\n will not be shown, you would have to be root to see it all.)\ntcp        0      0 :::8080                     :::*                        LISTEN      7764/java \n```\n配置管理用户\n\n```\n[tomcat@web01 conf]$ vim tomcat-users.xml \n<role rolename=\"manager-gui\" />\n<role rolename=\"admin-gui\" />\n<user username=\"tomcat\" password=\"redhat\" roles=\"manager-gui,admin-gui\" />\n```\n重启Tomcat\n\n```\n[tomcat@web01 tomcat]$ bin/shutdown.sh \nUsing CATALINA_BASE:   /usr/local/tomcat\nUsing CATALINA_HOME:   /usr/local/tomcat\nUsing CATALINA_TMPDIR: /usr/local/tomcat/temp\nUsing JRE_HOME:        /usr/local/jdk\nUsing CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar\n[tomcat@web01 tomcat]$ bin/startup.sh \nUsing CATALINA_BASE:   /usr/local/tomcat\nUsing CATALINA_HOME:   /usr/local/tomcat\nUsing CATALINA_TMPDIR: /usr/local/tomcat/temp\nUsing JRE_HOME:        /usr/local/jdk\nUsing CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar\nTomcat started.\n```\n如果写一个重启脚本的话就是先kill tomcat然后等待20~30s，看看有没有杀掉进程，如果没有杀掉就采用强制手段kill -9。然后清空temp和work目录下的临时文件。\n\n简易版本tomcat启动脚本：\n\n```\n[tomcat@web01 bin]$ cat tomcat.sh \n#!/bin/sh\nTOMCAT_PATH=/usr/local/tomcat\n\nusage(){\n  echo \"Usage: $0 [start|stop]\"\n}\nstatus(){\n ps -ef | grep java | grep tomcat | grep -v grep\n}\n\nstart(){\n  /usr/local/tomcat/bin/startup.sh\n}\n\nstop(){\n  TPID=$(ps -ef | grep java | grep tomcat | grep -v grep | awk \'{print $2}\')\n  kill -9 $TPID\n  sleep 5;\n\n  TSTAT=$(ps -ef | grep java | grep tomcat | grep -v grep | awk \'{print $2}\')\n     if [ -z $TSTAT ];then\n       echo \"tomcat stop\"\n     else \n       kill -9 $TSTAT\n     fi\n\ncd $TOMCAT_PATH\nrm temp/* -rf\nrm work/* -rf\n}\n\nmain(){\ncase $1 in\n  start)\n     start\n     ;;\n  stop)\n     stop\n     ;;\n  status)\n     status\n     ;;\n  *)\n     usage\n     ;;\nesac\n\n}\n\nmain $1;\n```\n我们去访问tomcat对应的界面：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-4-15/88556304-file_1492222305346_4c4b.jpg)\n\n但是直接访问的话会报错403，因此需要对以下文件进行相应的改动，比如我要访问manager页面：\n\n```\n[tomcat@web01 ~]$ cd /usr/local/tomcat/webapps/manager/META-INF\n[tomcat@web01 META-INF]$ vim context.xml \nallow=\"10.0.0.*\" />\n修改访问权限\n```\n如果你想要访问的话这个访问权限是必须开启的，默认是127.0.0.x。也就是只能本机，所以不改的话直接403，连输入账号密码的机会都没有。但是这个有些是不安全的，因此建议只留下Server status，其他的关闭或者直接移动到别的地方去。\n\n## Tomcat安全管理规范\n\n- 用户设置统一\n- 内部地址下载\n- 版本统一","timestamp":1541470330295},{"name":"002-Tomcat目录结构.md","path":"01-Linux运维/01-常用服务/01-Tomcat/002-Tomcat目录结构.md","content":"","timestamp":1541470330295},{"name":"003-Tomcat的日志.md","path":"01-Linux运维/01-常用服务/01-Tomcat/003-Tomcat的日志.md","content":"http://xstarcd.github.io/wiki/Java/tomcat_log.html","timestamp":1541470330295},{"name":"006-Tomcat配置https.md","path":"01-Linux运维/01-常用服务/01-Tomcat/006-Tomcat配置https.md","content":"## 配置Tomcat HTTPS\n\n","timestamp":1541470330295},{"name":"01-Haproxy介绍&部署.md","path":"01-Linux运维/01-常用服务/02-Haproxy/01-Haproxy介绍&部署.md","content":"# Haproxy负载均衡\n\n\n官方网站：http://www.haproxy.org/\n\n\n>Haproxy是一个专业的负载均衡软件，它支持图形界面，配置简单并且维护方便。拥有对服务器节点的健康检查功能，相当于Keepalived健康检查。后端服务器有故障可以自动摘除，恢复还能自动添加。\n\nHaproxy支持两种主要代理模式\n- 基于4层的TCP应用代理，例如可用于邮件服务，内部协议通信服务器，mysql，https服务等\n- 基于7层的http代理，在4层tcp代理模式下，haproxy仅在客户端和服务器之间进行流量转发，但是在7层的http代理模式下，haproxy会分析应用层协议，并且能够通过允许，拒绝，交换，增加，修改或者删除请求（request）或者回应（response）里指定的内容来控制协议。\n\nHaproxy有点类似于LVS的NAT模式，来回都要经过Haproxy，因此会存在瓶颈，一般3kw以内的PV都是可以支持的到的，但是Haproxy和NAT模式还不一样，因为NAT模式是实际的去修改包，但是Haproxy是代理客户去请求。\n\n## Haproxy的安装部署\n\n\n```\nuseradd haproxy -s /sbin/nologin -M\ncd /tools/\nwget http://www.haproxy.org/download/1.4/src/haproxy-1.4.27.tar.gz\ntar xf haproxy-1.4.27.tar.gz\ncd haproxy-1.4.27\nmake TARGET=linux2628 ARCH=x86_64\nmake PREFIX=/application/haproxy1.4.27 install\nln -s /application/haproxy1.4.27/ /application/haproxy\n```\n具体的make参数可以参照README中的帮助信息。\n\n## Haproxy配置调整\n\n官方配置文档说明:http://www.haproxy.org/download/1.4/doc/configuration.txt\n\n配置转发功能：\n\n```\n[root@data-1-2 haproxy-1.4.27]# vim /etc/sysctl.conf \n[root@data-1-2 haproxy-1.4.27]# sysctl -p\nnet.ipv4.ip_forward = 1\n```\n查看Haproxy的目录结构：\n\n```\n[root@data-1-1 haproxy]# tree ./\n./\n├── doc\n│   └── haproxy\n│       ├── architecture.txt\n│       ├── configuration.txt\n│       ├── haproxy-en.txt\n│       └── haproxy-fr.txt\n├── sbin\n│   └── haproxy\n└── share\n    └── man\n        └── man1\n            └── haproxy.1\n\n```\n为了方便管理应用，创建新的目录：\n\n```\n[root@data-1-1 haproxy]# pwd\n/application/haproxy\n[root@data-1-1 haproxy]# mkdir -p bin conf logs var/run var/chroot\n```\n### 配置文件总体规划\n\n![](http://omk1n04i8.bkt.clouddn.com/17-4-19/26436219-file_1492564629229_327e.jpg)\n\n配置文件说明：\n```\nglobal\n     chroot   /application/haproxy/var/chroot\n     daemon                                   ##以守护进程的方式运行\n     group    haproxy\n     user     haproxy\n     log      127.0.0.1:514 local0 warning    ##全局日志使用本地514端口的syslog服务中的local0日志设备，日志级别为warning\n     pidfile  /application/proxy/var/run/haproxy.pid\n     maxconn  20480     ##定义每一个haproxy进程的最大连接数\n     spread-checks  3\n     nbproc   8         ##设置启动时候启动的进程数，一般保持和主机核心数一致\ndefaults\n     log  global\n     mode http          ##mode {http|tcp|health}分别对应7层，4层，健康监测\n     #option httplog    ##启用日志记录http请求，默认不记录，只记录时间、日志服务器、实例名称以及信息\n     #option dontlognull  ## 启用该项，日志中将不会记录空连接，所谓空连接就是在上游的负载均衡器或者监控系统为了探测业务是否存活可用的时候，需要定期的链接或者获取某一固定的组件或者页面，或者探测扫描端口是否在监听或开放等动作称为空连接。如果该服务上游没有其他的LB的话，那就不要启用这个参数了。\n     retries  3\n     option redispatch   ##当使用了cookie时，haproxy将会将其请求的后端服务器的serverid插入到cookie中，以保证会话session的持久性，而此时，如果后端的服务器掉了，但是客户端的cookie是不会刷新的，如果设置此参数，将会把客户的请求强制定向到另外的一个后端的server上，以保证服务的正常。\n     contimeout   5000      ##单位是ms，新版本使用timeout \n     clitimeout   50000     ##设置链接客户端发送数据的时候链接最长等待时间，默认单位还是毫秒。\n     srvtimeout   50000     ##设置服务器回应1客户端数据发送的最长等待时间，单位是毫秒。\n     option abortonclose    ##当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接\n     option dontlognull\n     option httpclose\nlisten www              ##每一个listen都可看做是一个虚拟主机或者说是实例1\n        bind  x.x.x.x:80               ##监听的VIP\n        mode http\n        no   option splice-response\n        stats enable                   ##激活web界面\n        stats uri/admin?stats          ##web界面的uri\n        stats auth proxy:oldboy        ##web界面的认证\n        balance roundrobin             ##负载均衡的策略\n        option  httpclose\n        option  forwardfor             ##类似于X-forward-for，后端记录真实IP\n        option  httpchk HEAD /check.html  HTTP/1.0       ##健康检查\n        server  www01 10.0.0.9:80  check     ##realserver1\n        server  www02 10.0.0.8:80  check     ##realserver2\n```\n配置文件样例：\n\n```\n[root@data-1-1 conf]# pwd\n/application/haproxy/conf\n[root@data-1-1 haproxy]# cat ./conf/haproxy.conf\nglobal\n     chroot   /application/haproxy/var/chroot\n     daemon                                   \n     group    haproxy\n     user     haproxy\n     log      127.0.0.1:514 local0 warning    \n     pidfile  /application/haproxy/var/run/haproxy.pid\n     maxconn  20000     \n     spread-checks  3\n     nbproc   8    \n     \ndefaults\n     log  global\n     mode http          \n     retries  3\n     option redispatch \n     contimeout   5000 \n     clitimeout   50000\n     srvtimeout   50000\n\nlisten oldboytest \n     bind  *:80\n     mode  tcp\n     balance roundrobin\n     timeout server 15s\n     timeout connect 15s\n     server  web01 10.0.0.8:22  check port 22 inter 5000 fall 5\n     server  web02 10.0.0.18:80  check port 80 inter 5000 fall 5\n```\n上面的配置文件就是我用10.0.0.7去代理10.0.0.8的ssh，我们可以测试一下：\n\n\n启动服务\n```\n# 启动服务\n./sbin/haproxy -f ./conf/haproxy.conf -D\n\n# 查看服务启动状态\n[root@data-1-1 haproxy]# ps -ef | grep haproxy | grep -v grep    \nhaproxy    2781      1  0 23:29 ?        00:00:00 ./sbin/haproxy -f ./conf/haproxy.conf -D\nhaproxy    2782      1  0 23:29 ?        00:00:00 ./sbin/haproxy -f ./conf/haproxy.conf -D\nhaproxy    2783      1  0 23:29 ?        00:00:00 ./sbin/haproxy -f ./conf/haproxy.conf -D\nhaproxy    2784      1  0 23:29 ?        00:00:00 ./sbin/haproxy -f ./conf/haproxy.conf -D\nhaproxy    2785      1  0 23:29 ?        00:00:00 ./sbin/haproxy -f ./conf/haproxy.conf -D\nhaproxy    2786      1  0 23:29 ?        00:00:00 ./sbin/haproxy -f ./conf/haproxy.conf -D\nhaproxy    2787      1  0 23:29 ?        00:00:00 ./sbin/haproxy -f ./conf/haproxy.conf -D\nhaproxy    2788      1  0 23:29 ?        00:00:00 ./sbin/haproxy -f ./conf/haproxy.conf -D\n```\n测试结果：\n\n```\n[root@data-1-1 haproxy]# ssh -p80 10.0.0.7\nThe authenticity of host \'[10.0.0.7]:80 ([10.0.0.7]:80)\' can\'t be established.\nRSA key fingerprint is b3:0c:dd:a9:32:6d:14:cb:49:93:5d:aa:b8:34:90:0b.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added \'[10.0.0.7]:80\' (RSA) to the list of known hosts.\nroot@10.0.0.7\'s password: \nLast login: Tue Apr 18 20:51:30 2017 from 10.0.0.1\n[root@data-1-2 ~]# \n\n结果正常，已经ssh过去了。\n```","timestamp":1541470330295},{"name":"01-openldap.md","path":"01-Linux运维/01-常用服务/03-OpenLDAP/01-openldap.md","content":"# OpenLdap\n\n","timestamp":1541470330295},{"name":"001-概念性的问题.md","path":"01-Linux运维/01-常用服务/06-LNMP/001-概念性的问题.md","content":"## 理论知识\r\n\r\n### CGI\r\n\r\nCGI全称是“公共网关接口”(Common Gateway Interface)，HTTP服务器与你的或其它机器上的程序进行“交谈”的一种工具，其程序须运行在网络服务器上。\r\n\r\nCGI可以用任何一种语言编写，只要这种语言具有标准输入、输出和环境变量。如php,perl,tcl等。\r\n\r\n### FastCGI\r\n\r\nFastCGI像是一个常驻(long-live)型的CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去fork一次（这是CGI最为人诟病的fork-and-execute 模式）。它还支持分布式的运算，即 FastCGI 程序可以在网站服务器以外的主机上执行并且接受来自其它网站服务器来的请求。\r\n\r\nFastCGI是语言无关的、可伸缩架构的CGI开放扩展，其主要行为是将CGI解释器进程保持在内存中并因此获得较高的性能。众所周知，CGI解释器的反复加载是CGI性能低下的主要原因，如果CGI解释器保持在内存中并接受FastCGI进程管理器调度，则可以提供良好的性能、伸缩性、Fail- Over特性等等。\r\n\r\n#### FastCGI特点\r\n\r\nFastCGI具有语言无关性.\r\nFastCGI在进程中的应用程序，独立于核心web服务器运行，提供了一个比API更安全的环境。APIs把应用程序的代码与核心的web服务器链接在一起，这意味着在一个错误的API的应用程序可能会损坏其他应用程序或核心服务器。 恶意的API的应用程序代码甚至可以窃取另一个应用程序或核心服务器的密钥。\r\nFastCGI技术目前支持语言有：C/C++、Java、Perl、Tcl、Python、SmallTalk、Ruby等。相关模块在Apache, ISS, Lighttpd等流行的服务器上也是可用的。\r\nFastCGI的不依赖于任何Web服务器的内部架构，因此即使服务器技术的变化, FastCGI依然稳定不变。\r\n\r\n#### FastCGI的工作原理\r\n\r\nWeb Server启动时载入FastCGI进程管理器（IIS ISAPI或Apache Module)\r\nFastCGI进程管理器自身初始化，启动多个CGI解释器进程(可见多个php-cgi)并等待来自Web Server的连接。\r\n当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi。\r\nFastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器(运行在Web Server中)的下一个连接。 在CGI模式中，php-cgi在此便退出了。\r\n在上述情况中，你可以想象CGI通常有多慢。每一个Web请求PHP都必须重新解析php.ini、重新载入全部扩展并重初始化全部数据结构。使用FastCGI，所有这些都只在进程启动时发生一次。一个额外的好处是，持续数据库连接(Persistent database connection)可以工作。\r\n\r\n#### FastCGI的不足\r\n\r\n因为是多进程，所以比CGI多线程消耗更多的服务器内存，PHP-CGI解释器每进程消耗7至25兆内存，将这个数字乘以50或100就是很大的内存数。\r\n\r\nNginx 0.8.46+PHP 5.2.14(FastCGI)服务器在3万并发连接下，开启的10个Nginx进程消耗150M内存`（15M*10=150M）`，开启的64个php-cgi进程消耗1280M内存（20M*64=1280M），加上系统自身消耗的内存，总共消耗不到2GB内存。如果服务器内存较小，完全可以只开启25个php-cgi进程，这样php-cgi消耗的总内存数才500M。\r\n上面的数据摘自Nginx 0.8.x + PHP 5.2.13(FastCGI)搭建胜过Apache十倍的Web服务器(第6版)\r\n\r\n### PHP-CGI\r\n\r\nPHP-CGI是PHP自带的FastCGI管理器。\r\n\r\nPHP-CGI的不足：\r\n\r\nphp-cgi变更php.ini配置后需重启php-cgi才能让新的php-ini生效，不可以平滑重启。\r\n直接杀死php-cgi进程，php就不能运行了。(PHP-FPM和Spawn-FCGI就没有这个问题，守护进程会平滑从新生成新的子进程。）\r\n\r\n#### PHP-FPM\r\n\r\nPHP-FPM是一个PHP FastCGI管理器，是只用于PHP的，可以在 http://php-fpm.org/download下载得到。\r\n\r\nPHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。\r\n\r\n现在我们可以在最新的PHP 5.3.2的源码树里下载得到直接整合了PHP-FPM的分支，据说下个版本会融合进PHP的主分支去。相对Spawn-FCGI，PHP-FPM在CPU和内存方面的控制都更胜一筹，而且前者很容易崩溃，必须用crontab进行监控，而PHP-FPM则没有这种烦恼。\r\n\r\nPHP5.3.3已经集成php-fpm了，不再是第三方的包了。PHP-FPM提供了更好的PHP进程管理方式，可以有效控制内存和进程、可以平滑重载PHP配置，比spawn-fcgi具有更多有点，所以被PHP官方收录了。在./configure的时候带 –enable-fpm参数即可开启PHP-FPM。\r\n\r\n#### Spawn-FCGI\r\n\r\nSpawn-FCGI是一个通用的FastCGI管理服务器，它是lighttpd中的一部份，很多人都用Lighttpd的Spawn-FCGI进行FastCGI模式下的管理工作，不过有不少缺点。而PHP-FPM的出现多少缓解了一些问题，但PHP-FPM有个缺点就是要重新编译，这对于一些已经运行的环境可能有不小的风险(refer)，在php 5.3.3中可以直接使用PHP-FPM了。\r\n\r\nSpawn-FCGI目前已经独成为一个项目，更加稳定一些，也给很多Web 站点的配置带来便利。已经有不少站点将它与nginx搭配来解决动态网页。\r\n\r\n最新的lighttpd也没有包含这一块了(http://www.lighttpd.net/search?q=Spawn-FCGI)，但可以在以前版本中找到它。在lighttpd-1.4.15版本中就包含了(http://www.lighttpd.net/download/lighttpd-1.4.15.tar.gz)，目前Spawn-FCGI的下载地址是http://redmine.lighttpd.net/projects/spawn-fcgi，最新版本是http://www.lighttpd.net/download/spawn-fcgi-1.6.3.tar.gz。\r\n\r\n注：最新的Spawn-FCGI可以到lighttpd.net网站搜索“Spawn-FCGI”找到它的最新版本发布地址。\r\n\r\n#### PHP-FPM与spawn-CGI对比\r\n\r\nPHP-FPM的使用非常方便，配置都是在PHP-FPM.ini的文件内，而启动、重启都可以从php/sbin/PHP-FPM中进行。更方便的是修改php.ini后可以直接使用PHP-FPM reload进行加载，无需杀掉进程就可以完成php.ini的修改加载\r\n结果显示使用PHP-FPM可以使php有不小的性能提升。PHP-FPM控制的进程cpu回收的速度比较慢,内存分配的很均匀。\r\nSpawn-FCGI控制的进程CPU下降的很快，而内存分配的比较不均匀。有很多进程似乎未分配到，而另外一些却占用很高。可能是由于进程任务分配的不均匀导致的。而这也导致了总体响应速度的下降。而PHP-FPM合理的分配，导致总体响应的提到以及任务的平均。\r\n","timestamp":1541470330295},{"name":"002-认识Nginx.md","path":"01-Linux运维/01-常用服务/06-LNMP/002-认识Nginx.md","content":"## 认识Ningx\r\nNginx是一个开源的，支持高性能，高并发的www服务和代理服务软件。（engine x）\r\nNginx具有高并发（静态资源，小文件），占用系统资源少等特性，且功能逐渐完善\r\n具有web服务软件的功能，还具有反向代理负载均衡功能和缓存服务功能，在反向代理负载均衡方面类似于LVS负载均衡以及Haproxy专业代理软件，但是Nginx部署起来更为简单，方便，在缓存功能方面它又类似于squid等专业的缓存服务软件\r\n\r\n## Nginx HTTP服务器的特色以及优点：\r\n1. 支持高并发。能支持几万并发连接（特别是静态小文件业务环境）\r\n2. 资源消耗少：在3万并发连接下，开启10个nginx线程消耗不到200M内存\r\n3. 可以做HTTP反向代理及加速缓存，即负债均衡功能，内置对RS节点服务器健康检查功能，这相当于专业的haproxy软件或lvs功能\r\n4. 具备squid等专业缓存软件等的缓存功能\r\n5. 支持异步网络IO时间模型epoll（Linux2.6+）\r\n\r\n**关于同步和异步**\r\n\r\n类似于UDP和TCP的无链接的和有链接的。同步的效率并不高。但是异步效率高也有缺点，就是类似于UDP，安全性可靠性不高。\r\n## 代理\r\n- 反向代理：代替外部用户请求web服务器\r\n- 正向代理：服务器通过代理服务器去访问一些网站，这叫正向代理。\r\n\r\n## Nginx做为web服务器的主要应用场景：\r\n1. 使用Nginx运行HTML、JS、CSS、小图片等静态数据（此功能类似Lighttpd软件）\r\n2. Ngiinx结合FastCGI运行PHP等动态程序（例如fastcgi_pass方式）\r\n3. Nginx结合tomcat/resin等支持Java动态程序（常用proxy_pass方式）\r\n\r\n## 模型\r\n- Apache：基于传统的select模型（同步）。并发能力有限。\r\n- Nginx：不支持类似apache的DSO模式，扩展库必须编译进主程序（缺点）\r\n\r\n***\r\n### epoll模型和select 模型：\r\n##### epoll是异步的\r\n宿舍房间有多间，你的朋友来找你，select版本的大妈会带着你的朋友挨个房间去找，直到找到为止，epoll大妈会先记录下每位入住同学的房间号，当你的朋友来找你时，只需要告诉你的朋友你住在哪个房间里就可以了。如果同时来了100个人，epoll和select大妈的效率就立竿见影了。\r\n\r\n\r\n##### select是同步的\r\n另外一种理解：select的调度复杂度是线性的，举个例子，一个保姆照看一群孩子，如果把孩子是否需要尿尿比作是网络的IO事件，select的作用就好比这个保姆挨个询问每一个孩子是否要尿尿，如果孩子回答是的话，那么保姆则把还自己领出来放到另外一个地方。当所有孩子询问完以后，保姆领着这些要尿尿的孩子去上厕所（处理网络IO事件）\r\n还是以保姆照看一群孩子为例，在epoll机制下，保姆不再需要挨个询问每个孩子是否需要尿尿，取而代之的是，每个孩子如果想尿尿的话，自己主动的站到事先约定好的地方，而保姆的职责就是查看事先约定好的地方是否有孩子，如果有就带着小孩子去上厕所（处理IO事件），因此，epoll这种机制，能够高效的处理成千上万的并发连接，而且性能不会随着连接数增加而下降太多。\r\n\r\n静态高并发首选nginx\r\n避免同一个业务使用多款软件\r\n","timestamp":1541470330295},{"name":"01-Squid介绍和部署.md","path":"01-Linux运维/01-常用服务/08-Squid/01-Squid介绍和部署.md","content":"# Squid\r\n>缓存服务器（又可以称为代理服务器），即用来存储（介质为内存和硬盘）用户访问的网页，图片，文件等等细信息的专用服务器。这种服务器不仅可以使用户最快的得到他们想要的信息，而且可以大大减少服务端网络传输的数量。缓存服务器往往也是代理服务器，对于网站的用户来说，缓存服务器和代理服务器是不可见的，即在用户看来所有的网站信息都来自其正在访问的网站，而实际上可能是缓存服务器正在提供访问数据。目前国内常用的的缓存服务器有：squid，varnish，Nginx，ats。\r\n\r\nSquid官网网站 [http://www.squid-cache.org](http://www.squid-cache.org)\r\n\r\n## Web缓存相关概念\r\n### cache命中\r\ncache命中指的是cache server每次从它的缓存里满足客户端HTTP请求时发生。cache命中率，是所有客户端HTTP请求中命中的比例。Web缓存典型的命中率在30%~60%之间。另一个相似的度量单位叫做字节命中率，描绘了cache提供服务的数据容量（字节数）。\r\n#### 如何提高命中率？\r\n* apache nginx可以设置expires的cache-control缓冲头\r\n* 动静分离，静态化，对静态文件走CDN\r\n* mysql cache让缓存靠前\r\n### cache丢失\r\ncache丢失在cache server不能从它的换村里满足客户端HTTP请求的时候发生。cache丢失的原因有很多种。\r\n- 当第一次接收到用户请求的第一个新资源的时候，就会产生一个cache丢失。那么如何解决第一次命中？\r\n    - 预热或者预取，后端生成数据后统一推到前端。\r\n- 存储空间满或者对象自身过期，cache server会自动清除这些缓存对象以释放空间给新的对象。因此为了避免这个问题可以加大内存和磁盘，或者过期时间设置的长点；参数设置，缓存的参数设置的大一些，最大缓存对象2M。分资源缓存，比如1M的，10M的100M的，页面和视频进行分拆（通过acl或者正则匹配抛给不同的pools）。\r\n- 还有可能是客户访问的资源不可到达。原始服务器会指示cache server怎样处理用户响应，比如会提示数据不能被缓存，或在有限的时间内才被重复使用等等。\r\n### cache确认\r\ncache确认保证cache server不对访问的用户返回过期的数据。在重复使用缓存对象的时候，cache server需要经常从原始服务器确认它。假如服务器只是squid的拷贝仍然有效，数据就发送出去，否则，squid更新它的缓存拷贝，并且转发给客户。当用户更新了数据到数据库或者存储服务器的时候，就可以从业务角度主动调用该接口清除该对象缓存的指令。\r\n\r\n## Squid服务\r\n\r\n### Squid的用途\r\n- 用于放置在web服务器的前面，缓存网站web服务器的相关数据，这样用户请求缓存服务器就可以直接返回数据给用户了，从而提升了用户访问网站的体验，从另一方面也减轻了web服务器，数据库服务器的，图片文件存储服务器等业务的压力。这种应用也成为1反向代理业务。\r\n- 用于放置在企业内部关键出网位置或者共享网络的前端，缓存内部上网用户的数据，域名系统和其他网络搜索数据等。这样会大大的节约公司的带宽，这种应用被称之为正向代理（普通代理或者透明代理）\r\n- 通过放在网络的关键位置过滤网络流量和访问数据，提升整个网络的安全性，比如可以监控以及限制内部企业员工的上网行为，可以和iptables配合做为办公网的网关。\r\n- 用作局域网通过代理上网\r\n\r\n### 透明代理\r\n所谓透明代理是相对于代理服务器而言，客户端不需要做任何和代理服务器相关的设置和操作，对于用户而言，感受不到代理服务器的存在，所以称之为透明代理，即把代理服务器部署在核心的上网出口，当用户上网浏览页面的时候，会交给代理服务器向外请求，如果结合iptables可以实现代理+网关+内容过滤+流量安全控制等完整的上网解决方案。\r\n\r\n### 反向代理\r\n普通代理方式是代理内部网络用户访问Internet，反向代理服务器是指的代理服务器来接受来自internet上的请求，然后将请求转发给内部网络上的服务器，并将从内部服务器上得到的结果返回给internet上请求链接的客户端，此时代理服务武器对外就表现为一个服务器。\r\n\r\n## Squid部署\r\n>磁盘和内存的关联，因为squid对每个缓存响应使用少数内存，因此在磁盘空间和内存要求之间有一定的联系，基本规则是，每个G次哦按空间需要32M内存，这样，512M内存的系统能支持16G的磁盘缓存。根据情况不同，实际情况也不一样，内存需求依赖于如下的事实：缓存目标大小，CPU体系（32为或64位），同时在线的用户数量和你使用的特殊功能。\r\n\r\n### 虚拟机测试环境\r\n- 内存：大于等于512M\r\n- 硬盘：8-16G或更高\r\n- VM：1-2个牟其中一个部署缓存服务器，一个部署web服务器做测试使用。\r\n\r\n名称 | 接口 | IP | 用途\r\n---|---|---|---|\r\nSquid server | eth0 | 10.0.0.7 | 外网管理IP，用于WAN数据转发\r\nWeb Server | eth0 | 10.0.0.8 | 外网管理IP，用于WAN数据转发\r\n\r\n#### 软件下载安装\r\n\r\n```\r\nyum -y install openssl-devel\r\nwget http://www.squid-cache.org/Versions/v3/3.0/squid-3.0.STABLE20.tar.gz\r\ntar xf squid-3.0.STABLE20.tar.gz\r\ncd /tools/squid-3.0.STABLE20\r\n\r\n```\r\n#### 编译参数：\r\n\r\n```\r\n[root@web02 squid-3.0.STABLE20]# ./configure --prefix=/application/squid3.0 \\\r\n--enable-async-io=100 \\\r\n--with-pthreads \\\r\n--enable-storeio=\"aufs,diskd,ufs\" \\\r\n--enable-removal-policies=\"heap,lru\" \\\r\n--enable-icmp \\\r\n--enable-delay-pools \\\r\n--enable-useragent-log \\\r\n--enable-referer-log \\\r\n--enable-kill-parent-hack \\\r\n--enable-cachemgr-hostname=localhost \\\r\n--enable-arp-acl \\\r\n--enable-default-err-language=English \\\r\n--enable-err-languages=\"Simplify_Chinese English\" \\\r\n--disable-poll \\\r\n--disable-wccp \\\r\n--disable-wccpv2 \\\r\n--disable-internal-dns \\\r\n--enable-basic-auth-helpers=\"NCSA\" \\\r\n--enable-stacktrace \\\r\n--with-large-files \\\r\n--disable-mempools \\\r\n--with-filedescriptors=64000 \\\r\n--enable-ssl \\\r\n--enable-x-accelerator-vary \\\r\n--disable-snmp \\\r\n--with-aio \\\r\n--enable-linux-netfilter \\\r\n--enable-linux-tproxy\r\n```\r\n#### 安装\r\n\r\n```\r\nmake && make install\r\n[root@cache-server application]# ln -s /application/squid3.0/ /application/squid\r\n```\r\n\r\n\r\n#### 关于编译参数的说明\r\n\r\n```\r\n--prefix=/application/squid3.0 \\                     \r\n##指定安装位置是哪里默认是/usr/local/squid\r\n--enable-async-io=100 \\\r\n##使用100个线程进行同步IO\r\n--with-pthreads \\\r\n##使用POSIX（可移植性操作系统接口）线程\r\n--enable-storeio=\"aufs,diskd,ufs\" \\                  \r\n##支持ufs和aufs文件存储\r\n--enable-removal-policies=\"heap,lru\" \\\r\n##指定排除元素，排除元素是squid需要腾出空间给新的cache目标，用以排除旧的目标的机制，squid在2.5的时候支持3个排除元素：最少近期使用（LRU）、贪婪对偶大小（GDS）、最少经常使用（LFU）\r\n--enable-icmp \\                                      \r\n##squid利用icmp消息来确定回环试件尺寸，非常像ping程序。目的是激活netdb，必须使用--enable-icmp选项来配置squiid，也必须以超级用户权限来安装pinger程序。\r\n--enable-delay-pools \\\r\n##启用延迟池，，延迟池是squid用于传输形状或带宽限制的技术。该池由大量的客户端IP地址组成，当来自这些客户端的请求处理cache丢失状态，它们的响应可能被人工延迟\r\n--enable-useragent-log \\\r\n##该选项用来激活来自客户请求的HTTP用户代理头的日志\r\n--enable-referer-log \\\r\n##激活客户请求的HTTP referer日志\r\n--enable-kill-parent-hack \\\r\n##Useful for hackers only\r\n--enable-cachemgr-hostname=localhost \\\r\n--enable-arp-acl \\\r\n##squid在一些操作系统中支持ARP，或者acl，该代码使用非标准的函数接口来执行arp访问控制列表，所以它被默认禁止，假如你在linux或solaris上使用squid，你可能用上这个功能\r\n--enable-default-err-language=English \\\r\n##设置error_directory指令的默认值\r\n--enable-err-languages=\"Simplify_Chinese English\" \\\r\n##指定复制到安装目录($prefix/share/errors)的语言，不指定安装所有\r\n--disable-poll \\                                    \r\n##强制使用“poll()”函数扫描文件描述符\r\n--disable-wccp \\\r\n##禁用wccp协议\r\n--disable-wccpv2 \\\r\n##禁用wccp协议v2\r\n--disable-internal-dns \\\r\n##禁用内部dns\r\n--enable-basic-auth-helpers=\"NCSA\" \\\r\n##设置基础帮助名单\r\n--enable-stacktrace \\\r\n##启用崩溃追踪，squid崩溃后会自动记录cache.log\r\n--with-large-files \\\r\n##启用大文件服务\r\n--disable-mempools \\\r\n--with-filedescriptors=64000 \\\r\n##默认文件描述符是65535\r\n--enable-ssl \\\r\n--enable-x-accelerator-vary \\\r\n##该高级功能可能在squid被配置成加速器的时候使用，他建议squid在响应请求时，从后台原始服务器中寻找X-Acceleerator-Vary头\r\n--disable-snmp \\\r\n--with-aio \\\r\n--enable-linux-netfilter \\\r\n--enable-linux-tproxy\r\n##上面这两个参数在\r\n```\r\n","timestamp":1541470330295},{"name":"02-Squid的特性.md","path":"01-Linux运维/01-常用服务/08-Squid/02-Squid的特性.md","content":"# Squid的特性\r\n## 文件目录结构\r\n```\r\n[root@cache-server application]# tree -L 2 /application/squid\r\n/application/squid\r\n├── bin\r\n│   ├── RunAccel\r\n│   ├── RunCache\r\n│   └── squidclient\r\n├── etc\r\n│   ├── cachemgr.conf\r\n│   ├── cachemgr.conf.default\r\n│   ├── mime.conf\r\n│   ├── mime.conf.default\r\n│   ├── squid.conf\r\n│   └── squid.conf.default\r\n├── libexec\r\n│   ├── cachemgr.cgi\r\n│   ├── diskd\r\n│   ├── dnsserver\r\n│   ├── ncsa_auth\r\n│   ├── pinger\r\n│   └── unlinkd\r\n├── sbin\r\n│   └── squid\r\n├── share\r\n│   ├── errors\r\n│   ├── icons\r\n│   ├── man\r\n│   └── mib.txt\r\n└── var\r\n    └── logs\r\n```\r\n接下来对目录以及文件进行说明：\r\n\r\n文件名/目录名| 功能描述\r\n---|---\r\nsbin | squid主从程序目录，正常只能被root启动\r\nsbin/squid | squid的主程序\r\nbin | bin目录包含对所有用户可用的程序\r\nbin/Runcache | Runcache是一个shell脚本，你能用它来启动squid，假如squid死掉，该脚本自动重启它，除非它检测到经常性的重启\r\nbin/RunAccel | RunAccel与Runcache几乎一致，唯一的不同是它增加了一个命令行参数，告诉squid在哪里侦听HTTP请求。\r\nbin/squidclient | squidclient是一个简单的HTTP客户端程序，你能用他来测试squid。它也有一些特殊功能，用以对运行的squid进程发起管理请求\r\nlibexec | libexec程序目录包含了辅助程序，有一些命令你不能正常的启动，然而这些程序通常被其他程序启动。\r\nlinexec/unlinkd | unlinkd就是一个辅助程序，它从cache目录里删除文件\r\nlibexec/cachemgr.cgi | cachemgr.cgi是squid管理功能的CGI接口。为了使用它，你需要拷贝该程序到你的web服务器的cgi-bin目录\r\nlibexec/diskd | 假如你指定了--enable-storeio=diskd，你才能看到它\r\nlibexec/pinger | 假如你指定了--enable-icmp，你才能看到它\r\netc | squid的配置文件目录\r\netc/squid.conf | squid主配置文件\r\nvar | 包含了不是很重要的和经常变化的文件，这些文件不必正常的备份他们\r\nvar/logs | 这个目录是squid不同日志文件的默认位置。当你第一次安装squid的时候，它是空的，一旦squid开始运行，你能在这里看到名字为acces.log，cache.log和store.log这样的文件\r\nvar/cache | 假如你不在squid.conf文件里指定，这是默认的缓存目录（cache_dir）\r\n\r\n## 配置Squid\r\n为了保证squid能够正常使用，我们需要对squid进行一系列的配置，和其他的应用一样，squid的运行也需要有一个账户，默认如果不指定的话那就是nobody\r\n\r\n```\r\ncache_effective_user squid\r\ncache_effective_group squid\r\n```\r\n修改squid的日志记录信息\r\n\r\n```\r\naccess_log /application/squid3.0/var/logs/access.log squid\r\ncache_log /application/squid3.0/var/logs/cache.log\r\ncache_store_log /application/squid3.0/var/logs/store.log\r\n```\r\n打开磁盘的缓存\r\n\r\n```\r\ncache_dir ufs /application/squid3.0/var/cache 100 16 256\r\n```\r\nSquid的端口号（默认端口号是3128），如果要做缓存服务器要改成80，如果要做代理那么就不用管，当然这个http_port可以写多个。\r\n\r\n```\r\nhttp_port 3128\r\n```\r\n配置主机名：\r\n\r\n```\r\nvisible_hostname img01.etiantian.org\r\n```\r\n配置管理员信息：\r\n\r\n```\r\ncache_mgr 1020561033@qq.com\r\n```\r\n\r\n## Squid的日志文件\r\nsquid有三个主要的日志文件：cache.log access.log store.log\r\n- cache.log：squid的配置信息，性能警告，以及严重错误\r\n- access.log：记录访问日志\r\n- store.log：有关存储或者删除cache目标的记录\r\n","timestamp":1541470330295},{"name":"03-Squid服务应用.md","path":"01-Linux运维/01-常用服务/08-Squid/03-Squid服务应用.md","content":"# Squid服务应用\r\n## 运行Squid\r\n\r\n查看运行前的帮助：\r\n\r\n```\r\n[root@cache-server ~]# /application/squid/sbin/squid -h\r\nUsage: squid [-cdhvzCDFNRVYX] [-s | -l facility] [-f config-file] [-[au] port] [-k signal]\r\n       -a port   Specify HTTP port number (default: 3128).    ##指定新的http_port值，如果这里指定了这个选项，那么会覆盖配置文件中的那个值\r\n       -d level  Write debugging to stderr also.              ##让squid将它的调试信息写到标准错误\r\n       -f file   Use given config-file instead of             ##指定配置文件启动\r\n                 /application/squid3.0/etc/squid.conf\r\n       -h        Print help message.               \r\n       -k reconfigure|rotate|shutdown|interrupt|kill|debug|check|parse  ##指定squid执行不同的管理功能，功能参数这里都给列出来了。\r\n                 Parse configuration file, then send signal to\r\n                 running copy (except -k parse) and exit.\r\n       -s | -l facility\r\n                 Enable logging to syslog.         ##激活日志记录到syslog进程。squid使用LOCAL4 syslog设备。\r\n       -u port   Specify ICP port number (default: 3130), disable with 0.\r\n       -v        Print version.\r\n       -z        Create swap directories        ##初始化缓存\r\n       -C        Do not catch fatal signals.\r\n       -D        Disable initial DNS tests.     ##禁止初始化DNS测试，正常请工况下squid直到验证它的dns可用才会启动，该选项阻止了这样的检测。\r\n       -F        Don\'t serve any requests until store is rebuilt.\r\n       -N        No daemon mode.\r\n       -R        Do not set REUSEADDR on port.\r\n       -S        Double-check swap during rebuild.\r\n       -X        Force full debugging.\r\n       -Y        Only return UDP_HIT or UDP_MISS_NOFETCH during fast reload.\r\n```\r\n\r\n\r\n检查配置文件语法：\r\n\r\n```\r\n[root@cache-server etc]# /application/squid/sbin/squid -k parse\r\n2017/02/24 00:08:27| Processing Configuration File: /application/squid3.0/etc/squid.conf (depth 0)\r\n2017/02/24 00:08:27| cache_cf.cc(346) squid.conf:1707 unrecognized: \'/cache_dir\'\r\n2017/02/24 00:08:27| Initializing https proxy context\r\nWARNING: Cannot write log file: /application/squid3.0/var/logs/cache.log\r\n/application/squid3.0/var/logs/cache.log: Permission denied\r\n         messages will be sent to \'stderr\'.\r\n##这里发现有一个报错提示我们logs文件夹下没有可以写的权限，因此我们需要对目录进行授权。\r\n\r\n[root@cache-server etc]# chown -R squid.squid /application/squid/var/logs/\r\n\r\n##授权完成以后再次进行配置文件的语法检查\r\n[root@cache-server etc]# /application/squid/sbin/squid -k parse           \r\n2017/02/24 00:09:15| Processing Configuration File: /application/squid3.0/etc/squid.conf (depth 0)\r\n2017/02/24 00:09:15| cache_cf.cc(346) squid.conf:1707 unrecognized: \'/cache_dir\'\r\n2017/02/24 00:09:15| Initializing https proxy context\r\n```\r\n\r\n添加环境变量：\r\n\r\n```\r\n[root@cache-server ~]# echo \'export PATH=$PATH:/application/squid/sbin:/application/squid/bin\' >> /etc/profile\r\n[root@cache-server ~]# . /etc/profile\r\n[root@cache-server ~]# echo $PATH\r\n/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/application/squid/sbin:/application/squid/bin\r\n```\r\n初始化Cache_dir：\r\n\r\n```\r\n[root@cache-server ~]# chown -R squid /application/squid/var/\r\n[root@cache-server ~]# squid -z\r\n2017/02/24 00:24:55| cache_cf.cc(346) squid.conf:1707 unrecognized: \'/cache_dir\'\r\n2017/02/24 00:24:55| Creating Swap Directories\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/00\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/01\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/02\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/03\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/04\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/05\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/06\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/07\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/08\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/09\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/0A\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/0B\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/0C\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/0D\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/0E\r\n2017/02/24 00:24:55| Making directories in /application/squid3.0/var/cache/0F\r\n```\r\n>可以看到上面的结构，记得我们调整cache_dir的时候对应的L1和L2的值么？L1对应的是16个也就是上面的16个目录，L2对应的是256个，意味着上面的每个文件夹下面还有256个目录，以后squid通过hash算法放到这些目录里。\r\n\r\n测试启动：\r\n\r\n```\r\n[root@cache-server etc]# squid -N -d1         \r\n2017/02/24 00:31:12| Starting Squid Cache version 3.0.STABLE20 for x86_64-unknown-linux-gnu...\r\n2017/02/24 00:31:12| Process ID 77759\r\n2017/02/24 00:31:12| With 4096 file descriptors available\r\n2017/02/24 00:31:12| Performing DNS Tests...\r\n2017/02/24 00:31:13| Successful DNS name lookup tests...\r\n2017/02/24 00:31:13| helperOpenServers: Starting 5/5 \'dnsserver\' processes\r\n2017/02/24 00:31:13| User-Agent logging is disabled.\r\n2017/02/24 00:31:13| Referer logging is disabled.\r\n2017/02/24 00:31:13| Unlinkd pipe opened on FD 14\r\n2017/02/24 00:31:13| Swap maxSize 102400 + 8192 KB, estimated 8507 objects\r\n2017/02/24 00:31:13| Target number of buckets: 425\r\n2017/02/24 00:31:13| Using 8192 Store buckets\r\n2017/02/24 00:31:13| Max Mem  size: 8192 KB\r\n2017/02/24 00:31:13| Max Swap size: 102400 KB\r\n2017/02/24 00:31:13| Version 1 of swap file without LFS support detected...\r\n2017/02/24 00:31:13| Rebuilding storage in /application/squid3.0/var/cache (CLEAN)\r\n2017/02/24 00:31:13| Using Least Load store dir selection\r\n2017/02/24 00:31:13| Set Current Directory to /application/squid3.0/var/cache\r\n2017/02/24 00:31:13| Loaded Icons.\r\n2017/02/24 00:31:13| Accepting  HTTP connections at 0.0.0.0, port 3128, FD 16.\r\n2017/02/24 00:31:13| Accepting ICP messages at 0.0.0.0, port 3130, FD 17.\r\n2017/02/24 00:31:13| HTCP Disabled.\r\n2017/02/24 00:31:13| Pinger socket opened on FD 19\r\n2017/02/24 00:31:13| Ready to serve requests.\r\n2017/02/24 00:31:13| Done reading /application/squid3.0/var/cache swaplog (0 entries)\r\n2017/02/24 00:31:13| Finished rebuilding storage from disk.\r\n2017/02/24 00:31:13|         0 Entries scanned\r\n2017/02/24 00:31:13|         0 Invalid entries.\r\n2017/02/24 00:31:13|         0 With invalid flags.\r\n2017/02/24 00:31:13|         0 Objects loaded.\r\n2017/02/24 00:31:13|         0 Objects expired.\r\n2017/02/24 00:31:13|         0 Objects cancelled.\r\n2017/02/24 00:31:13|         0 Duplicate URLs purged.\r\n2017/02/24 00:31:13|         0 Swapfile clashes avoided.\r\n2017/02/24 00:31:13|   Took 0.01 seconds (  0.00 objects/sec).\r\n2017/02/24 00:31:13| Beginning Validation Procedure\r\n2017/02/24 00:31:13|   Completed Validation Procedure\r\n2017/02/24 00:31:13|   Validated 25 Entries\r\n2017/02/24 00:31:13|   store_swap_size = 0\r\n2017/02/24 00:31:14| storeLateRelease: released 0 objects\r\n```\r\n如果看到`2017/02/24 00:31:13| Ready to serve requests.`这一行就证明启动成功了。\r\n\r\n查看端口占用情况：\r\n\r\n```\r\n[root@cache-server ~]# netstat -lntup | grep squid\r\ntcp        0      0 0.0.0.0:3128                0.0.0.0:*                   LISTEN      77759/squid         \r\nudp        0      0 0.0.0.0:3130                0.0.0.0:*                               77759/squid   \r\n```\r\n测试使用：\r\n\r\n![](http://omk1n04i8.bkt.clouddn.com/17-3-28/23053038-file_1490692421178_169eb.jpg)\r\n\r\n此时我们可以通过IE浏览器去访问一些网站然后发现是访问正常的，此时我们去查看squid的日志：\r\n\r\n```\r\n[root@cache-server ~]# tail /application/squid/var/logs/access.log  \r\n1487867890.006  59035 10.0.0.1 TCP_MISS/503 0 CONNECT clients1.google.com:443 - DIRECT/74.125.23.138 -\r\n1487867911.725  24281 10.0.0.1 TCP_MISS/200 657 POST http://bbs.dcgamer.top/json/get_notifications - DIRECT/60.211.204.165 application/json\r\n1487867912.622  10724 10.0.0.1 TCP_MISS/200 6076 CONNECT note.youdao.com:443 - DIRECT/123.58.182.251 -\r\n1487867912.884  10240 10.0.0.1 TCP_MISS/200 6264 CONNECT rpc3.note.youdao.com:443 - DIRECT/123.58.182.209 -\r\n1487867922.003  59465 10.0.0.1 TCP_MISS/503 0 CONNECT clients1.google.com:443 - DIRECT/74.125.23.113 -\r\n1487867924.918    771 10.0.0.1 TCP_MISS/200 1460 GET http://notify3.note.youdao.com/pushserver3/client? - DIRECT/123.58.182.253 text/json\r\n1487867927.219   1760 10.0.0.1 TCP_MISS/200 1460 GET http://notify3.note.youdao.com/pushserver3/client? - DIRECT/123.58.182.253 text/json\r\n1487867937.106  20206 10.0.0.1 TCP_MISS/200 7897 CONNECT note.youdao.com:443 - DIRECT/123.58.182.252 -\r\n1487867937.217  19727 10.0.0.1 TCP_MISS/200 7773 CONNECT rpc3.note.youdao.com:443 - DIRECT/123.58.182.210 -\r\n1487867939.884  24438 10.0.0.1 TCP_MISS/200 657 POST http://bbs.dcgamer.top/json/get_notifications - DIRECT/123.132.254.130 application/json\r\n```\r\n此时其实可以发现有了日志信息了，而且如果说把squid停掉的话我们用ie就上不去网了。上述的启动方式属于前台启动，-N参数表示不使用守护进程模式，因此我们再使用后台模式把squid启动起来。\r\n\r\n\r\n```\r\n[root@cache-server etc]# squid -D\r\n[root@cache-server etc]# ps -ef | grep squid\r\nroot      77799      1  0 00:47 ?        00:00:00 squid -D\r\nsquid     77801  77799  0 00:47 ?        00:00:00 (squid) -D\r\nsquid     77802  77801  0 00:47 ?        00:00:00 (dnsserver)\r\nsquid     77803  77801  0 00:47 ?        00:00:00 (dnsserver)\r\nsquid     77804  77801  0 00:47 ?        00:00:00 (dnsserver)\r\nsquid     77805  77801  0 00:47 ?        00:00:00 (dnsserver)\r\nsquid     77806  77801  0 00:47 ?        00:00:00 (dnsserver)\r\nsquid     77807  77801  0 00:47 ?        00:00:00 (unlinkd)\r\nroot      77810  77470  0 00:47 pts/0    00:00:00 grep --color squid\r\n```\r\n把squid加入到开机自启动：\r\n\r\n```\r\n[root@cache-server etc]# echo \"/application/squid/sbin/squid -D\">> /etc/rc.local\r\n```\r\n## 制作Squid的启动脚本\r\n很简单的一个脚本\r\n```\r\n[root@cache-server init.d]# cat /etc/init.d/squid\r\n#!/bin/sh\r\n# chkconfig: 345 88 14\r\n# description: To manage squid deamon\r\ncase \"$1\" in\r\nstart)\r\n     /application/squid/sbin/squid -D\r\n     ;;\r\nstop)\r\n     /application/squid/sbin/squid -k shutdown\r\n     ;;\r\nrestart)\r\n     /application/squid/sbin/squid -k reconfigure\r\n     ;;\r\nparse)\r\n     /application/squid/sbin/squid -k parse\r\n     ;;\r\ncheck)\r\n     /application/squid/sbin/squid -k check\r\n     ;;\r\n*)\r\n    echo \"Usage(start|stop|restart|parse|check)\"\r\n     ;;\r\nesac\r\n```\r\n## 日志轮询\r\n\r\n```\r\n[root@cache-server init.d]# ll /application/squid/var/logs/\r\ntotal 648\r\n-rw-r----- 1 squid squid 278098 Feb 24 01:02 access.log\r\n-rw-r----- 1 squid squid  18318 Feb 24 00:59 cache.log\r\n-rw-r--r-- 1 root  squid      6 Feb 24 00:58 squid.pid\r\n-rw-r----- 1 squid squid 350751 Feb 24 01:02 store.log\r\n[root@cache-server init.d]# squid -k rotate\r\n[root@cache-server init.d]# ll /application/squid/var/logs/\r\ntotal 660\r\n-rw-r----- 1 squid squid    140 Feb 24 01:02 access.log\r\n-rw-r----- 1 squid squid 278236 Feb 24 01:02 access.log.0\r\n-rw-r----- 1 squid squid    457 Feb 24 01:02 cache.log\r\n-rw-r----- 1 squid squid  18318 Feb 24 00:59 cache.log.0\r\n-rw-r--r-- 1 root  squid      6 Feb 24 00:58 squid.pid\r\n-rw-r----- 1 squid squid    178 Feb 24 01:02 store.log\r\n-rw-r----- 1 squid squid 350930 Feb 24 01:02 store.log.0\r\n```\r\n做了两件事：\r\n- 关闭当前打开的日志文件\r\n- 对日志文件进行重命名，如上面的命令显示后面加了个0做为扩展名，一次类推，下一次就是1,2,3……达到你在文件中设置的值。\r\n\r\n```\r\n#  TAG: logfile_rotate\r\n#       Specifies the number of logfile rotations to make when you\r\n#       type \'squid -k rotate\'. The default is 10, which will rotate\r\n#       with extensions 0 through 9. Setting logfile_rotate to 0 will\r\n#       disable the file name rotation, but the logfiles are still closed\r\n#       and re-opened. This will enable you to rename the logfiles\r\n#       yourself just before sending the rotate signal.\r\n#\r\n#       Note, the \'squid -k rotate\' command normally sends a USR1\r\n#       signal to the running squid process.  In certain situations\r\n#       (e.g. on Linux with Async I/O), USR1 is used for other\r\n#       purposes, so -k rotate uses another signal.  It is best to get\r\n#       in the habit of using \'squid -k rotate\' instead of \'kill -USR1\r\n#       <pid>\'.\r\n#\r\n#Default:\r\n# logfile_rotate 10\r\n\r\n```\r\n具体的值是在上面定义的，默认就是10个。\r\n","timestamp":1541470330295},{"name":"04-Squid ACL应用.md","path":"01-Linux运维/01-常用服务/08-Squid/04-Squid ACL应用.md","content":"# Squid ACL应用实战\r\n### 备份配置文件\r\n\r\n```\r\n[root@cache-server etc]# pwd\r\n/application/squid/etc\r\n[root@cache-server etc]# cp squid.conf{,.normal}\r\n[root@cache-server etc]# ll\r\ntotal 524\r\n-rw-r--r-- 1 root root    419 Feb 23 18:46 cachemgr.conf\r\n-rw-r--r-- 1 root root    419 Feb 23 18:46 cachemgr.conf.default\r\n-rw-r--r-- 1 root root  11651 Feb 23 18:46 mime.conf\r\n-rw-r--r-- 1 root root  11651 Feb 23 18:46 mime.conf.default\r\n-rw-r--r-- 1 root root 165175 Feb 24 00:30 squid.conf\r\n-rw-r--r-- 1 root root 165113 Feb 23 18:46 squid.conf.default\r\n-rw-r--r-- 1 root root 165175 Feb 24 01:13 squid.conf.normal\r\n[root@cache-server etc]# egrep -v \"^#|^$\" squid.conf.normal >squid.conf\r\n```\r\n在配置文件中加入如下的两行\r\n\r\n```\r\nacl sex url_regex -i ^http://.*oldboy.*\r\nhttp_access deny sex\r\n##这里指的注意的是最下面有一个http_access deny all，这一条命令要放在deny all的前面。\r\n```\r\n然后我们再去访问有关于oldboy关键字的网站的时候就会得到如下的结果：\r\n\r\n![](http://omk1n04i8.bkt.clouddn.com/17-3-28/60953621-file_1490695126385_4eba.jpg)\r\n\r\n如果我想要禁用域名中包含某些字符串的网址的访问（这里要使用urlpath_regex）：\r\n\r\n```\r\nacl sex urlpath_regex archive\r\nhttp_access deny sex\r\n```\r\n![](http://omk1n04i8.bkt.clouddn.com/17-3-28/57676733-file_1490695421051_178ac.jpg)\r\n\r\n使用acl控制上网下载的例子\r\n\r\n```\r\nacl BT urlpath_regex -i \\.torrents$\r\nacl BT urlpath_regex -i \\.torrents$ \\.mp3$\r\nhttp_access deny BT\r\n```\r\n控制访问某黄色网站\r\n\r\n```\r\nacl sex url_regex -i ^http://.*sex.*$\r\nhttp_access deny sex\r\n```\r\n单个IP每秒最多请求（并发）30个：可以用来防止爬虫，多线程下载：\r\n\r\n```\r\nacl OverConnLimit maxconn 30\r\nhttp_access deny OverConnLimit\r\n```\r\n\r\n使用acl不记录指定类型文件的日志\r\n```\r\nacl url_no_log urlpath_regex  \\.gif \\.jpg \\.css \\.js \\.swf \\.GIF \\.JPG \\.SWF F5BigIP\r\nacl method_no_log method PURGE HEAD\r\naccess_log /squid/logs/access.log combined !url_no_log !method_no_log\r\n```\r\n### 通过配置实现web管理squid\r\n开启apache\r\n```\r\n[root@cache-server ~]# /application/apache/bin/apachectl start\r\n```\r\n查找\r\n\r\n```\r\n[root@cache-server ~]# find /application/squid/ -name \"cachemgr.cgi\"\r\n/application/squid/libexec/cachemgr.cgi\r\n```\r\n然后将如下内容加入到我们的vhosts文件中，并将主配置文件的端口改为8080，供之后的代理的使用：\r\n\r\n```\r\nScriptAlias \"/squid\" \"/application/squid/libexec/cachemgr.cgi\"\r\n<Location \"/squid\">\r\n       Order   deny,allow\r\n       Deny    from all\r\n       Allow   from all\r\n</Location>\r\n\r\n主配置文件：\r\nListen 8080\r\n# 监听的端口，也可以指定监听哪个IP的指定端口\r\n[root@cache-server ~]# /application/apache/bin/apachectl graceful\r\n```\r\n访问测试：\r\n\r\n![](http://omk1n04i8.bkt.clouddn.com/17-3-28/63067339-file_1490696766701_540.jpg)\r\n默认的是没有用户名密码的，这个我们可以进行自定义的设置：\r\n\r\n```\r\ncachemgr_passwd oldboy config\r\n上面这条命令的格式为：\r\ncachemgr_passwd 密码 行为\r\n具体请参照default配置文件\r\n```\r\n\r\n![](http://omk1n04i8.bkt.clouddn.com/17-3-28/47540237-file_1490696769379_112c1.jpg)\r\n","timestamp":1541470330295},{"name":"05-Squid代理.md","path":"01-Linux运维/01-常用服务/08-Squid/05-Squid代理.md","content":"# Squid的代理\r\n## 代理模式\r\n### 透明代理\r\n>所谓的透明代理就是对于用户来说其实他和正常上网没什么区别，但是他走得是代理，对于用户来说，用户是根本感知不到代理的存在的，之前配置的代理我们又称为服务器代理。透明代理一般布置在网络的出口位置\r\n\r\n做透明代理具体需求如下：\r\n- 至少有两块网卡，一块连接出口的路由器，另外一块连接公司的内部网络\r\n- 所有的上网请求都通过代理服务器（即把代理服务器设置为网关）\r\n\r\n一般要做透明代理的的话，一般要在编译的时候把下面两条参数编译进去：\r\n\r\n```\r\n--enable-linux-netfilter\r\n--enable-linux-tproxy\r\n```\r\n\r\n配置透明代理很简单（帮助信息可以查看默认文件的http_port的TAG，直接搜索即可）：\r\n\r\n```\r\nhttp_port 3128 transparent\r\n并加入如下的三行\r\ncache_mem 80 MB               ##可以被使用的内存的总数，注意这个值要小于cache_dir中设置的值。\r\ncache_swap_low 90             ##squid使用率低于这个使用率不会进行删除目标      \r\ncache_swap_high 95            ##使用率超过95%，逐出对象的操作更加剧烈\r\nmaximum_object_size 8192 KB    ##最大的缓存对象的大小，默认是8K，如果大于这个值就不会放在磁盘里了。\r\nminimum_object_size 0 KB     \r\nmaximum_object_size_in_memory 4096 KB   ##这个是允许保存在内存里的对象的最大的大小。超过这个大小就不会保存在内存中了。\r\nemulate_httpd_log on\r\nmemory_replacement_policy lru  ##缓存算法 最少最近使用。\r\nrefresh_pattern \\.(jpg|png|gif|mp3|xml) 1440    50%     2880    ignore-reload\r\n```\r\n设置完透明代理后，进行防火墙的调整：\r\n\r\n```\r\n[root@cache-server ~]# iptables -t nat -A POSTROUTING -o eth0 -s 172.16.1.0/24 -j MASQUERADE\r\n开启设备的NAT功能，其中eth0为外网卡，eth1为内网卡，内网网段为172.16.1.0/24，对这个网段做nat转换\r\n\r\n[root@cache-server ~]# iptables -t nat -A PREROUTING -i eth1 -p tcp --dport 80 -j REDIRECT --to-ports 3128\r\n把从内网卡收到的请求做一个端口的重定向，针对80端口的访问重定向到squid的3128端口上。\r\n\r\n[root@cache-server ~]# vim /etc/sysctl.conf\r\nnet.ipv4.ip_forward = 1\r\n开启设备的IP转发\r\n\r\n[root@cache-server ~]# sysctl -p            \r\nnet.ipv4.ip_forward = 1\r\nnet.ipv4.conf.default.rp_filter = 1\r\nnet.ipv4.conf.default.accept_source_route = 0\r\nkernel.sysrq = 0\r\nkernel.core_uses_pid = 1\r\nnet.ipv4.tcp_syncookies = 1\r\nkernel.msgmnb = 65536\r\nkernel.msgmax = 65536\r\nkernel.shmmax = 68719476736\r\nkernel.shmall = 4294967296\r\n```\r\n测试：\r\n\r\n这里我新开了一台机器，网卡地址为172.16.1.100\r\n添加网关为172.16.1.7\r\n```\r\nroute add default gw 172.16.1.7\r\ncurl -I www.baidu.com\r\n回显为200，说明访问成功了！\r\n```\r\n我们再看squid服务器的日志信息\r\n\r\n```\r\n[root@cache-server etc]# tail -f ../var/logs/access.log\r\n1487880222.719     48 172.16.1.100 TCP_MISS/200 2873 GET http://www.baidu.com/ - DIRECT/61.135.169.125 text/html\r\n1487880228.207     41 172.16.1.100 TCP_MISS/200 424 HEAD http://www.baidu.com/ - DIRECT/61.135.169.121 text/html\r\n```\r\n这里的TCP/MISS其实就是代表了没有缓存的意思，透明代理实验成功。\r\n\r\n### 反向代理\r\n>公司购买CDN了，那么还要不要搭建squid\r\n\r\n基本需求就不是很大了。\r\n\r\n#### squid反向代理如何获得数据更新\r\n>squid反向代理一般只缓存可缓冲的数据（比如HTML网页，js，css和图片等），而一些CGI脚本程序或者ASP、JSP、PHP之类的动态程序默认不缓存。它根据从WEB服务器返回的HTTP头标记来缓冲静态页面。有四个重要的HTTP头标记\r\n- Last-Modified：告诉反向代理页面什么时间被修改\r\n- Expires：告诉反向代理页面什么时间应该从缓冲区中删除\r\n- Cache-Control：告诉反向代理页面是否应该被缓冲\r\n- Pragma：用来包含实现特定的命令，最常用的是Pragma：no-Cache\r\n\r\n优先级的对比（no-cache，expires，max-age）：\r\n\r\n经验：在squid中Caache-control：no-cache→Expires→refresh_pattern→Last-Modified（靠前面的最重要，前面的生效后，后面的基本就失效了）\r\n\r\n#### 常用header简单讲解：\r\n1. 不缓存控制\r\n    - Cache-Control：no-store：禁止中间的缓存服务器存储这个对象，并把header转发给用户。\r\n    - Cache-Control：no-cache：缓存服务器可以给文件缓存在本地缓存区，只是在和源站新鲜验证前，不能提供给客户端使用\r\n    - Pragma：：no-cache：这是兼容HTTP1.0的时候使用的，原则上是只能对于HTTP请求，用处和Cache-Control：no-cache一样。\r\n2. 指定过期时间控制\r\n    - Cache-Control：max-age表示如果缓存服务器拿到这个文件后，这个对象多久之内是新鲜的可以用的，可以发送给客户端使用的\r\n    - Cache-Control：s-maxage行为上和上面一样，只是只能适用于public的时候缓存\r\n    - Cache-Control：must-revalidate，默认的情况下，缓存代理时可以提供给客户一些旧的对象的内容，以提高性能，但是如果原始服务器不希望这样，就可以配置这个选项，进行严格的检查，比如源站不可用的时候，回源验证过程会失败，默认会吐旧的数据，但是配置了这个以后会吧报504 gateway timeout\r\n    - Expires：这个作用和max-age是一样的，但这是指定一个过期的日期，但不是秒数。所以不建议使用，因为很多缓存服务器和源服务器常常时间不同步，所以基于max-age是使用相对的时间来表示还剩下多少秒可以使用，不要使用expires来使用绝对时间。\r\n\r\n#### 反向代理测试\r\n>测试机器web01(10.0.0.8)\r\n\r\n配置文件进行备份加入如下的新内容：\r\n\r\n```\r\n#refresh_pattern [-i] regexp min percent max [options]\r\nrefresh_pattern -i \\.jpg$ 30 50% 4320 reload-into-ims\r\nrefresh_pattern -i \\.png$ 30 50% 4320 reload-into-ims\r\nrefresh_pattern -i \\.gif$ 30 50% 4320 reload-into-ims\r\nhttp_port 80 accel vhost vport\r\ncache_peer 10.0.0.8 parent 80 0 no-query no-digest max-conn=32 originserver\r\nhosts_file /etc/hosts\r\nrequest_header_max_size 128 KB\r\nipcache_size 1024\r\nipcache_low 90\r\nipcache_high 95\r\n#offline_mode on    ##不管你怎么刷还是ctrl+f5进行强刷不会有影响，普通的情况下如果源站挂了，客户端进行ctrl强刷，缓存是会失效的。\r\n```\r\n**注意：要把所有的系统时间同步再做缓存，否则会对缓存结果产生影响。**\r\n##### Tip\r\n- 这里的cache_peer后面可以跟源站的域名也可以跟源站的ip。我这里直接写的源站的ip，如果你要是写源站的域名的话，记得在本机的/etc/hosts中配置一下。\r\n\r\n配置成功以后对squid进行重启，然后访问squid反向代理服务器（设置ntp同步时间的定时任务），发现代理已经成功。返回的日志信息如下：\r\n\r\n```\r\n[root@cache-server etc]# tail  /application/squid/var/logs/access.log  \r\n1487894195.232      6 10.0.0.1 TCP_REFRESH_UNMODIFIED/200 77573 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 image/jpeg\r\n1487894258.432      5 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 386 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487894259.700      0 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 386 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487894260.369      1 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 386 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487894287.578      1 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 386 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487894288.384      0 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 386 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487894289.968      5 10.0.0.1 TCP_CLIENT_REFRESH_MISS/200 77453 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 image/jpeg\r\n1487894290.011      1 10.0.0.1 TCP_MISS/404 798 GET http://10.0.0.7/favicon.ico - FIRST_UP_PARENT/10.0.0.8 text/html\r\n1487894291.651      5 10.0.0.1 TCP_CLIENT_REFRESH_MISS/200 77453 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 image/jpeg\r\n1487894291.688      0 10.0.0.1 TCP_MISS/404 798 GET http://10.0.0.7/favicon.ico - FIRST_UP_PARENT/10.0.0.8 text/html\r\n```\r\n通过curl查看header头：\r\n\r\n```\r\n[root@cache-server etc]# curl -I -s 10.0.0.7/1.jpg| grep -i X-cache\r\nX-Cache: HIT from img01.etiantian.org\r\n[root@cache-server etc]# curl -I -s 10.0.0.7/2.jpg| grep -i X-cache\r\nX-Cache: HIT from img01.etiantian.org\r\n[root@cache-server etc]# curl -I -s 10.0.0.7/3.jpg| grep -i X-cache\r\nX-Cache: HIT from img01.etiantian.org\r\n[root@cache-server etc]# curl -I -s 10.0.0.7/4.jpg| grep -i X-cache\r\nX-Cache: HIT from img01.etiantian.org\r\n[root@cache-server etc]# curl -I -s 10.0.0.7/5.jpg| grep -i X-cache\r\nX-Cache: MISS from img01.etiantian.org\r\n```\r\n#### 日志分析\r\n首先看一下配置文件中默认的日志格式：\r\n\r\n```\r\n#  TAG: logformat\r\n#       Usage:\r\n#\r\n#       logformat <name> <format specification>\r\n#\r\n#       Defines an access log format.\r\n#\r\n#       The <format specification> is a string with embedded % format codes\r\n#\r\n#       % format codes all follow the same basic structure where all but\r\n#       the formatcode is optional. Output strings are automatically escaped\r\n#       as required according to their context and the output format\r\n#       modifiers are usually not needed, but can be specified if an explicit\r\n#       output format is desired.\r\n#\r\n#               % [\"|[|\'|#] [-] [[0]width] [{argument}] formatcode\r\n#\r\n#               \"       output in quoted string format\r\n#               [       output in squid text log format as used by log_mime_hdrs\r\n#               #       output in URL quoted format\r\n#               \'       output as-is\r\n#\r\n#               -       left aligned\r\n#               width   field width. If starting with 0 the\r\n#                       output is zero padded\r\n#               {arg}   argument such as header name etc\r\n#\r\n#       Format codes:\r\n#\r\n#               >a      Client source IP address\r\n#               >A      Client FQDN\r\n#               >p      Client source port\r\n#               <A      Server IP address or peer name\r\n#               la      Local IP address (http_port)\r\n#               lp      Local port number (http_port)\r\n#               ts      Seconds since epoch\r\n#               tu      subsecond time (milliseconds)\r\n#               tl      Local time. Optional strftime format argument\r\n#                       default %d/%b/%Y:%H:%M:%S %z\r\n#               tg      GMT time. Optional strftime format argument\r\n#                       default %d/%b/%Y:%H:%M:%S %z\r\n#               tr      Response time (milliseconds)\r\n#               >h      Request header. Optional header name argument\r\n#                       on the format header[:[separator]element]\r\n#               <h      Reply header. Optional header name argument\r\n#                       as for >h\r\n#               un      User name\r\n#               ul      User name from authentication\r\n#               ui      User name from ident\r\n#               us      User name from SSL\r\n#               Ss      Squid request status (TCP_MISS etc)\r\n#               Sh      Squid hierarchy status (DEFAULT_PARENT etc)\r\n#               mt      MIME content type\r\n#               rm      Request method (GET/POST etc)\r\n#               ru      Request URL\r\n#               rp      Request URL-Path excluding hostname\r\n#               rv      Request protocol version\r\n#               et      Tag returned by external acl\r\n#               ea      Log string returned by external acl\r\n#               <st     Reply size including HTTP headers\r\n#               >st     Request size including HTTP headers\r\n#               st      Request+Reply size including HTTP headers\r\n#               <sH     Reply high offset sent\r\n#               <sS     Upstream object size\r\n#               %       a literal % character\r\n#\r\n#       The default formats available (which do not need re-defining) are:\r\n#\r\n#logformat squid %ts.%03tu %6tr %>a %Ss/%03Hs %<st %rm %ru %un %Sh/%<A %mt\r\n#logformat squidmime %ts.%03tu %6tr %>a %Ss/%03Hs %<st %rm %ru %un %Sh/%<A %mt [%>h] [%<h]\r\n#logformat common %>a %ui %un [%tl] \"%rm %ru HTTP/%rv\" %Hs %<st %Ss:%Sh\r\n#logformat combined %>a %ui %un [%tl] \"%rm %ru HTTP/%rv\" %Hs %<st \"%{Referer}>h\" \"%{User-Agent}>h\" %S\r\ns:%Sh\r\n#\r\n#Default:\r\n# none\r\n```\r\n设置日志格式：\r\n\r\n```\r\naccess_log /application/squid3.0/var/logs/access.log combined\r\nlogformat combined %{X-Forwarded-For}>h %ui %un [%tl] \"%rm %ru HTTPP/%rv\" %Hs %<st \"%{Referer}>h\" \"%{\r\nUser-Agent}>h\" %Ss:%Sh\r\n```\r\n然后访问后查看日志：\r\n\r\n```\r\n[root@cache-server etc]# tail -f /application/squid/var/logs/access.log\r\n1487902472.069      2 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 386 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487902474.810      2 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 386 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487902475.652      1 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 386 GET http://10.0.0.7/4.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487902480.350      1 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 385 GET http://10.0.0.7/3.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487902493.632      1 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 385 GET http://10.0.0.7/2.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487902498.371      2 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 385 GET http://10.0.0.7/1.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n1487902500.072      1 10.0.0.1 TCP_REFRESH_UNMODIFIED/304 385 GET http://10.0.0.7/1.jpg - FIRST_UP_PARENT/10.0.0.8 -\r\n```\r\n\r\n\r\n日志缓存编码：\r\n\r\naccess.log日志缓存编码| 说明\r\n---|---\r\nTCP_HIT | Squid发现请求的资源貌似新鲜的拷贝，并将其立即发送到客户端\r\nTCP_MISS | Squid没有请求资源的cache拷贝\r\nTCP_REFRESH_HIT | squid发现请求的资源貌似陈旧的拷贝，并发送确认请求到源站，源站返回304（未修改）响应，提示squid的拷贝仍然是新鲜的\r\nTCP_REF_FAIL_HIT | squid发现请求的资源貌似陈旧的拷贝，并发送确认请求到源站，然而源站服务器响应失败，或者返回的响应squid不能理解，在此情况下，squid发送现有的cache拷贝（很可能是陈旧的）到客户端\r\nTCP_REFRESH_MISS | Squid发现请求资源貌似陈旧的拷贝，并发送确认请求到源站，源站响应了新的内容弄，只是这个cache拷贝确实是过期了\r\nTCP_CLIENT_REFERSH_MISS | Squid发现了请求资源的拷贝，但是客户端的请求包含了cache-control：no-cache命令，squid转发客户端的请求到原始服务器强迫cache确认，就比如我们在浏览器使用ctrl+F5\r\nTCP_IMS_HIT | 客户端发送确认请求，squid发现更近来的，貌似新鲜的请求资源的拷贝，squid发送更新的内容到客户端，而不联系源站，F5\r\nTCP_SWAPFAIL_MISS | squid发现请求资源的有效拷贝，但从磁盘装载它失败，这时squid发送请求到原始服务器，就如同这是个cache丢失一样\r\nTCP_NEGATIVE_HIT | 在对原始服务器的请求导致HTTP错误的时候，Squid也会cache这个响应，在短时间内对这些资源的重复请求，导致了否命中，negative_ttl指令控制这些错误被cache的时间数量，值得注意的是，这些错误只在内存中cache，不会被写入磁盘，下列状态码可能导致否定的cache：204,305,400,403,404,405,414,500,501,502，503,504\r\nTCP_MEM_HIT | Squid在内存cache里发现请求资源的有效拷贝，并将其立即发往客户端。注意这点并非精确的呈现了所有从内存服务的响应。例如，某些cache在内存里，但要求确认的响应，会以TCP_REFRESH_HIT等形式记录。\r\nTCP_DENIED | 因为http_access或者http_reply_access规则，客户端的情被拒绝了。注意被http_access拒绝的请求在第9域的值是NONE，然而被http_reply_access拒绝的请求，在相应的地方有一个有效值。\r\nTCP_OFFLINE_HIT | 当offline_mode激活的是时候，squid对任何cache响应返回cache命中，而不用考虑它的新鲜程度\r\nTCP_REDIRECT | 重定向程序告诉squid产生一个http重定向到新的URI。正常的，squid不会记录这些重定向，假如要这样做，必须在编译squid前，手工定义LOG_TCP_REDIRECTS预处理命令\r\n","timestamp":1541470330295},{"name":"00-常用小技巧.md","path":"01-Linux运维/03-日常运维总结/00-常用小技巧.md","content":"# 服务器禁ping\n\n> 服务器禁ping有两种方式，一个是通过修改内核参数实现，另外一个则是通过iptables进行拦截\n\n## 修改内核参数\n\n```\nsysctl -w net.ipv4.icmp_echo_ignore_all=1 \n```\n\n/proc/sys/net/ipv4/icmp_echo_ignore_all   内容为 1 禁止ping  内容为0 开启ping。\n\n## 添加iptables策略\n\n```shell\niptables -A INPUT -p icmp --icmp-type 8 -s 0/0 -j DROP  \n```\n\nping 命令工作的是 发送一个ICMP请求报文交给目的IP，然后目的IP回复一个ICMP报文。上述命令就是利用iptables丢弃掉请求的ICMP包，达到禁ping效果。\n\n\n\n上述的方法都是临时修改，如果需要永久修改的话还是加到配置文件里去比较靠谱。\n\n```\n在/etc/sysctl.conf文件中添加\nnet.ipv4.icmp_echo_ignore_all = 1\n\n然后执行 sysctl -p\n```\n\n","timestamp":1541470330295},{"name":"01-进程管理.md","path":"01-Linux运维/03-日常运维总结/01-进程管理.md","content":"# 进程管理\n\n> 在日常运维的过程中，难免会遇到进程需要管理和查看的地方。\n\n常见的查看方法","timestamp":1541470330295},{"name":"02-nmon.md","path":"01-Linux运维/03-日常运维总结/02-nmon.md","content":"# NMON\n\n> nmon是一种在AIX与各种Linux操作系统上广泛使用的监控与分析工具， nmon所记录的信息是比较全面的，它能在系统运行过程中实时地捕捉系统资源的使用情况，并且能输出结果到文件中。\n\n- 官方网站：http://nmon.sourceforge.net/pmwiki.php\n- 分析工具：[nmon analyser](https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Power+Systems/page/nmon_analyser)\n\n## 下载安装\n\nnmon可以直接去官方网站下载nmon的二进制文件，或者使用yum安装，Ubuntu可以使用apt-get\n\n- Ubuntu：`sudo apt-get install -y nmon`\n- CentOS：`sudo yum install -y nmon`，前提是你已经有安装 epel 源\n  - 或者使用 RPM 包：http://tools.dcgamer.top/nmon/nmon-14i-8.el6.x86_64.rpm\n    - 安装命令：`rpm -ivh nmon-14i-8.el6.x86_64.rpm`\n- 分析工具 nmon analyser：http://tools.dcgamer.top/nmon/nmon_analyser_v5_0_2.zip\n\n\n\n\n\n\n\nnmom定义问题：http://www.51testing.com/html/25/15146625-3714909.html\n\n","timestamp":1541470330295},{"name":"99-常见错误集锦.md","path":"01-Linux运维/03-日常运维总结/99-常见错误集锦.md","content":"# 常见Linux错误集锦\n\n- Peer reports incompatible or unsupported protocol version.\n\n  ```shell\n  # 解决办法\n  yum update -y nss curl libcurl \n  ```\n\n- bin/mysqld: error while loading shared libraries: libnuma.so.1\n\n  ```shell\n  yum -y install numactl\n  sudo apt-get install numactl\n  ```\n","timestamp":1541470330295},{"name":"1-简单实用.md","path":"01-Linux运维/05-Python&Linux/1-简单实用.md","content":"# Python for Linux简单实用\n\n[TOC]\n\n## 一、内置小工具的简单使用\n\n### 1、使用python内置工具开启一个httpserver\n\n- 进入对应的要共享的目录\n\n  ```shell\n  cd target_dir\n  ```\n\n- 执行内置命令\n\n  ```shell\n  python -m SimpleHTTPServer or python -m http.server\n  ```\n\n### 2、字符串转化为json格式的字符串\n\n```python\n echo \'{\"job\":\"developer\",\"name\":\"lmx\",\"sex\":\"male\"}\' | python -m json.tool\n```\n\n### 3、检测模块是否安装\n\n```python\npython -c \"import paramiko\"\n```\n\n## 二、Pip\n\n> pip是一个用来安装和管理python包的工具，是easy_install的替代品，Python2.7和3.4以上内置了pip如果不是这两个版本也可以使用石洞进行安装。可以直接使用yum，Ubuntu可以使用apt-get。\n\n```shell\nyum -y install python-pip\n\n# 升级pip\npip install -U pip\n```\n\n### Pip简单实用\n\nPip的优点：\n\n- 提供了丰富的功能，支持以列表显示，安装，卸载等。\n- 很好的支持python的虚拟环境\n- pip可以处理二进制格式，比如.whl\n- pip是先下载后安装，如果安装失败会处理干净，不会留下中间状态。\n\npip的用法：\n\n```shell\n- install：安装软件包\n- download：下载软件包\n- uninstall：卸载软件包\n- freeze：按照requirements格式输出安装包，可以到其他服务器上执行pip install -r requirements.txt 直接安装软件，pip freeze > requirements.txt\n- list：列出当前系统中的安装包\n- show：查看安装包信息\n- check：pip 9.0.1 提供的最新子命令，检查安装包的依赖是否完整\n- search：查找安装包\n- wheel：打包软件到whell格式\n- hash：计算安装包的hash值\n- completion：生成命令不全配置\n- help：获取pip的帮助信息。\n```\n\n### 加速pip的访问\n\n可以通过加-i参数指定一个较快的镜像源进行安装\n\n```shell\npip install -i https://pypi.douban.com/simple pkg_name\n```\n\n修改配置文件指定默认的高速镜像源\n\n```shell\n$ cat pip.conf\n[global]\nindex-url = https://pypi.douban.com/simple/\n```\n\n### 下载到本地安装\n\n```shell\npip install --download=\'路径\' -r requirements.txt\npip install --no-index -f file://\'路径\' -r requirements.txt\n```\n\n## 配置VIM编写python\n\n\n\n```shell\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\"    Quickly Run   \"\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nmap <F5>:call CompileRunGcc()<CR>\nfunc! CompileRunGcc()\n    exec \"w\"\n    if &filetype == \'c\'\n        exec \"!g++ % -o %<\"\n        exec \"!time ./%<\"\n```\n\n","timestamp":1541470330295},{"name":"2-使用python编写脚本.md","path":"01-Linux运维/05-Python&Linux/2-使用python编写脚本.md","content":"# Python编写脚本\n\n> shell中我们可以根据自己的需要去编写脚本，shell中提供了很多常用的方法，比如`$1`,`$?`等等，\n\n","timestamp":1541470330295},{"name":"01-Docker介绍.md","path":"01-Linux运维/06-容器云/01-Docker基础使用/01-Docker介绍.md","content":"# Docker\n\n> Docker是Docker.Inc公司开源的一个基于LXC技术之上构建的Container容器引擎，源代码托管在github上，基于Go语言并遵循Apache2.0协议开源。\n>\n> Docker是通过内核虚拟化技术（namespaces以及cgroups等）来提供容器的资源隔离与安全保证等。由于Docker通过系统层的虚拟化实现隔离，所以Docker容器在运行的时候不需要类似虚拟机额外的操作系统的开销（经验来看一般一个完整的系统大概会消耗一个物理主机6%左右的性能），提高资源利用率。\n\n**docker的核心理念**\n\n- 构建（Build）\n- 运输（Ship）\n- 运行（Run）\n\n## Docker介绍\n\n### 容器VS虚拟化\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-11/23003726.jpg)\n\n虚拟机是完整的资源隔离。容器是隔离不是虚拟，它不需要虚拟出来操作系统环境。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-11/3645079.jpg)\n\n### Docker可以做什么\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-11/87167288.jpg)\n\n1. 简化配置\n2. 代码流水线的管理，让开发，测试生产都跑在同样一个环境，保证开发环境的一致性。\n3. 提高开发效率\n4. 应用的隔离（虚拟机也可以做到）\n5. 整合服务器，通过docker的隔离能力整合多个服务器降低成本。\n6. 调试能力\n7. 多租户环境\n8. 快速部署\n\n### Docker改变了什么？\n\n- 面向产品：产品交付\n- 面向开发：简化环境配置\n- 面向测试：多版本测试\n- 面向运维：环境一致性，可以环境和代码一起发布，回滚的时候也可以做到一起回滚。\n- 面向架构：自动化扩容（微服务）\n\n## Docker的安装\n\n> 最新的安装信息请以官方文档的安装信息为准，[官方Doc文档地址](https://docs.docker.com/install/linux/docker-ce/centos/#set-up-the-repository)\n\n以下是一个简单的安装步骤：\n\n```shell\nyum install -y yum-utils device-mapper-persistent-data lvm2\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nyum install docker-ce\nsystemctl start docker\n```\n\n查看docker启动状态：\n\n```shell\n[root@localhost ~]# ps -ef | grep docker\nroot     31551     1  2 00:43 ?        00:00:00 /usr/bin/dockerd\nroot     31555 31551  0 00:43 ?        00:00:00 docker-containerd --config /var/run/docker/containerd/containerd.toml\nroot     31667 31082  0 00:43 pts/0    00:00:00 grep --color=auto docker\n```\n\n拉取docker镜像，这里如果直接拉的话可能会因为网速慢导致拉不下来，因此我们可以配置一下国内的docker镜像源\n\n### 配置国内docker镜像源\n\n> 国内的Docker镜像源有很多可以选择，[参考原文](https://www.cnblogs.com/anliven/p/6218741.html)\n>\n> - [DaoCloud - Docker加速器](https://dashboard.daocloud.io/)\n> - [阿里云 - 开发者平台](https://dev.aliyun.com/)\n> - [微镜像 - 希云cSphere](https://csphere.cn/hub)\n> - [镜像广场 - 时速云](https://hub.tenxcloud.com/)\n> - [灵雀云](https://hub.alauda.cn/)\n> - [网易蜂巢](https://c.163.com/)\n\n这里以阿里云的Docker加速器为例，注册并登陆[阿里云 - 开发者平台](https://dev.aliyun.com/)之后，在首页点击“创建我的容器镜像”，然后就会来到阿里云的服务面板。点击加速器标签。根据提示输入Docker登录时需要使用的密码（后期可更改），用户名就是登录阿里云的用户名。在出现的页面中，可以得到一个专属的镜像加速地址，类似于“[https://1234abcd.mirror.aliyuncs.com](https://1234abcd.mirror.aliyuncs.com/)”。根据页面中的“操作文档”信息，配置自己的Docker加速器。\n\n或者，登录[阿里云 - 容器Hub服务控制台](https://cr.console.aliyun.com/)之后，点击加速器标签，也会出现相应信息。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-11/49585375.jpg)\n\n**其他国内Docker镜像的配置方法**\n\n国内其他Docker加速器配置方法和阿里云的差不多：\n\n- 注册账号，获取专属的镜像加速地址\n- 根据提示和系统类型，升级，并配置Docker，然后重启。\n- 验证操作结果\n\n**手动配置Docker加速器**\n\n配置Docker加速器的本质就是把Docker配置文件中的镜像下载地址由默认的Docker Hub地址变为国内镜像的加速地址。\n\n```shell\n/lib/systemd/system/docker.service\n/etc/systemd/system/docker.service\n\n# 比如centos7中\n将 OPTIONS=--registry-mirror=http://abcd1234.m.daocloud.io加入到docker的配置文件/etc/sysconfig/docker中，然后重启Docker\n```\n\n## Docker镜像\n\n### 镜像搜索\n\n```shell\n# docker有一个docker hub仓库，这个其实和github很相似。仓库中存了很多已经构建好的镜像。\n# 大多数情况我们可以直接下载一个现成的镜像而不需要我们自己构建\nCOMAND:\n\n$ sudo docker search TERM\n\nOPTIONS:\n\n--automated=false     是否仅显示自动创建的镜像  \n--no-trunc=false      是否截断输出  \n-s, --stars=0         仅显示至少有x颗星的镜像  \n\n示例:\n\n[root@maxiaoyu ~]# docker search nginx\nINDEX       NAME                    DESCRIPTION               STARS     OFFICIAL   AUTOMATED\ndocker.io   docker.io/nginx    Official build of Nginx.       7127        [OK]\n```\n\n我这里截取了搜索出结果的第一行，当然如果你实际搜索的话会有很多行的内容的，其中包含了官方的以及各种自制的。\n\n- NAME：镜像名称\n\n\n- DESCRIPTION：也就是镜像的描述，\n\n\n- STARS类似于github里面的stars，表示点赞和热度。\n\n\n- OFFICIAL：指docker标准库, 由docker 官方建立. 用户建立的image则会有userid的prefix.\n\n\n- automated builds ：则是通过代码版本管理网站结合docker hub提供的接口生成的, 例如github, bitbucket, 你需要注册docker hub, 然后使用github或bitbucket的在账户链接到docker hub, 然后就可以选择在github或bitbucket里面的项目自动build docker image, 这样的话只要代码版本管理网站的项目有更新, 就会触发自动创建image.对于的image属于什么版本，下面的“[OK]”就会打在什么地方\n\n### 获取镜像\n\n获取镜像的方式有两种，一种是直接去pull我们刚才用docker search搜索到的镜像：\n\n```shell\n[root@maxiaoyu ~]# docker pull docker.io/nginx   \nUsing default tag: latest\nTrying to pull repository docker.io/library/nginx ... \nlatest: Pulling from docker.io/library/nginx\nbc95e04b23c0: Pull complete \n110767c6efff: Pull complete \nf081e0c4df75: Pull complete \nDigest: sha256:004ac1d5e791e705f12a17c80d7bb1e8f7f01aa7dca7deee6e65a03465392072\n[root@maxiaoyu ~]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\ndocker.io/nginx     latest              1e5ab59102ce        2 weeks ago         108.3 MB\ndocker.io/centos    latest              328edcd84f1b        12 weeks ago        192.5 MB\n```\n\n导入本地的docker包：\n\n```shell\ndocker load --input centos.tar\n或者\ndocker load < nginx.tar\n```\n\n我们也可以通过docker的导出功能将我们pull下来的image导出成一个tar包，生成的tar包会保存在当前的目录：\n\n```shell\ndocker save -o centos.tar centos\n```\n\n使用docker inspect去查看image的内容：\n\n```shell\ndocker inspect docker.io/nginx:latest   \n```\n\n列出当前下载的所有的镜像：\n\n```shell\n[root@localhost ~]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nnginx               latest              ae513a47849c        10 days ago         109MB\ncentos              latest              e934aafc2206        4 weeks ago         199MB\n```\n\n如果我们在docker pull的时候不加额外的参数，那么下载的就是最新的，可以在tag中看到是latest的。但是我们可以指定版本，比如：\n\n```shell\n# 参考示例\ndocker pull centos:v1.0\n```\n\n### 删除镜像\n\n```shell\ndocker rmi 镜像ID，比如：\n[root@maxiaoyu ~]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\ndocker.io/nginx     latest              1e5ab59102ce        2 weeks ago         108.3 MB\ndocker.io/centos    latest              328edcd84f1b        12 weeks ago        192.5 MB\n[root@maxiaoyu ~]# docker rmi 1e5ab59102ce\nUntagged: docker.io/nginx:latest\nUntagged: docker.io/nginx@sha256:004ac1d5e791e705f12a17c80d7bb1e8f7f01aa7dca7deee6e65a03465392072\nDeleted: sha256:1e5ab59102ce46c277eda5ed77affaa4e3b06a59fe209fe0b05200606db3aa7a\nDeleted: sha256:182a54bd28aa918a440f7edd3066ea838825c3d6a08cc73858ba070dc4f27211\nDeleted: sha256:a527b2a06e67cab4b15e0fd831882f9e6a6485c24f3c56f870ac550b81938771\nDeleted: sha256:cec7521cdf36a6d4ad8f2e92e41e3ac1b6fa6e05be07fa53cc84a63503bc5700\n```\n\n实际上是按照image的id去删除的，当然如果你的image属于被其他容器引用的情况下的话是无法删除的。会收到如下的报错信息：\n\n```shell\n[root@maxiaoyu ~]# docker rmi 328edcd84f1b\nError response from daemon: conflict: unable to delete 328edcd84f1b (must be forced) - image is being used by stopped container 1284da16efeb\n```\n\n## Docker容器\n\n### 创建一个容器\n\n```shell\n[root@maxiaoyu ~]# docker run --name myfirstdocker -i -t centos /bin/bash\n[root@2ce82d7a275e /]# uname -a\nLinux 2ce82d7a275e 3.10.0-514.26.2.el7.x86_64 #1 SMP Tue Jul 4 15:04:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n[root@2ce82d7a275e /]# ps aux\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.1  11764  1888 ?        Ss   09:40   0:00 /bin/bash\nroot        14  0.0  0.0  47436  1676 ?        R+   09:44   0:00 ps aux\n```\n\n这样就新建了一个容器，我们也随之会进入到容器的界面。docker容器的启动，即使没有把镜像pull下来，在执行如上的命令的时候依然可以执行，因为docker发现你没有这个镜像的时候会帮你把镜像pull下来。容器的主机名就是容器的container id。接下来看看如上的几个参数都代表什么意思：\n\n- --name:指定这个生成的容器的名字，当然如果不指定的话name也会自动生成，我们指定名字只不过是为了更方便的去管理我们的容器。\n- -i：允许标准输入 ，即确保容器的STDIN是开启的。可以看到，运行命令以后我们进入到了容器中，进程为PID的是/bin/bash，也就是刚才我们指定要运行的命令。因此docker其实是为进程执行隔离作用的，虚拟机是给操作系统做隔离的。\n- -t：开启一个tty伪终端。\n- -d：如果需要容器在后台运行的话，可以加上-d参数。范围值为容器的id\n\n>以上操作其实是经历了这样一个过程：\n>\n>1. 执行上面操作首先会在系统本地去找有没有对应的这样一个image，如果没有的话那么就会去Docker Hub Registry去找，一旦找到以后就回去下载然后保存到本地宿主机器。\n>2. Docker利用这个image创建了一个容器，这个容器拥有自己的网络，ip，以及桥接外部网络的接口。\n>3. 我们告诉这个容器要去执行什么命令（/bin/bash），当然这个命令是可以在容器中指定的，指定容器起来的时候自动执行某个命令，那这里就可以不写了。\n\n当前我们是在容器的内部，通过`ps aux`我们可以得知，pid的大树根并不是init（centos7的树根并不是init），而是我们运行的/bin/bash，如果此时我们使用exit退出容器的话，那么此时的容器就会被关掉，它就完成了它的使命。\n\n```shell\n[root@2ce82d7a275e /]# exit\nexit\n[root@maxiaoyu ~]# docker ps -a\nCONTAINER ID  IMAGE    COMMAND      CREATED         STATUS                   PORTS     NAMES     \n2ce82d7a275e  centos  \"/bin/bash\"  10 minutes ago  Exited (0) 5 seconds ago       myfirstdocker\n```\n\nDocker其实是单进程的，他需要一个进程在前台跑着，因此如果这个程序执行完了，那么整个容器也就退出了，就像我们刚才执行/bin/bash后进入到容器，当exit退出的时候这个进程结束以后整个容器也就跟着一起退出了。所以说不是所有的应用都适合docker。\n\n### 启动并进入一个容器\n\n那么如何启动已经关闭的容器呢？\n\n**方法一**\n\n```\ndocker start docker_name\n\n比如（这样就一直跑起来了）：\n[root@maxiaoyu ~]# docker start myfirstdocker\nmyfirstdocker\n```\n\n**方法二**\n\n```\n[root@maxiaoyu ~]# docker attach myfirstdocker\n[root@2ce82d7a275e /]# \n# 这样就是直接进到容器里面去了，不过exit以后容器还是会停止，因此一般不会去这么操作的\n# 而且多人同时进入到这个容器这个命令显示是同步的。\n```\n\n**方法三**\n\n```shell\n# 生产中建议使用的方法\n[root@maxiaoyu ~]# yum -y install util-linux\n[root@maxiaoyu ~]# docker start mydocker\nmydocker\n# 获取当前的docker的pid，如果获取到的pid=0，说明你这个容器没起来，后面可以接容器id也可以接容器名称。\n[root@maxiaoyu ~]# docker inspect -f \"{{ .State.Pid }}\" mydocker\n13500\n[root@maxiaoyu ~]# nsenter -t 13500 -m -u -i -n -p \n# 使用这种方法进入容器，即使退出的话仍然可以保证容器是开启的，进程并不会结束，docker ps能看到\n[root@1284da16efeb /]# exit\nlogout\n# 那么为什么即使exit出去也不会退出容器呢？\n[root@1284da16efeb /]# ps aux\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.0  11764  1676 ?        Ss+  10:01   0:00 /bin/bash\nroot        26  0.0  0.1  15192  1996 ?        S    10:05   0:00 -bash\nroot        39  0.0  0.0  50868  1816 ?        R+   10:05   0:00 ps aux\n# 主要原因是因为多了一个-bash的进程，因此退出当前的进程这个docker不会退出，因为仍然还有一个/bin/bash的进程正在运行，因此整个容器是并不会退出的。\n```\n\n查看一下nsenter的帮助信息：\n\n```\n[root@maxiaoyu ~]# nsenter --help\n\nUsage:\n nsenter [options] <program> [<argument>...]\n\nRun a program with namespaces of other processes.\n\nOptions:\n -t, --target <pid>     target process to get namespaces from\n -m, --mount[=<file>]   enter mount namespace\n -u, --uts[=<file>]     enter UTS namespace (hostname etc)\n -i, --ipc[=<file>]     enter System V IPC namespace\n -n, --net[=<file>]     enter network namespace\n -p, --pid[=<file>]     enter pid namespace\n -U, --user[=<file>]    enter user namespace\n -S, --setuid <uid>     set uid in entered namespace\n -G, --setgid <gid>     set gid in entered namespace\n     --preserve-credentials do not touch uids or gids\n -r, --root[=<dir>]     set the root directory\n -w, --wd[=<dir>]       set the working directory\n -F, --no-fork          do not fork before exec\'ing <program>\n -Z, --follow-context   set SELinux context according to --target PID\n\n -h, --help     display this help and exit\n -V, --version  output version information and exit\n\nFor more details see nsenter(1).\n```\n\n因此我们可以针对第三种生产中使用的方法去写一个小脚本然后通过批量部署分发后使用：\n\n```shell\n# $1可以是容器的名称，或者容器的id\n[root@maxiaoyu ~]# cat docker_in.sh \n#!/bin/bash\n\n# Use nsenter to access docker \n\ndocker_in (){\n   NAME_ID=$1\n   PID=$(docker inspect -f \"{{ .State.Pid }}\" $NAME_ID)\n   nsenter -t $PID -m -u -i -n -p\n}\n\ndocker_in $1\n[root@maxiaoyu ~]# chmod +x docker_in.sh\n```\n\n**方法四**\n\n```shell\n[root@localhost ~]# docker exec mydocker uptime\n 06:38:47 up  3:51,  0 users,  load average: 0.00, 0.03, 0.05\n```\n\n我不想真的进入容器，但是我还想让这个容器给我执行个命令，就可以使用exec，这个是exec命令的用途本意。不过通过exec也能进入容器，比如：\n\n```shell\n[root@linux-node1 ~]# docker exec -it mydocker /bin/bash\n[root@e95a62d6770f /]# ps aux\nUSER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot          1  0.0  0.0  11768  1676 ?        Ss+  02:28   0:00 /bin/bash\nroot         50  0.5  0.0  11768  1884 ?        Ss   02:41   0:00 /bin/bash\nroot         62  0.0  0.0  47440  1676 ?        R+   02:41   0:00 ps aux\n###有两个/bin/bash，因此这个容器技术退出了仍然还在运行，他退出的是pid=50的/bin/bash\n\n[root@e95a62d6770f /]# exit\nexit\n[root@linux-node1 ~]# docker ps -a\nCONTAINER ID    IMAGE    COMMAND     CREATED         STATUS        PORTS         NAMES\ne95a62d6770f    centos  \"/bin/bash\" 33 minutes ago  Up 12 minutes              mydocker\n78fc36ba1e5a    centos  \"/bin/echo xx\" 39 minutes ago  Exited (0) 39 minutes ago                       compassionate_rosalind\n```\n\n### 删除容器\n\n```shell\ndocker rm 容器id\n```\n\n如果容器在使用的话那是不允许你删除的，不过你可以使用-f强制干掉。当然一般不建议这么做。一般来讲都是先把容器停掉以后再把容器干掉。\n\n运行玩意后直接删除容器\n\n```shell\n## --rm参数可以使得一个容器运行完成以后就直接删除了。下面的内容执行完成以后再docker ps就看不到了\n[root@linux-node1 ~]# docker run --rm centos /bin/echo \"hello lamber\"\nhello lamber\n```\n\n### 停止容器\n\n```shell\ndocker stop 容器ID\n```\n\n\n\n","timestamp":1541470330295},{"name":"02-Docker数据存储和网络访问.md","path":"01-Linux运维/06-容器云/01-Docker基础使用/02-Docker数据存储和网络访问.md","content":"# Docker数据存储&网络访问\n\n## Docker的网络应用\n\n### 通过端口映射的方式访问Docker\n\n我们安装了docker后会多了一个桥接网卡docker0：\n\n```shell\n[root@localhost ~]# ifconfig docker0\ndocker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:baff:fea1:dfa8  prefixlen 64  scopeid 0x20<link>\n        ether 02:42:ba:a1:df:a8  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 10  bytes 1876 (1.8 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n[root@localhost ~]# yum install bridge-utils\n\n[root@localhost ~]# brctl show\nbridge name\tbridge id\t\tSTP enabled\tinterfaces\ndocker0\t\t8000.0242baa1dfa8\tno\t\tveth92ad03f\n```\n\n那么现在启动一个容器并映射端口，端口的映射分为随机映射和指定映射：\n\n- 随机映射\n  - docker run -P\n- 指定映射\n  - -p hostPort:containerPort       # 映射所有ip的指定端口到容器ip的指定端口\n  - -p ip:hostPort:containerPort   # 如果物理机有多个ip地址，我们也可以指定一个ip\n  - -p ip::containerPort   # 映射到指定地址的任意端口\n  - -p hostPort:containerPort:udp # 默认是tcp的，可以指定协议为udp\n  - -p 80:81 -p 443:443 ##同时映射多个端口\n\n#### 随机端口映射\n\n由于之前下载了一个nginx的镜像，那么我们就直接先来启用一个nginx容器：\n\n```shell\n[root@localhost ~]# docker run -d -P --name nginx-test1 nginx\nWARNING: IPv4 forwarding is disabled. Networking will not work.\n0b3299999a96eb216b05f2a5c68f32a2775751a49d240034a2f89305bb7bd236\n\n# 可以看到容器启动，返回了容器的id的，但是报了一个警报说如果不打开ipv4转发的话那么网络将不会有效。那么我们就先把系统的网络转发打开\necho 1 > /proc/sys/net/ipv4/ip_forward\n\n# 查看容器的状态\n[root@localhost ~]# docker ps\nCONTAINER ID IMAGE   COMMAND              CREATED             STATUS              PORTS                   NAMES\n0b3299999a96 nginx \"nginx -g \'daemon of…\"   3 minutes ago       Up 3 minutes        0.0.0.0:32768->80/tcp   nginx-test1\n```\n\n从上面可以看到将nginx容器的80端口映射到了宿主机的32768端口。此时我们就可以通过访问宿主机的32768端口来访问docker了，具体我还可以通过iptables来查看，`iptables -t nat nvL`。可以通过docker logs查看日志：\n\n```shell\n[root@localhost ~]# docker logs nginx-test1\n192.168.56.1 - - [11/May/2018:07:32:23 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36\" \"-\"\n2018/05/11 07:32:24 [error] 5#5: *1 open() \"/usr/share/nginx/html/favicon.ico\" failed (2: No such file or directory), client: 192.168.56.1, server: localhost, request: \"GET /favicon.ico HTTP/1.1\", host: \"192.168.56.101:32768\", referrer: \"http://192.168.56.101:32768/\"\n192.168.56.1 - - [11/May/2018:07:32:24 +0000] \"GET /favicon.ico HTTP/1.1\" 404 572 \"http://192.168.56.101:32768/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36\" \"-\"\n```\n\n随机映射是非常简单的，但是管理起来也不是很方便的，因为我们需要知道每个容器的端口的映射关系，好处就是端口不会重复，启用很方便。\n\n#### 指定映射\n\n```shell\n[root@localhost ~]# docker run -d -p 192.168.56.101:88:80 --name nginx-test2 nginx\n\nf2eccbad48a94111e7844562ce8750584bced374894cd4dad0af7b201eef8ffc\n[root@localhost ~]# curl 192.168.56.101:88 -I\nHTTP/1.1 200 OK\nServer: nginx/1.13.12\nDate: Fri, 11 May 2018 07:45:34 GMT\nContent-Type: text/html\nContent-Length: 612\nLast-Modified: Mon, 09 Apr 2018 16:01:09 GMT\nConnection: keep-alive\nETag: \"5acb8e45-264\"\nAccept-Ranges: bytes\n```\n\n查看容器映射：\n\n```shell\n# -l参数指的是查看最后一个最新创建的容器\n[root@localhost ~]# docker ps -l\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                       NAMES\nf2eccbad48a9        nginx               \"nginx -g \'daemon of…\"   2 minutes ago       Up 2 minutes        192.168.56.101:88->80/tcp   nginx-test2\n```\n\n查看一下iptables的nat规则：\n\n```shell\nChain DOCKER (2 references)\n pkts bytes target     prot opt in     out     source               destination         \n    0     0 RETURN     all  --  docker0 *       0.0.0.0/0            0.0.0.0/0           \n    2   128 DNAT       tcp  --  !docker0 *       0.0.0.0/0            0.0.0.0/0            tcp dpt:32768 to:172.17.0.3:80\n    1    60 DNAT       tcp  --  !docker0 *       0.0.0.0/0            192.168.56.101       tcp dpt:88 to:172.17.0.4:80\n```\n\n经过NAT转换所以对于吞吐量比较大的业务还是多少有一些影响的。\n\n## Docker数据存储\n\n> 生产中不建议直接在docker容器中去写数据，建议使用数据卷或者数据卷容器写入\n\n### 数据卷\n\n> - Docker镜像由多个只读层叠加而成，当启动容器的时候，Docker会加载只读镜像层，并在镜像栈顶部添加一个读写层\n> - 如果运行中的容器修改了现有的一个已经存在的文件，那么该文件将会从读写层下面的只读层复制到读写层，该文件的只读版本仍然存在，只是已经被读写层中该文件的副本所隐藏，此即”写时复制（COW）“机制，鉴于这种问题，层数那么多，在写的方面效率相对较低。\n> - 数据卷使得即使容器脱离它的生命周期，数据仍然存在。\n\n我们新建一个容器，并把物理机的一个区域给它mount到容器中的data目录下，使用-v参数：\n\n```shell\n[root@localhost ~]# docker run -d --name nginx-volume-test1 -v /data nginx\n7cb33525f1027208402a86c95d0deedc4bf592264d113ddb47901d46797daa94\n```\n\n为了方便测试，我们直接去容器内的data目录下新建了一个hehe文件。那么这个文件被映射到物理机的什么地方呢？\n\n```shell\n[root@localhost ~]# docker inspect -f {{.Mounts}} nginx-volume-test1\n[{volume c2316666b28d0875aa66ec90ef511e61c0e044e531d56a54e835789ac9792229 /var/lib/docker/volumes/c2316666b28d0875aa66ec90ef511e61c0e044e531d56a54e835789ac9792229/_data /data local  true }]\n[root@localhost ~]# cd /var/lib/docker/volumes/c2316666b28d0875aa66ec90ef511e61c0e044e531d56a54e835789ac9792229/_data\n[root@localhost _data]# ll\n总用量 0\n-rw-r--r--. 1 root root 0 5月  11 04:14 hehe\n```\n\n另外一种挂载方式，指定我们的映射目录，一个源一个目的：\n\n```shell\n# 源是物理机的，目的是docker容器的。注意对应关系\nmkdir /data/docker-volume-nginx -p\ndocker run -d --name nginx-volume-test2 -v /data/docker-volume-nginx/:/data nginx\n6b739fc4d20f1064abf5c2fb619a394772f445f15636b303b0527bb148bd2818\n\ntouch /data/docker-volume-nginx/hehehe\ndocker_in.sh nginx-volume-test2\n# 进入容器\nroot@6b739fc4d20f:/# ls -l /data/\ntotal 0\n-rw-r--r-- 1 root root 0 Mar 31 08:20 hehehe\n```\n\n但是上面的这种方法在dockerfile中就是不支持的，试想如果这样操作了，那么可移植性就下降了，你要确保移植的位置也有你这个物理机的目录和数据。\n\n其他的几个选项：\n\n```shell\ndocker run -d --name nginx-volume-test2 -v /data/docker-volume-nginx/:/data:ro  只读\n```\n\n挂载文件：\n\n```shell\n[root@linux-node1 ~]# docker run --rm -it -v /root/docker_in.sh:/root/ nginx /bin/bash\nroot@239820f3e6bd:/# ls /root/ -l --color\ntotal 4\n-rwxr-xr-x 1 root root 179 Mar 31 07:48 docker_in.sh\n\n###记得前后文件名要对应\n```\n\n### 数据卷容器\n\n实现数据在多个容器之间共享\n\n```shell\n[root@linux-node1 ~]# docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                               NAMES\n6b739fc4d20f        nginx               \"nginx -g \'daemon off\"   11 minutes ago      Up 11 minutes       80/tcp, 443/tcp                     nginx-volume-test2\n925564d95872        nginx               \"nginx -g \'daemon off\"   20 minutes ago      Up 20 minutes       80/tcp, 443/tcp                     nginx-volumn-test1\ndce2e78b22be        nginx               \"nginx -g \'daemon off\"   36 minutes ago      Up 36 minutes       443/tcp, 192.168.56.11:81->80/tcp   nginx2\n[root@linux-node1 ~]# docker run -it --name volume-test3 --volumes-from nginx-volume-test2 centos /bin/bash\n[root@034018de2dc4 /]# ls /data/\nhehehe\n```\n\n即使把nginx-volume-test2给停掉了仍然不影响volume-test3的访问，因为这个数据卷是mount上去的。而且我们这个时候占用的这个共享卷的时候，这个nginx-volume-test2你是删除不掉的。\n\n**实际应用**\n\n比如创建一个容器挂载数据卷，然后其他容器都共享它的。比如可以用到日志统一管理，多个容器挂载一个日志数据卷，然后用logstash统一收集管理。\n\n```shell\n[root@linux-node1 ~]# docker run -d --name nfs-test -v /data/nfs-data/:/data nginx\n[root@linux-node1 ~]# docker run --rm -it --volumes-from nfs-test centos /bin/bash\n[root@ac637a64910f /]# cd /data/\n[root@ac637a64910f data]# ls -l\ntotal 0\n-rw-r--r-- 1 root root 0 Mar 31 08:41 iamatest\n此时我们在物理机上创建的测试文件就显示出来了。\n```\n\n","timestamp":1541470330295},{"name":"03-手动构建镜像.md","path":"01-Linux运维/06-容器云/01-Docker基础使用/03-手动构建镜像.md","content":"# Docker手动构建\n\n杀死所有正在运行的容器并删除它\n\n```shell\n[root@linux-node1 ~]# docker ps -a -q\n319cc917e421\n00c801224fed\n9af1e1593e1c\n034018de2dc4\n6b739fc4d20f\n925564d95872\ndce2e78b22be\n35e9b3386c8a\ndfff10104bae\ne95a62d6770f\n78fc36ba1e5a\n[root@linux-node1 ~]# docker kill $(docker ps -a -q)\n[root@linux-node1 ~]# docker rm $(docker ps -a -q)\n```\n\n然后我们重新创建一个新的centos的容器，安装nginx：\n\n```shell\n[root@linux-node1 ~]# docker run --name mynginx -it centos \n\n# 进入容器，安装扩展源\n[root@c7426bc61497 /]# rpm -ivh https://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm\n\n# 安装nginx，这里测试用就直接yum了，生产中一般都是编译安装：\n[root@c7426bc61497 /]# yum install -y nginx\n\n# 前面说到容器的运行需要前台进程的支撑，因此如果nginx在后台跑的话这个docker容器是起不来的，因此我们需要对nginx做一些修改，让它在前台运行.\n[root@c7426bc61497 /]# grep -v \'^#\' /etc/nginx/nginx.conf | head -1\ndaemon off;\n配置文件中添加一行deamon off，然后退出容器\n[root@linux-node1 ~]# docker ps -a\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES\nc7426bc61497        centos              \"/bin/bash\"         12 minutes ago      Exited (0) 4 seconds ago                       mynginx\n```\n\n对容器修改完以后接下来我们需要提交，其实这个操作很类似于Git，其中-m指的是comment，就是一个描述，后面跟container id，然后nginx是库名称。\n\n```shell\n[root@linux-node1 ~]# docker commit -m \"My nginx\" c7426bc61497 nginx/mynginx:v1\nsha256:81f1607bb8a07d4874a68e1cffa369707f243e935f381373d8482cde6ee6a6ed\n[root@linux-node1 ~]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED              SIZE\nnginx/mynginx       v1                  81f1607bb8a0        About a minute ago   355 MB\ndocker.io/nginx     latest              5e69fe4b3c31        3 days ago           182.5 MB\ndocker.io/centos    latest              98d35105a391        2 weeks ago          192.5 MB\n```\n\n运行测试：\n\n```shell\n[root@linux-node1 ~]# docker run --name mynginxv1 -d -p 81:80 nginx/mynginx:v1 nginx\n这个名称要写全了，如果不写全的话，它会使用别的版本的最后这一个nginx是执行的命令。\n```\n\n![](http://omk1n04i8.bkt.clouddn.com/17-3-31/84755152-file_1490951666292_e7.jpg)\n\n","timestamp":1541470330295},{"name":"04-DockerFile.md","path":"01-Linux运维/06-容器云/01-Docker基础使用/04-DockerFile.md","content":"# DockerFile\n\n> Dockerfile是为快速构建docker image而设计的，当你使用dockerbuild 命令的时候，docker 会读取当前目录下的命名为Dockerfile(首字母大写)的纯文本文件并执行里面的指令构建出一个docker image。这比SaltStack的配置管理要简单的多，不过还是要掌握一些简单的指令。 Dockerfile 由一行行命令语句组成，并且支持以#开头的注释行。指令是不区分大小写的，但是通常我们都大写。\n\n下面我们通过构建一个Nginx的镜像来学习Dockerfile. 首先实现创建好目录，我这在opt下创建目录dockerfile，然后在dockerfile目录下创建nginx目录，在nginx目录下新建一个Dockerfile文件。Dcockerfile这个文件的首字母要大写，不然有可能不会被识别。\n\n```shell\n[root@linux-node1 ~]# cd /opt/\n[root@linux-node1 opt]# cd dockerfile/\n[root@linux-node1 dockerfile]# cd nginx/\n[root@linux-node1 nginx]# echo \"nginx in Docker ,hahahah\" >index.html\n[root@linux-node1 nginx]# cat Dockerfile \n# This Dockerfile is used to practice \n# Version: 1.0\n# Author: lamber\n\n# Base Image\nFROM centos\n\n# Who will take care of this image\nMAINTAINER lamber 1020561033@qq.com\n\n# Prepare Epel\nRUN rpm -ivh https://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm\n\n# Install Nginx and deal with the config file\nRUN yum -y install nginx && yum clean all\nRUN echo \"daemon off;\" >> /etc/nginx/nginx.conf\nADD index.html /usr/share/nginx/html/index.html\n\n# Run\nEXPOSE 80\nCMD [\"nginx\"]\n```\n\n说明：\n\n- FROM：这个镜像的妈是谁，指定基础镜像，除了注释外的第一行必须是他。如果本地没有这个镜像，它会给你pull下来。\n- MAINTAINER：告诉别人谁负责养他，指定维护者的信息\n- RUN：你想让他干啥，在命令前面加上RUN就可以了。\n- ADD：给它点创业资金，copy文件进去，会自动解压\n- WORKDIR：我是cd，今天刚化了妆（设置当前的工作目录）\n- VOLUME：给它一个存放行李的地方，设置卷，挂载主机目录\n- EXPOSE：它要打开的门是啥，指定对外的端口\n- CMD：奔跑吧，兄弟，指定容器启动后要干的事情，这里双引一下，单引可能出现问题。。。。\n\n构建docker镜像（后面那个点就是在当前目录，意思是告诉docker去哪里找这个dockerfile，一个点就是在当前目录找dockerfile，这个你也可以写绝对路径也是ok的），然后创建容器：\n\n```shell\n[root@linux-node1 nginx]# docker build -t mynginx:v2 .\n[root@linux-node1 nginx]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nmynginx             v2                  5104f2ed9887        5 seconds ago       280.7 MB\nnginx/mynginx       v1                  81f1607bb8a0        32 minutes ago      355 MB\ndocker.io/nginx     latest              5e69fe4b3c31        3 days ago          182.5 MB\ndocker.io/centos    latest              98d35105a391        2 weeks ago         192.5 MB\n[root@linux-node1 nginx]# docker run --name mynginxv2 -d -p 82:80 mynginx:v2 nginx\na1efc632ba6d2412c3bc9fded592ca289c0f6c14dd1832118fc52539a2c1123f\n```\n\n起来以后我们就可以在网页端进行测试了！\n\n## 附录：Dockerfile指令详解\n\n下面我们来分别介绍下上面使用到的命令：\n\n#### FROM\n\n- 格式：FROM `<image>` 或FROM `<image>:<tag>`。\n- 解释：FROM是Dockerfile里的第一条指令（必须是），后面跟有效的镜像名（如果该镜像你的本地仓库没有则会从远程仓库Pull取）。然后后面的其它指令FROM的镜像中执行。\n\n#### MAINTAINER\n\n- 格式：MAINTAINER  `<name>`\n- 解释：指定维护者信息。\n\n#### RUN\n\n格式：RUN `<command>` 或 RUN [\"executable\", \"param1\", \"param2\"]。 解释：运行命令，命令较长使可以使用\\来换行。推荐使用上面数组的格式\n\n#### CMD\n\n```\n格式：\n   CMD [\"executable\",\"param1\",\"param2\"] 使用 exec 执行，推荐方式；\n   CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用；\n   CMD [\"param1\",\"param2\"] 提供给ENTRYPOINT的默认参数；\n```\n\n解释： CMD指定容器启动是执行的命令，每个Dockerfile只能有一条CMD命令，如果指定了多条，只有最后一条会被执行。如果你在启动容器的时候也指定的命令，那么会覆盖Dockerfile构建的镜像里面的CMD命令。\n\n#### ENTRYPOINT\n\n```\n格式：\n   ENTRYPOINT [\"executable\", \"param1\",\"param2\"]\n   ENTRYPOINT command param1 param2（shell中执行）。\n```\n\n解释：和CMD类似都是配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。 每个 Dockerfile 中只能有一个ENTRYPOINT，当指定多个时，只有最后一个起效。ENTRYPOINT没有CMD的可替换特性，也就是你启动容器的时候增加运行的命令不会覆盖ENTRYPOINT指定的命令。\n\n所以生产实践中我们可以同时使用ENTRYPOINT和CMD，例如：\n\n```\nENTRYPOINT [\"/usr/bin/rethinkdb\"]\nCMD [\"--help\"]\n```\n\n#### USER\n\n- 格式：USER daemon\n- 解释：指定运行容器时的用户名和UID，后续的RUN指令也会使用这里指定的用户。\n\n#### EXPOSE\n\n- 格式：EXPOSE `<port> [<port>…]`\n- 解释：设置Docker容器内部暴露的端口号，如果需要外部访问，还需要启动容器时增加-p或者-P参数进行分配。\n\n#### ENV\n\n```\n格式：\nENV <key> <value>\nENV <key>=<value> ...\n```\n\n解释：设置环境变量，可以在RUN之前使用，然后RUN命令时调用，容器启动时这些环境变量都会被指定\n\n#### ADD\n\n```\n格式：\n   ADD <src>... <dest>\n   ADD [\"<src>\",... \"<dest>\"]\n```\n\n解释：将指定的<src>复制到容器文件系统中的<dest> 所有拷贝到container中的文件和文件夹权限为0755,uid和gid为0 如果文件是可识别的压缩格式，则docker会帮忙解压缩\n\n#### VOLUME\n\n- 格式：VOLUME [\"/data\"]\n- 解释：可以将本地文件夹或者其他container的文件夹挂载到container中。\n\n#### WORKDIR\n\n- 格式：WORKDIR/path/to/workdir\n- 解释：切换目录，为后续的RUN、CMD、ENTRYPOINT 指令配置工作目录。\n\n可以多次切换(相当于cd命令)， 也可以使用多个WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。\n\n```\n例如\nWORKDIR /a\nWORKDIR b\nWORKDIR c\nRUN pwd\n则最终路径为 /a/b/c。\n```\n\n#### ONBUILD\n\nONBUILD 指定的命令在构建镜像时并不执行，而是在它的子镜像中执行\n\n#### ARG\n\n- 格式：ARG `<name>[=<default value>]`\n- 解释：ARG指定了一个变量在docker build的时候使用，可以使用--build-arg  `<varname>=<value>`来指定参数的值，不过如果构建的时候不指定就会报错。\n\n参考自运维社区：https://mp.weixin.qq.com/s/A8KSp3zmpL_u9a2aYv8WYw","timestamp":1541470330295},{"name":"01-Docker镜像生产实战.md","path":"01-Linux运维/06-容器云/02-Docker进阶/01-Docker镜像生产实战.md","content":"# Docker镜像生产规划与实战\n\n> 公开的dockerfile：https://github.com/dockerfile\n\n## 分层的设计\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-15/1214172.jpg)\n\n```\nA(系统层)-->B(运行环境层)-->C(应用服务层)\n```\n\n\n\n```\n[root@linux-node1 ~]# mkdir docker\n[root@linux-node1 ~]# cd docker/\n[root@linux-node1 docker]# mkdir system\n[root@linux-node1 docker]# mkdir runtime\n[root@linux-node1 docker]# mkdir app\n[root@linux-node1 docker]# cd system/\n[root@linux-node1 system]# mkdir centos\n[root@linux-node1 system]# mkdir ubuntu\n[root@linux-node1 system]# mkdir centos-ssh\n[root@linux-node1 system]# cd ../runtime/\n[root@linux-node1 runtime]# mkdir php\n[root@linux-node1 runtime]# mkdir java\n[root@linux-node1 runtime]# mkdir python\n[root@linux-node1 runtime]# cd ../app/\n[root@linux-node1 app]# mkdir xxx.api\n[root@linux-node1 app]# mkdir xxx.admin\n[root@linux-node1 docker]# tree .\n.\n├── app\n│   ├── xxx.admin\n│   └── xxx.api\n├── runtime\n│   ├── java\n│   ├── php\n│   └── python\n└── system\n    ├── centos\n    ├── centos-ssh\n    └── ubuntu\n\n```\n## 模拟案例\n### 规划：\nrequirement.txt\n\npip install -r requirement.txt\n\n创建dockerfile然后build镜像\n\n### 构建一个基础的centos镜像\n```\n[root@linux-node1 docker]# cd system/centos\n[root@linux-node1 centos]# pwd\n/root/docker/system/centos\n[root@linux-node1 centos]# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo\n--2017-03-31 18:13:42--  http://mirrors.aliyun.com/repo/epel-7.repo\n正在解析主机 mirrors.aliyun.com (mirrors.aliyun.com)... 115.28.122.210, 112.124.140.210\n正在连接 mirrors.aliyun.com (mirrors.aliyun.com)|115.28.122.210|:80... 已连接。\n已发出 HTTP 请求，正在等待回应... 200 OK\n长度：1084 (1.1K) [application/octet-stream]\n正在保存至: “/etc/yum.repos.d/epel.repo”\n\n100%[====================================================================================>] 1,084       --.-K/s 用时 0s      \n\n2017-03-31 18:13:42 (16.7 MB/s) - 已保存 “/etc/yum.repos.d/epel.repo” [1084/1084])\n\n[root@linux-node1 centos]# cp /etc/yum.repos.d/epel.repo .\n\n```\n\n\n```\n[root@linux-node1 centos]# vim Dockerfile\n# Docker for CentOS\n\nFROM centos\n\nMAINTAINER lamber 1020561033@qq.com\n\n# EPEL\nADD epel.repo /etc/yum.repos.d/\n\n# Base pkg\nRUN yum install -y wget mysql-devel supervisor git redis tree net-tools sudo psmisc && yum clean all\n\n[root@linux-node1 centos]# docker build -t lamber/centos:base .\n[root@linux-node1 centos]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nlamber/centos       base                6a427d784875        6 seconds ago       283.1 MB\nmynginx             v2                  5104f2ed9887        42 minutes ago      280.7 MB\nnginx/mynginx       v1                  81f1607bb8a0        About an hour ago   355 MB\ndocker.io/nginx     latest              5e69fe4b3c31        3 days ago          182.5 MB\ndocker.io/centos    latest              98d35105a391        2 weeks ago         192.5 MB\n\n```\n再创建运行环境的时候就应该from上面我们创建的镜像了：\n\n```\n[root@linux-node1 python]# cat Dockerfile \nFROM lamber/centos:base\n\nMAINTAINER lamber 1020561033@qq.com\n\n# Python env\nRUN yum install -y python-devel python-pip supervisor\n\n# Upgrade pip\nRUN pip install --upgrade pip\n\n\n```\n这里引用的就是上面我们创建好的镜像。\n\n构建docker镜像\n\n```\n[root@linux-node1 python]# docker build -t lamber/python .\n[root@linux-node1 app]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nlamber/python       latest              94747e30d7b4        2 minutes ago       413.3 MB\nlamber/centos       base                6a427d784875        About an hour ago   283.1 MB\nmynginx             v2                  5104f2ed9887        2 hours ago         280.7 MB\nnginx/mynginx       v1                  81f1607bb8a0        2 hours ago         355 MB\ndocker.io/nginx     latest              5e69fe4b3c31        3 days ago          182.5 MB\ndocker.io/centos    latest              98d35105a391        2 weeks ago         192.5 MB\n\n\n```\n## 构建一个带ssh的centos docker镜像\n\n```\n[root@linux-node1 centos-ssh]# pwd\n/root/docker/system/centos-ssh\n[root@linux-node1 centos-ssh]# cat Dockerfile \n# Docker for CentOS\n\nFROM centos\n\nMAINTAINER lamber 1020561033@qq.com\n\n# EPEL\nADD epel.repo /etc/yum.repos.d/\n\n# Base pkg\nRUN yum install -y openssh-clients openssl-devel openssh-server wget mysql-devel supervisor git redis tree net-tools sudo psmisc && yum clean all\n\n# For SSHD\nRUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key\nRUN ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key\nRUN echo \"root:redhat\" | chpasswd\n[root@linux-node1 centos-ssh]# docker build -t lamber/centos-ssh .\n[root@linux-node1 centos-ssh]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nlamber/centos-ssh   latest              41db0593e915        2 minutes ago       284.1 MB\nlamber/python       latest              94747e30d7b4        16 minutes ago      413.3 MB\nlamber/centos       base                6a427d784875        About an hour ago   283.1 MB\nmynginx             v2                  5104f2ed9887        2 hours ago         280.7 MB\nnginx/mynginx       v1                  81f1607bb8a0        3 hours ago         355 MB\ndocker.io/nginx     latest              5e69fe4b3c31        3 days ago          182.5 MB\ndocker.io/centos    latest              98d35105a391        2 weeks ago         192.5 MB\n\n```\n部署环境层：\n\n```\n[root@linux-node1 runtime]# cp -r python/ python-ssh\n[root@linux-node1 runtime]# ll\n总用量 0\ndrwxr-xr-x 2 root root  6 3月  31 18:08 java\ndrwxr-xr-x 2 root root  6 3月  31 18:08 php\ndrwxr-xr-x 2 root root 24 3月  31 19:52 python\ndrwxr-xr-x 2 root root 24 3月  31 22:39 python-ssh\n[root@linux-node1 runtime]# cd python\n[root@linux-node1 python]# cat Dockerfile \nFROM lamber/centos-ssh\n\nMAINTAINER lamber 1020561033@qq.com\n\n# Python env\nRUN yum install -y python-devel python-pip supervisor\n\n# Upgrade pip\nRUN pip install --upgrade pip\n[root@linux-node1 python]# docker build -t lamber/python-ssh .\n[root@linux-node1 python]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nlamber/python-ssh   latest              657b57f25bdd        24 seconds ago      414.3 MB\nlamber/centos-ssh   latest              41db0593e915        2 hours ago         284.1 MB\nlamber/python       latest              94747e30d7b4        2 hours ago         413.3 MB\nlamber/centos       base                6a427d784875        4 hours ago         283.1 MB\nmynginx             v2                  5104f2ed9887        5 hours ago         280.7 MB\nnginx/mynginx       v1                  81f1607bb8a0        5 hours ago         355 MB\ndocker.io/nginx     latest              5e69fe4b3c31        3 days ago          182.5 MB\ndocker.io/centos    latest              98d35105a391        2 weeks ago         192.5 MB\n\n```\n部署应用层：\n\n测试脚本：\n\n```\n[root@linux-node1 shop-api]# pwd\n/root/docker/app/shop-api\n\n[root@linux-node1 shop-api]# cat app.py \nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.route(\'/\')\ndef hello():\n    return \'Hello World!\' \n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", debug=True)\n\n```\n测试脚本在本机进行测试（要首先确保本地跑没问题，然后再封装进docker镜像里面去）：\n\n```\n[root@linux-node1 shop-api]# yum -y install python-pip\n[root@linux-node1 python-ssh]# pip install flask\n[root@linux-node1 shop-api]# python app.py \n * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n * Restarting with stat\n * Debugger is active!\n * Debugger PIN: 248-731-527\n\n起到了5000端口，访问测试\n[root@linux-node1 shop-api]# curl  127.0.0.1:5000 \nHello World!\n```\n创建Dockerfile：\n\n```\n[root@linux-node1 shop-api]# cat Dockerfile \n#Base image\nFROM lamber/python-ssh\n\n#Maintainer\nMAINTAINER lamber 1020561033@qq.com\n\n# Add www user\nRUN useradd -s /sbin/nologin -M www\n\n# ADD file\nADD app.py /opt/app.py\nADD requirements.txt /opt/\nADD supervisord.conf /etc/supervisord.conf\nADD app-supervisor.ini /etc/supervisord.d/\n\n# pip\nRUN /usr/bin/pip2.7 install -r /opt/requirements.txt\n\n# Port\nEXPOSE 22 5000\n\n#CMD\nCMD [\"/usr/bin/supervisord\", \"-c\", \"/etc/supervisord.conf\"]\n##有参数是上面这种写法\n```\n\n创建supervisor的配置文件：\n\n```\n[root@linux-node1 shop-api]# cat app-supervisor.ini \n[program:shop-api]\ncommand=/usr/bin/python2.7 /opt/app.py\nprocess_name=%(program_name)s\nautostart=true\nuser=www\nstdout_logfile=/tmp/app.log\nstderr_logfile=/tmp/app.error\n\n[program:sshd]\ncommand=/usr/sbin/sshd -D\nprocess_name=%(program_name)s\nautostart=true\n\n```\n\n创建依赖文件：\n\n```\n[root@linux-node1 shop-api]# cat requirements.txt \nflask\n\n```\n修改supervisor.conf的配置文件：\n\n```\n[root@linux-node1 shop-api]# cat supervisord.conf | grep nodaemon\nnodaemon=true              ; (start in foreground if true;default false)\n将nodaemon改为true，这样supervisor就在前台运行了，如此创建容器以后就能起来了。\n```\n\n补全文件：\n\n```\n[root@linux-node1 shop-api]# ll\n总用量 24\n-rw-r--r-- 1 root root  172 9月  10 2016 app.py\n-rw-r--r-- 1 root root  257 9月  10 2016 app-supervisor.ini\n-rw-r--r-- 1 root root  433 9月  10 2016 Dockerfile\n-rw-r--r-- 1 root root    6 9月  10 2016 requirements.txt\n-rw-r--r-- 1 root root 7952 9月  10 2016 supervisord.conf\n```\n生成docker镜像：\n\n```\n[root@linux-node1 shop-api]# docker build -t lamber/shop-api .\n[root@linux-node1 shop-api]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nlamber/shop-api     latest              9a9470aa92eb        32 seconds ago      420.3 MB\nlamber/python-ssh   latest              f1c4bcf54bad        19 minutes ago      414.3 MB\nlamber/python       latest              570e81c8e8bf        23 minutes ago      413.3 MB\nlamber/centos-ssh   latest              41db0593e915        3 hours ago         284.1 MB\nlamber/centos       base                6a427d784875        4 hours ago         283.1 MB\nmynginx             v2                  5104f2ed9887        5 hours ago         280.7 MB\nnginx/mynginx       v1                  81f1607bb8a0        6 hours ago         355 MB\ndocker.io/nginx     latest              5e69fe4b3c31        3 days ago          182.5 MB\ndocker.io/centos    latest              98d35105a391        2 weeks ago         192.5 MB\n\n```\n启动镜像容器：\n\n```\n[root@linux-node1 shop-api]# docker run --name shop-api -d -p 88:5000 -p 8022:22 lamber/shop-api\nf38807176f44970632f0156bd02a614c102343749a627a1eb945a6e745c2e95b\n[root@linux-node1 shop-api]# docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                        NAMES\nf38807176f44        lamber/shop-api     \"/usr/bin/supervisord\"   7 seconds ago       Up 6 seconds        0.0.0.0:8022->22/tcp, 0.0.0.0:88->5000/tcp   shop-api\na1efc632ba6d        mynginx:v2          \"nginx\"                  5 hours ago         Up 5 hours          0.0.0.0:82->80/tcp                           mynginxv2\n604ac1c6443a        nginx/mynginx:v1    \"nginx\"                  6 hours ago         Up 6 hours          0.0.0.0:81->80/tcp                           mynginxv1\n\n```\n测试结果：\n\n```\n[root@linux-node1 shop-api]# curl 127.0.0.1:88\nHello World!\n[root@linux-node1 shop-api]# /root/docker_in.sh shop-api\n[root@f38807176f44 /]# ps aux\nUSER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot          1  0.0  0.5 117256 14796 ?        Ss   15:21   0:00 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.con\nroot          7  0.0  0.1  82524  3592 ?        S    15:21   0:00 /usr/sbin/sshd -D\nwww           8  0.0  0.6 119760 17328 ?        S    15:21   0:00 /usr/bin/python2.7 /opt/app.py\nwww          13  0.6  0.6 196036 18052 ?        Sl   15:21   0:02 /usr/bin/python2.7 /opt/app.py\nroot         19  0.0  0.0  15172  1896 ?        S    15:27   0:00 -bash\nroot         32  0.0  0.0  50844  1700 ?        R+   15:27   0:00 ps aux\n\n```\n访问容器的22端口：\n\n密码就是我们在创建centos-ssh时候指定的root：redhat\n\n![](http://omk1n04i8.bkt.clouddn.com/17-3-31/36142994-file_1490974494177_17425.jpg)\n#### 总结\n这就是分层的便利性，生产情况下都是使用supervisor来启动，即使是一个也要用supervisor来启动，python的依赖文件要写好。实际生产过程中，需要在真机上测试好了然后再进行镜像的封装。\n\n```\n[root@linux-node1 docker]# tree\n.\n├── app\n│   ├── shop-api\n│   │   ├── app.py\n│   │   ├── app-supervisor.ini\n│   │   ├── Dockerfile\n│   │   ├── requirements.txt\n│   │   └── supervisord.conf\n│   ├── xxx.admin\n│   └── xxx.api\n├── runtime\n│   ├── java\n│   ├── php\n│   ├── python\n│   │   └── Dockerfile\n│   └── python-ssh\n│       └── Dockerfile\n└── system\n    ├── centos\n    │   ├── Dockerfile\n    │   └── epel.repo\n    ├── centos-ssh\n    │   ├── Dockerfile\n    │   └── epel.repo\n    └── ubuntu\n\n```\n\n### 使用supervisor管理进程\n#### 参考文档\n\n> http://supervisord.org/\n>\n> http://liyangliang.me/posts/2015/06/using-supervisor/\n\n\n\n安装supervisor\n\n```\n[root@linux-node1 ~]# yum install supervisor -y\n[root@linux-node1 ~]# rpm -ql supervisor | head -2\n/etc/logrotate.d/supervisor\n/etc/supervisord.conf\n[root@linux-node1 ~]# tail -2 /etc/supervisord.conf \n[include]\nfiles = supervisord.d/*.ini\n\n```\n\n\n\n\n```\n[program:sshd]\ncommand=/usr/sbin/sshd -D\nprocess_name=%(program_name)s\nautostart=true\n```\n\n\n\n```\n# docker容器统一使用supervisor进行管理，是管理操作标准化起来。\n[root@6dd90ccf92d0 ~]# ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 18:01 ?        00:00:00 /usr/bin/python /usr/bin/supervisord -c /\nroot         7     1  0 18:01 ?        00:00:00 /usr/sbin/sshd -D\nroot         8     7  0 18:02 ?        00:00:00 sshd: root@pts/0\nroot        10     8  0 18:02 pts/0    00:00:00 -bash\nroot        23    10  0 18:03 pts/0    00:00:00 ps -ef\n[root@6dd90ccf92d0 ~]# supervisorctl status\nsshd                             RUNNING   pid 7, uptime 0:01:28\n```\n\n","timestamp":1541470330295},{"name":"02-Docker-registetry.md","path":"01-Linux运维/06-容器云/02-Docker进阶/02-Docker-registetry.md","content":"# Docker-Registry\n\n> DockerFile建议通过git来保存，\n\n\n\n实验环境可以操作的，生产不建议这样去操作的内容：\n\n- 容器停止后就自动删除：docker run —rm centos /bin/echo \"hello world\"\n- 杀死所有正在运行的服务器：docker kill $(docker ps -a -q)\n- 删除所有已经停止的容器：docker rm $(docker ps -a -q)\n- 删除所有未打标签的镜像：docker rmi $(docker images -q -f dangling=true)\n\n\n\n\n\nDocker registry功能比较单一，没有web界面。\n\nNginx + Docker registry 验证https（自签名证书）：\n\n1. 手动创建证书\n\n```shell\n[root@localhost registry]# openssl req -x509 -days 3650 -nodes -newkey rsa:2048 -keyout ./docker-registry.key -out ./docker-registry.crt\nGenerating a 2048 bit RSA private key\n...............................................................+++\n...+++\nwriting new private key to \'./docker-registry.key\'\n-----\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter \'.\', the field will be left blank.\n-----\nCountry Name (2 letter code) [XX]:\nState or Province Name (full name) []:\nLocality Name (eg, city) [Default City]:\nOrganization Name (eg, company) [Default Company Ltd]:\nOrganizational Unit Name (eg, section) []:\nCommon Name (eg, your name or your server\'s hostname) []:reg.unixhot.com\nEmail Address []:\n[root@localhost registry]# ll\n总用量 8\n-rw-r--r--. 1 root root 1289 5月  11 20:39 docker-registry.crt\n-rw-r--r--. 1 root root 1708 5月  11 20:39 docker-registry.key\n```\n\n2. 安装httpd-tools htpasswd实现验证功能\n\n```shell\n# htpasswd是httpd-tools工具集中的工具，因此首先要安装httpd-tools\nyum install -y httpd-tools\n# 创建使用-c参数，加密码不要使用-c，指定用户为demo\n[root@localhost registry]# htpasswd -c /opt/registry/docker-registry.htpasswd demo\nNew password: \nRe-type new password: \nAdding password for user demo\n```\n\n3. nginx proxy https  （有一个现成的镜像），启动一个docker-registry的容器，proxy到这里。\n\n```shell\n# --link可以让容器之间可以互访\ndocker run -d -p 443:443 \\\n--name docker-registry-proxy \\\n-e REGISTRY_HOST=\"docker-registry\" \\\n-e REGISTRY_PORT=\"5000\" \\\n-e SERVER_NAME=\"reg.unixhot.com\" \\\n--link docker-registry:docker-registry \\\n-v /opt/registry/docker-registry.htpasswd:/etc/nginx/.htpasswd:ro \\\n-v /opt/registry:/etc/nginx/ssl:ro \\\ncontainersol/docker-registry-proxy\n```\n\n4. docker 配置使用证书\n\n```shell\n# 在/etc/hosts中针对reg.unixhot.com做域名的映射\n192.168.56.101  reg.unixhot.com\n# 配置docker使用证书，如果说不买证书的话那么所有的需要连接的服务器都要配置这一部分\n# 将自签名证书放到/etc/docker下面\ncd /etc/docker\nmkdir -p certs.d/reg.unixhot.com\ncd certs.d/reg.unixhot.com\ncp /opt/registry/docker-registry.crt ca.crt\n# 检测docker是否可以进行登录\n[root@localhost ~]# docker login reg.unixhot.com\nUsername: demo\nPassword: \nLogin Succeeded\n```\n\n5. 登录，push镜像\n\n```shell\n# Push镜像第一件需要做的事情就是打标签，这个标签是给docker入库我们创建这个registry的时候打的标签\n[root@localhost ~]# docker tag unixhot/centos reg.unixhot.com/unixhot/centos\n# push镜像到仓库\n[root@localhost ~]# docker push reg.unixhot.com/unixhot/centos\nThe push refers to repository [reg.unixhot.com/unixhot/centos]\n1e11f9cfa6aa: Pushed \n43e653f84b79: Pushed \nlatest: digest: sha256:e0bf9b8009fdea481f4546d7139aa3beeabbe799d489843f1c6a61339ef11271 size: 3768\n```\n\n6. 查看，传上去了以后只能通过提供的api进行查看。\n\n```shell\n# 使用docker images也能查看到\n[root@localhost ~]# curl -X GET https://demo:demo@reg.unixhot.com/v2/_catalog -k\n{\"repositories\":[\"unixhot/centos\"]}\n```\n\n\n\n如果是购买的证书的话只需要上述的第二步和第三步以及第五步即可。手动创建和配置docker使用证书就过了。\n\n\n\n```shell\n[root@localhost opt]# mkdir registry\n[root@localhost opt]# cd registry/\n[root@localhost registry]# docker run -d --name docker-registry -v /opt/registry/:/tmp/registry-dev registry:2.2.1\nUnable to find image \'registry:2.2.1\' locally\n2.2.1: Pulling from library/registry\n8387d9ff0016: Pull complete \n3b52deaaf0ed: Pull complete \n4bd501fad6de: Pull complete \na3ed95caeb02: Pull complete \nb1f99b5938be: Pull complete \n82c34c0ec017: Pull complete \n5426c0c1c293: Pull complete \nDigest: sha256:30adb707d1b4d2ad694c38da3ea1e7d303fdbdce2538ab0372afe6f1523ae3c8\nStatus: Downloaded newer image for registry:2.2.1\n4b19999b188ce8ed1a0ea7eab52c36a9a3e17ce78147f24a99d04d39624d9d87\n```\n\n\n\n## 使用Habor构建企业级Docker Registry\n\n>Harbor是一个企业级Registry服务。它对开源的Docker Registry服务进行了扩展，添加了更多企业用户需要的功能。Harbor被设计用于部署一套组织内部使用的私有环境，这个私有Registry服务对于非常关心安全 的组织来说是十分重要的。另外，私有Registry服务可以通过避免从公域网下载镜像而提高企业生产力。这对于没有良好的Internet连接状态，使用Docker Container的用户是一个福音。\n>\n>Harbor是VMware公司最近开源的企业级Docker Registry项目(https://github.com/vmware/harbor) 。其目标是帮助用户迅速搭建一个企业级的Docker registry服务。它提供了管理UI, 基于角色的访问控制(Role Based Access Control)，AD/LDAP集成、以及审计日志(Audit logging) 等企业用户需求的功能，同时还原生支持中文。Harbor的每个组件都是以Docker容器的形式构建的，使用Docker Compose来对它进行部署。\n>\n>Harbor项目使用了go语言开发，WEB框架采用beego。容器应用的开发和运行离不开可靠的镜像管理。从安全和效率等方面考虑，在企业私有环境内部署的Registry服务是非常必要的。\n>\n>Harbor(https://github.com/vmware/harbor)由VMware中国研发团队为企业用户设计的Registry Server开源项目，包括了权限管理(RBAC)、图形管理界面、LDAP/AD集成、审计、自我注册、HA等企业必需的功能，同时针对中国用户的特点，原生支持中文，并计划实现镜像复制(roadmap)等功能。\n>\n>可参考内容：http://www.jiagoumi.com/work/1221.html\n\n### 安装Docker-compose\n\n```shell\n# 安装过程中要用到docker-compose，这个玩意是用python写的，所以用pip来安装\nyum -y install python-pip\npip install docker-compose\n```\n\n由于国内网速的问题这里我下载了harbor的离线包，离线包包含了所需的所有需要在线下载的镜像包，省去了很多麻烦的事情。[官方下载点](https://github.com/vmware/harbor/releases)&[百度云下载点](https://pan.baidu.com/s/1Ndp8Z_SHVD5AQ9J7ir7HYg)【提取码：5n52】\n\n安装过程就异常简单了，我们可以照着[官方文档](https://github.com/vmware/harbor/blob/master/docs/installation_guide.md)直接去操作，官方文档详细的介绍了，我们在安装过程中需要调整的内容。这里其实就是简单的设置一下\n\n### 修改harbor.cfg\n\n这里我只简单的修改了3个配置，具体的配置在官方文档中，有非常详细的介绍，详细到介绍每一个配置项，大家可以根据自己的需要去仔细查看\n\n```shell\n# 修改harbor管理台UI的访问地址，不要用localhost或者127.0.0.1这种本地的地址，因为要对外提供服务\nhostname = reg.unixhot.com\n# 配置访问的方式为https，如果是自己在测试机上搞的话那么可以使用http，但是生产建议务必使用https\nui_url_protocol = https\n# 如果有需要的话修改一下harbor的admin登录密码\nharbor_admin_password = Harbor12345\n```\n\n初始化相关配置文件：\n\n```shell\n./prepare\n```\n\n运行install脚本进行安装部署harbor：\n\n```shell\n# 在线安装的过程太痛苦了，直接clone下来的包docker-compose.yml中不知道为啥，所有registry里面的镜像的tag都是__version__导致下载的时候直接找不到对应的version，不知道是不是只能手动改才行。\n./install.sh\n```\n\n至此为止安装过程就结束了，离线版本包的安装是非常简单的，一步一步的操作即可，管理的话需要使用docker-compose来进行管理。\n\n### 配置SSL\n\n> 这里模拟使用https来进行访问，目前并没有购买证书，因此我们自己只能创建自签名证书来模拟这个环境。关于自签名证书的配置官方也是有教程的，直接按照教程去做就可以了。[跳转链接](https://github.com/vmware/harbor/blob/master/docs/configure_https.md)\n\n具体的说明就不在这里赘述了，要看说明可以看官方文档，这里只是体现命令\n\n```shell\nopenssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 365 -out ca.crt\nopenssl req -newkey rsa:4096 -nodes -sha256 -keyout yourdomain.com.key -out reg.unixhot.com.csr\nopenssl x509 -req -days 365 -in reg.unixhot.com.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out reg.unixhot.com.crt\n```\n\n查看harbor.cfg配置文件中指定的ssl证书的位置：\n\n```shell\n#The path of cert and key files for nginx, they are applied only the protocol is set to https\nssl_cert = /data/cert/server.crt\nssl_cert_key = /data/cert/server.key\n```\n\n由于是默认配置，我也就没改，接下来就是把我们生成的key放到/data/cert/下并且按照配置文件中的重命名为server，注意这里是可以修改的，我图省事没有去动配置文件。\n\n```shell\n[root@localhost ~]# ll /data/cert/\ntotal 8\n-rw-r--r--. 1 root root 1866 May 12 13:22 server.crt\n-rw-r--r--. 1 root root 3272 May 12 13:22 server.key\n```\n\n刷新配置文件：\n\n```shell\n./prepare\ndocker-compose down\n# 启动harbor\ndocker-compose up -d\n```\n\n测试一下：\n\n```shell\n# 这里测试成功以后我们也就可以在网页端访问测试了。\n[root@localhost harbor]# docker login reg.unixhot.com \nUsername (admin): admin\nPassword: \nLogin Succeeded\n```\n\n### Push镜像测试\n\n将server.crt复制到/etc/docker/cert.d/reg.unixhot.com目录下，目录没有自己新建一个：\n\n```shell\n[root@localhost reg.unixhot.com]# pwd\n/etc/docker/certs.d/reg.unixhot.com\n[root@localhost reg.unixhot.com]# ll\ntotal 4\n-rw-r--r--. 1 root root 1866 May 12 14:25 server.crt\n```\n\n在web端Harbor中新建一个项目明为exercise\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-22/97293193.jpg)\n\npush镜像：\n\n```shell\n[root@localhost reg.unixhot.com]# docker login reg.unixhot.com -uadmin -pHarbor12345\nWARNING! Using --password via the CLI is insecure. Use --password-stdin.\nLogin Succeeded\n# 首先记得打标签，docker tag src dst\n# dockerhub域名/项目名/镜像名:TAG\n[root@localhost reg.unixhot.com]# docker tag unixhot/centos reg.unixhot.com/exercise/centos\n[root@localhost reg.unixhot.com]# docker push reg.unixhot.com/exercise/centos\nThe push refers to repository [reg.unixhot.com/exercise/centos]\n1e11f9cfa6aa: Pushed \n43e653f84b79: Pushed \nlatest: digest: sha256:792ead7dcec256fc00102cd0dd505c11b54a906ff2df2c090be972a92976ebc7 size: 741\n```\n\n在网页端查看，就能看到我们的镜像了。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-22/51015014.jpg)\n\n从Harbor把镜像给Pull下来测试：\n\n```shell\n[root@localhost ~]# docker pull reg.unixhot.com/exercise/centos:latest\nlatest: Pulling from exercise/centos\n469cfcc7a4b3: Already exists \n6863d4929975: Pull complete \nDigest: sha256:792ead7dcec256fc00102cd0dd505c11b54a906ff2df2c090be972a92976ebc7\nStatus: Downloaded newer image for reg.unixhot.com/exercise/centos:latest\n```\n\n测试成功。","timestamp":1541470330295},{"name":"01-k8s介绍和环境准备.md","path":"01-Linux运维/06-容器云/03-K8S手动部署/01-k8s介绍和环境准备.md","content":"# k8s介绍和环境准备\n\n> Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。如果你曾经用过Docker容器技术部署容器，那么可以将Docker看成Kubernetes内部使用的低级别组件。Kubernetes不仅仅支持Docker，还支持Rocket，这是另一种容器技术。\n>\n> 参考内容：https://github.com/unixhot/salt-kubernetes\n>\n> 使用Kubernetes可以：\n>\n> - 自动化容器的部署和复制\n> - 随时扩展或收缩容器规模\n> - 将容器组织成组，并且提供容器间的负载均衡\n> - 很容易地升级应用程序容器的新版本\n> - 提供容器弹性，如果容器失效就替换它，等等...\n\n\n\nK8S架构\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/5948708.jpg)\n\n\n\n\n\nK8s物理架构图\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-24/38069438.jpg)\n\n\n\n## 基础环境准备\n\n| FQDN                    | IP地址         | 硬件                |\n| ----------------------- | -------------- | ------------------- |\n| linux-node1.example.com | 192.168.56.101 | 1C，2G内存，50G硬盘 |\n| linux-node2.example.com | 192.168.56.102 | 1C，2G内存，50G硬盘 |\n| linux-node3.example.com | 192.168.56.103 | 1C，2G内存，50G硬盘 |\n\n### 环境准备前提\n\n- 安装Centos7的64位操作系统\n- 基本系统：1核CPU，2G内存，50G硬盘\n  1. 网络选择：使用NAT\n  2. 软件包选择：最小化安装\n  3. 关闭iptables和selinux\n- 设置所有节点的主机名和ip地址，做好本地的主机名解析。\n\n```shell\n# 设置主机名\nhostnamectl set-hostname linux-node1.example.com\n[root@linux-node3 ~]# hostnamectl --static\nlinux-node3.example.com\n[root@linux-node3 ~]# hostnamectl --transient\nlinux-node3.example.com\n[root@linux-node3 ~]# hostname\nlinux-node3.example.com\n\n# 关闭防火墙和selinux\nsystemctl stop firewalld\nsystemctl disable firewalld\nsetenforce 0\nsed \"s/enforcing/disabled/g\" /etc/selinux/config  -i\n\n# 针对hosts做解析\necho -e \"192.168.56.101   linux-node1.example.com\\n192.168.56.102   linux-node2.example.com\\n192.168.56.103   linux-node3.example.com\" >> /etc/hosts\n```\n\n### 安装文件准备\n\n#### 安装Docker\n\n略，可以参照Docker部署这一小节，同时替换掉Docker的源为自己的阿里云加速源，不过说一个小问题，就是启动docker的时候可能会遇到这么一个报错，一般会遇到这个报错是因为你是直接yum安装的，而不是按照官方网站提供的办法安装的，版本不一致。\n\n```\nError starting daemon: SELinux is not supported with the overlay2 graph driver on this kernel. Either boot into a newer kernel or disable selinux in docker (--selinux-enabled=false)\n```\n\n意思是此linux的内核中的SELinux不支持 overlay2 graph driver ，解决方法有两个，要么启动一个新内核，要么就在docker里禁用selinux，--selinux-enabled=false，按照提示说的，我们修改一下参数：\n\n```shell\n[root@linux-node2 ~]# vim /etc/sysconfig/docker\n# /etc/sysconfig/docker\n\n# Modify these options if you want to change the way the docker daemon runs\nOPTIONS=\'--selinux-enabled=false --log-driver=journald --signature-verification=false\'\nif [ -z \"${DOCKER_CERT_PATH}\" ]; then\n    DOCKER_CERT_PATH=/etc/docker\nfi\n```\n\n#### 准备部署目录\n\n```shell\nmkdir -p /opt/kubernetes/{cfg,bin,ssl,log}\n```\n\n#### 准备软件包\n\n```shell\n# 将解压后的所有的内容放到/usr/local/src下面\n[root@linux-node1 ~]# ll /usr/local/src/\ntotal 599096\n-rw-r--r--. 1 root root   6595195 Mar 30  2016 cfssl-certinfo_linux-amd64\n-rw-r--r--. 1 root root   2277873 Mar 30  2016 cfssljson_linux-amd64\n-rw-r--r--. 1 root root  10376657 Mar 30  2016 cfssl_linux-amd64\n-rw-r--r--. 1 root root  17108856 Apr 12 17:35 cni-plugins-amd64-v0.7.1.tgz\n-rw-r--r--. 1 root root  10562874 Mar 30 01:58 etcd-v3.2.18-linux-amd64.tar.gz\n-rw-r--r--. 1 root root   9706487 Jan 24 02:58 flannel-v0.10.0-linux-amd64.tar.gz\n-rw-r--r--. 1 root root  13344537 Apr 13 01:51 kubernetes-client-linux-amd64.tar.gz\n-rw-r--r--. 1 root root 112427817 Apr 13 01:51 kubernetes-node-linux-amd64.tar.gz\n-rw-r--r--. 1 root root 428337777 Apr 13 01:51 kubernetes-server-linux-amd64.tar.gz\n-rw-r--r--. 1 root root   2716855 Apr 13 01:51 kubernetes.tar.gz\n```\n\n如果是生产环境的话可以直接去github上面去直接下载。\n\n```\ngithub的项目：https://github.com/kubernetes/kubernetes\nCHANGE_LOG_1.10：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.10.md\n```\n\n#### 解压和环境变量\n\n```shell\n# 把我们下载下来的包进行解压的操作，然后设置一下我们的环境变量。\ncd /usr/local/src/\ntar zxf kubernetes.tar.gz \ntar zxf kubernetes-client-linux-amd64.tar.gz \ntar zxf kubernetes-node-linux-amd64.tar.gz \ntar zxf kubernetes-server-linux-amd64.tar.gz\n\n# 设置环境变量\nvim /root/.bash_profile\nPATH=$PATH:$HOME/bin:/opt/kubernetes/bin\n# 让环境变量生效\nsource /root/.bash_profile\n```\n\n","timestamp":1541470330295},{"name":"02-CA证书制作.md","path":"01-Linux运维/06-容器云/03-K8S手动部署/02-CA证书制作.md","content":"# CA证书制作\n\n## CA证书创建和分发\n\n> 从1.8开始部署k8s都要使用TLS证书对通信进行加密。\n>\n> CA证书管理（自签名）：\n>\n> - easyrsa\n> - openssl\n> - cfssl（这里选用cfssl是因为cfssl相对简单，使用json文件进行管理）\n\n### 1、安装CFSSL\n\n```shell\n# 如果要下载的话可以去这里下载：http://pkg.cfssl.org/\ncd /usr/local/src\nwget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64\nwget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64\nwget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64\nchmod +x cfssl*\nmv cfssl-certinfo_linux-amd64 /opt/kubernetes/bin/cfssl-certinfo\nmv cfssljson_linux-amd64  /opt/kubernetes/bin/cfssljson\nmv cfssl_linux-amd64  /opt/kubernetes/bin/cfssl\n\n# 复制cfssl命令文件到k8s-node1和k8s-node2节点。如果实际中多个节点，就都需要同步复制。\nscp /opt/kubernetes/bin/cfssl* 192.168.56.102: /opt/kubernetes/bin\nscp /opt/kubernetes/bin/cfssl* 192.168.56.103: /opt/kubernetes/bin\n```\n\n### 2、初始化cfssl\n\n```shell\n# /usr/local/src目录下\nmkdir ssl && cd ssl\ncfssl print-defaults config > config.json\ncfssl print-defaults csr > csr.json\n\n[root@linux-node1 ssl]# ll\ntotal 8\n-rw-r--r--. 1 root root 567 May 13 05:27 config.json\n-rw-r--r--. 1 root root 287 May 13 05:27 csr.json\n```\n\n### 3、创建用来生成CA文件的JSON配置文件\n\n```json\n# /usr/local/src/ssl目录下，配置ca证书的话肯定有很多选项，cfssl的方式是以读取json文件的方式拿到这些选项。\n[root@linux-node1 ssl]# vim ca-config.json\n{\n  \"signing\": {\n    \"default\": {\n      \"expiry\": \"8760h\"\n    },\n    \"profiles\": {\n      \"kubernetes\": {\n        \"usages\": [\n            \"signing\",\n            \"key encipherment\",\n            \"server auth\",\n            \"client auth\"\n        ],\n        \"expiry\": \"8760h\"\n      }\n    }\n  }\n}\n```\n\n### 4、创建用来生成 CA 证书签名请求（CSR）的 JSON 配置文件\n\n```json\n[root@linux-node1 ssl]# vim ca-csr.json\n{\n  \"CN\": \"kubernetes\",\n  \"key\": {\n    \"algo\": \"rsa\",\n    \"size\": 2048\n  },\n  \"names\": [\n    {\n      \"C\": \"CN\",\n      \"ST\": \"BeiJing\",\n      \"L\": \"BeiJing\",\n      \"O\": \"k8s\",\n      \"OU\": \"System\"\n    }\n  ]\n}\n```\n\n### 5、生成CA证书（ca.pem）和密钥（ca-key.pem）\n\n```shell\n[root@ linux-node1 ssl]# cfssl gencert -initca ca-csr.json | cfssljson -bare ca\n[root@ linux-node1 ssl]# ls -l ca*\n-rw-r--r-- 1 root root  290 Mar  4 13:45 ca-config.json\n-rw-r--r-- 1 root root 1001 Mar  4 14:09 ca.csr\n-rw-r--r-- 1 root root  208 Mar  4 13:51 ca-csr.json\n-rw------- 1 root root 1679 Mar  4 14:09 ca-key.pem\n-rw-r--r-- 1 root root 1359 Mar  4 14:09 ca.pem\n```\n\n### 6、分发证书\n\n```shell\n# /usr/local/src/ssl目录下\ncp ca.csr ca.pem ca-key.pem ca-config.json /opt/kubernetes/ssl\n# SCP证书到k8s-node1和k8s-node2节点\nscp ca.csr ca.pem ca-key.pem ca-config.json 192.168.56.102:/opt/kubernetes/ssl \nscp ca.csr ca.pem ca-key.pem ca-config.json 192.168.56.103:/opt/kubernetes/ssl\n```\n\n\n\n","timestamp":1541470330295},{"name":"03-ETCD集群部署.md","path":"01-Linux运维/06-容器云/03-K8S手动部署/03-ETCD集群部署.md","content":"# ETCD集群部署\n\n> etcd集群是整个k8s集群中负责存储的部分，所以这一块要先有。\n>\n> etcd的github地址：https://github.com/coreos/etcd\n\n## 准备etcd的软件包\n\n```shell\n# 首先可以直接去这里去下载\nwget https://github.com/coreos/etcd/releases/download/v3.2.18/etcd-v3.2.18-linux-amd64.tar.gz\n\n# 解压并处理\n[root@linux-node1 src]# tar zxf etcd-v3.2.18-linux-amd64.tar.gz\n[root@linux-node1 src]# cd etcd-v3.2.18-linux-amd64\n[root@linux-node1 etcd-v3.2.18-linux-amd64]# cp etcd etcdctl /opt/kubernetes/bin/\n\n# 分发到其他的两个node节点\n[root@linux-node1 etcd-v3.2.18-linux-amd64]# scp etcd etcdctl 192.168.56.102:/opt/kubernetes/bin/\n[root@linux-node1 etcd-v3.2.18-linux-amd64]# scp etcd etcdctl 192.168.56.103:/opt/kubernetes/bin/\n```\n\n## 创建etcd证书签名请求\n\n```shell\n# 注意这里hosts应该是node1就写node1的ip，node2就写node2的ip，但是这里为了批量通用分发，所以把所有的node节点ip都写上，便于分发。\n[root@linux-node1 ssl]# cat etcd-csr.json \n{\n  \"CN\": \"etcd\",\n  \"hosts\": [\n    \"127.0.0.1\",\n\"192.168.56.101\",\n\"192.168.56.102\",\n\"192.168.56.103\"\n  ],\n  \"key\": {\n    \"algo\": \"rsa\",\n    \"size\": 2048\n  },\n  \"names\": [\n    {\n      \"C\": \"CN\",\n      \"ST\": \"BeiJing\",\n      \"L\": \"BeiJing\",\n      \"O\": \"k8s\",\n      \"OU\": \"System\"\n    }\n  ]\n}\n```\n\n## 生成etcd证书和私钥\n\n```shell\n[root@linux-node1 ssl]# cfssl gencert -ca=/opt/kubernetes/ssl/ca.pem \\\n-ca-key=/opt/kubernetes/ssl/ca-key.pem \\\n-config=/opt/kubernetes/ssl/ca-config.json \\\n-profile=kubernetes etcd-csr.json | cfssljson -bare etcd\n2018/05/13 07:12:23 [INFO] generate received request\n2018/05/13 07:12:23 [INFO] received CSR\n2018/05/13 07:12:23 [INFO] generating key: rsa-2048\n2018/05/13 07:12:24 [INFO] encoded CSR\n2018/05/13 07:12:24 [INFO] signed certificate with serial number 259443634666846653641933831011491882088863744942\n2018/05/13 07:12:24 [WARNING] This certificate lacks a \"hosts\" field. This makes it unsuitable for\nwebsites. For more information see the Baseline Requirements for the Issuance and Management\nof Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);\nspecifically, section 10.2.3 (\"Information Requirements\").\n\n# 查看相关内容\n[root@linux-node1 ssl]# ll etcd*\n-rw-r--r--. 1 root root 1062 May 13 07:12 etcd.csr\n-rw-r--r--. 1 root root  290 May 13 07:09 etcd-csr.json\n-rw-------. 1 root root 1675 May 13 07:12 etcd-key.pem\n-rw-r--r--. 1 root root 1436 May 13 07:12 etcd.pem\n```\n\n## 将证书移动到/opt/kubernetes/ssl目录下\n\n```shell\n# 刚才操作的/usr/local/src/ssl目录下执行操作\ncp etcd*.pem /opt/kubernetes/ssl\nscp etcd*.pem 192.168.56.102:/opt/kubernetes/ssl\nscp etcd*.pem 192.168.56.103:/opt/kubernetes/ssl\n```\n\n## 配置ETCD的配置文件\n\n这里有很多的ip地址，分发到其他主机以后记得修改对应的ip地址，启动以后，会占用2379和2380两个端口，我们以后如果说k8s有什么问题的话排查端口就可以知道哪一个部分出现了问题了。\n\n```shell\n[root@linux-node1 ~]# vim /opt/kubernetes/cfg/etcd.conf\n#[member]\nETCD_NAME=\"etcd-node1\"\nETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\"\n#ETCD_SNAPSHOT_COUNTER=\"10000\"\n#ETCD_HEARTBEAT_INTERVAL=\"100\"\n#ETCD_ELECTION_TIMEOUT=\"1000\"\nETCD_LISTEN_PEER_URLS=\"https://192.168.56.101:2380\"\nETCD_LISTEN_CLIENT_URLS=\"https://192.168.56.101:2379,https://127.0.0.1:2379\"\n#ETCD_MAX_SNAPSHOTS=\"5\"\n#ETCD_MAX_WALS=\"5\"\n#ETCD_CORS=\"\"\n#[cluster]\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"https://192.168.56.101:2380\"\n# if you use different ETCD_NAME (e.g. test),\n# set ETCD_INITIAL_CLUSTER value for this name, i.e. \"test=http://...\"\nETCD_INITIAL_CLUSTER=\"etcd-node1=https://192.168.56.101:2380,etcd-node2=https://192.168.56.102:2380,etcd-node3=https://192.168.56.103:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\nETCD_INITIAL_CLUSTER_TOKEN=\"k8s-etcd-cluster\"\nETCD_ADVERTISE_CLIENT_URLS=\"https://192.168.56.101:2379\"\n#[security]\nCLIENT_CERT_AUTH=\"true\"\nETCD_CA_FILE=\"/opt/kubernetes/ssl/ca.pem\"\nETCD_CERT_FILE=\"/opt/kubernetes/ssl/etcd.pem\"\nETCD_KEY_FILE=\"/opt/kubernetes/ssl/etcd-key.pem\"\nPEER_CLIENT_CERT_AUTH=\"true\"\nETCD_PEER_CA_FILE=\"/opt/kubernetes/ssl/ca.pem\"\nETCD_PEER_CERT_FILE=\"/opt/kubernetes/ssl/etcd.pem\"\nETCD_PEER_KEY_FILE=\"/opt/kubernetes/ssl/etcd-key.pem\"\n```\n\n## 创建ETCD系统服务\n\ncentos7下面和centos6的系统启动管理脚本还是不太一样的，具体内容如下，设置完成以后不要着急启动，因为etcd会检查整个集群的健康状态，现在启动的话会一直卡住，等我们把所有的node节点都部署完成以后然后再进行启动。\n\n```shell\n[root@linux-node1 ~]# vim /etc/systemd/system/etcd.service\n[Unit]\nDescription=Etcd Server\nAfter=network.target\n\n[Service]\nType=simple\nWorkingDirectory=/var/lib/etcd\nEnvironmentFile=-/opt/kubernetes/cfg/etcd.conf\n# set GOMAXPROCS to number of processors\nExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /opt/kubernetes/bin/etcd\"\nType=notify\n\n[Install]\nWantedBy=multi-user.target\n```\n\n## 重载系统服务\n\n```shell\n[root@linux-node1 ~]# systemctl daemon-reload\n[root@linux-node1 ~]# systemctl enable etcd\n```\n\n将配置文件分发到其他的节点并重载系统服务\n\n```shell\nscp /opt/kubernetes/cfg/etcd.conf 192.168.56.102:/opt/kubernetes/cfg/\nscp /etc/systemd/system/etcd.service 192.168.56.102:/etc/systemd/system/\nscp /opt/kubernetes/cfg/etcd.conf 192.168.56.103:/opt/kubernetes/cfg/\nscp /etc/systemd/system/etcd.service 192.168.56.103:/etc/systemd/system/\n```\n\n在所有节点上创建etcd存储目录并启动etcd\n\n```shell\n# 注意在执行这一部分之前务必要将其他的节点的etcd的配置文件部分的ip都改掉。\nmkdir /var/lib/etcd\nsystemctl start etcd\nsystemctl status etcd\n```\n\n\n\n## 验证集群\n\n```shell\n[root@linux-node1 ~]# etcdctl --endpoints=https://192.168.56.11:2379 \\\n  --ca-file=/opt/kubernetes/ssl/ca.pem \\\n  --cert-file=/opt/kubernetes/ssl/etcd.pem \\\n  --key-file=/opt/kubernetes/ssl/etcd-key.pem cluster-health\nmember 435fb0a8da627a4c is healthy: got healthy result from https://192.168.56.12:2379\nmember 6566e06d7343e1bb is healthy: got healthy result from https://192.168.56.11:2379\nmember ce7b884e428b6c8c is healthy: got healthy result from https://192.168.56.13:2379\ncluster is healthy\n```\n\n\n\n","timestamp":1541470330295},{"name":"04-K8S_master_node部署.md","path":"01-Linux运维/06-容器云/03-K8S手动部署/04-K8S_master_node部署.md","content":"## 1.部署Kubernetes API服务部署\n\n> Kubernetes的master节点除去我们部署好的etcd之外，我们还需要部署API Server，scheduler，controller manager这三个内容。来看一下这几个小内容的基本功能\n>\n> - apiserver提供集群管理的REST API接口，包括认证授权、数据校验以及集群状态变更等\n>   - 只有API Server才直接操作etcd\n>   - 其他模块通过API Server查询或修改数据\n>   - 提供其他模块之间的数据交互和通信的枢纽\n> - scheduler负责分配调度Pod到集群内的node节点\n>   - 监听kube-apiserver，查询还未分配Node的Pod\n>   - 根据调度策略为这些Pod分配节点\n> - controller-manager由一系列的控制器组成，它通过apiserver监控整个 集群的状态，并确保集群处于预期的工作状态\n\n### 0.准备软件包\n```\n[root@linux-node1 ~]# cd /usr/local/src/kubernetes\n[root@linux-node1 kubernetes]# cp server/bin/kube-apiserver /opt/kubernetes/bin/\n[root@linux-node1 kubernetes]# cp server/bin/kube-controller-manager /opt/kubernetes/bin/\n[root@linux-node1 kubernetes]# cp server/bin/kube-scheduler /opt/kubernetes/bin/\n```\n\n### 1.创建生成CSR的 JSON 配置文件\n```\n[root@linux-node1 src]# vim kubernetes-csr.json\n{\n  \"CN\": \"kubernetes\",\n  \"hosts\": [\n    \"127.0.0.1\",\n    \"192.168.56.11\",\n    \"10.1.0.1\", # 这个ip是干嘛的？\n    \"kubernetes\",\n    \"kubernetes.default\",\n    \"kubernetes.default.svc\",\n    \"kubernetes.default.svc.cluster\",\n    \"kubernetes.default.svc.cluster.local\"\n  ],\n  \"key\": {\n    \"algo\": \"rsa\",\n    \"size\": 2048\n  },\n  \"names\": [\n    {\n      \"C\": \"CN\",\n      \"ST\": \"BeiJing\",\n      \"L\": \"BeiJing\",\n      \"O\": \"k8s\",\n      \"OU\": \"System\"\n    }\n  ]\n}\n```\n\n### 2.生成 kubernetes 证书和私钥\n```\n [root@linux-node1 src]# cfssl gencert -ca=/opt/kubernetes/ssl/ca.pem \\\n   -ca-key=/opt/kubernetes/ssl/ca-key.pem \\\n   -config=/opt/kubernetes/ssl/ca-config.json \\\n   -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes\n[root@linux-node1 src]# cp kubernetes*.pem /opt/kubernetes/ssl/\n[root@linux-node1 ~]# scp kubernetes*.pem 192.168.56.12:/opt/kubernetes/ssl/\n[root@linux-node1 ~]# scp kubernetes*.pem 192.168.56.13:/opt/kubernetes/ssl/\n```\n\n### 3.创建 kube-apiserver 使用的客户端 token 文件\n```\n[root@linux-node1 ~]#  head -c 16 /dev/urandom | od -An -t x | tr -d \' \'\nad6d5bb607a186796d8861557df0d17f \n[root@linux-node1 ~]# vim /opt/kubernetes/ssl/bootstrap-token.csv\nad6d5bb607a186796d8861557df0d17f,kubelet-bootstrap,10001,\"system:kubelet-bootstrap\"\n```\n\n### 4.创建基础用户名/密码认证配置\n```\n[root@linux-node1 ~]# vim /opt/kubernetes/ssl/basic-auth.csv\nadmin,admin,1\nreadonly,readonly,2\n```\n\n### 5.部署Kubernetes API Server\n```\n[root@linux-node1 ~]# vim /usr/lib/systemd/system/kube-apiserver.service\n[Unit]\nDescription=Kubernetes API Server\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=network.target\n\n[Service]\nExecStart=/opt/kubernetes/bin/kube-apiserver \\\n  --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota,NodeRestriction \\\n  --bind-address=192.168.56.11 \\\n  --insecure-bind-address=127.0.0.1 \\\n  --authorization-mode=Node,RBAC \\\n  --runtime-config=rbac.authorization.k8s.io/v1 \\\n  --kubelet-https=true \\\n  --anonymous-auth=false \\\n  --basic-auth-file=/opt/kubernetes/ssl/basic-auth.csv \\\n  --enable-bootstrap-token-auth \\\n  --token-auth-file=/opt/kubernetes/ssl/bootstrap-token.csv \\\n  --service-cluster-ip-range=10.1.0.0/16 \\\n  --service-node-port-range=20000-40000 \\\n  --tls-cert-file=/opt/kubernetes/ssl/kubernetes.pem \\\n  --tls-private-key-file=/opt/kubernetes/ssl/kubernetes-key.pem \\\n  --client-ca-file=/opt/kubernetes/ssl/ca.pem \\\n  --service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\\n  --etcd-cafile=/opt/kubernetes/ssl/ca.pem \\\n  --etcd-certfile=/opt/kubernetes/ssl/kubernetes.pem \\\n  --etcd-keyfile=/opt/kubernetes/ssl/kubernetes-key.pem \\\n  --etcd-servers=https://192.168.56.11:2379,https://192.168.56.12:2379,https://192.168.56.13:2379 \\\n  --enable-swagger-ui=true \\\n  --allow-privileged=true \\\n  --audit-log-maxage=30 \\\n  --audit-log-maxbackup=3 \\\n  --audit-log-maxsize=100 \\\n  --audit-log-path=/opt/kubernetes/log/api-audit.log \\\n  --event-ttl=1h \\\n  --v=2 \\\n  --logtostderr=false \\\n  --log-dir=/opt/kubernetes/log\nRestart=on-failure\nRestartSec=5\nType=notify\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n### 6.启动API Server服务\n```shell\n# 如果服务压根没起来要去/var/log/messages下去查看错误日志。\n# kube-api监控6443端口，本地127.0.0.1监听8080端口是给scheduler，controller-manager使用的。别人要想访问的话就必须通过6443，就必须做验证。\n\nsystemctl daemon-reload\nsystemctl enable kube-apiserver\nsystemctl start kube-apiserver\n```\n\n查看API Server服务状态\n```\n[root@linux-node1 ~]# systemctl status kube-apiserver\n```\n\n## 部署Controller Manager服务\n```\n[root@linux-node1 ~]# vim /usr/lib/systemd/system/kube-controller-manager.service\n[Unit]\nDescription=Kubernetes Controller Manager\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\n\n[Service]\nExecStart=/opt/kubernetes/bin/kube-controller-manager \\\n  --address=127.0.0.1 \\\n  --master=http://127.0.0.1:8080 \\\n  --allocate-node-cidrs=true \\\n  --service-cluster-ip-range=10.1.0.0/16 \\\n  --cluster-cidr=10.2.0.0/16 \\\n  --cluster-name=kubernetes \\\n  --cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\\n  --cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\\n  --service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\\n  --root-ca-file=/opt/kubernetes/ssl/ca.pem \\\n  --leader-elect=true \\\n  --v=2 \\\n  --logtostderr=false \\\n  --log-dir=/opt/kubernetes/log\n\nRestart=on-failure\nRestartSec=5\n\n[Install]\nWantedBy=multi-user.target\n```\n\n### 3.启动Controller Manager\n```\n# 监听本地的10252端口(127.0.0.1)\n[root@linux-node1 ~]# systemctl daemon-reload\n[root@linux-node1 scripts]# systemctl enable kube-controller-manager\n[root@linux-node1 scripts]# systemctl start kube-controller-manager\n```\n\n## 4.查看服务状态\n```\n[root@linux-node1 scripts]# systemctl status kube-controller-manager\n```\n\n## 部署Kubernetes Scheduler\n```\n[root@linux-node1 ~]# vim /usr/lib/systemd/system/kube-scheduler.service\n[Unit]\nDescription=Kubernetes Scheduler\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\n\n[Service]\nExecStart=/opt/kubernetes/bin/kube-scheduler \\\n  --address=127.0.0.1 \\\n  --master=http://127.0.0.1:8080 \\\n  --leader-elect=true \\\n  --v=2 \\\n  --logtostderr=false \\\n  --log-dir=/opt/kubernetes/log\n\nRestart=on-failure\nRestartSec=5\n\n[Install]\nWantedBy=multi-user.target\n```\n\n### 2.部署服务\n```\n# \n[root@linux-node1 ~]# systemctl daemon-reload\n[root@linux-node1 scripts]# systemctl enable kube-scheduler\n[root@linux-node1 scripts]# systemctl start kube-scheduler\n[root@linux-node1 scripts]# systemctl status kube-scheduler\n```\n\n## 部署kubectl 命令行工具\n\n1.准备二进制命令包\n```\n[root@linux-node1 ~]# cd /usr/local/src/kubernetes/client/bin\n[root@linux-node1 bin]# cp kubectl /opt/kubernetes/bin/\n```\n\n2.创建 admin 证书签名请求\n```\n[root@linux-node1 ~]# cd /usr/local/src/ssl/\n[root@linux-node1 ssl]# vim admin-csr.json\n{\n  \"CN\": \"admin\",\n  \"hosts\": [],\n  \"key\": {\n    \"algo\": \"rsa\",\n    \"size\": 2048\n  },\n  \"names\": [\n    {\n      \"C\": \"CN\",\n      \"ST\": \"BeiJing\",\n      \"L\": \"BeiJing\",\n      \"O\": \"system:masters\",\n      \"OU\": \"System\"\n    }\n  ]\n}\n```\n\n3.生成 admin 证书和私钥：\n```shell\n[root@linux-node1 ssl]# cfssl gencert -ca=/opt/kubernetes/ssl/ca.pem \\\n   -ca-key=/opt/kubernetes/ssl/ca-key.pem \\\n   -config=/opt/kubernetes/ssl/ca-config.json \\\n   -profile=kubernetes admin-csr.json | cfssljson -bare admin\n[root@linux-node1 ssl]# ls -l admin*\n-rw-r--r-- 1 root root 1009 Mar  5 12:29 admin.csr\n-rw-r--r-- 1 root root  229 Mar  5 12:28 admin-csr.json\n-rw------- 1 root root 1675 Mar  5 12:29 admin-key.pem\n-rw-r--r-- 1 root root 1399 Mar  5 12:29 admin.pem\n\n[root@linux-node1 src]# cp admin*.pem /opt/kubernetes/ssl/\n```\n\n4.设置集群参数\n```shell\n[root@linux-node1 src]# kubectl config set-cluster kubernetes \\\n   --certificate-authority=/opt/kubernetes/ssl/ca.pem \\\n   --embed-certs=true \\\n   --server=https://192.168.56.11:6443\nCluster \"kubernetes\" set.\n```\n\n5.设置客户端认证参数\n```\n[root@linux-node1 src]# kubectl config set-credentials admin \\\n   --client-certificate=/opt/kubernetes/ssl/admin.pem \\\n   --embed-certs=true \\\n   --client-key=/opt/kubernetes/ssl/admin-key.pem\nUser \"admin\" set.\n```\n\n6.设置上下文参数\n```\n[root@linux-node1 src]# kubectl config set-context kubernetes \\\n   --cluster=kubernetes \\\n   --user=admin\nContext \"kubernetes\" created.\n```\n\n7.设置默认上下文\n```\n[root@linux-node1 src]# kubectl config use-context kubernetes\nSwitched to context \"kubernetes\".\n```\n\n做完了上面这一堆的配置以后其实是在家目录下的.kube目录下生成一个config文件，可以卡一下，kubectl就是通过这个文件来和kubeapiserver进行通信的。\n\n```shell\n[root@linux-node1 .kube]# ll config \n-rw------- 1 root root 6261 May 30 06:12 config\n[root@linux-node1 .kube]# pwd\n/root/.kube\n```\n\n8.使用kubectl工具\n\n```\n[root@linux-node1 ~]# kubectl get cs\nNAME                 STATUS    MESSAGE             ERROR\ncontroller-manager   Healthy   ok                  \nscheduler            Healthy   ok                  \netcd-1               Healthy   {\"health\":\"true\"}   \netcd-2               Healthy   {\"health\":\"true\"}   \netcd-0               Healthy   {\"health\":\"true\"}   \n```\n","timestamp":1541470330295},{"name":"05-Node节点部署.md","path":"01-Linux运维/06-容器云/03-K8S手动部署/05-Node节点部署.md","content":"## 部署kubelet\n\n1.二进制包准备\n将软件包从linux-node1复制到linux-node2中去。\n```\n[root@linux-node1 ~]# cd /usr/local/src/kubernetes/server/bin/\n[root@linux-node1 bin]# cp kubelet kube-proxy /opt/kubernetes/bin/\n[root@linux-node1 bin]# scp kubelet kube-proxy 192.168.56.12:/opt/kubernetes/bin/\n[root@linux-node1 bin]# scp kubelet kube-proxy 192.168.56.13:/opt/kubernetes/bin/\n```\n\n2.创建角色绑定\n```\n[root@linux-node1 ~]# kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap\nclusterrolebinding \"kubelet-bootstrap\" created\n```\n\n3.创建 kubelet bootstrapping kubeconfig 文件\n设置集群参数\n```\n[root@linux-node1 ~]# kubectl config set-cluster kubernetes \\\n   --certificate-authority=/opt/kubernetes/ssl/ca.pem \\\n   --embed-certs=true \\\n   --server=https://192.168.56.11:6443 \\\n   --kubeconfig=bootstrap.kubeconfig\nCluster \"kubernetes\" set.\n```\n\n设置客户端认证参数\n```\n[root@linux-node1 ~]# kubectl config set-credentials kubelet-bootstrap \\\n   --token=ad6d5bb607a186796d8861557df0d17f \\\n   --kubeconfig=bootstrap.kubeconfig   \nUser \"kubelet-bootstrap\" set.\n```\n\n设置上下文参数\n```\n[root@linux-node1 ~]# kubectl config set-context default \\\n   --cluster=kubernetes \\\n   --user=kubelet-bootstrap \\\n   --kubeconfig=bootstrap.kubeconfig\nContext \"default\" created.\n```\n\n选择默认上下文\n```\n[root@linux-node1 ~]# kubectl config use-context default --kubeconfig=bootstrap.kubeconfig\nSwitched to context \"default\".\n\n# 生成bootstrap.kubconfig文件\n[root@linux-node1 kubernetes]# cp bootstrap.kubeconfig /opt/kubernetes/cfg\n[root@linux-node1 kubernetes]# scp bootstrap.kubeconfig 192.168.56.12:/opt/kubernetes/cfg\n[root@linux-node1 kubernetes]# scp bootstrap.kubeconfig 192.168.56.13:/opt/kubernetes/cfg\n```\n\n部署kubelet\n1.设置CNI支持\n```\n[root@linux-node2 ~]# mkdir -p /etc/cni/net.d\n[root@linux-node2 ~]# vim /etc/cni/net.d/10-default.conf\n{\n        \"name\": \"flannel\",\n        \"type\": \"flannel\",\n        \"delegate\": {\n            \"bridge\": \"docker0\",\n            \"isDefaultGateway\": true,\n            \"mtu\": 1400\n        }\n}\n\n\n```\n\n2.创建kubelet目录\n```\n[root@linux-node2 ~]# mkdir /var/lib/kubelet\n```\n\n3.创建kubelet服务配置\n```\n[root@k8s-node2 ~]# vim /usr/lib/systemd/system/kubelet.service\n[Unit]\nDescription=Kubernetes Kubelet\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nWorkingDirectory=/var/lib/kubelet\nExecStart=/opt/kubernetes/bin/kubelet \\\n  --address=192.168.56.12 \\\n  --hostname-override=192.168.56.12 \\\n  --pod-infra-container-image=mirrorgooglecontainers/pause-amd64:3.0 \\\n  --experimental-bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\\n  --kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\\n  --cert-dir=/opt/kubernetes/ssl \\\n  --network-plugin=cni \\\n  --cni-conf-dir=/etc/cni/net.d \\\n  --cni-bin-dir=/opt/kubernetes/bin/cni \\\n  --cluster-dns=10.1.0.2 \\\n  --cluster-domain=cluster.local. \\\n  --hairpin-mode hairpin-veth \\\n  --allow-privileged=true \\\n  --fail-swap-on=false \\\n  --logtostderr=true \\\n  --v=2 \\\n  --logtostderr=false \\\n  --log-dir=/opt/kubernetes/log\nRestart=on-failure\nRestartSec=5\n```\n\n4.启动Kubelet\n```\n[root@linux-node2 ~]# systemctl daemon-reload\n[root@linux-node2 ~]# systemctl enable kubelet\n[root@linux-node2 ~]# systemctl start kubelet\n```\n\n5.查看服务状态\n```\n[root@linux-node2 kubernetes]# systemctl status kubelet\n```\n\n6.查看csr请求\n注意是在linux-node1上执行。\n```\n[root@linux-node1 ~]# kubectl get csr\nNAME                                                   AGE       REQUESTOR           CONDITION\nnode-csr-0_w5F1FM_la_SeGiu3Y5xELRpYUjjT2icIFk9gO9KOU   1m        kubelet-bootstrap   Pending\n```\n\n7.批准kubelet 的 TLS 证书请求\n```\n# 批准以后会多一个kubernetes-client.crt这么一个证书\n[root@linux-node1 ~]# kubectl get csr|grep \'Pending\' | awk \'NR>0{print $1}\'| xargs kubectl certificate approve\n```\n执行完毕后，查看节点状态已经是Ready的状态了\n[root@linux-node1 ssl]#  kubectl get node\nNAME            STATUS    ROLES     AGE       VERSION\n\n## 部署Kubernetes Proxy\n1.配置kube-proxy使用LVS\n```\n[root@linux-node2 ~]# yum install -y ipvsadm ipset conntrack\n```\n\n2.创建 kube-proxy 证书请求\n```\n[root@linux-node1 ~]# cd /usr/local/src/ssl/\n[root@linux-node1 ~]# vim kube-proxy-csr.json\n{\n  \"CN\": \"system:kube-proxy\",\n  \"hosts\": [],\n  \"key\": {\n    \"algo\": \"rsa\",\n    \"size\": 2048\n  },\n  \"names\": [\n    {\n      \"C\": \"CN\",\n      \"ST\": \"BeiJing\",\n      \"L\": \"BeiJing\",\n      \"O\": \"k8s\",\n      \"OU\": \"System\"\n    }\n  ]\n}\n```\n\n3.生成证书\n```\n[root@linux-node1~]# cfssl gencert -ca=/opt/kubernetes/ssl/ca.pem \\\n   -ca-key=/opt/kubernetes/ssl/ca-key.pem \\\n   -config=/opt/kubernetes/ssl/ca-config.json \\\n   -profile=kubernetes  kube-proxy-csr.json | cfssljson -bare kube-proxy\n```\n4.分发证书到所有Node节点\n```\n[root@linux-node1 ssl]# cp kube-proxy*.pem /opt/kubernetes/ssl/\n[root@linux-node1 ssl]# scp kube-proxy*.pem 192.168.56.12:/opt/kubernetes/ssl/\n[root@linux-node1 ssl]# scp kube-proxy*.pem 192.168.56.12:/opt/kubernetes/ssl/\n```\n\n5.创建kube-proxy配置文件\n```\n[root@linux-node2 ~]# kubectl config set-cluster kubernetes \\\n   --certificate-authority=/opt/kubernetes/ssl/ca.pem \\\n   --embed-certs=true \\\n   --server=https://192.168.56.11:6443 \\\n   --kubeconfig=kube-proxy.kubeconfig\nCluster \"kubernetes\" set.\n\n[root@linux-node2 ~]# kubectl config set-credentials kube-proxy \\\n   --client-certificate=/opt/kubernetes/ssl/kube-proxy.pem \\\n   --client-key=/opt/kubernetes/ssl/kube-proxy-key.pem \\\n   --embed-certs=true \\\n   --kubeconfig=kube-proxy.kubeconfig\nUser \"kube-proxy\" set.\n\n[root@linux-node2 ~]# kubectl config set-context default \\\n   --cluster=kubernetes \\\n   --user=kube-proxy \\\n   --kubeconfig=kube-proxy.kubeconfig\nContext \"default\" created.\n\n[root@linux-node2 ~]# kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig\nSwitched to context \"default\".\n```\n6.分发kubeconfig配置文件\n```\n[root@linux-node1 ssl]# cp kube-proxy.kubeconfig /opt/kubernetes/cfg/\n[root@linux-node1 ~]# scp kube-proxy.kubeconfig 192.168.56.12:/opt/kubernetes/cfg/\n[root@linux-node1 ~]# scp kube-proxy.kubeconfig 192.168.56.13:/opt/kubernetes/cfg/\n```\n\n7.创建kube-proxy服务配置\n```\n[root@linux-node2 bin]# mkdir /var/lib/kube-proxy\n\n[root@k8s-node2 ~]# vim /usr/lib/systemd/system/kube-proxy.service\n[Unit]\nDescription=Kubernetes Kube-Proxy Server\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=network.target\n\n[Service]\nWorkingDirectory=/var/lib/kube-proxy\nExecStart=/opt/kubernetes/bin/kube-proxy \\\n  --bind-address=192.168.56.12 \\\n  --hostname-override=192.168.56.12 \\\n  --kubeconfig=/opt/kubernetes/cfg/kube-proxy.kubeconfig \\\n--masquerade-all \\\n  --feature-gates=SupportIPVSProxyMode=true \\\n  --proxy-mode=ipvs \\\n  --ipvs-min-sync-period=5s \\\n  --ipvs-sync-period=5s \\\n  --ipvs-scheduler=rr \\\n  --logtostderr=true \\\n  --v=2 \\\n  --logtostderr=false \\\n  --log-dir=/opt/kubernetes/log\n\nRestart=on-failure\nRestartSec=5\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n8.启动Kubernetes Proxy\n[root@linux-node2 ~]# systemctl daemon-reload\n[root@linux-node2 ~]# systemctl enable kube-proxy\n[root@linux-node2 ~]# systemctl start kube-proxy\n```\n\n9.查看服务状态\n查看kube-proxy服务状态\n```\n[root@linux-node2 scripts]# systemctl status kube-proxy\n\n检查LVS状态\n[root@linux-node2 ~]# ipvsadm -L -n\nIP Virtual Server version 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn\nTCP  10.1.0.1:443 rr persistent 10800\n  -> 192.168.56.11:6443           Masq    1      0          0         \n```\n如果你在两台实验机器都安装了kubelet和proxy服务，使用下面的命令可以检查状态：\n```\n[root@linux-node1 ssl]#  kubectl get node\nNAME            STATUS    ROLES     AGE       VERSION\n192.168.56.12   Ready     <none>    22m       v1.10.1\n192.168.56.13   Ready     <none>    3m        v1.10.1\n```\nlinux-node3节点请自行部署。\n","timestamp":1541470330295},{"name":"06-flannel网络.md","path":"01-Linux运维/06-容器云/03-K8S手动部署/06-flannel网络.md","content":"- Flannel要使用etcd\n- Flannel给每一个node分配出来的ip地址段都不一样。\n\n1.为Flannel生成证书\n\n```\n[root@linux-node1 ~]# vim flanneld-csr.json\n{\n  \"CN\": \"flanneld\",\n  \"hosts\": [],\n  \"key\": {\n    \"algo\": \"rsa\",\n    \"size\": 2048\n  },\n  \"names\": [\n    {\n      \"C\": \"CN\",\n      \"ST\": \"BeiJing\",\n      \"L\": \"BeiJing\",\n      \"O\": \"k8s\",\n      \"OU\": \"System\"\n    }\n  ]\n}\n```\n\n2.生成证书\n```\n[root@linux-node1 ~]# cfssl gencert -ca=/opt/kubernetes/ssl/ca.pem \\\n   -ca-key=/opt/kubernetes/ssl/ca-key.pem \\\n   -config=/opt/kubernetes/ssl/ca-config.json \\\n   -profile=kubernetes flanneld-csr.json | cfssljson -bare flanneld\n```\n3.分发证书\n```\n[root@linux-node1 ~]# cp flanneld*.pem /opt/kubernetes/ssl/\n[root@linux-node1 ~]# scp flanneld*.pem 192.168.56.12:/opt/kubernetes/ssl/\n[root@linux-node1 ~]# scp flanneld*.pem 192.168.56.13:/opt/kubernetes/ssl/\n```\n\n4.下载Flannel软件包\n```\n[root@linux-node1 ~]# cd /usr/local/src\n# wget\n https://github.com/coreos/flannel/releases/download/v0.10.0/flannel-v0.10.0-linux-amd64.tar.gz\n \n[root@linux-node1 src]# tar zxf flannel-v0.10.0-linux-amd64.tar.gz\n[root@linux-node1 src]# cp flanneld mk-docker-opts.sh /opt/kubernetes/bin/\n复制到linux-node2节点\n[root@linux-node1 src]# scp flanneld mk-docker-opts.sh 192.168.56.12:/opt/kubernetes/bin/\n[root@linux-node1 src]# scp flanneld mk-docker-opts.sh 192.168.56.13:/opt/kubernetes/bin/\n复制对应脚本到/opt/kubernetes/bin目录下。\n[root@linux-node1 ~]# cd /usr/local/src/kubernetes/cluster/centos/node/bin/\n[root@linux-node1 bin]# cp remove-docker0.sh /opt/kubernetes/bin/\n[root@linux-node1 bin]# scp remove-docker0.sh 192.168.56.12:/opt/kubernetes/bin/\n[root@linux-node1 bin]# scp remove-docker0.sh 192.168.56.13:/opt/kubernetes/bin/\n```\n\n5.配置Flannel\n```\n[root@linux-node1 ~]# vim /opt/kubernetes/cfg/flannel\nFLANNEL_ETCD=\"-etcd-endpoints=https://192.168.56.11:2379,https://192.168.56.12:2379,https://192.168.56.13:2379\"\nFLANNEL_ETCD_KEY=\"-etcd-prefix=/kubernetes/network\"\nFLANNEL_ETCD_CAFILE=\"--etcd-cafile=/opt/kubernetes/ssl/ca.pem\"\nFLANNEL_ETCD_CERTFILE=\"--etcd-certfile=/opt/kubernetes/ssl/flanneld.pem\"\nFLANNEL_ETCD_KEYFILE=\"--etcd-keyfile=/opt/kubernetes/ssl/flanneld-key.pem\"\n复制配置到其它节点上\n[root@linux-node1 ~]# scp /opt/kubernetes/cfg/flannel 192.168.56.12:/opt/kubernetes/cfg/\n[root@linux-node1 ~]# scp /opt/kubernetes/cfg/flannel 192.168.56.13:/opt/kubernetes/cfg/\n```\n\n6.设置Flannel系统服务\n```\n[root@linux-node1 ~]# vim /usr/lib/systemd/system/flannel.service\n[Unit]\nDescription=Flanneld overlay address etcd agent\nAfter=network.target\nBefore=docker.service\n\n[Service]\nEnvironmentFile=-/opt/kubernetes/cfg/flannel\nExecStartPre=/opt/kubernetes/bin/remove-docker0.sh\nExecStart=/opt/kubernetes/bin/flanneld ${FLANNEL_ETCD} ${FLANNEL_ETCD_KEY} ${FLANNEL_ETCD_CAFILE} ${FLANNEL_ETCD_CERTFILE} ${FLANNEL_ETCD_KEYFILE}\nExecStartPost=/opt/kubernetes/bin/mk-docker-opts.sh -d /run/flannel/docker\n\nType=notify\n\n[Install]\nWantedBy=multi-user.target\nRequiredBy=docker.service\n复制系统服务脚本到其它节点上\n# scp /usr/lib/systemd/system/flannel.service 192.168.56.12:/usr/lib/systemd/system/\n# scp /usr/lib/systemd/system/flannel.service 192.168.56.13:/usr/lib/systemd/system/\n```\n\n## Flannel CNI集成\n下载CNI插件\n```\nhttps://github.com/containernetworking/plugins/releases\nwget https://github.com/containernetworking/plugins/releases/download/v0.7.1/cni-plugins-amd64-v0.7.1.tgz\n[root@linux-node1 ~]# mkdir /opt/kubernetes/bin/cni\n[root@linux-node1 src]# tar zxf cni-plugins-amd64-v0.7.1.tgz -C /opt/kubernetes/bin/cni\n# scp -r /opt/kubernetes/bin/cni/* 192.168.56.12:/opt/kubernetes/bin/cni/\n# scp -r /opt/kubernetes/bin/cni/* 192.168.56.13:/opt/kubernetes/bin/cni/\n```\n创建Etcd的key\n```shell\n# 创建pod的网段是什么，要在etcd配置上，flannel会从etcd来取然后分配\n/opt/kubernetes/bin/etcdctl --ca-file /opt/kubernetes/ssl/ca.pem --cert-file /opt/kubernetes/ssl/flanneld.pem --key-file /opt/kubernetes/ssl/flanneld-key.pem \\\n      --no-sync -C https://192.168.56.11:2379,https://192.168.56.12:2379,https://192.168.56.13:2379 \\\nmk /kubernetes/network/config \'{ \"Network\": \"10.2.0.0/16\", \"Backend\": { \"Type\": \"vxlan\", \"VNI\": 1 }}\' >/dev/null 2>&1\n```\n启动flannel\n```\n[root@linux-node1 ~]# systemctl daemon-reload\n[root@linux-node1 ~]# systemctl enable flannel\n[root@linux-node1 ~]# chmod +x /opt/kubernetes/bin/*\n[root@linux-node1 ~]# systemctl start flannel\n```\n查看服务状态\n```\n[root@linux-node1 ~]# systemctl status flannel\n```\n\n## 配置Docker使用Flannel\n```\n[root@linux-node1 ~]# vim /usr/lib/systemd/system/docker.service\n[Unit] #在Unit下面修改After和增加Requires\nAfter=network-online.target firewalld.service flannel.service\nWants=network-online.target\nRequires=flannel.service\n\n[Service] #增加EnvironmentFile=-/run/flannel/docker\nType=notify\nEnvironmentFile=-/run/flannel/docker\nExecStart=/usr/bin/dockerd $DOCKER_OPTS\n```\n将配置复制到另外两个阶段\n```\n# scp /usr/lib/systemd/system/docker.service 192.168.56.12:/usr/lib/systemd/system/\n# scp /usr/lib/systemd/system/docker.service 192.168.56.13:/usr/lib/systemd/system/\n```\n重启Docker\n```\n[root@linux-node1 ~]# systemctl daemon-reload\n[root@linux-node1 ~]# systemctl restart docker\n```\n\n## 创建第一个K8s应用\n\n1.创建一个测试用的deployment\n\n```\n[root@linux-node1 ~]# kubectl run net-test --image=alpine --replicas=2 sleep 360000\n```\n\n2.查看获取IP情况\n\n```\n[root@linux-node1 ~]# kubectl get pod -o wide\nNAME                        READY     STATUS    RESTARTS   AGE       IP          NODE\nnet-test-5767cb94df-q92md   1/1       Running   0          35s       10.2.40.2   192.168.56.13\nnet-test-5767cb94df-s76nb   1/1       Running   0          35s       10.2.79.2   192.168.56.12\n```\n\n3.测试联通性\n\n```\nping 10.2.40.2\nping 10.2.79.2\n```\n\n书写deployement\n\n```\n[root@linux-node1 ~]# vim nginx-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.10.3\n        ports:\n        - containerPort: 80\n```\n\n创建\n\n```\n[root@linux-node1 ~]# kubectl create -f nginx-deployment.yaml \ndeployment.apps \"nginx-deployment\" created\n\n[root@linux-node1 ~]# kubectl get deployment\nNAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nnet-test           2         2         2            2           6m\nnginx-deployment   3         3         3            0           31s\n```\n\n查看详情：\n\n```\n[root@linux-node1 ~]# kubectl describe deployment nginx-deployment\nName:                   nginx-deployment\nNamespace:              default\nCreationTimestamp:      Wed, 30 May 2018 07:35:06 -0400\nLabels:                 app=nginx\nAnnotations:            deployment.kubernetes.io/revision=1\nSelector:               app=nginx\nReplicas:               3 desired | 3 updated | 3 total | 0 available | 3 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=nginx\n  Containers:\n   nginx:\n    Image:        nginx:1.10.3\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      False   MinimumReplicasUnavailable\n  Progressing    True    ReplicaSetUpdated\nOldReplicaSets:  <none>\nNewReplicaSet:   nginx-deployment-75d56bb955 (3/3 replicas created)\nEvents:\n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  1m    deployment-controller  Scaled up replica set nginx-deployment-75d56bb955 to 3\n```\n\n查看pod\n\n```shel\nkubectl describe pod nginx-deployment-75d56bb955-djxmq\n```\n\n```\n[root@linux-node1 ~]# kubectl get pod\nNAME                                READY     STATUS    RESTARTS   AGE\nnet-test-5767cb94df-q92md           1/1       Running   0          10m\nnet-test-5767cb94df-s76nb           1/1       Running   0          10m\nnginx-deployment-75d56bb955-djxmq   1/1       Running   0          4m\nnginx-deployment-75d56bb955-dm4xs   1/1       Running   0          4m\nnginx-deployment-75d56bb955-l674f   1/1       Running   0          4m\n```\n\n```\n[root@linux-node1 ~]# kubectl get pod -o wide\nNAME                                READY     STATUS    RESTARTS   AGE       IP          NODE\nnet-test-5767cb94df-q92md           1/1       Running   0          11m       10.2.40.2   192.168.56.13\nnet-test-5767cb94df-s76nb           1/1       Running   0          11m       10.2.79.2   192.168.56.12\nnginx-deployment-75d56bb955-djxmq   1/1       Running   0          5m        10.2.40.4   192.168.56.13\nnginx-deployment-75d56bb955-dm4xs   1/1       Running   0          5m        10.2.40.3   192.168.56.13\nnginx-deployment-75d56bb955-l674f   1/1       Running   0          5m        10.2.79.3   192.168.56.12\n\n[root@linux-node1 ~]# curl --head http://10.2.40.4\nHTTP/1.1 200 OK\nServer: nginx/1.10.3\nDate: Wed, 30 May 2018 11:40:55 GMT\nContent-Type: text/html\nContent-Length: 612\nLast-Modified: Tue, 31 Jan 2017 15:01:11 GMT\nConnection: keep-alive\nETag: \"5890a6b7-264\"\nAccept-Ranges: bytes\n```\n\n更新deployment\n\n```shell\n# --record记录历史日志\nkubectl set image deployment/nginx-deployment nginx=nginx:1.12.2 --record\n```\n\n查看更新后的deployment\n\n```shell\nkubectl get deployment -o wide\n```\n\n查看更新历史\n\n```shell\nkubectl rollout history deployment/nginx-deployment\n```\n\n查看具体某一个版本的升级历史\n\n```shell\nkubectl rollout history deployment/nginx-deployment --revision=1\n```\n\n快速回滚到上一个版本\n\n```shell\nkubectl rollout undo deployment/nginx-deployment\n```\n\n在这个过程中会发现过程中每次pod的ip都会发生变化。因此不能去访问pod的ip，要去访问service：\n\n```\n[root@linux-node1 ~]# vim nginx-service.yaml\nkind: Service\napiVersion: v1\nmetadata:\n  name: nginx-service\nspec:\n  selector:\n    app: nginx\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n    \n\n[root@linux-node1 ~]# kubectl create -f nginx-service.yaml \nservice \"nginx-service\" created\n\n\n# 这个拿到的就是vip，可以帮我们做负载均衡。\n# 记住只有node节点，装了kube-proxy的才能访问，比如你的k8s master没装kube-proxy那就不能访问的\n[root@linux-node1 ~]# kubectl get service\nNAME            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE\nkubernetes      ClusterIP   10.1.0.1      <none>        443/TCP   1h\nnginx-service   ClusterIP   10.1.225.31   <none>        80/TCP    29s\n\n# 当前副本是3个，快速扩容到5个\nkubectl scale deployment nginx-deployment --replicas 5\n```\n\n","timestamp":1541470330295},{"name":"07-Dashboard.md","path":"01-Linux运维/06-容器云/03-K8S手动部署/07-Dashboard.md","content":"# Kubernetes Dashboard\n\n## coredns.yaml\n\n```\n[root@linux-node1 ~]# cat coredns.yaml \napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: coredns\n  namespace: kube-system\n  labels:\n      kubernetes.io/cluster-service: \"true\"\n      addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  labels:\n    kubernetes.io/bootstrapping: rbac-defaults\n    addonmanager.kubernetes.io/mode: Reconcile\n  name: system:coredns\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - endpoints\n  - services\n  - pods\n  - namespaces\n  verbs:\n  - list\n  - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  annotations:\n    rbac.authorization.kubernetes.io/autoupdate: \"true\"\n  labels:\n    kubernetes.io/bootstrapping: rbac-defaults\n    addonmanager.kubernetes.io/mode: EnsureExists\n  name: system:coredns\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: system:coredns\nsubjects:\n- kind: ServiceAccount\n  name: coredns\n  namespace: kube-system\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns\n  namespace: kube-system\n  labels:\n      addonmanager.kubernetes.io/mode: EnsureExists\ndata:\n  Corefile: |\n    .:53 {\n        errors\n        health\n        kubernetes cluster.local. in-addr.arpa ip6.arpa {\n            pods insecure\n            upstream\n            fallthrough in-addr.arpa ip6.arpa\n        }\n        prometheus :9153\n        proxy . /etc/resolv.conf\n        cache 30\n    }\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: coredns\n  namespace: kube-system\n  labels:\n    k8s-app: coredns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: \"CoreDNS\"\nspec:\n  replicas: 2\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n  selector:\n    matchLabels:\n      k8s-app: coredns\n  template:\n    metadata:\n      labels:\n        k8s-app: coredns\n    spec:\n      serviceAccountName: coredns\n      tolerations:\n        - key: node-role.kubernetes.io/master\n          effect: NoSchedule\n        - key: \"CriticalAddonsOnly\"\n          operator: \"Exists\"\n      containers:\n      - name: coredns\n        image: coredns/coredns:1.0.6\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        args: [ \"-conf\", \"/etc/coredns/Corefile\" ]\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/coredns\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n      dnsPolicy: Default\n      volumes:\n        - name: config-volume\n          configMap:\n            name: coredns\n            items:\n            - key: Corefile\n              path: Corefile\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: coredns\n  namespace: kube-system\n  labels:\n    k8s-app: coredns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: \"CoreDNS\"\nspec:\n  selector:\n    k8s-app: coredns\n  clusterIP: 10.1.0.2\n  ports:\n  - name: dns\n    port: 53\n    protocol: UDP\n  - name: dns-tcp\n    port: 53\n    protocol: TCP\n```\n\n## 创建CoreDNS\n```\n[root@linux-node1 ~]# kubectl create -f coredns.yaml \n\n[root@linux-node1 ~]# kubectl get pod -n kube-system\nNAME                                    READY     STATUS    RESTARTS   AGE\ncoredns-77c989547b-9pj8b                1/1       Running   0          6m\ncoredns-77c989547b-kncd5                1/1       Running   0          6m\n\n[root@linux-node1 ~]# kubectl get deployment -n kube-system\nNAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\ncoredns   2         2         2            2           2m\n\n[root@linux-node1 ~]# kubectl get service -n kube-system\nNAME      TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE\ncoredns   ClusterIP   10.1.0.2     <none>        53/UDP,53/TCP   3m\n\n# 在有kube-proxy的位置查看转发\n[root@linux-node2 ~]# ipvsadm -Ln\nIP Virtual Server version 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn\nTCP  10.1.0.1:443 rr persistent 10800\n  -> 192.168.56.11:6443           Masq    1      1          0         \nTCP  10.1.0.2:53 rr\n  -> 10.2.40.9:53                 Masq    1      0          0         \n  -> 10.2.79.8:53                 Masq    1      0          0         \nTCP  10.1.225.31:80 rr\n  -> 10.2.40.6:80                 Masq    1      0          0         \n  -> 10.2.40.7:80                 Masq    1      0          0         \n  -> 10.2.40.8:80                 Masq    1      0          0         \n  -> 10.2.79.6:80                 Masq    1      0          0         \n  -> 10.2.79.7:80                 Masq    1      0          0         \nUDP  10.1.0.2:53 rr\n  -> 10.2.40.9:53                 Masq    1      0          0         \n  -> 10.2.79.8:53                 Masq    1      0          0 \n  \n  \n[root@linux-node1 ~]# kubectl get pod -n kube-system       \nNAME                       READY     STATUS    RESTARTS   AGE\ncoredns-77c989547b-54hwk   1/1       Running   0          5m\ncoredns-77c989547b-gf54w   1/1       Running   0          5m\n\n\n# 起容器\n[root@linux-node1 ~]# kubectl run dns-test --rm -it --image=alpine /bin/sh \nIf you don\'t see a command prompt, try pressing enter.\n/ # ping dcgamer.top\nPING dcgamer.top (124.193.0.2): 56 data bytes\n64 bytes from 124.193.0.2: seq=0 ttl=127 time=7.602 ms\n64 bytes from 124.193.0.2: seq=1 ttl=127 time=5.979 ms\n64 bytes from 124.193.0.2: seq=2 ttl=127 time=5.164 ms\n64 bytes from 124.193.0.2: seq=3 ttl=127 time=5.314 ms\n\n# 查看日志\n[root@linux-node1 dashboard]# kubectl get pod -n kube-system\nNAME                                    READY     STATUS              RESTARTS   AGE\ncoredns-77c989547b-54hwk                1/1       Running             0          15m\ncoredns-77c989547b-gf54w                1/1       Running             0          15m\nkubernetes-dashboard-66c9d98865-spkfj   0/1       ContainerCreating   0          12s\n[root@linux-node1 dashboard]# kubectl logs pod/coredns-77c989547b-54hwk -n kube-system\n.:53\nCoreDNS-1.0.6\nlinux/amd64, go1.10, 83b5eadb\n2018/05/30 12:22:51 [INFO] CoreDNS-1.0.6\n2018/05/30 12:22:51 [INFO] linux/amd64, go1.10, 83b5eadb\n```\n\n## 创建Dashboard\n\n```\n[root@linux-node1 dashboard]# ll\ntotal 28\n-rw-r--r-- 1 root root  515 May 17 10:09 admin-token.yaml\n-rw-r--r-- 1 root root  357 May 17 06:26 admin-user-sa-rbac.yaml\n-rw-r--r-- 1 root root  330 May 17 10:07 dashboard-admin.yaml\n-rw-r--r-- 1 root root 4901 May 17 06:26 kubernetes-dashboard.yaml\n-rw-r--r-- 1 root root  458 May 17 06:26 ui-admin-rbac.yaml\n-rw-r--r-- 1 root root  477 May 17 06:26 ui-read-rbac.yaml\n\n[root@linux-node1 dashboard]# kubectl create -f .\nclusterrolebinding.rbac.authorization.k8s.io \"admin\" created\nserviceaccount \"admin\" created\nserviceaccount \"admin-user\" created\nclusterrolebinding.rbac.authorization.k8s.io \"admin-user\" created\nclusterrolebinding.rbac.authorization.k8s.io \"kubernetes-dashboard\" created\nsecret \"kubernetes-dashboard-certs\" created\nserviceaccount \"kubernetes-dashboard\" created\nrole.rbac.authorization.k8s.io \"kubernetes-dashboard-minimal\" created\nrolebinding.rbac.authorization.k8s.io \"kubernetes-dashboard-minimal\" created\ndeployment.apps \"kubernetes-dashboard\" created\nservice \"kubernetes-dashboard\" created\nclusterrole.rbac.authorization.k8s.io \"ui-admin\" created\nrolebinding.rbac.authorization.k8s.io \"ui-admin-binding\" created\nclusterrole.rbac.authorization.k8s.io \"ui-read\" created\nrolebinding.rbac.authorization.k8s.io \"ui-read-binding\" created\n\n\n# 监听了node port。映射到了node节点的25106，记得是node节点的25106，不是master，因为master没有起kube-proxy\n[root@linux-node1 dashboard]# kubectl get service -n kube-system\nNAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE\ncoredns                ClusterIP   10.1.0.2     <none>        53/UDP,53/TCP   18m\nkubernetes-dashboard   NodePort    10.1.13.1    <none>        443:25106/TCP   3m\n\n# 记得访问https的地址\nhttps://192.168.100.12:25106/\n```\n\n```\n[root@linux-node1 ~]# kubectl create -f dashboard/\n```\n\n```\n# 执行这个命令获取令牌，登录仪表盘，输入令牌\nkubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk \'{print $1}\')\n```\n\n","timestamp":1541470330295},{"name":"04-K8S自动化部署.md","path":"01-Linux运维/06-容器云/04-K8S自动化部署.md","content":"","timestamp":1541470330295},{"name":"01-k8s.md","path":"01-Linux运维/06-容器云/05-K8S/01-k8s.md","content":"\n\n\n\n\n\n```\nkubectl get nodes\nget命令是kubectl众多命令中的一个，kubectl是连接api-server的一个客户端程序。是管理入口的客户端工具。\n\ncontroller是一个统称\n```\n\n","timestamp":1541470330295},{"name":"01-01、专业mysql部署.md","path":"01-Linux运维/07-DBA运维/01-Mysql/01-Mysql的部署/01-01、专业mysql部署.md","content":"# 专家级Mysql部署\n\n> 工欲善其事必先利其器，因此在玩转mysql之前一定要进行合理的Mysql的部署和优化，了解其启动原理等，本文针对Mysql的部署做分步骤的阐述和整理。\n\n## 1、软件准备\n\n目前oracle的mysql的最新的版本是mysql5.7.20.我们可以选择这一个版本进行安装，较旧版来说新版本修复了很多的bug信息，下载网站我们可以去mysql的[官方网站](https://dev.mysql.com)去寻找最新的安装包下载。\n\nMysql的安装方式不唯一，可以使用编译好的二进制包，可以使用cmake进行手动编译，亦或是yum，rpm方式的安装都是可以的，这里使用编译好的二进制包的方式进行部署。yum方式不做过多的赘述，如果需要了解cmake安装方式的请到第二篇文章查看。\n\n首先需要做的就是下载一个最新版本的符合自身系统的安装包：\n\n```shell\n[root@maxiaoyu opt]# ls\nmysql-5.7.20-linux-glibc2.12-x86_64.tar.gz\n```\n\n## 2、硬件环境的优化\n\n虚拟机或者云端的就不赘述，如果是物理机的还要在硬件和系统层面进行一些优化，因为机器在默认出厂的时候cpu和内存默认的都是节能模式，因此首要应该做的就是改成高性能模式。\n\n- 关闭numa\n  - [numa的取舍](http://www.cnblogs.com/yjf512/archive/2012/12/10/2811823.html)，可以查看这一篇文章对numa有一个简单的理解，Mysql属于那种既占用CPU又吃内存的应用，因此建议是关闭掉numa\n  - [如何关闭掉numa](http://www.dataguru.cn/thread-462113-1-1.html)，[numa特性禁用](http://www.cnblogs.com/wjoyxt/p/4804081.html).\n    - 硬件层：在bios设置中关闭掉\n    - OS层：在启动的时候设置关闭掉numa\n    - 可以用numactl命令将内存分配策略修改为interleave（交叉）\n\n在OS层我们可以设置启动的时候关闭，直接修改grub.conf文件即可：\n\n```shell\nvim /boot/grub/grub.conf\n```\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-6/63141757.jpg)\n\n- 网络优化&/etc/security/limits.conf \n\n```shell\n[root@maxiaoyu opt]# ulimit -a \ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 7285\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 65535\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 7285\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n\n修改ulimit\n\n```shell\necho -e \'* soft nproc 65535\\n* hard nproc 65535\\n* soft nofile 65535\\n* hard nofile 65535\\n\' >> /etc/security/limits.conf\n```\n\n修改一些内核参数：\n\n```shell\n# 在/etc/sysctl.conf后面添加如下内容\nnet.ipv4.tcp_max_syn_backlog = 819200\nnet.core.netdev_max_backlog = 400000\nnet.core.somaxconn = 4096\nnet.ipv4.tcp_tw_reuse=1\nnet.ipv4.tcp_tw_recycle=0\n# 添加完成以后手动生效\nsysctl -p\n```\n\n同时有一个需要注意的是，如果你的机器是开启的多实例的话建议修改一下`max user processes`这个参数，这个参数我们可以在刚才的ulimit -a中查看到，或者我们可以使用ulimit -u去单独查看这个参数的值，那么这个值代表什么意思呢？\n\n这个ulimit -u是用来限制每个用户的最大processes数量。如果ulimit -u进行了限制那么每个linux用户可以派生出来的process就会被限制再这个数值之内。在mysql多实例的时候就很可能会受到这个参数的影响而导致根本无法链接，具体设置可以参考：http://blog.csdn.net/bbaiggey/article/details/51004817\n\n- Swap优化：直接禁用，现在的数据库独立服务器的配置普遍已经很高了，按照之前的一些说法，swap要分内存的1.5~2倍，如果遇到64gb或者128gb内存的情况下，分1.5~2倍其实是很不理智的一个选择，现在内存大多数情况已经够用，因此swap是可以直接禁用掉的，如果要分的话建议分配不超过4g。\n\n- IO优化：针对不同的盘使用不同的策略可以带来不同的优化效果。\n\n  查看对应的磁盘的IO调度策略可以通过如下的方式查看：\n\n  ```shell\n  [root@DBServer1 ~]# cat /sys/block/sda/queue/scheduler \n  noop anticipatory deadline [cfq]\n  ```\n\n  被括号括起来的就是当前的IO调度策略。那么对于不同的磁盘建议的调度策略如下：\n\n  - SAS：deadline\n  - SSD：noop\n\n- 文件系统：关于数据目录毫不犹豫的使用xfs格式的。\n\n- selinux和iptables：selinux建议禁掉，如果你的mysql完全跑内网，那么iptables可以也不用开\n\n  ​\n\n## 3、Mysql的安装\n\n> 基础环境优化完毕以后，就可以进行Mysql数据库的安装了。当然这里使用的是二进制安装包的方式进行安装，如果你使用rpm安装的话这一切都会自动的为你搞定，因为默认的配置都给你设置好了，缺点就是你没办法进行自定义的调整配置。\n>\n> 当然你也可以把rpm解包，重新做相应的脚本以及再次做rpm包。\n\n### 创建账户\n\n```shell\ngroupadd mysql\nuseradd -g mysql -d /usr/local/mysql -s /sbin/nologin -M mysql\nid mysql\n```\n\n### 软件基本安装\n\n```shell\nmkdir /opt/mysql\ncd /opt/mysql\ntar xf mysql-5.7.20-linux-glibc2.12-x86_64.tar.gz \ncd /usr/local\nln -s /opt/mysql/mysql-5.7.20-linux-glibc2.12-x86_64/ /usr/local/mysql5.7.20\nchown -R mysql.mysql mysql5.7.20/\n```\n\n### 数据目录创建\n\n```shell\ncd /data\nmkdir -p 3330/{data,logs,tmp}\n```\n\n### 配置文件准备\n\n```shell\n# 准备配置文件，你默认的也好，自定义的也好\n[root@maxiaoyu 3330]# pwd\n/data/3330\n[root@maxiaoyu 3330]# ls -l my.cnf\n-rw-r--r-- 1 root root 4014 Nov  6 11:58 my.cnf\n```\n\n### 初始化Mysql\n\n```mysql\n# 5.7的初始化方式\ncd /usr/local/mysql5.7.20/\n./bin/mysqld --defaults-file=/etc/my.cnf --initialize\n\n# 5.6,5.5,5.1的初始化方式\n./script/mysql_db_install\n./bin/mysql_db_install\n```\n\n### 启动\n\n```shell\n# 数据库这里可以设置开启自启，但是一般不建议这么做，如果出问题了，应该先排查问题然后再手动重启。\ncp support-files/mysql.server /etc/init.d/mysql\n/etc/init.d/mysql start\n\n# 设置开机自启的方式（不建议）\nchkconfig add mysql\n\n# 手工启动\n/usr/local/mysql/bin/mysqld --defaults-file=/etc/my.cnf &\n/usr/local/mysql/bin/mysqld_safe --defaults-file=/etc/my.cnf &\n```\n\n### 检查错误日志查看是否正常\n\n启动起来以后还要修改环境变量，是否启动正常从以下几个角度排查\n\n- 起来以后确认进程在不在\n- 确认加载的配置文件对不对？\n- 看错误日志。查看有没有error信息\n\n### 链接数据库\n\n```shell\n# 默认第一次会生成一个随机密码，我们可以在errorlog里看到\ncat /data/mysql/mysql3306/data/error.log | grep password 看密码\nmysql -S /tmp/mysql3306.sock -p\n# 修改密码，这是必要的\n>alter user user() identified by \'new_pass\';\n```\n\n### 关闭数据库\n\n```shell\n# 利用系统脚本关闭\n/etc/init.d/mysql stop\n\n# 利用mysqladmin关闭，加上-h参数甚至可以关闭掉远端的mysql\nmysqladmin -S /tmp/mysql.sock -p shutdown\n\n# 在mysql5.7.19以后多了一个可以在mysql命令行直接打shutdown关闭的命令。\nmysql>shutdown;\n```\n\n## 4、Mysql安装过程中遇到的问题小结\n\n### 4.1、手贱授权错目录咋整\n\n前面提到了要给mysql的目录授权为属主是mysql，用户组也是mysql，假如说授权错误，比如直接授权给了根目录改咋整，这个时候一定不要退出，否则很可能你就再也登不上来了。具体问题可以参考Linux系统权限修复：http://www.cnblogs.com/xdxhg/p/6139818.html\n\n### 4.2、依赖缺失\n\n```shell\n# 查看库的依赖\n[root@DBServer1 ~]# ldd /home/mysql/db9018/bin/mysqld \n        linux-vdso.so.1 =>  (0x00007fffdd7ff000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x0000003c4c800000)\n        librt.so.1 => /lib64/librt.so.1 (0x0000003c4cc00000)\n        libcrypt.so.1 => /lib64/libcrypt.so.1 (0x0000003c5aa00000)\n        libdl.so.2 => /lib64/libdl.so.2 (0x0000003c4c000000)\n        libstdc++.so.6 => /usr/lib64/libstdc++.so.6 (0x0000003c53000000)\n        libm.so.6 => /lib64/libm.so.6 (0x0000003c4d000000)\n        libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x0000003c52400000)\n        libc.so.6 => /lib64/libc.so.6 (0x0000003c4c400000)\n        /lib64/ld-linux-x86-64.so.2 (0x0000003c4bc00000)\n        libfreebl3.so => /lib64/libfreebl3.so (0x0000003c5ae00000)\n```\n\n### 4.3、Selinux没有关闭\n\n```shell\n# 临时关闭\nsetenforce 0 \n# 修改配置文件永久关闭，需重启\n[root@innerManager1 ~]# cat /etc/sysconfig/selinux \n\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\nSELINUX=enforcing\n# SELINUXTYPE= can take one of these two values:\n#     targeted - Targeted processes are protected,\n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted \n\n将SELINUX=enforcing改为disabled即可\n```\n\n### 4.4、文件目录权限不对\n\n```shell\n# 如果出现permission denied的相关错误日志就要考虑一下是不是你的权限分配错误了？\nchown -R mysql.mysql /data/mysql\n```\n\n### 4.5、datadir非空\n\n当datadir不是空的时候，初始化会出现错误，因此确保初始化的时候datadir是空目录。\n\n### 4.6 磁盘空间不够\n\n```shell\ndf -h\n```\n\n### 4.7 初始化参数不对！\n\n参数写错了这个问题其实看似简单但是有时候操作者会有意无意的忽略掉，所以说对待这种问题的时候最好还是看看错误日志，可以立即打醒你。\n\n```shell\ncat /data/mysql/data/error.log | grep ERR\n```\n\n## 5、遇到问题该怎么处理？\n\n- 查看error.log\n\n大部分的日志错误都是可以在error.log中查看到的，直接去监控错误日志即可。\n\n- 把日志打开\n- 启动不起来的话利用mysqld手工启动一下查看\n- 利用strace再现一下启动过程\n\n```shell\n# 我们使用mysqld的方式去手动启动mysql\nstrace /usr/local/mysql/bin/mysqld --defaults-file=/etc/my.cnf\n# strace的结果是很长的，但是我们需要看的内容并不是很多，记住以下的几个用法即可阅读\n- execve相当于调用系统外部命令的一个命令\n- mmap相当于把数据读取到内存里面\n- access是访问一个文件\n- open是打开一个文件\n- fstat查看文件状态\n\nexecve(\"/usr/local/mysql/bin/mysqld\", [\"/usr/local/mysql/bin/mysqld\", \"--defaults-file=/etc/my.cnf\"], [/* 18 vars */]) = 0\nbrk(0)                                  = 0x37bc000\nmmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f45615b7000\naccess(\"/etc/ld.so.preload\", R_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3\nfstat(3, {st_mode=S_IFREG|0644, st_size=79083, ...}) = 0\nmmap(NULL, 79083, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f45615a3000\nclose(3)                                = 0\n# 简单的来看一段，可以发现系统的一开始调用了我们的命令，将对应的内容映射到内存中去，然后访问了对应的so库文件，查看文件状态，映射到内存中，接下来的操作基本都是读取各种库文件       \n```\n\n通过strace还可以看到加载配置文件的过程（如果指定了defaults-file这个参数，只会读取指定的这个配置文件）：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-6/57224031.jpg)\n\n默认的配置文件的读取顺序：\n\n```shell\n[root@maxiaoyu 15:29:19 /root]\n#mysqld --verbose --help | grep my.cnf\n/etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf \n# 可以看到如果没有指定配置文件的位置的话默认会从上面的四个位置读取配置文件。\n```\n\n查看加载表结构的过程：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-6/77738193.jpg)\n\nmysql5.7的io模型是基于poll的，当看到如下的字样的时候就代表mysql已经启动成功了\n\n```\npoll[{fd=33,events=POLLIN},{fd=36,events=POLLIN}],2,-1\n```\n\n### 5.1、查看报错代码的意思\n\n如果查看ERROR里面的code代码不知道什么意思的时候该如何处理？\n\n```shell\n[root@maxiaoyu 15:35:34 /root]\n#/usr/local/mysql/bin/perror 11\nOS error code  11:  Resource temporarily unavailable\n\n[root@maxiaoyu 15:35:58 /root]\n#/usr/local/mysql/bin/perror 13\nOS error code  13:  Permission denied\n\n[root@maxiaoyu 15:36:05 /root]\n#/usr/local/mysql/bin/perror 24\nOS error code  24:  Too many open files\n\n[root@maxiaoyu 15:36:12 /root]\n#/usr/local/mysql/bin/perror 27\nOS error code  27:  File too large\n\n[root@maxiaoyu 15:36:14 /root]\n#/usr/local/mysql/bin/perror 28\nOS error code  28:  No space left on device\n```\n\n\n\n","timestamp":1541470330295},{"name":"00-Mysql基础应用.md","path":"01-Linux运维/07-DBA运维/01-Mysql/02-MYSQL基本维护/00-Mysql基础应用.md","content":"# MySQL基础\n\n[TOC]\n\n## 日志\n\n- 日志可能会占用大量的磁盘空间\n- 现在部分日志可以存储在表里（现在不提倡使用）\n- 以文本格式写入日志（二进制日志除外）\n\n### **日志类型**\n\n- 错误日志\n- 慢查询日志\n- 常规日志\n- 二进制日志\n- 审计日志\n\n### **日志文件**\n\n| 日志文件 | 选项                                   | 文件名或表名称                     | 程序                            |\n| ---- | ------------------------------------ | --------------------------- | ----------------------------- |\n| 错误   | --log-error                          | host_name.err               | N/A                           |\n| 常规   | --general_log                        | host_name.log/general.log   | N/A                           |\n| 慢查询  | --slow_query_log & --long_query_time | host_name-slow.log/slow_log | mysqldumpslow/pt-query-digest |\n| 二进制  | --log-bin & --expire-logs-days       | host_name-bin.000001        | mysqlbinlog & binlog2sql      |\n| 审计   | --audit_log等                         | audit.log                   | N/A                           |\n| 中继   |                                      | host_name-relay.log         |                               |\n\n- 常规日志既会记录正确日志也会记录错误日志\n- long_query_time默认是10s，建议改成1s或者以下。慢日志分析推荐pt-query-digest\n- 一定要设置二进制日志的expire-logs-days，否则会被日志占满\n- relay-log的日志名字是和hostname有关的，不止relaylog，假如说更改了主机名，而且relay-log未定义，按照默认的走，改了主机名以后可能找不到对应命名的relay-log。\n\n查看mysql中和日志有关的变量：\n\n```mysql\nmysql> show global variables like \'%log%\';\n```\n\n其中的`log_queries_not_using_indexes`是可以不用开启的，因为小于1s的你用没用其实我也不用关心，你大于1s的即使你用了我毕业要想办法优化。\n\n还有就是log是可以定义到syslog中的，比如说用elk进行收集等等：\n\n```mysql\nlog_syslog                              | OFF   \nlog_syslog_facility                     | daemon\nlog_syslog_include_pid                  | ON    \nlog_syslog_tag                          |       \n```\n\n- relay_log_purge：relay-log被sql thread消耗完毕以后清除掉\n- relay_log_space_limit：这个参数默认是开启的，允许我们设置接受的relay-log的最大的大小，当relay-log超过设置的大小了以后就不再从master那边取了。因此这个参数不建议去使用。一般可用于磁盘紧张而且主从复制出现了大量延迟的时候避免被relay-log撑满磁盘空间可以使用这个参数。\n- general_log：默认是不开启的，如果想要开启可以`set global general_log = 1`不过这个参数一般也不会进行开启。可以用来排查问题或者在比较严格的环境做审计使用。\n\n**修改日志记录的时间：**\n\n```mysql\ntime_zone                       | SYSTEM \nsystem_time_zone                | CST \n```\n\n### 二进制日志\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-18/17887452.jpg)\n\n**二进制日志什么时间会刷新（切换）？**\n\n- 达到了系统定义的max_binlog_size\n- 运行了flush logs\n- 服务器重启\n\n在重启这里有一个要进行说明的，重启过程中mysql会去读取这些bin-log的文件名，只是读取文件名，然后根据文件名进行排序，获取最大的，然后在这个最大的序号基础上+1生成一个新的文件（不是根据mysqlbin.index文件产生的，单纯的是根据排序后的序号最大的+1产生的新文件），加入说binlog过多的话，比如上万个，这种情况下不管是开启还是关闭相对来说就会很慢，因此binlog的size要合理的进行设置，太小的话就会造成binlog文件过多的问题。默认的是1个G。用这个默认的设置其实就可以，不要太大也不要太小。\n\n那么mysqlbin.index是干什么用的？\n\n```mysql\nmysql> show binary logs;\n+----------------------+-----------+\n| Log_name             | File_size |\n+----------------------+-----------+\n| ecs-mysql-bin.000001 |    814133 |\n| ecs-mysql-bin.000002 |      1909 |\n| ecs-mysql-bin.000003 |       177 |\n| ecs-mysql-bin.000004 |       205 |\n| ecs-mysql-bin.000005 |       650 |\n+----------------------+-----------+\n13 rows in set (0.01 sec)\n```\n\n上面这一条命令是从index文件中读取的。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-18/80515399.jpg)\n\n关于binlog_format：推荐使用row格式。\n\n**查询二进制日志文件**\n\n```mysql\nshow binary logs;\n# 列出当前的日志文件以及大小\n\nshow master status;\n# 显示mysql当前的日志以及状态（需要super，replication，client权限）\n\nshow binlog events in \'mysql-bin.000010\';\n# mysql的二进制日志是以‘事件（event）’为单位存储到日志中的。一个insert，update……由多个事件组成，比如：\n- GTID event\n- query event\n- table_map event\n- write_rows event\n- xid event\n可以截取事件日志的其中一部分看一下：\n\n| ecs-mysql-bin.000013 | 1009189 | Query     | 1 | 1009263 | BEGIN                          |\n| ecs-mysql-bin.000013 | 1009263 | Table_map | 1 | 1009321 | table_id: 461 (zabbix.sessions)|\n| ecs-mysql-bin.000013 | 1009321 | Write_rows| 1 | 1009406 | table_id: 461 flags: STMT_END_F|\n| ecs-mysql-bin.000013 | 1009406 | Xid       | 1 | 1009437 | COMMIT /* xid=620202 */        |\n针对DDL语句，没有query（begin），xid（commit），table_map这样得event。\n\n# 专业名称：日志文件：mysqlbin.000010，字节偏移量（位置），position，单位是字节。\nmysql> show master status;\n+----------------------+----------+--------------+------------------+-------------------+\n| File                 | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+----------------------+----------+--------------+------------------+-------------------+\n| ecs-mysql-bin.000013 |  1012070 |              |                  |                   |\n+----------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n\n[root@maxiaoyu 21:09:53 /data/mysql]\n#ll /data/mysql/ecs-mysql-bin.000013\n-rw-r----- 1 mysql mysql 1012070 Nov 18 20:18 /data/mysql/ecs-mysql-bin.000013\n\n# 可以看到和上面的master status中的position是一致的。\n```\n\n**查看二进制日志：**\n\n二进制日志是无法用文本查看的，日志以紧凑的二进制格式存储，以事件组合，可以使用工具mysqlbinlog来进行查看：\n\n```mysql\nmysqlbinlog -v --base64-output=decode-rows ecs-mysql-bin.000013 | less\n```\n\n其中mysqlbinlog有几个比较重要的参数，比如：\n\n- --start-position\n- --stop-position\n- --start-datetime=name\n- --stop-datetime-name\n- --stop-never\n\n**二进制日志维护：**\n\n基于时间删除二进制日志\n\n```mysql\nset global expire_logs_days=7;\n\npurge binary logs before now() -interval 3 days;\nPURGE BINARY LOGS BEFORE \'2008-04-02 22:46:26\';\n# 如果忘了purge的使用方法，可以在mysql命令行中直接help purge;\n```\n\n根据文件名删除：\n\n```mysql\n# 把mysql-bin.000010之前的日志都干掉。\npurge binary logs to \'mysql-bin.000010\';\n```\n\n那么使用purge删除的话会保证主从复制所有数据都传递到从库？当然，这个是不能保证的。因此purge之前要确保日志都传递到从库了（确认方法可以在主库flush logs然后去从库看看有没有传递过去）。还有就是使用purge删除的话会把mysqlbin.index中的也删掉，这个是rm做不到的，因此不建议使用rm进行删除binlog，不过一定要使用rm删除的话，记得在数据库里使用purge调用一下。\n\n### 审计日志\n\n审计日志是官方的一个收费组件，需要购买企业版。\n\n- 基于策略的日志记录：\n  - 通过audit_log_policy选项设置\n  - 提供日志记录选项ALL、NONE、LOGINS或QUERIES，默认为ALL\n\n在日志文件中生成一个服务器活动审计的记录：\n\n- 内容取决于策略，可能包括：\n  - 在系统上发生的错误的记录\n  - 客户机链接和断开的链接的时间\n  - 客户机在连接期间执行的操作\n  - 客户机访问的数据库和表\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-18/45961731.jpg)\n\n## DBA运维常用命令总览\n\n### 认识information_schema数据库\n\n> 学习利用information_schema的字典信息生成语句，information_schema相当于Mysql的中央信息库。\n\n**模式和模式对象**\n\n服务器的统计信息（状态变量，设置，链接），该库不持久化，属于“虚拟数据库”，不可更改，即使是root也干不掉。我们在物理的datadir下是找不到这个数据库的，可以通过select访问。\n\n#### Information_schema重要对象\n\n比如当我们想统计哪些库中有哪些表的时候，我们就可以这样去访问：\n\n```mysql\nmysql> select table_name from information_schema.tables where table_schema=\'information_schema\' order by table_name;\n```\n\n查看库中的表和表引擎：\n\n```mysql\nmysql> select table_name,engine from information_schema.tables where table_schema=\'wordpress\';\n+----------------------------+--------+\n| table_name                 | engine |\n+----------------------------+--------+\n| mxyblog_commentmeta        | MyISAM |\n| mxyblog_comments           | MyISAM |\n| mxyblog_hermit             | MyISAM |\n| mxyblog_hermit_cat         | MyISAM |\n| mxyblog_links              | MyISAM |\n| mxyblog_ngg_album          | MyISAM |\n| mxyblog_ngg_gallery        | MyISAM |\n| mxyblog_ngg_pictures       | MyISAM |\n| mxyblog_options            | MyISAM |\n| mxyblog_postmeta           | MyISAM |\n| mxyblog_posts              | MyISAM |\n| mxyblog_term_relationships | MyISAM |\n| mxyblog_term_taxonomy      | MyISAM |\n| mxyblog_termmeta           | MyISAM |\n| mxyblog_terms              | MyISAM |\n| mxyblog_usermeta           | MyISAM |\n| mxyblog_users              | MyISAM |\n+----------------------------+--------+\n17 rows in set (0.00 sec)\n```\n\n查看mysql系统默认的字符集和校对集：\n\n```mysql\nmysql> select character_set_name,collation_name from information_schema.collations where is_default=\'Yes\';\n```\n\n查看每个库的表统计\n\n```mysql\nmysql> select table_schema,count(*) from information_schema.tables group by table_schema;\n+--------------------+----------+\n| table_schema       | count(*) |\n+--------------------+----------+\n| carbon             |       23 |\n| emlog              |       15 |\n| gogs               |       36 |\n| information_schema |       61 |\n| mysql              |       31 |\n| performance_schema |       87 |\n| sys                |      101 |\n| wordpress          |       17 |\n| zabbix             |      127 |\n+--------------------+----------+\n9 rows in set (0.00 sec)\n```\n\n常见用法-语句拼合生成(可以结合into outfile使用)：\n\n```mysql\nmysql> select concat(\"mysqldump -uroot -pxxxx\",\" \",table_schema,\" \",table_name,\">\",table_schema,\".\",table_name,\".bak.sql\") from information_schema.tables where table_name like \"mxyblog_%\"; \n```\n\n### show核心语句(help show)\n\n- show databases\n- show tables;/show tables from db_name;\n- show columns from db_name.tb_name;\n- show full columns from db_name.tb_name;\n- show processlist\n- show create table table_name\n- show index from table_name\n- show open tables;\n- show table status;\n\n####  show还支持like和where使用\n\n- show databases like \'mxyblog_%\';\n- show columns from zst where \'Default\' is null\n- show character set;\n- show collation;\n\n## Mysql的目录结构\n\n首先先来看一下data目录下都有什么内容：\n\n```shell\n[root@maxiaoyu 11:57:18 /data/mysql]\n#ls -lh\ntotal 186M\n-rw-r----- 1 mysql mysql    56 Jun 16 12:08 auto.cnf\n-rw------- 1 root  root   1.7K Jun 16 12:10 ca-key.pem\n-rw-r--r-- 1 root  root   1.1K Jun 16 12:10 ca.pem\n-rw-r--r-- 1 root  root   1.1K Jun 16 12:10 client-cert.pem\n-rw------- 1 root  root   1.7K Jun 16 12:10 client-key.pem\n-rw-r----- 1 mysql mysql 1005K Nov 19 11:22 ecs-mysql-bin.000013\n-rw-r----- 1 mysql mysql    23 Nov 18 21:36 ecs-mysql-bin.index\n-rw-r----- 1 mysql mysql   830 Nov  6 15:22 ib_buffer_pool\n-rw-r----- 1 mysql mysql   76M Nov 19 10:52 ibdata1\n-rw-r----- 1 mysql mysql   48M Nov 19 10:52 ib_logfile0\n-rw-r----- 1 mysql mysql   48M Aug 28 15:42 ib_logfile1\n-rw-r----- 1 mysql mysql   12M Nov 19 11:26 ibtmp1\n-rw-r----- 1 mysql mysql  113K Nov  6 14:41 maxiaoyu.err\n-rw-r----- 1 mysql mysql     6 Nov  6 15:23 maxiaoyu.pid\n-rw-r----- 1 mysql mysql  4.3K Nov  6 15:23 maxiaoyu-slow.log\ndrwxr-x--- 2 mysql mysql  4.0K Jun 16 12:08 mysql\ndrwxr-x--- 2 mysql mysql  4.0K Jun 16 12:08 performance_schema\n-rw------- 1 root  root   1.7K Jun 16 12:10 private_key.pem\n-rw-r--r-- 1 root  root    451 Jun 16 12:10 public_key.pem\n-rw-r--r-- 1 root  root   1.1K Jun 16 12:10 server-cert.pem\n-rw------- 1 root  root   1.7K Jun 16 12:10 server-key.pem\ndrwxr-x--- 2 mysql mysql   12K Jun 16 12:08 sys\n```\n\n- auto_cnf下存放的是server的uuid\n\n  ```mysql\n  [root@maxiaoyu 11:57:21 /data/mysql]\n  #cat auto.cnf \n  [auto]\n  server-uuid=7e40a68a-5249-11e7-94f1-00163e06bd3d\n  ```\n\n- ib_buffer_pool：insert buffer pool\n\n- ibdata1：整体的一个数据字典文件，Innodb表的元数据；变更缓冲区；双写缓冲区；撤销日志。ibdata1存储的内容可以参考[为什么mysql里的ibdata1文件不断的增长](https://linux.cn/article-5829-1.html)\n\n- ib_logfile0：redo文件，建议最少设置成3~5个。\n\n- ibtemp1：临时表文件\n\n**使用mysql_config查找对应的库位置：**\n\n```shell\n$sudo /usr/local/mysql/bin/mysql_config\nUsage: /usr/local/mysql/bin/mysql_config [OPTIONS]\nCompiler: GNU 4.4.4\nOptions:\n        --cflags         [-I/usr/local/mysql/include ]\n        --cxxflags       [-I/usr/local/mysql/include ]\n        --include        [-I/usr/local/mysql/include]\n        --libs           [-L/usr/local/mysql/lib -lmysqlclient -lpthread -lm -lrt -ldl]\n        --libs_r         [-L/usr/local/mysql/lib -lmysqlclient -lpthread -lm -lrt -ldl]\n        --plugindir      [/usr/local/mysql/lib/plugin]\n        --socket         [/tmp/mysql.sock]\n        --port           [0]\n        --version        [5.7.18]\n        --libmysqld-libs [-L/usr/local/mysql/lib -lmysqld -lpthread -lm -lrt -lcrypt -ldl -laio]\n        --variable=VAR   VAR is one of:\n                pkgincludedir [/usr/local/mysql/include]\n                pkglibdir     [/usr/local/mysql/lib]\n                plugindir     [/usr/local/mysql/lib/plugin]\n```\n\n**mysql对应的插件目录（比如半同步）**：\n\n```shell\n/usr/local/mysql/lib/plugin\n```\n\n**帮助手册：**\n\n如果说系统的帮助手册man不到mysql的话我们可以手动拷贝一下mysql安装目录中的man手册到系统下，这样就可以实现使用系统man查看帮助手册了：\n\n```shell\ncp /usr/local/mysql/man/man* /usr/local/share/man -r\n```\n\n**share目录**\n\nshare目录保存的是一些字符集，以及一些初始化用的sql。 \n\n**bin目录：**\n\n- mysqld\n- mysql\n- mysqldump\n- mysqlbinlog\n- mysqladmin\n- mysql_config_editor：配合--login-path使用\n- perror：展示错误代码\n- mysqlslap：做mysql的性能测试\n\n**性能测试工具：**\n\n- sysbench1.1\n- mysql-tpcc：使用percona版本\n- YCSB：雅虎的，可以适配多种数据库 & NOSQL\n- fio：磁盘性能监测\n\n***\n\n如果说遇到数据库整库打包迁移后域名解析错误该怎么办？\n\n```shell\n# 这种问题可以借助sql自带的resolveip来反解析一下看看对不对\n\n[lamber@maxiaoyu 12:59:52 /usr/local/mysql/bin]\n$./resolveip 47.94.132.15\nHost name of 47.94.132.15 is maxiaoyu, blog.dcgamer.top\n\n# 如果说不对的话可以使用strace来看一下\n$strace ./resolveip 47.94.132.15 \n```\n\n***\n\n安装percona-tools\n\n\n\nmysqlbinlog统计：\n\nhttps://github.com/wubx/mysql-binlog-statistic\n\n### Mysql的5.7的SYS库\n\n","timestamp":1541470330295},{"name":"01-Mysql用户账户维护.md","path":"01-Linux运维/07-DBA运维/01-Mysql/02-MYSQL基本维护/01-Mysql用户账户维护.md","content":"# Mysql用户维护\n\n账户管理的重要性\n\n- 在mysql中可以通过账户控制允许或者不允许用户执行操作\n- 可以精细分配不同的权限给不同职能的账户\n- 避免使用root账户\n  - 应用不能直接使用root\n  - 防止维护期间出错\n- 限定特定权限账户确保数据的完整性\n  - 允许特定授权账户完成期工作\n  - 阻止未经授权的用户访问超出其特权的数据\n\n在root上可以做一些限制的操作：\n\n```mysql\nupdate mysql.user set user=\'xroot\' where user=\'root\';\nflush privileges;\n```\n\n## 账户管理\n\n查看mysql账户\n\n```mysql\n# mysql 5.6及以前版本\nselect user,host,password from mysql.user;\n# 在初始化数据库以后要删除掉匿名账户(在5.7中会自动执行这条命令)\ndelete from mysql.user where user!=\'root\' or localhost!=\'localhost\';\n\n# mysql 5.7及以后\nmysql root@localhost:(none)> select user,host,authentication_string from mysql.user;\n```\n\nmysql的账户验证现在大多验证使用mysql_native_password这个plugin，在mysql验证的时候使用以下三个要素：\n\n- 用户名\n- 主机所属范围（主机来源）\n- 用户密码\n\n查看用户授权有两个函数，一个是user()另外一个是current_user()\n\n```mysql\nmysql maxiaoyu@localhost:(none)> select user(),current_user();\n+--------------------+----------------+\n| user()             | current_user() |\n+--------------------+----------------+\n| maxiaoyu@localhost | maxiaoyu@%     |\n+--------------------+----------------+\n1 row in set\nTime: 0.006s\n```\n\n从上面的结果可以看到user函数是指的当前登录进来的用户和它的主机范围，current_user这个函数指的是授权的信息。\n\n用户连接和查询流程\n\n![](http://omk1n04i8.bkt.clouddn.com/17-10-17/7497028.jpg)\n\n和用户权限把控相关的主要是mysql库中的四张表，user表，db表以及columns_priv表，table_priv表。\n\n创建用户\n\n```mysql\ncreate user 用户名@主机 identified by \'密码\'\n# 这样创建的账号的只有链接权限，其他的啥都做不了\n# %通配，_表示匹配一个。\n```\n\n用户名建议8~16个字符，密码一般是16-32个字符，mysql域名最好在60个字符以内。我们可以使用mkpasswd去生成随机密码，也可以使用其他的方式。linux可以生成随机密码的方式有很多，可以选择自己喜欢的方式做为常用方式去升级。\n\n创建用户要注意的几个风险：\n\n- 不要创建没有用户名的账号\n- 不要创建没有密码的账号\n- 在可能的情况下主机限制那里不要使用通配符，尽量缩小范围。\n\n关于主机名的匹配是走最精确的，比如‘root’@\'192.168.%\'和‘root’@‘192.168.1.%’，它会去优先匹配后面这个，不看排序只看精确程度，或者这里我们可以通过通配符结合/etc/hosts来进行域名的解析数据库的登录。\n\n那么如何针对一个大范围内的部分主机IP进行限制呢？\n\n```mysql\n# 比如授权一个\ncreate user \'lamber\'@\'192.168.1.%\' identified by \'password\'\n\n# 我现在唯独想把192.168.1.100这个ip的不让他进行访问，那么我们就可以单独处理\ncreate user \'lamber\'@\'192.168.1.100\' identified by \'otherpasswd\'\n\n# 由于最精确匹配的原则，这个1.100ip的人的密码就是这个otherpasswd而不是password因此就会限制这个ip的用户的登录\n```\n\n使用password函数查看加密处理的authentication_string是什么：\n\n```mysql\nmysql maxiaoyu@localhost:mysql> select password(\'maxiaoyuhahaha\');\n+-------------------------------------------+\n| password(\'maxiaoyuhahaha\')                |\n+-------------------------------------------+\n| *92A2BE17BB2A1064C25BAE92A1AAFCF8B961B8C2 |\n+-------------------------------------------+\n1 row in set\nTime: 0.006s\n```\n\n有时候忘了密码还能猜猜，当然你如果是随机密码那就别这么玩了。。不过密码忘了有一种暴力修改的方式就是：\n\n```mysql\nupdate mysql.user set authentication_string=password(\'new_pass\') where user=\'current_user\';\nflush privileges;\n```\n\n在使用这个暴力方法的时候务必要加where的条件，要不然不这个系统上的所有mysql账户全部gg，而且修改完以后要刷一下缓存。上面这一种方法并不是官方推荐的方法，当然你也尽可能的不要去使用，手抖一下问题还是挺多的。除了使用上面的暴力方法还可以使用下面这种方法为用户修改密码：\n\n```mysql\nset password for \'maxiaoyu\'@\'%\'=password(\'new_pass\');\n```\n\n更好地修改方法：\n\n```mysql\nset password for \'maxiaoyu\'@\'%\'=\'hahahaha\'\n\n# 因为使用password函数的方法将会在后期的版本被移除，这个信息可以通过show warnings查看\nmysql maxiaoyu@localhost:mysql> show warnings\\G;\n***************************[ 1. row ]***************************\nLevel   | Warning\nCode    | 1287\nMessage | \'SET PASSWORD FOR <user> = PASSWORD(\'<plaintext_password>\')\' is deprecated and will be removed in a future release. Please use SET PASSWORD FOR <user> = \'<plaintext_password>\' instead\n```\n\n使用alter的方法去修改用户的密码：\n\n```mysql\nmysql maxiaoyu@localhost:mysql> alter user \'maxiaoyu\'@\'%\' identified by \'new_pass\';\nQuery OK, 0 rows affected\nTime: 0.001s\n```\n\n确认没有密码的用户（把没有密码的用户干掉）：\n\n```mysql\nselect user,host from mysql.user where password=\'\';\nselect user,host from mysql.user where authentication_string=\'\';\n```\n\n让用户口令失效，登录后必须修改密码（5.7使用，如果是5.5或者以前的话登录直接会报错）：\n\n```mysql\nalter user \'maxiaoyu\'@\'%\' passwird expire;\n```\n\n删除用户：\n\n```mysql\n# 直接删除该用户，从授权表中删除该用户的记录\ndrop user \'maxiaoyu\'@\'%\'\n\n# 如果不加主机名的话默认会删除主机名为%的记录\ndrop user \'maxiaoyu\'(drop user \'maxiaoyu\'@\'%\')\n```\n\n重命名用户：\n\n```mysql\n# 更改账号的名称，保留权限，可以更改：用户名和主机名部分\nrename user \'maxiaoyu\'@\'%\' to \'lamber\'@\'%\'\n```\n\n如果忘记了语法的使用可以使用help\n\n```mysql\nhelp create user\n```\n\n## 权限管理\n\n使用create创建的用户其实是什么权限都没有的，只能看到一个information_schema这么一个库，如果你要创建一个和root一样的权限的账号，可以参考root的权限，很重要的一点就是`with grant option`。\n\n合理的控制授权也是dba的重要责任之一，权限可以划分的很细致，主要从以下几个方面：\n\n- 全局级别\n- 数据库级别\n- 表级别\n- 列级别\n- 存储过程级别\n\n**只读用户**\n\n全局，数据库或者表级别权限，只用select\n\n**开发用户**\n\n业务库权限：insert、update、delete、select，call\n\n**管理用户**\n\n全局级别，权限：insert、update、delete、create、alter、drop、file(现在基本不用给这个权限了)、process、shutdown、super\n\n### 以下权限需要注意\n\nFILE：允许用户指示mysql服务器在服务器主机文件系统中读写文件，在mysql5.7中需要打开配置文件中的一个参数来配合：\n\n```mysql\n# file\n# @secure-file-priv=/tmp\n```\n\n如果需要文件权限就需要打开这个注释，不过5.7还是默认把这个给干掉了，因为漏洞还是挺多的。\n\nPROCESS：允许用户使用show processlist语句，这个是管理中常用的语句（如果show processlist显示内容过多的话可以使用[pager more](http://wubx.net/mysql-client-tips/)这个功能）\n\nSUPER：运行用户终止其他客户机的链接，或者更改服务器的运行时的配置，执行kill set shutdown\n\nALL：授予所有权限（但是不能向其他用户授予权限）\n\nGRANT ALL … WITH GRANT OPTION：授予所有特权，相当于root\n\n### 权限的授予与去除（grant and revoke）\n\nGRANT命令可以给现有的用户添加权限，如果用户不存在的话还可以创建用户\n\n```mysql\ngrant select,insert,update,delete on *.* to \'maxiaoyu\'@\'%\' identified by \'password\'\n```\n\nTips:\n\n- 多个权限使用逗号隔开，不区分大小写\n- 授权的对象\n  - 全局级别：\\*.\\*\n  - 数据库级别：dbname.\\*\n  - 表级别：db_name.table_name\n- 要创建或是授权的用户：\'username\'@\'hostname(IP/network)\'\n- 密码：可选\n\n查看账户的权限：\n\n```mysql\nshow grants;\nshow grants for current_user();\nshow grants for \'root\'@\'localhost\';\n```\n\n我们可以通过`show privileges`来查看mysql支持的权限：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-10-19/55799788.jpg)\n\n### 权限控制表\n\n|     表（MyISAM）     |       用处       |\n| :---------------: | :------------: |\n|    mysql.user     | 每个创建的用户在这里都有记录 |\n|     mysql.db      |  限制用户做用户特定的db  |\n| mysql.tables_priv |   用于表级别的权限控制   |\n| mysql.procs_priv  | 用户存储过程和函数权限控制  |\n\nMysql启动的时候从mysql库中把权限读取加载到内存中，如果通过DML更新权限表需要借助于flush privilegesl才能生效。*<u>特别需要注意的是：不要对权限表进行DML操作</u>*。\n\n#### 权限的revoke\n\n使用revoke语句撤销对用户的授权：\n\n```mysql\nrevoke delete,insert,update on world_innodb.* from \'maxiaoyu\'@\'%\'\nrevoke all privileges,grant option from \'maxiaoyu\'@\'%\';\n\n# revoke语法：\n# revoke关键字：指定要撤掉的特权列表。\n# on子句：只是要撤销特权的级别（全局级别的时候可以不用带）。\n# from子句：指定账户名称。\n```\n\n批量对部分表进行授权：\n\n```mysql\nmysql root@localhost:(none)> use information_schema\nYou are now connected to database \"information_schema\" as user \"root\"\nTime: 0.001s\nmysql root@localhost:information_schema> select concat(\'grant select on \',table_schema,\'.\',table_name,\" to \'testuser2\'@\'%\';\") from tables where table_schema=\'wordpress\' and table_name like \"mxy%\";\n+-------------------------------------------------------------------------------+\n| concat(\'grant select on \',table_schema,\'.\',table_name,\" to \'testuser2\'@\'%\';\") |\n+-------------------------------------------------------------------------------+\n| grant select on wordpress.mxyblog_commentmeta to \'testuser2\'@\'%\';             |\n| grant select on wordpress.mxyblog_comments to \'testuser2\'@\'%\';                |\n| grant select on wordpress.mxyblog_hermit to \'testuser2\'@\'%\';                  |\n| grant select on wordpress.mxyblog_hermit_cat to \'testuser2\'@\'%\';              |\n| grant select on wordpress.mxyblog_links to \'testuser2\'@\'%\';                   |\n| grant select on wordpress.mxyblog_ngg_album to \'testuser2\'@\'%\';               |\n| grant select on wordpress.mxyblog_ngg_gallery to \'testuser2\'@\'%\';             |\n| grant select on wordpress.mxyblog_ngg_pictures to \'testuser2\'@\'%\';            |\n| grant select on wordpress.mxyblog_options to \'testuser2\'@\'%\';                 |\n| grant select on wordpress.mxyblog_postmeta to \'testuser2\'@\'%\';                |\n| grant select on wordpress.mxyblog_posts to \'testuser2\'@\'%\';                   |\n| grant select on wordpress.mxyblog_term_relationships to \'testuser2\'@\'%\';      |\n| grant select on wordpress.mxyblog_term_taxonomy to \'testuser2\'@\'%\';           |\n| grant select on wordpress.mxyblog_termmeta to \'testuser2\'@\'%\';                |\n| grant select on wordpress.mxyblog_terms to \'testuser2\'@\'%\';                   |\n| grant select on wordpress.mxyblog_usermeta to \'testuser2\'@\'%\';                |\n| grant select on wordpress.mxyblog_users to \'testuser2\'@\'%\';                   |\n+-------------------------------------------------------------------------------+\n17 rows in set\nTime: 0.008s\n```\n\n## 禁用验证控制\n\n视频点：第四课：1小时23分\n\n\n\n\n\n\n\n\n\n","timestamp":1541470330295},{"name":"01-01、Mysql主从.md","path":"01-Linux运维/07-DBA运维/01-Mysql/03-MYSQL数据安全/01-01、Mysql主从.md","content":"hexdump -C mysql-bin.010100\n\n","timestamp":1541470330295},{"name":"02-02、Mysql备份.md","path":"01-Linux运维/07-DBA运维/01-Mysql/03-MYSQL数据安全/02-02、Mysql备份.md","content":"","timestamp":1541470330295},{"name":"05-05、Mysql高可用.md","path":"01-Linux运维/07-DBA运维/01-Mysql/03-MYSQL数据安全/05-05、Mysql高可用.md","content":"# Mysql常见高可用架构\n\n> 常见Mysql高可用大纲\n>\n> - 基于主从的高可用\n> - 基于DRBD+Heartbeat的高可用\n> - 官方推荐的Mysql NDB Cluster\n> - 基于PXC模型的高可用\n> - 基于Proxy模型的高可用\n> - Mysql 5.7 Group Replication高可用\n> - 基于多源复制高可用\n> - 自主实现mysql高可用\n> - 业界DB四层架构设计\n\n## 1、基于复制的高可用\n\n**传统的复制模型：**\n\n- statement\n- mixed\n- row\n\n如果你的mysql版本是5.6以上的话毫不犹豫的建议使用GTID+ROW的形式\n\n### 1.1、基于Keepalived实现主从故障切换\n\n\n\n### 1.2、基于MHA的高可用\n\n> 作者已经放弃了对mha的维护了\n\n\n\n### 1.3、基于DNS或介入服务的高可用\n\n","timestamp":1541470330295},{"name":"02-02、mysql基础操作.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/02-02、mysql基础操作.md","content":"# Mysql基础操作\n\n## 1、库操作，DDL\n\n### 1.1 创建（create）\n\ncreate database 库名 [库选项]\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/45809924.jpg)\n\n注意的问题：\n\n库选项，只有字符集，校对集的概念！每个库，会对应一个数据目录\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/30978819.jpg)\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/91773687.jpg)\n\n默认的只有字符集，校对集的概念：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/9094061.jpg)\n\n其他需要注意的问题：\n\n- 关于创建名称大小写的问题，这个是跟着系统走的，看你操作是否大小写敏感，比如windows是大小写不敏感的，但是linux是敏感的，因此为了保持一致性，使用的时候要保持大小写敏感，从而保证系统的稳定运行\n\n- 你创建的库或者是表不能是关键字敏感的，比如下面的：\n\n  ```\n  mysql> create database order;\n  ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \'order\' at line 1\n  ```\n\n  但是这并不是绝对的，我们只要告诉数据库我要创建的这是一个表名称就可以了，需要将名称用反引号引起来，就是数组1左侧的那个按键：\n\n  ```\n  mysql> create database `order`;\n  Query OK, 1 row affected (0.00 sec)\n  ```\n\n- 中文等都可以作为标识符（库名），需要同样反引号！（多字节字符，还需要注意字符集的问题），需要设置字符集为gbk，因为当前是在windows上。不然无法创建的。\n\n  ```\n  mysql> set names gbk;\n  Query OK, 0 rows affected (0.00 sec)\n\n  mysql> create database `小雨`;\n  Query OK, 1 row affected (0.04 sec)\n\n  mysql> show databases;\n  +--------------------+\n  | Database           |\n  +--------------------+\n  | information_schema |\n  | 小雨               |\n  | mysql              |\n  | order              |\n  | performance_schema |\n  | sys                |\n  | test               |\n  +--------------------+\n  7 rows in set (0.00 sec)\n  ```\n\n### 1.2 查询库\n\n```mysql\nshow databases;\nshow databases likes \'%_scheme\';   # 使用like可以实现通配符匹配\n=========================================\n可以使用通配符（通用匹配符，可以匹配多个字符）\n% 匹配任意字符的任意次数（包括0次）的组合！\n_ 匹配任意字符的一次！\nlike ‘x_y’;\nx1y xby xxy（可以）\nxy(不可以)\n通配符是与 like 关键字一起使用！\n=========================================\n```\n\n注意如需要匹配特定的通配符，则需要对通配符转义，使用反斜杠\\完成转义！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/55760220.jpg)\n\n**查看某一个库的定义**\n\n```mysql\nmysql> show create database mysql\\G;\n*************************** 1. row ***************************\n       Database: mysql\nCreate Database: CREATE DATABASE `mysql` /*!40100 DEFAULT CHARACTER SET latin1 */\n1 row in set (0.00 sec)\n\nERROR:\nNo query specified\n```\n\n### 1.3 修改库\n\nalter database 数据库名\n\n```\nmysql> alter database `小雨` charset gbk;\nQuery OK, 1 row affected (0.00 sec)\n```\n\n### 1.4 删除库\n\ndrop database 名字\n\n### 1.5 if not exist,if exist\n\n```mysql\n在  create  与 drop 时，创建和删除时，有两个额外的操作：\n \ncreate database if not exists\n如果不存在则创建\n \ndrop database if exists\n如果存在，则删除\n```\n\n### 1.6 查看警告状态\n\nshow warnings;   \n\n此命令可以查看警告项\n\n## 2、表操作\n\n### 2.1 创建，create table\n\n```mysql\ncreate table 表名 (\n字段的定义\n) [表选项];\n\n其中表名，一定先要确定数据库！因此一个典型的表名是由两部分组成：\n所在库.表名（库与表之间用“.”连接）\ntest.itcast       test库内itcast表\nitcast.stu         itcast库内的stu表\n但是我们可以设置默认数据库，如果不指定则使用默认数据库（当前数据库）\nuse 数据库名。选择默认数据库！\n在使用表名但是没有指明其所在数据库时，默认数据库才会起作用！\n\n比如：\n在itcast库内创建：\nuse itcast ; create table stu;\n或者\ncreate table itcast.stu\n```\n\n**关于字段**\n\n字段才是最终的数据的载体（与变量的概念是类似的，都是基本保存数据的），mysql的是强类型，字段的类型是固定的，提前定义好的！因此，在定义字段时，至少要字段名和字段类型！两种最基本的mysql数据类型（int， varchar,varchar必须指定最大长度字符为单位）varchar单位为字符数，一般是255.比如大葱，这就是两个字符，在UTF-8中就是占用6个字节。具体多少字节和字符集有关系。\n\n创建一个表的示例：\n\n```mysql\nmysql> create table test2 (\n        id int auto_increment,\n        name varchar(255),\n        sex char(16)\n        ) engine=innodb charset=utf8;\n        \nAbout auto_increment:\nauto_increment指的是自增列，这个列可以实现数据id自增，常用与表的id列。\n我们可以指定auto_increment的起始位置\n\nalter table table_name AUTO_INCREMENT=20;\n或者在创建的时候在engine后面跟一个auto_increment=xx也可以\n\n当然现在自增是一个一个的，我们可以为它设置步长，可以跳着增加。\nmysql自增步长是基于会话级别的，什么叫会话级别的，就是你当前打开一个mysql终端\n这就是建立了一个会话，针对当前有一个设置有一个默认的步长：\nmysql> show session variables like \'auto_increment%\';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 1     |\n| auto_increment_offset    | 1     |\n+--------------------------+-------+\n2 rows in set, 1 warning (0.00 sec)\n大家默认的步长都是1，每个会话的步长可以不一样，我们可以通过set命令\n\nmysql> set session auto_increment_increment=2;\nQuery OK, 0 rows affected (0.00 sec)\n当然退出重新登录就相当于一个新的会话了，之前的设置就没了。\n\n如果要设置所有人都一样的话也不是不可以，设置全局变量即可：\nmysql> set global auto_increment_increment=200;\nQuery OK, 0 rows affected (0.00 sec)\n当然服务器重启以后还是会重置，如果需要永久修改还是放到配置文件去吧。\n\n当然还有基于表级别的设置步长，给一个表单独设置步长。这个和会话就没关系了。\n```\n\n- 当然字段可以创建的时候就指定好，也可以后续的添加：\n\n```\nalter table table_name add column 字段定义 [字段位置]\n\neg:\nmysql> alter table test2 add column age int;\nQuery OK, 0 rows affected (0.91 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> desc test2;\n+-------+--------------+------+-----+---------+-------+\n| Field | Type         | Null | Key | Default | Extra |\n+-------+--------------+------+-----+---------+-------+\n| id    | int(11)      | YES  |     | NULL    |       |\n| name  | varchar(255) | YES  |     | NULL    |       |\n| sex   | char(16)     | YES  |     | NULL    |       |\n| age   | int(11)      | YES  |     | NULL    |       |\n+-------+--------------+------+-----+---------+-------+\n4 rows in set (0.00 sec)\n\n指定添加字段的位置，加在某一个字段后可以使用after，加在第一行可以使用first关键字：\nmysql> alter table test2 add column comment varchar(255) after sex;\nQuery OK, 0 rows affected (0.68 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> desc test2;\n+---------+--------------+------+-----+---------+-------+\n| Field   | Type         | Null | Key | Default | Extra |\n+---------+--------------+------+-----+---------+-------+\n| id      | int(11)      | YES  |     | NULL    |       |\n| name    | varchar(255) | YES  |     | NULL    |       |\n| sex     | char(16)     | YES  |     | NULL    |       |\n| comment | varchar(255) | YES  |     | NULL    |       |\n| age     | int(11)      | YES  |     | NULL    |       |\n+---------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n```\n\n### 2.2 查\n\n查看所有的表：\n\n```mysql\nmysql> show tables;\n+----------------+\n| Tables_in_test |\n+----------------+\n| test1          |\n| test2          |\n+----------------+\n2 rows in set (0.00 sec)\n```\n\n使用like进行模糊匹配：\n\n```mysql\nmysql> show tables like \'%es%\';\n+-----------------------+\n| Tables_in_test (%es%) |\n+-----------------------+\n| test1                 |\n| test2                 |\n+-----------------------+\n2 rows in set (0.02 sec)\n```\n\n查看建表的时候相关信息：\n\n```python\nmysql> show create table test1\\G;\n*************************** 1. row ***************************\n       Table: test1\nCreate Table: CREATE TABLE `test1` (\n  `id` int(11) DEFAULT NULL,\n  `name` varchar(255) DEFAULT NULL,\n  `sex` char(16) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n1 row in set (0.00 sec)\n```\n\n查询表结构\n\n```mysql\nmysql> desc test1;\n+-------+--------------+------+-----+---------+-------+\n| Field | Type         | Null | Key | Default | Extra |\n+-------+--------------+------+-----+---------+-------+\n| id    | int(11)      | YES  |     | NULL    |       |\n| name  | varchar(255) | YES  |     | NULL    |       |\n| sex   | char(16)     | YES  |     | NULL    |       |\n+-------+--------------+------+-----+---------+-------+\n3 rows in set (0.00 sec)\n```\n\n### 2.3 改\n\nalter命令进行修改的操作，alter table table_name 设置对应的字段值：\n\n```mysql\nmysql> alter table test1 engine=myisam charset=gbk;\nQuery OK, 0 rows affected (0.64 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> show create table test1\\G;\n*************************** 1. row ***************************\n       Table: test1\nCreate Table: CREATE TABLE `test1` (\n  `id` int(11) DEFAULT NULL,\n  `name` varchar(255) CHARACTER SET latin1 DEFAULT NULL,\n  `sex` char(16) CHARACTER SET latin1 DEFAULT NULL\n) ENGINE=MyISAM DEFAULT CHARSET=gbk\n1 row in set (0.00 sec)\n```\n\n表名称的修改\n\n```mysql\nrename table test1 to hahahal\n\nmysql> show tables;\n+----------------+\n| Tables_in_test |\n+----------------+\n| hahahal        |\n| test2          |\n+----------------+\n2 rows in set (0.00 sec) \n\n注意，表名可以由库名.表名形式的！因此，可以跨库修改表名：只要在表名前增加库名即可\n```\n\n针对字段的定义的修改：\n\n```mysql\nalter table table_name modify column column_name 新的定义！\n\neg:\nmysql> desc test2;\n+---------+--------------+------+-----+---------+-------+\n| Field   | Type         | Null | Key | Default | Extra |\n+---------+--------------+------+-----+---------+-------+\n| id      | int(11)      | YES  |     | NULL    |       |\n| name    | varchar(255) | YES  |     | NULL    |       |\n| sex     | char(16)     | YES  |     | NULL    |       |\n| comment | varchar(255) | YES  |     | NULL    |       |\n| age     | int(11)      | YES  |     | NULL    |       |\n+---------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n\nmysql> alter table test2 modify column id char(4) after age;\nQuery OK, 0 rows affected (0.79 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> desc test2;\n+---------+--------------+------+-----+---------+-------+\n| Field   | Type         | Null | Key | Default | Extra |\n+---------+--------------+------+-----+---------+-------+\n| name    | varchar(255) | YES  |     | NULL    |       |\n| sex     | char(16)     | YES  |     | NULL    |       |\n| comment | varchar(255) | YES  |     | NULL    |       |\n| age     | int(11)      | YES  |     | NULL    |       |\n| id      | char(4)      | YES  |     | NULL    |       |\n+---------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n```\n\n修改字段名称：\n\n```mysql\nalter table table_name change column 原字段名 新字段名 新字段定义！【选项】\n注意，不是纯粹的改名，而是需要在修改定义的同时改名！\n\nmysql> desc test2;\n+---------+--------------+------+-----+---------+-------+\n| Field   | Type         | Null | Key | Default | Extra |\n+---------+--------------+------+-----+---------+-------+\n| name    | varchar(255) | YES  |     | NULL    |       |\n| sex     | char(16)     | YES  |     | NULL    |       |\n| comment | varchar(255) | YES  |     | NULL    |       |\n| age     | int(11)      | YES  |     | NULL    |       |\n| id      | char(4)      | YES  |     | NULL    |       |\n+---------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n\nmysql> alter table test2 change column name username char(128) after sex;\nQuery OK, 0 rows affected (0.77 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> desc test2;\n+----------+--------------+------+-----+---------+-------+\n| Field    | Type         | Null | Key | Default | Extra |\n+----------+--------------+------+-----+---------+-------+\n| sex      | char(16)     | YES  |     | NULL    |       |\n| username | char(128)    | YES  |     | NULL    |       |\n| comment  | varchar(255) | YES  |     | NULL    |       |\n| age      | int(11)      | YES  |     | NULL    |       |\n| id       | char(4)      | YES  |     | NULL    |       |\n+----------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n```\n\n### 2.4 删\n\n- 直接删除表\n\n```mysql\ndrop table table_name;\n```\n\n- 删除字段\n\n```mysql\nalter table table_name drop column column_name;\n```\n\n## 3、数据操作\n\n### 3.1 增\n\ninsert into 表名 (字段列表) values (与字段相对的值列表)。不一定要一次性插入所有字段，或者按照原始的字段顺序插入，但是字段要与值的数量匹配。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/38995012.jpg)\n\n如果数量不匹配的话就会报错：\n\n```mysql\nmysql> insert into test2 (sex,username,comment) values(\'male\');\nERROR 1136 (21S01): Column count doesn\'t match value count at row 1\n```\n\n当然如果要向所有的字段插入数据的话那么就可以省略字段直接添加values，同样的，要一一对应。\n\n```mysql\nmysql> insert into test2 values(\'male\',\'lamber\',\'test\',26,2);\nQuery OK, 1 row affected (0.11 sec)\n\nmysql> select * from test2;\n+------+----------+---------+------+------+\n| sex  | username | comment | age  | id   |\n+------+----------+---------+------+------+\n| male | lamber   | test    |   26 | 2    |\n+------+----------+---------+------+------+\n1 row in set (0.00 sec)\n\n也可以一条命令添加多条数据：\ninsert into test2 values(\'male\',\'lamber\',\'test\',26,2),(\'female\',\'testuser1\',\'test2\',27,1)……;\n多个数据之间都接在values后面用逗号隔开。\n```\n\n将A表里的数据插入到B表：\n\n```mysql\ninsert into tableB(name,age) select name,age from tableA\n```\n\n也是支持上面这种写法的。\n\n### 3.2 删\n\n- 清空表数据\n\n```mysql\ndelete from table_name;\ntruncate table table_name;\n\n说下二者的区别，truncate是要比delete from清空数据快的多的，DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。 简单来说delete比较慢的原因是它是一行一行删的。\n\nTRUNCATE,DELETE,DROP放在一起比较：\nTRUNCATE TABLE：删除内容、释放空间但不删除定义。\nDELETE TABLE:删除内容不删除定义，不释放空间。\nDROP TABLE：删除内容和定义，释放空间。\n```\n\n- 删除详细数据就要结合where条件语句\n\n```mysql\ndelete from 表名 where 条件;\n关于条件，可以省略。表示永远为真。注意，删除是不可逆的。要避免没有条件的删除！\n\ndelete from t_name where id > 2; [> < != = or and]\n```\n\n### 3.3 改\n\nupdate操作\n\n```mysql\nupdate 表名 set 字段=新值, 字段n=新值n where 条件\n\neg:\nmysql> update test2 set name=\'shiyue2\' where name=\'shiyue\';\nQuery OK, 1 row affected (0.30 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n\nmysql> select * from test2;\n+----+---------+------+---------+\n| id | name    | age  | comment |\n+----+---------+------+---------+\n|  1 | lamber  |   26 | test1   |\n|  2 | shiyue2 |   23 | test2   |\n+----+---------+------+---------+\n2 rows in set (0.00 sec)\n```\n\n### 3.4 查\n\n`select 字段列表 from 表名 [where 条件表达式]`\n\n其中字段列表可以使用 * 表示所有字段！\n\n```mysql\nmysql> select * from test2;\n+----+--------+------+---------+\n| id | name   | age  | comment |\n+----+--------+------+---------+\n|  1 | lamber |   26 | test1   |\n|  2 | shiyue |   23 | test2   |\n+----+--------+------+---------+\n2 rows in set (0.00 sec)\n```\n\n关于条件表达式，默认是没有，表示永远为真！但是，很少出现没有条件的情况！为了突出，应该所有的语句都有查询条件！即使没有条件，我也强制增加一个 where 1;（1表示true）\n\n```mysql\nmysql> select * from test2 where id=2;\n+----+--------+------+---------+\n| id | name   | age  | comment |\n+----+--------+------+---------+\n|  2 | shiyue |   23 | test2   |\n+----+--------+------+---------+\n1 row in set (0.00 sec)\n```\n\n## 4、数据类型\n\n```mysql\nbit[(M)]\n二进制位（101001），m表示二进制位的长度（1-64），默认m＝1\n\ntinyint[(m)] [unsigned] [zerofill]\n小整数，数据类型用于保存一些范围的整数数值范围：\n有符号：-128 ～ 127.\n无符号：～ 255\n\n特别的： MySQL中无布尔值，使用tinyint(1)构造。\n\nint[(m)][unsigned][zerofill]\n整数，数据类型用于保存一些范围的整数数值范围：\n有符号：-2147483648 ～ 2147483647\n无符号：～ 4294967295\n\n特别的：整数类型中的m仅用于显示，对存储范围无限制。例如： int(5),当插入数据2时，select 时数据显示为： 00002\n\nbigint[(m)][unsigned][zerofill]\n大整数，数据类型用于保存一些范围的整数数值范围：\n有符号：-9223372036854775808 ～ 9223372036854775807\n无符号：～  18446744073709551615\n\ndecimal[(m[,d])] [unsigned] [zerofill]\n准确的小数值，m是数字总个数，算上小数点前+小数点后面支持的总位数（负号不算），d是小数点后个数。 m最大值为65，d最大值为30。\n用法：decimal(10,5)\n特别的：对于精确数值计算时需要用此类型.decaimal能够存储精确值的原因在于其内部按照字符串存储。\n\nFLOAT[(M,D)] [UNSIGNED] [ZEROFILL]\n单精度浮点数（非准确小数值），m是数字总个数，d是小数点后个数。\n无符号：\n-3.402823466E+38 to -1.175494351E-38,\n1.175494351E-38 to 3.402823466E+38\n有符号：\n1.175494351E-38 to 3.402823466E+38\n**** 数值越大，越不准确 ****\n\nDOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]\n双精度浮点数（非准确小数值），m是数字总个数，d是小数点后个数。\n无符号：\n-1.7976931348623157E+308 to -2.2250738585072014E-308\n2.2250738585072014E-308 to 1.7976931348623157E+308\n有符号：\n2.2250738585072014E-308 to 1.7976931348623157E+308\n**** 数值越大，越不准确 ****\n\n\nchar (m)\nchar数据类型用于表示固定长度的字符串，可以包含最多达255个字符。其中m代表字符串的长度。char一上来就会开辟你指定的空间的大小。如果没有占满会填充空\nPS: 即使数据小于m长度，也会占用m长度\nvarchar(m)【节省空间，但是速度没有char快】\nvarchars数据类型用于变长的字符串，可以包含最多达255个字符。其中m代表该数据类型所允许保存的字符串的最大长度，只要长度小于该最大值的字符串都可以被保存在该数据类型中。\n\n注：虽然varchar使用起来较为灵活，但是从整个系统的性能角度来说，char数据类型的处理速度更快，有时甚至可以超出varchar处理速度的50%。因此，用户在设计数据库时应当综合考虑各方面的因素，以求达到最佳的平衡。因此定长的往前放，变长的往后放。\n\ntext\ntext数据类型用于保存变长的大字符串，可以组多到65535 (2**16 − 1)个字符。\n\nmediumtext\nA TEXT column with a maximum length of 16,777,215 (2**24 − 1) characters.\n\nlongtext\nA TEXT column with a maximum length of 4,294,967,295 or 4GB (2**32 − 1) characters.\n\nenum，枚举类型：\nAn ENUM column can have a maximum of 65,535 distinct elements. (The practical limit is less than 3000.)\n示例：\nCREATE TABLE shirts (\n    name VARCHAR(40),\n    size ENUM(\'x-small\', \'small\', \'medium\', \'large\', \'x-large\')\n);\nINSERT INTO shirts (name, size) VALUES (\'dress shirt\',\'large\'), (\'t-shirt\',\'medium\'),(\'polo shirt\',\'small\');\n\nset\n集合类型\nA SET column can have a maximum of 64 distinct members.\n示例：\n    CREATE TABLE myset (col SET(\'a\', \'b\', \'c\', \'d\'));\n    INSERT INTO myset (col) VALUES (\'a,d\'), (\'d,a\'), (\'a,d,a\'), (\'a,d,d\'), (\'d,a,d\');\n\nDATE\n    YYYY-MM-DD（1000-01-01/9999-12-31）\n\nTIME\n    HH:MM:SS（\'-838:59:59\'/\'838:59:59\'）\n\nYEAR\n    YYYY（1901/2155）\n\nDATETIME\n\n    YYYY-MM-DD HH:MM:SS（1000-01-01 00:00:00/9999-12-31 23:59:59    Y）\n\nTIMESTAMP\n\n    YYYYMMDD HHMMSS（1970-01-01 00:00:00/2037 年某时）\n    \n二进制数据类型：\n二进制数据：TinyBlob、Blob、MediumBlob、LongBlob\n```\n\n### 4.1 针对枚举和set单独拿出来说一下\n\n#### 枚举\n\n需要在定义枚举类型时，列出哪些是可能的！意义在于：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/28981298.jpg)\n\n1. 限制可以插入值的可能性，不让你随便插入值。\n2. 速度快，比普通的字符串速度快！原因是枚举型是利用整数进行管理的，能够2个字节进行管理！每个值，都是一个整数标识，从第一个选项开始为1，逐一递增！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/91520219.jpg)\n\n管理时整数的形式，速度比字符串快！2 个字节，0-65535，因此可以有 65535个选项可以使用！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/19664276.jpg)\n\nTip：注意enum(\'obj1\',\'obj2\')里面的条目要用单引号引起来。\n\n#### 集合\n\n类似于 enum枚举，在定义时，也需要指定其已有值！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/4899381.jpg)\n\n与字符串相比，优势是：\n\n1. 也是采用整数进行管理的！采用位运算，从第一位开始为1,逐一x2！\n2. 每个集合类型8个字节，64位，因此可以表示64个元素！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/80926930.jpg)\n\n```\n注意：\n站在 mysql的角度，尽量多用枚举和集合！\n但是站在python操作mysql的角度，尽量少用！（兼容性差）\n```\n\n## 5、键和约束\n\n### 5.1 主键\n\n主键的用处：保持数据的唯一性。主键不能为空\n\n一张表只能有一个主键，但是并不代表一个主键只能代表一列，我们可以指定多列联合为一个主键：\n\n```mysql\ncreate table test(\nid int unsigned not null auto_increment,\nname varchar(255) not null,\nsex char(8),\ncontent text,\nprimary key(id,name)\n) engine=innodb default charset=utf8;\n```\n\n### 5.2 外键约束\n\n约束的作用，是用于保证数据的完整性或者合理性的工具!\n\n外键：foreign key，当前表内，指向其他表的主键的字段，称之为外键！\n\n外键约束：用于限制相关联的记录在逻辑上保证合理性的约束称之为外键约束！\n\n**约束，不是字段。**\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/39334644.jpg)\n\n这样每一次写所属班级的时候不用写班级的名字，直接写班级的id，一定的程度上节省了空间。同时约束可以保证数据的一致性，导致不会让你随便写个班级id导致实际的班级找不到。\n\n首先创建两个表，添加约束。\n\n```mysql\nmysql> use test;\nDatabase changed\n\ncreate table userinfo(\nuid int unsigned auto_increment primary key,\nname varchar(32),\ndepartment_id int unsigned,\nconstraint fk_user_depart foreign key (`department_id`) references department(`id`)\n# 添加约束   约束名称        外键    （约束可以添加多个，多个约束名字不一样即可）      \n) engine=innodb default charset=utf8;\n\n\ncreate table department(\nid int unsigned auto_increment primary key,\ntitle char(15)\n) engine=innodb default charset=utf8;\nQuery OK, 0 rows affected (0.31 sec)\n\n如果建表的时候没有加的话可以后续手动加上：\nmysql> alter table userinfo add constraint fk_user_depart foreign key (`department_id`) references department(`id`);\nQuery OK, 0 rows affected (1.11 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> show create table userinfo\\G;\n*************************** 1. row ***************************\n       Table: userinfo\nCreate Table: CREATE TABLE `userinfo` (\n  `uid` int(10) unsigned NOT NULL AUTO_INCREMENT,\n  `name` varchar(32) DEFAULT NULL,\n  `department_id` int(10) unsigned DEFAULT NULL,\n  PRIMARY KEY (`uid`),\n  KEY `fk_user_depart` (`department_id`),\n  CONSTRAINT `fk_user_depart` FOREIGN KEY (`department_id`) REFERENCES `department` (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n1 row in set (0.00 sec)\n```\n\nTip：字段，键（key）用反引号引起来。\n\n被约束关联的表是无法直接删除的，比如上面图中的学生表里所属的班级表里的班级id，如果有一个外键在学生表里还有引用，那么这个班级就无法删除，必须把这个学生和这个班级id的关联取消才可以进行删除。\n\n外键的名字是不允许重复的，如果约束引用的表的主键是联合的，那么在设置约束的时候也可以设置多列。如果约束引用的表的主键不是联合主键是单列的就不可以使用这种方式了。\n\n```mysql\nCONSTRAINT `test` FOREIGN KEY (`id1`,`id2`) REFERENCES `department`(`d_id`,`s_id`) \n```\n\n## 6、索引\n\n> 索引的目标就是加速查找，比如书的目录\n>\n> - 约束不能重复（但是可以为空，但是主键不能为空）\n> - 加速查找\n\n建立索引最直观的就是加快访问速度，但是建立索引是会占用空间的，因此索引虽然加快了查找的速度但不是完全没有代价的。如果对索引进行滥用的话，虽然大大提高了查询速度，但是会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快。\n\n### 6.1 普通索引\n\n添加普通索引：\n\n```mysql\n# 修改表结构添加索引\nmysql> alter table test add index idx_id (`id`);\nQuery OK, 0 rows affected (0.34 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> show create table test\\G;\n*************************** 1. row ***************************\n       Table: test\nCreate Table: CREATE TABLE `test` (\n  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n  `name` varchar(255) NOT NULL,\n  `sex` char(8) DEFAULT NULL,\n  `content` text,\n  PRIMARY KEY (`id`,`name`),\n  KEY `idx_id` (`id`)   # 我们添加的索引\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n1 row in set (0.00 sec)\n\n\n# 添加索引\nCREATE INDEX indexName ON table_name(column(前缀长度length)); \n\n# 建表的时候添加索引\nindex index_name (column(length))\n```\n\n删除索引\n\n```mysql\ndrop index index_name on table_name;\n```\n\n### 6.2 唯一索引\n\n唯一索引可以在创建的时候添加也可以在创建以后补加，唯一索引的索引列的值可以为空，但是必须唯一，如果是组合索引，那么组合索引的值必须唯一。\n\n- 创建的时候添加\n\n```mysql\nunique 索引名称 (索引字段)\n```\n\n- 创建后补加\n\n```mysql\nALTER TABLE `table_name` ADD UNIQUE index_name (`column`(length))  # length可以不写\nCREATE UNIQUE INDEX indexName ON table_name(username(length)) \n```\n\n***\n\n上面说到的是单列索引，当然索引和是多列的，称为组合索引。如果where判定条件有一个的话那么单列索引就足够了。\n\n>有四种方式来添加数据表的索引：\n>\n>- ALTER TABLE tbl_name ADD PRIMARY KEY (column_list):  该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。\n>- **ALTER TABLE tbl_name ADD UNIQUE index_name (column_list):** 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。\n>- **ALTER TABLE tbl_name ADD INDEX index_name (column_list):** 添加普通索引，索引值可出现多次。\n>- **ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):**该语句指定了索引为 FULLTEXT ，用于全文索引。\n\n查看表索引信息：\n\n```mysql\nmysql> show index from test\\G;\n```\n\n","timestamp":1541470330295},{"name":"03-03、关于索引.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/03-03、关于索引.md","content":"http://www.cnblogs.com/aspnethot/articles/1504082.html\n\nhttp://www.cnblogs.com/hustcat/archive/2009/10/28/1591648.html\n\nhttp://www.open-open.com/lib/view/open1370089357102.html\n\nhttp://www.cnblogs.com/dreamhome/archive/2013/04/16/3025304.html\n\nhttp://blog.csdn.net/xluren/article/details/32746183\n\n# 索引\n\n- 普通索引：加速查找\n\n\n- 主键索引：加速查找，不能为空，不能重复。\n- 唯一索引：加速查找，不能重复\n- 联合索引（组合索引）：多列组合成一个索引\n  - 联合主键索引\n  - 联合唯一索引\n  - 联合普通索引\n\n```python\n### 使用pymysql创建测试数据，插入200w条数据：\n表结构：\nmysql> desc user;\n+--------+------------------+------+-----+---------+----------------+\n| Field  | Type             | Null | Key | Default | Extra          |\n+--------+------------------+------+-----+---------+----------------+\n| id     | int(10) unsigned | NO   | PRI | NULL    | auto_increment |\n| gender | char(16)         | NO   |     | NULL    |                |\n| age    | int(10) unsigned | NO   |     | NULL    |                |\n| name   | varchar(32)      | NO   |     | NULL    |                |\n+--------+------------------+------+-----+---------+----------------+\n\n# 模拟数据的Python脚本\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport pymysql\nimport random\n\n# make a generator\ncreate_user = (x for x in range(2000000))\n\n# connect to the mysqld\nconn = pymysql.connect(host=\'192.168.171.10\',user=\'maxiaoyu\',password=\'13082171785\',database=\'indextest\')\n\n# tools to get data\ncursor = conn.cursor()\nprint(cursor.__dict__)\nsql = \"insert into user(gender,age,name) values(%s,%s,%s)\"\n\n\nfor user in create_user:\n    user_name = \'testuser\'+str(user)\n    cursor.execute(sql,(random.choice([\'male\',\'female\']),random.randint(1,100),user_name))\n    conn.commit()\n\n\ncursor.close()\nconn.close()\n```\n\n速度测试：\n\n```mysql\nmysql> select * from user where name=\'testuser1111232\';  \n+---------+--------+-----+-----------------+\n| id      | gender | age | name            |\n+---------+--------+-----+-----------------+\n| 1111237 | male   |   2 | testuser1111232 |\n+---------+--------+-----+-----------------+\n1 row in set (1.31 sec)\n\n\nmysql> select * from user where id=\'1111232\'; \n+---------+--------+-----+-----------------+\n| id      | gender | age | name            |\n+---------+--------+-----+-----------------+\n| 1111232 | female |  18 | testuser1111227 |\n+---------+--------+-----+-----------------+\n1 row in set (0.04 sec)\n```\n\n观察这个可以发现通过id查询的效率是非常高的仅有0.04s，但是通过name查找则会发现有1.31s。因为我们为id添加了主键索引了。\n\n> ##### 如何去理解索引：\n>\n> 索引可以理解为字典或者书的目录，我们可以认为计算机很笨，在没有索引的情况下它去翻阅一本字典取找一个字只能一页一页一行一行的从头翻到尾，如果要找的字在前面还好，如果要找到的字在最后那真的就是从头翻到尾了。\n>\n> 为了能够更好的查找数据我们添加了索引（index），其实也就是目录的意思，添加一个目录，我们没有必要去知道所有的内容，只看针对某一个字段或者某一部分的关键字就可以知道我们要找的内容在哪里。就好比可以根据拼音首字母，或者根据笔画去查，可以很快的根据索引定位到多少页。索引可以帮我们定位数据在表中的位置。当然创建索引（做目录的时候）也是需要一定的时间的，当数据量够大的时候会发现创建索引也是挺慢的。\n>\n> 当然就如大家所知道的，一本字典很厚，索引页也占用好几十页的空间，也就是说索引不是凭空的，而是真实的占用空间的，如果不恰当的使用索引就会导致索引的内容非常大，想想一下一本书，目录就占了半本，我为什么不直接去翻正文呢？\n\n创建普通索引的方法：\n\n```mysql\ncreate index name_index on user (name); \ncreate index 索引名     on 表 (column(length)……)\n```\n\n### 索引种类\n\n#### hash索引：索引表\n\n会把对应的列的数据转换成hash值放到一个表里，同时把对应的hash值对应的数据的存储地址也记录上。当对应的hash值被匹配到了以后就会直接去找这个数据所在的地址，然后通过游标直接跳过去即可。\n\n当然索引表是有一个缺陷的，在找**单值**的时候速度很快，但是如果去匹配一个条件，比如id>102321这样的就会比较慢了，因为索引表存储的索引信息其实是无序的。对于这样非单值的查找比如连续性的范围就很耗费时间了。\n\n#### BTree索引（innodb引擎）\n\n二叉树，具体二叉树相关内容请参考：\n\n\n\n建立索引：\n\n- 额外的文件保存特殊的数据结构\n- ​","timestamp":1541470330295},{"name":"04-04、mysql进阶.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/04-04、mysql进阶.md","content":"#  \n\n## 1、实体之间的关系\n\n多个是体表应该如何设计！\n\n### 实体之间存在哪些关系？\n\n```\n班级，学生两类实体！(一个班级对应多个学生实体，多个学生实体对应一个班级实体)\n一对多，多对一，1:N, N:1\n \n班级，讲师两类实体！（一个讲师可以在多个班级任教，反过来也是一样的。）\n多对多，M：N\n \n学生常用信息，学生不常用信息（学生与自己个人信息的肯定是一一对应的）\n一对一，1：1\n```\n\n### 如何设计？\n\n#### 多对一，一对多\n\n在多的那端（那个表内），增加一个字段，用于保存于当前记录相关联的一端记录的主键！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-27/92928316.jpg)\n\n#### 多对多\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-27/74244288.jpg)\n\n增加一个专门管理关联的表，使班级与讲师都与关连表存在联系。从而是两个实体间有多对多的关系！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-27/81487.jpg)\n\n因此，一个多对多，会拆分成两个多对一！这里的班级id和讲师id都应该是foreign key，同时应该还应该做一个联合唯一，因为这种关系对应有一个就够了。\n\n### 一对一\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-27/54806190.jpg)\n\n可见，两个表之间存在相同的主键ID即可！也可以做外键+唯一约束。外键保证这个用户真实存在，唯一约束保证不为空且不重复。\n\n## 2、mysql语句扩展\n\n- 在查询的时候给字段起别名：\n\n```mysql\nmysql> desc test;\n+---------+------------------+------+-----+---------+----------------+\n| Field   | Type             | Null | Key | Default | Extra          |\n+---------+------------------+------+-----+---------+----------------+\n| id      | int(10) unsigned | NO   | PRI | NULL    | auto_increment |\n| name    | varchar(255)     | NO   | PRI | NULL    |                |\n| sex     | char(8)          | YES  |     | NULL    |                |\n| content | text             | YES  |     | NULL    |                |\n+---------+------------------+------+-----+---------+----------------+\n4 rows in set (0.00 sec)\n\n\nmysql> select name as testname,sex from test;\n+----------+--------+\n| testname | sex    |\n+----------+--------+\n| user1    | male   |\n| user2    | female |\n+----------+--------+\n2 rows in set (0.00 sec)\n```\n\n也可以在查询后加额外的一列，比如：\n\n```mysql\nmysql> select name,sex,123 from test;\n+-------+--------+-----+\n| name  | sex    | 123 |\n+-------+--------+-----+\n| user1 | male   | 123 |\n| user2 | female | 123 |\n+-------+--------+-----+\n2 rows in set (0.00 sec)\n\n那么这玩意有什么用呢？\n```\n\n### 2.1 查询深入\n\n```mysql\nselect * from table where id > 2\nselect * from table where id < 2\nselect * from table where id = 2\nselect * from table where id != 2\nselect * from table where id <> 2\nselect * from table where id > 2 and name=\'xxx\'\nselect * from table where id > 100 or id=30 or id=20 or id=40;\nselect * from table where id in (20,30,40)\nselect * from table where id in (select nid from table_name) # 子查询\nselect * from table where id not in (20,30,40)\nselect * from table where id between 6 and 12; # 这个锁定的范围是闭区间\nselect * from table limit 10; # 查看前10条\nselect * from table limit 0,2; # 从第一条开始取（位置），往后取两条（数量）\nselect * from table limit 20 offset 10; # 取20条，从第11个位置开始\n\n如何取到后10条？那么就先顺序倒过来，然后再limit 10就可以了。\n```\n\n### 2.2 排序（order by）\n\n```mysql\nselect * from table order by id desc; # 倒序\nselect * from table order by id asc;  # 正序\n\n# 当按照一列的规则进行排序的时候有可能有重复的，针对相同的这一些按照列2的规则排\nselect * from 表 order by 列1 desc,列2 asc\n```\n\n### 2.3 分组\n\n```mysql\n首先说说分组能干啥，比如有很多学生，他们都有自己所属的班级id，那么我只要：\nselect class_id,max(stu_id) from stu group by class_id=\'xxx\'\n就可以以班级id为标准把id一样的人分组给分出来,返回的结果重复的去掉。取出来的id去重复内容条目中的最大的。\n\n- max:取最大值\n- min：去最小值\n- count：取总数\n- sum：求和\n- avg：取平均值\n\nselect num from 表 group by num\nselect num,nid from 表 group by num,nid\nselect num,nid from 表  where nid > 10 group by num,nid order nid desc\nselect num,nid,count(*),sum(score),max(score),min(score) from 表 group by num,nid\n \nselect num from 表 group by num having max(id) > 10\n\n特别的：group by 必须在where之后，order by之前\n```\n\n### 2.4 表链接\n\n```mysql\n无对应关系则不显示\nselect A.num, A.name, B.name\nfrom A,B\nWhere A.nid = B.nid\n\n无对应关系则不显示\nselect A.num, A.name, B.name\nfrom A inner join B\non A.nid = B.nid\n\nA表所有显示，如果B中无对应关系，则值为null\nselect A.num, A.name, B.name\nfrom A left join B\non A.nid = B.nid\n\nB表所有显示，如果B中无对应关系，则值为null\nselect A.num, A.name, B.name\nfrom A right join B\non A.nid = B.nid\n```\n\n#### 2.4.1 简单连接\n\n```mysql\nmysql> select * from student;\n+----+--------+\n| id | name   |\n+----+--------+\n|  1 | 张三   |\n|  2 | 李四   |\n|  3 | 王二   |\n+----+--------+\n3 rows in set (0.00 sec)\n\nmysql> select * from course;\n+----+--------+\n| id | cname  |\n+----+--------+\n|  1 | 足球   |\n|  2 | 音乐   |\n|  3 | 美术   |\n+----+--------+\n3 rows in set (0.00 sec)\n```\n\n简单的表连接\n\n```mysql\nmysql> select * from student,course;\n+----+--------+----+--------+\n| id | name   | id | cname  |\n+----+--------+----+--------+\n|  1 | 张三   |  1 | 足球   |\n|  2 | 李四   |  1 | 足球   |\n|  3 | 王二   |  1 | 足球   |\n|  1 | 张三   |  2 | 音乐   |\n|  2 | 李四   |  2 | 音乐   |\n|  3 | 王二   |  2 | 音乐   |\n|  1 | 张三   |  3 | 美术   |\n|  2 | 李四   |  3 | 美术   |\n|  3 | 王二   |  3 | 美术   |\n+----+--------+----+--------+\n9 rows in set (0.00 sec)\n```\n\n可以看到简单的表连接是对两个表做了笛卡尔积。\n\n> 笛卡尔积：\n>\n> ![](http://omk1n04i8.bkt.clouddn.com/17-9-28/87001516.jpg)\n>\n> 依次做匹配，比如樱木给一个前锋位置给一个后卫位置，其他人同理。\n\n不过当然平常的情况下我们并不会这样去做，而是建立在某种条件的约束下进行表连接\n\n```mysql\nmysql> select * from student,course where student.id=course.id;\n+----+--------+----+--------+\n| id | name   | id | cname  |\n+----+--------+----+--------+\n|  1 | 张三   |  1 | 足球   |\n|  2 | 李四   |  2 | 音乐   |\n|  3 | 王二   |  3 | 美术   |\n+----+--------+----+--------+\n3 rows in set (0.00 sec)\n```\n\n当然上面这个例子很不合适，但是代表了是建立在某种约束下查询出来的。\n\n#### 2.4.2 Join连接\n\n>http://www.blogjava.net/GavinMiao/archive/2011/10/20/361640.html\n>\n>http://blog.163.com/xueling1231989@126/blog/static/102640807201231493651609/\n>\n>http://www.cnblogs.com/stone-d/p/7258340.html\n>\n>http://www.cnblogs.com/qiuqiuqiu/p/6442791.html\n>\n>http://blog.163.com/li_hx/blog/static/18399141320141127102622383/\n>\n>\n\n\n\nJoin连接类型，可分为三种：\n\n- 内连接（inner）\n- 外连接（outer）\n- 交叉连接（cross）\n\n##### 内连接\n\n\n\n\n\n内连接(INNER JOIN)使用比\n\n较运算符进行表间某(些)列数据的比较操作，并列出这些表中与连接条件相匹配的数据行。根据所使用\n\n的比较方式不同，内连接又分为等值连接、自然连接和不等连接三种。\n\n外连接分为左外连接(LEFT OUTER JOIN或LEFT JOIN)、右外连接(RIGHT OUTER JOIN或RIGHT JOIN)\n\n和全外连接(FULL OUTER JOIN或FULL JOIN)三种。与内连接不同的是，外连接不只列出与连接条件相匹\n\n配的行，而是列出左表(左外连接时)、右表(右外连接时)或两个表(全外连接时)中所有符合搜索条件的\n\n数据行。\n\n交叉连接(CROSS JOIN)没有WHERE 子句，它返回连接表中所有数据行的笛卡尔积，其结果集合中的\n\n数据行数等于第一个表中符合查询条件的数据行数乘以第二个表中符合查询条件的数据行数。\n\n连接操作中的ON (join_condition) 子句指出连接条件，它由被连接表中的列和比较运算符、逻辑\n\n运算符等构成。\n\n无论哪种连接都不能对text、ntext和image数据类型列进行直接连接，但可以对这三种列进行间接\n\n连接。\n\n","timestamp":1541470330295},{"name":"07-07、SQL优化.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/07-07、SQL优化.md","content":"http://blog.csdn.net/hguisu/article/details/5731629","timestamp":1541470330295},{"name":"08-08、数据库优化.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/08-08、数据库优化.md","content":"","timestamp":1541470330295},{"name":"22-22、Mysql练习.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/22-22、Mysql练习.md","content":"# Mysql Exercise\n\n> 请创建如下表，并创建相关约束\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/59526112.jpg)\n\n1、自行创建测试数据\n\n```mysql\n/*\n Navicat Premium Data Transfer\n\n Source Server         : localhost\n Source Server Type    : MySQL\n Source Server Version : 50624\n Source Host           : localhost\n Source Database       : sqlexam\n\n Target Server Type    : MySQL\n Target Server Version : 50624\n File Encoding         : utf-8\n\n Date: 10/21/2016 06:46:46 AM\n*/\n\nSET NAMES utf8;\nSET FOREIGN_KEY_CHECKS = 0;\n\n-- ----------------------------\n--  Table structure for `class`\n-- ----------------------------\nDROP TABLE IF EXISTS `class`;\nCREATE TABLE `class` (\n  `cid` int(11) NOT NULL AUTO_INCREMENT,\n  `caption` varchar(32) NOT NULL,\n  PRIMARY KEY (`cid`)\n) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `class`\n-- ----------------------------\nBEGIN;\nINSERT INTO `class` VALUES (\'1\', \'三年二班\'), (\'2\', \'三年三班\'), (\'3\', \'一年二班\'), (\'4\', \'二年九班\');\nCOMMIT;\n\n-- ----------------------------\n--  Table structure for `course`\n-- ----------------------------\nDROP TABLE IF EXISTS `course`;\nCREATE TABLE `course` (\n  `cid` int(11) NOT NULL AUTO_INCREMENT,\n  `cname` varchar(32) NOT NULL,\n  `teacher_id` int(11) NOT NULL,\n  PRIMARY KEY (`cid`),\n  KEY `fk_course_teacher` (`teacher_id`),\n  CONSTRAINT `fk_course_teacher` FOREIGN KEY (`teacher_id`) REFERENCES `teacher` (`tid`)\n) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `course`\n-- ----------------------------\nBEGIN;\nINSERT INTO `course` VALUES (\'1\', \'生物\', \'1\'), (\'2\', \'物理\', \'2\'), (\'3\', \'体育\', \'3\'), (\'4\', \'美术\', \'2\');\nCOMMIT;\n\n-- ----------------------------\n--  Table structure for `score`\n-- ----------------------------\nDROP TABLE IF EXISTS `score`;\nCREATE TABLE `score` (\n  `sid` int(11) NOT NULL AUTO_INCREMENT,\n  `student_id` int(11) NOT NULL,\n  `course_id` int(11) NOT NULL,\n  `num` int(11) NOT NULL,\n  PRIMARY KEY (`sid`),\n  KEY `fk_score_student` (`student_id`),\n  KEY `fk_score_course` (`course_id`),\n  CONSTRAINT `fk_score_course` FOREIGN KEY (`course_id`) REFERENCES `course` (`cid`),\n  CONSTRAINT `fk_score_student` FOREIGN KEY (`student_id`) REFERENCES `student` (`sid`)\n) ENGINE=InnoDB AUTO_INCREMENT=53 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `score`\n-- ----------------------------\nBEGIN;\nINSERT INTO `score` VALUES (\'1\', \'1\', \'1\', \'10\'), (\'2\', \'1\', \'2\', \'9\'), (\'5\', \'1\', \'4\', \'66\'), (\'6\', \'2\', \'1\', \'8\'), (\'8\', \'2\', \'3\', \'68\'), (\'9\', \'2\', \'4\', \'99\'), (\'10\', \'3\', \'1\', \'77\'), (\'11\', \'3\', \'2\', \'66\'), (\'12\', \'3\', \'3\', \'87\'), (\'13\', \'3\', \'4\', \'99\'), (\'14\', \'4\', \'1\', \'79\'), (\'15\', \'4\', \'2\', \'11\'), (\'16\', \'4\', \'3\', \'67\'), (\'17\', \'4\', \'4\', \'100\'), (\'18\', \'5\', \'1\', \'79\'), (\'19\', \'5\', \'2\', \'11\'), (\'20\', \'5\', \'3\', \'67\'), (\'21\', \'5\', \'4\', \'100\'), (\'22\', \'6\', \'1\', \'9\'), (\'23\', \'6\', \'2\', \'100\'), (\'24\', \'6\', \'3\', \'67\'), (\'25\', \'6\', \'4\', \'100\'), (\'26\', \'7\', \'1\', \'9\'), (\'27\', \'7\', \'2\', \'100\'), (\'28\', \'7\', \'3\', \'67\'), (\'29\', \'7\', \'4\', \'88\'), (\'30\', \'8\', \'1\', \'9\'), (\'31\', \'8\', \'2\', \'100\'), (\'32\', \'8\', \'3\', \'67\'), (\'33\', \'8\', \'4\', \'88\'), (\'34\', \'9\', \'1\', \'91\'), (\'35\', \'9\', \'2\', \'88\'), (\'36\', \'9\', \'3\', \'67\'), (\'37\', \'9\', \'4\', \'22\'), (\'38\', \'10\', \'1\', \'90\'), (\'39\', \'10\', \'2\', \'77\'), (\'40\', \'10\', \'3\', \'43\'), (\'41\', \'10\', \'4\', \'87\'), (\'42\', \'11\', \'1\', \'90\'), (\'43\', \'11\', \'2\', \'77\'), (\'44\', \'11\', \'3\', \'43\'), (\'45\', \'11\', \'4\', \'87\'), (\'46\', \'12\', \'1\', \'90\'), (\'47\', \'12\', \'2\', \'77\'), (\'48\', \'12\', \'3\', \'43\'), (\'49\', \'12\', \'4\', \'87\'), (\'52\', \'13\', \'3\', \'87\');\nCOMMIT;\n\n-- ----------------------------\n--  Table structure for `student`\n-- ----------------------------\nDROP TABLE IF EXISTS `student`;\nCREATE TABLE `student` (\n  `sid` int(11) NOT NULL AUTO_INCREMENT,\n  `gender` char(1) NOT NULL,\n  `class_id` int(11) NOT NULL,\n  `sname` varchar(32) NOT NULL,\n  PRIMARY KEY (`sid`),\n  KEY `fk_class` (`class_id`),\n  CONSTRAINT `fk_class` FOREIGN KEY (`class_id`) REFERENCES `class` (`cid`)\n) ENGINE=InnoDB AUTO_INCREMENT=17 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `student`\n-- ----------------------------\nBEGIN;\nINSERT INTO `student` VALUES (\'1\', \'男\', \'1\', \'理解\'), (\'2\', \'女\', \'1\', \'钢蛋\'), (\'3\', \'男\', \'1\', \'张三\'), (\'4\', \'男\', \'1\', \'张一\'), (\'5\', \'女\', \'1\', \'张二\'), (\'6\', \'男\', \'1\', \'张四\'), (\'7\', \'女\', \'2\', \'铁锤\'), (\'8\', \'男\', \'2\', \'李三\'), (\'9\', \'男\', \'2\', \'李一\'), (\'10\', \'女\', \'2\', \'李二\'), (\'11\', \'男\', \'2\', \'李四\'), (\'12\', \'女\', \'3\', \'如花\'), (\'13\', \'男\', \'3\', \'刘三\'), (\'14\', \'男\', \'3\', \'刘一\'), (\'15\', \'女\', \'3\', \'刘二\'), (\'16\', \'男\', \'3\', \'刘四\');\nCOMMIT;\n\n-- ----------------------------\n--  Table structure for `teacher`\n-- ----------------------------\nDROP TABLE IF EXISTS `teacher`;\nCREATE TABLE `teacher` (\n  `tid` int(11) NOT NULL AUTO_INCREMENT,\n  `tname` varchar(32) NOT NULL,\n  PRIMARY KEY (`tid`)\n) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `teacher`\n-- ----------------------------\nBEGIN;\nINSERT INTO `teacher` VALUES (\'1\', \'张磊老师\'), (\'2\', \'李平老师\'), (\'3\', \'刘海燕老师\'), (\'4\', \'朱云海老师\'), (\'5\', \'李杰老师\');\nCOMMIT;\n\nSET FOREIGN_KEY_CHECKS = 1;\n\n表结构和数据\n```\n\n2、查询“生物”课程比“物理”课程成绩高的所有学生的学号；\n\n```mysql\nselect A.student_id from \n(select score.sid,score.student_id,course.cname,score.num from score LEFT JOIN course on score.course_id=course.cid where course.cname=\'生物\' ) as A\nINNER JOIN \n(select score.sid,score.student_id,course.cname,score.num from score LEFT JOIN course on score.course_id=course.cid where course.cname=\'物理\' ) as B\non A.student_id=B.student_id where A.num>B.num\n```\n\n3、查询平均成绩大于60分的同学的学号和平均成绩； \n\n```mysql\nselect temp.student_id,student.sname,temp.number from (select student_id,avg(num) as number from score  GROUP BY student_id having number > 60) as temp LEFT JOIN student on temp.student_id=sid;\n```\n\n4、查询所有同学的学号、姓名、选课数、总成绩；\n\n```mysql\nselect score.student_id,student.sname,count(score.student_id),sum(score.num) from score LEFT JOIN\nstudent on score.student_id=student.sid\nGROUP BY score.student_id\n```\n\n5、查询姓“李”的老师的个数；\n\n```mysql\nselect * from teacher where t_name like \'李%\';\n```\n\n6、查询没学过“叶平”老师课的同学的学号、姓名；\n\n```mysql\nselect student.sid,student.sname from student where sid not in (\nselect student_id from score where score.course_id  in \n(select cid from course LEFT JOIN teacher on course.teacher_id=teacher.tid where tname=\'李平老师\')\nGROUP BY student_id\n)\n```\n\n7、查询学过“001”并且也学过编号“002”课程的同学的学号、姓名；\n\n```mysql\nselect student_id,student.sname as count from score \nLEFT JOIN student on score.student_id=student.sid\nwhere course_id=1 or course_id=2 GROUP BY student_id HAVING count(student_id) > 1\n```\n\n8、查询学过“叶平”老师所教的所有课的同学的学号、姓名；\n\n```mysql\nselect score.student_id,student.sname from score \nLEFT JOIN student on score.student_id=student.sid\nwhere course_id in \n(select cid from course \nLEFT JOIN teacher on \ncourse.teacher_id=teacher.tid WHERE teacher.tname=\'李平老师\')\nGROUP BY student_id having COUNT(course_id) = \n(select count(cid) from course \nLEFT JOIN teacher on \ncourse.teacher_id=teacher.tid WHERE teacher.tname=\'李平老师\')\n```\n\n9、查询课程编号“002”的成绩比课程编号“001”课程低的所有同学的学号、姓名；\n\n```mysql\nselect A.student_id,student.sname from \n(select * from score LEFT JOIN course on score.course_id=course.cid where course.cid=1) as A\nINNER JOIN\n(select * from score LEFT JOIN course on score.course_id=course.cid where course.cid=2) as B\non A.student_id=B.student_id\nLEFT JOIN student on A.student_id=student.sid\nwhere A.num > B.num\n```\n\n10、查询有课程成绩小于60分的同学的学号、姓名；\n\n```mysql\nselect student.sid,student.sname from score\nLEFT JOIN student on student.sid=score.student_id\nwhere score.num < 60\nGROUP BY sid\n\n或者使用distinct\n\nselect DISTINCT student.sid,student.sname from score\nLEFT JOIN student on student.sid=score.student_id\nwhere score.num < 60\n\n但是distinct效率并不是很高，能少用就少用。\n```\n\n11、查询没有学全所有课的同学的学号、姓名；\n\n```mysql\n-- 以后要么count主键，要么就count1\nselect student_id,student.sname as count_num from score\nLEFT JOIN student on score.student_id=student.sid\nGROUP BY student_id\nHAVING count(1) < (select count(1) from course)\n```\n\n12、查询至少有一门课与学号为“001”的同学所学相同的同学的学号和姓名；\n\n```mysql\n-- 假如001学了3门课程，只要001学过的任何一门课程我学过，那么我就是符合条件的。\nselect student_id,sname from score \nLEFT JOIN student on score.student_id=student.sid\nwhere student.sid <> 1 and score.course_id in\n(select course.cid from score \nLEFT JOIN course on score.course_id=course.cid\nwhere student_id=1)\nGROUP BY student_id\n```\n\n13、查询至少学过学号为“001”同学所有课的**其他同学**学号和姓名；\n\n```mysql\nselect student_id,sname from score \nLEFT JOIN student on score.student_id=student.sid\nwhere student.sid <> 1 and score.course_id in\n(select course.cid from score \nLEFT JOIN course on score.course_id=course.cid\nwhere student_id=1)\nGROUP BY student_id \nhaving count(1)=(select count(score.course_id) from score where student_id = 1)\n```\n\n14、查询和“002”号的同学学习的课程完全相同的其他同学学号和姓名；\n\n```mysql\n-- 先把和002选择个数一样的，再把不在002选择课程内的剔除\nselect student_id,sname from score LEFT JOIN student on score.student_id=student.sid\nwhere student_id in \n(select student_id from score where student_id <> 1 GROUP BY student_id HAVING count(1) = (select count(1) from score where student_id=1))\nand course_id in (select course_id from score where student_id=1)\nGROUP BY student_id HAVING count(1) = (select count(1) from score where student_id=1)\n```\n\n15、删除学习“李平”老师课的SC表记录；\n\n```mysql\nDELETE from score where score.course_id in \n(select cid from course LEFT JOIN teacher on course.teacher_id=teacher.tid where tname=\'李平老师\')\n```\n\n16、向Score表中插入一些记录，这些记录要求符合以下条件：①没有上过编号“002”课程的同学学号；②插入“002”号课程的平均成绩； \n\n```mysql\ninsert into score(student_id,course_id,num)\nselect student_id,2,(select avg(num) from score where course_id=2) from score where course_id!=2\n```\n\n17、按平均成绩从低到高显示所有学生的“语文”、“数学”、“英语”三门的课程成绩，按如下形式显示： 学生ID,语文,数学,英语,有效课程数,有效平均分；\n\n```mysql\nselect \n   student_id as \'学生ID\',\n   (select num from score as s2 where s2.student_id=s1.student_id and course_id=1) as \'语文\',\n   (select num from score as s2 where s2.student_id=s1.student_id and course_id=2) as \'数学\',\n   (select num from score as s2 where s2.student_id=s1.student_id and course_id=3) as \'英语\'\nfrom score as s1;\n```\n\n18、查询各科成绩最高和最低的分：以如下形式显示：课程ID，最高分，最低分；\n\n```mysql\nselect course_id,max(num),min(num) from score GROUP BY course_id\n\n假如说要求最低分小于10的就显示0那么可以写成如下的：\nselect course_id,max(num),min(num),case when min(num)<10 then 0 else min(num) end from score GROUP BY course_id\n```\n\n19、按各科平均成绩从低到高和及格率的百分数从高到低顺序；\n\n```mysql\nselect course_id,AVG(num),sum(case when num<60 then 0 else 1 end),sum(1),sum(case when num<60 then 0 else 1 end)/sum(1) as jigelv from score GROUP BY course_id ORDER BY avg(num) asc,jigelv desc\n```\n\n20、课程平均分从高到低显示（显示任课老师）；\n\n```mysql\nselect score.course_id,course.cname,avg(IF(ISNULL(score.num),0,score.num)),teacher.tname from score \nLEFT JOIN course on score.course_id=course.cid \nLEFT JOIN teacher on teacher.tid=course.teacher_id\nGROUP BY score.course_id order by avg(num) desc\n\n# 三目运算符，如果score.num为null的话（也就是范围为true，那么给个默认值为0.否则为score.num）\n```\n\n21、查询各科成绩前三名的记录:(不考虑成绩并列情况) \n\n```mysql\n\n```\n\n22、查询每门课程被选修的学生数；\n\n```mysql\nselect course_id, count(1) from score group by course_id;\n```\n\n23、查询出只选修了一门课程的全部学生的学号和姓名；\n\n```mysql\nselect student_id,sname,count(1) as num from score \nLEFT JOIN student on score.student_id=student.sid\nGROUP BY student_id having num=1\n```\n\n24、查询男生、女生的人数；\n\n```mysql\nselect gender,count(1) from student group by gender\n```\n\n25、查询姓“张”的学生名单；\n\n```mysql\nselect sname from student where sname like \'张%\';\n```\n\n26、查询同名同姓学生名单，并统计同名人数；\n\n```mysql\nselect sname,count(1) as count from student group by sname;\n```\n\n27、查询每门课程的平均成绩，结果按平均成绩升序排列，平均成绩相同时，按课程号降序排列；\n\n```mysql\nselect course_id,avg(if(isnull(num), 0 ,num)) as avg from score group by course_id order by avg asc,course_id desc;\n```\n\n28、查询平均成绩大于85的所有学生的学号、姓名和平均成绩；\n\n```mysql\nselect student_id,sname, avg(if(isnull(num), 0 ,num)) as avgnum from score left join student on score.student_id = student.sid group by student_id having avgnum > 85\n```\n\n29、查询课程名称为“数学”，且分数低于60的学生姓名和分数；\n\n```mysql\nselect student.sname,A.num from student join (\nselect student_id,num from score left join course on score.course_id = course.cid\nwhere cname=\'生物\' and num < 60\n) as A\non student.sid = A.student_id\n\n-- 或者\n\nselect student.sname,score.num from score\nleft join course on score.course_id = course.cid\nleft join student on score.student_id = student.sid\nwhere score.num < 60 and course.cname = \'生物\'\n```\n\n30、查询课程编号为003且课程成绩在80分以上的学生的学号和姓名； \n\n```mysql\nselect * from score where score.student_id = 3 and score.num > 80\n```\n\n31、求选了课程的学生人数\n\n```mysql\n-- 1、\nselect count(c) from \n(\nselect count(student_id) as c from score group by student_id\n) as A\n\n-- 2、\nselect count(distinct student_id) from score\n```\n\n32、查询选修“张磊”老师所授课程的学生中，成绩最高的学生姓名及其成绩；\n\n```mysql\nselect sname,num from score\nleft join student on score.student_id = student.sid\nwhere score.course_id in \n(\nselect course.cid from course \nleft join teacher on course.teacher_id = teacher.tid \nwhere tname=\'张磊老师\'\n) order by num desc limit 1;\n```\n\n33、查询各个课程及相应的选修人数；\n\n```mysql\nselect course.cname,count(course_id) from score left join course\non score.course_id = course.cid\nGROUP BY course.cid\n```\n\n*34、查询不同课程但成绩相同的学生的学号、课程号、学生成绩；\n\n```mysql\nselect DISTINCT s1.course_id,s2.course_id,s1.num,s2.num from score as s1, score as s2 where s1.num = s2.num and s1.course_id != s2.course_id;\n```\n\n*35、查询每门课程成绩最好的前两名；\n\n```mysql\nselect score.sid,score.course_id,score.num,T.first_num,T.second_num from score left join\n(\nselect\n    sid,\n    (select num from score as s2 where s2.course_id = s1.course_id order by num desc limit 0,1) as first_num,\n    (select num from score as s2 where s2.course_id = s1.course_id order by num desc limit 1,1) as second_num\n    from\n        score as s1\n) as T\n    on score.sid =T.sid\n    where score.num <= T.first_num and score.num >= T.second_num\n```\n\n36、检索至少选修两门课程的学生学号；\n\n```mysql\nselect student_id from score group by student_id having count(student_id) > 1\n```\n\n37、查询全部学生都选修的课程的课程号和课程名；\n\n```mysql\n-- 找到学生的总数，哪一门课的成绩统计数=课程总数就证明，这门课所有人都学习了\nselect course_id,count(1) from score group by course_id having count(1) = (select count(1) from student);\n```\n\n38、查询没学过“叶平”老师讲授的任一门课程的学生姓名；\n\n```mysql\nselect student_id,student.sname from score\nleft join student on score.student_id = student.sid\nwhere score.course_id not in \n(\n-- 首先获取到\nselect cid from course left join teacher on course.teacher_id = teacher.tid where tname = \'张磊老师\'\n)\ngroup by student_id\n```\n\n39、查询两门以上不及格课程的同学的学号及其平均成绩；\n\n```mysql\nselect student_id,count(1) from score where num < 60 group by student_id having count(1) > 2\n```\n\n40、检索“004”课程分数小于60，按分数降序排列的同学学号；\n\n```mysql\nselect student_id from score where course_id = 4 and num < 60 order by num desc;\n```\n\n41、删除“002”同学的“001”课程的成绩；\n\n```mysql\ndelete from score where course_id = 1 and student_id = 2;\n```\n\n","timestamp":1541470330295},{"name":"24-24、视图.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/24-24、视图.md","content":"# 视图\n\n>视图是一个虚拟表（非真实存在），其本质是【根据SQL语句获取动态的数据集，并为其命名】，用户使用时只需使用【名称】即可获取结果集，并可以将其当作表来使用。\n\n临时表取一个别名，也是我们查询出来的，但是这个表并不是真实存在的。因此给某一个查询语句设置别名，日后方便使用，创建的这个别名的行为就是创建一个视图。别名也就是视图的名称。\n\n```mysql\n# 创建视图\ncreate view as v1 select * from student where sid>10;\n# 以后直接搜索视图就可以了\nselect * from v1\n```\n\n视图是虚拟的，动态的从真实表中读取出来放到内存中，因此视图不能增删改，这个是不允许的，而且如果数据源表进行了更改以后，视图结果也会跟着改变。\n\n修改视图：\n\n```mysql\n# 修改视图\nalter view view_name as new_sql\n# 删除视图\ndrop view view_name\n```\n\nTip：在开发中并不常用~开发中就直接写子查询，写在代码里","timestamp":1541470330295},{"name":"25-25、触发器.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/25-25、触发器.md","content":"# 触发器\n\n> 触发器在开发中也并不是很常用\n\n情境：用户注册，每注册一个插入用的同时要去日志表插入一条数据。针对这个问题，在程序级别上，可以分两步进行操作，用户注册的同时，分别向两个表里插入数据，当然这里也可以使用触发器。\n\n### 触发器创建基本语法\n\n```mysql\nBEFORE ：在xxx操作之前\nAFTER  ：在XXX操作之后\nFOR EACH ROW ：操作每一行的时候触发器就会执行一遍\n\n# 插入前\nCREATE TRIGGER tri_before_insert_tb1 BEFORE INSERT ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 插入后\nCREATE TRIGGER tri_after_insert_tb1 AFTER INSERT ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 删除前\nCREATE TRIGGER tri_before_delete_tb1 BEFORE DELETE ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 删除后\nCREATE TRIGGER tri_after_delete_tb1 AFTER DELETE ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 更新前\nCREATE TRIGGER tri_before_update_tb1 BEFORE UPDATE ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 更新后\nCREATE TRIGGER tri_after_update_tb1 AFTER UPDATE ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n```\n\n可以发现唯独查询的时候，没有触发操作。\n\n```mysql\ndelimiter //\ncreate trigger t1 before insert on student for each ROW\nBEGIN\n  INSERT into teacher(tname) values(\'hahaha\');\nEND //\ndelimiter ;\n\n# 语句中的触发语句用分号去分割，因此如果使用默认的分隔符，到END之前就会终止\n# 因此我们要使用delimiter先去指定其他的分隔符，比如指定//\n# 在执行完了以后还要将分隔符设置回来，不影响其他人使用\n```\n\n比如说触发器执行增删改操作的时候触发操作的数据要和用户增删改的数据关联，那么久需要用到如下的两个参数：\n\n- NEW：指的是新插入的数据，一整行\n- OLD：指的是即将删除的数据行\n\n针对insert和update操作的时候用到NEW，针对delete和update操作的时候用到OLD\n\n```mysql\ndelimiter //\nCREATE TRIGGER tri_after_insert_tb1 AFTER INSERT ON tb1 FOR EACH ROW\nBEGIN\n    IF NEW. num = 666 THEN\n        INSERT INTO tb2 (NAME)\n        VALUES\n            (\'666\'),\n            (\'666\') ;\n    ELSEIF NEW. num = 555 THEN\n        INSERT INTO tb2 (NAME)\n        VALUES\n            (\'555\'),\n            (\'555\') ;\n    END IF;\nEND//\ndelimiter ;\n\n# 可以直接讲NEW.column放到插入的values里作为插入的值。\n```\n\n删除触发器：\n\n```mysql\nDROP TRIGGER tri_after_insert_tb1;\n```\n\n使用触发器：\n\n```mysql\n# 触发器无法由用户直接调用，而知由于对表的【增/删/改】操作被动引发的。\ninsert into tb1(num) values(666)\n```\n\n\n\n","timestamp":1541470330295},{"name":"26-26、存储过程.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/26-26、存储过程.md","content":"","timestamp":1541470330295},{"name":"27-28、函数.md","path":"01-Linux运维/07-DBA运维/01-Mysql/05-SQL语法基础/27-28、函数.md","content":"# Mysql函数\n\n>\n\n如何使用内置函数？\n\n```mysql\n# select 函数名\nmysql> select CURDATE();\n+------------+\n| CURDATE()  |\n+------------+\n| 2017-10-13 |\n+------------+\n1 row in set (0.11 sec)\n```\n\n部分内置函数：\n\n```mysql\nCHAR_LENGTH(str)\n返回值为字符串str 的长度，长度的单位为字符。一个多字节字符算作一个单字符。\n对于一个包含五个二字节字符集, LENGTH()返回值为 10, 而CHAR_LENGTH()的返回值为5。\n\nCONCAT(str1,str2,...)\n字符串拼接\n如有任何一个参数为NULL ，则返回值为 NULL。\n\nCONCAT_WS(separator,str1,str2,...)\n字符串拼接（自定义连接符）\nCONCAT_WS()不会忽略任何空字符串。 (然而会忽略所有的 NULL）。\n\nCONV(N,from_base,to_base)\n进制转换\n例如：\n    SELECT CONV(\'a\',16,2); 表示将 a 由16进制转换为2进制字符串表示\n\nFORMAT(X,D)\n将数字X的格式写为\'#,###,###.##\',以四舍五入的方式保留小数点后 D 位， 并将结果以字符串的形式返回。若D为0, 则返回结果不带有小数点，或不含小数部分。\n例如：\nSELECT FORMAT(12332.1,4); 结果为： \'12,332.1000\'\nINSERT(str,pos,len,newstr)\n        在str的指定位置插入字符串\n            pos：要替换位置起始位置\n            len：替换的长度\n            newstr：新字符串\n        特别的：\n            如果pos超过原字符串长度，则返回原字符串\n            如果len超过原字符串长度，则由新字符串完全替换\nINSTR(str,substr)\n        返回字符串 str 中子字符串的第一个出现位置。\n\n    LEFT(str,len)\n        返回字符串str 从开始的len位置的子序列字符。\n\n    LOWER(str)\n        变小写\n\n    UPPER(str)\n        变大写\n\n    LTRIM(str)\n        返回字符串 str ，其引导空格字符被删除。\n    RTRIM(str)\n        返回字符串 str ，结尾空格字符被删去。\n    SUBSTRING(str,pos,len)\n        获取字符串子序列\n\n    LOCATE(substr,str,pos)\n        获取子序列索引位置\n\n    REPEAT(str,count)\n        返回一个由重复的字符串str 组成的字符串，字符串str的数目等于count 。\n        若 count <= 0,则返回一个空字符串。\n        若str 或 count 为 NULL，则返回 NULL 。\n    REPLACE(str,from_str,to_str)\n        返回字符串str 以及所有被字符串to_str替代的字符串from_str 。\n    REVERSE(str)\n        返回字符串 str ，顺序和字符顺序相反。\n    RIGHT(str,len)\n        从字符串str 开始，返回从后边开始len个字符组成的子序列\n\n    SPACE(N)\n        返回一个由N空格组成的字符串。\n\n    SUBSTRING(str,pos) , SUBSTRING(str FROM pos) SUBSTRING(str,pos,len) , SUBSTRING(str FROM pos FOR len)\n        不带有len 参数的格式从字符串str返回一个子字符串，起始于位置 pos。带有len参数的格式从字符串str返回一个长度同len字符相同的子字符串，起始于位置 pos。 使用 FROM的格式为标准 SQL 语法。也可能对pos使用一个负值。假若这样，则子字符串的位置起始于字符串结尾的pos 字符，而不是字符串的开头位置。在以下格式的函数中可以对pos 使用一个负值。\n\n        mysql> SELECT SUBSTRING(\'Quadratically\',5);\n            -> \'ratically\'\n\n        mysql> SELECT SUBSTRING(\'foobarbar\' FROM 4);\n            -> \'barbar\'\n\n        mysql> SELECT SUBSTRING(\'Quadratically\',5,6);\n            -> \'ratica\'\n\n        mysql> SELECT SUBSTRING(\'Sakila\', -3);\n            -> \'ila\'\n\n        mysql> SELECT SUBSTRING(\'Sakila\', -5, 3);\n            -> \'aki\'\n\n        mysql> SELECT SUBSTRING(\'Sakila\' FROM -4 FOR 2);\n            -> \'ki\'\n\n    TRIM([{BOTH | LEADING | TRAILING} [remstr] FROM] str) TRIM(remstr FROM] str)\n        返回字符串 str ， 其中所有remstr 前缀和/或后缀都已被删除。若分类符BOTH、LEADIN或TRAILING中没有一个是给定的,则假设为BOTH 。 remstr 为可选项，在未指定情况下，可删除空格。\n\n        mysql> SELECT TRIM(\'  bar   \');\n                -> \'bar\'\n\n        mysql> SELECT TRIM(LEADING \'x\' FROM \'xxxbarxxx\');\n                -> \'barxxx\'\n\n        mysql> SELECT TRIM(BOTH \'x\' FROM \'xxxbarxxx\');\n                -> \'bar\'\n\n        mysql> SELECT TRIM(TRAILING \'xyz\' FROM \'barxxyz\');\n                -> \'barx\'\n\n部分内置函数\n```\n\n","timestamp":1541470330295},{"name":"09-01、数据库安装.md","path":"01-Linux运维/07-DBA运维/01-Mysql/09-01、数据库安装.md","content":"# Mysql的安装\n\n> 现在安装mysql有很多的方式，接下来分不同的平台进行说明。\n>\n> 安装包下载地址：\n>\n> https://dev.mysql.com/downloads/mysql/\n\n## 1-Windows\n\n### 1.1-Mysql Installer\n\n使用Mysql安装包的形式进行安装\n\n### 1.2-ZIP Archive\n\n使用已经打包好的内容进行安装。\n\n- 首先我把mysql的zip程序解压到了d:/mysql/下，在这个目录下创建一个data目录，当然现在这个data目录肯定是空的，啥都没有的。\n\n- 然后再命令行初始化数据库\n\n  ```mysql\n  D:\\mysql\\bin>mysqld -install                # 添加到windows系统服务\n  D:\\mysql\\bin>mysqld --initialise-insecure\n  ```\n\n  如果说你遇到下面这个报错的话说明你运行程序的权限是有问题的。这个时候我们只要以windows的administrator的权限去运行就可以了。这个其实和linux给一个道理，一般我们linux编译安装的时候都是用root，就算是不用root你也得用个sudo不~\n\n  ```\n  mysqld: Could not create or access the registry key needed for the MySQL application\n  to log to the Windows EventLog. Run the application with sufficient\n  privileges once to create the key, add the key manually, or turn off\n  logging for that application.\n  ```\n\n  解决方法很简单：打开cmd，右键使用管理员身份运行。然后再运行如上的这条初始化命令就好了。\n\n- 查看一下data目录下多了什么？\n\n  ```python\n  D:\\mysql\\data>dir\n   驱动器 D 中的卷是 workspace\n   卷的序列号是 F466-9ADB\n\n   D:\\mysql\\data 的目录\n\n  2017/09/25 周一  10:55    <DIR>          .\n  2017/09/25 周一  10:55    <DIR>          ..\n  2017/09/25 周一  10:55             7,552 DESKTOP-CH3QMNF.err\n  2017/09/25 周一  10:55        12,582,912 ibdata1\n  2017/09/25 周一  10:55               253 ib_buffer_pool\n  2017/09/25 周一  10:55        50,331,648 ib_logfile0\n  2017/09/25 周一  10:55        50,331,648 ib_logfile1\n                 5 个文件    113,254,013 字节\n                 2 个目录 138,721,185,792 可用字节\n  ```\n\n- 默认初始化以后密码为空的，mysql肯定是需要配置文件的，不过5.7.18版本后的配置文件就需要自己手动创建了。创建的内容文本如下，创建好了后保存为my.ini文件，移动到bin目录下：\n\n  ```\n  [client]\n  port=3306\n  default-character-set=utf8\n  [mysqld]\n  port=3306\n  character_set_server=utf8\n  basedir=D:\\mysql\n  datadir=D:\\mysql\\data\n  [WinMySQLAdmin]\n  D:\\mysql\\bin\\mysqld.exe\n  ```\n\n- 启动mysql服务，启动完成以后就可以链接了：\n\n  ```mysql\n  net start mysql       # 只有添加到windows的启动服务列表里才可以使用这条命令\n  关闭：\n  net stop mysql\n\n  # 链接mysql\n  mysql -uroot -p\n  ```\n\n新建用户：\n\n```\nmysql> create user \'lamber\'@\'localhost\' identified by \'13082171785\';\nQuery OK, 0 rows affected (0.00 sec)\n\n使用通配符的：\nmysql> create user \'testuser1\'@\'%\' identified by \'13082171785\';\nQuery OK, 0 rows affected (0.00 sec)\n\n授权：\ngrant select,insert on db_name.table_name to \'testuser1\'@\'%\'\n\n或者可以使用grant语句授权，省去创建用户的步骤而且直接把密码也给了：\nmysql> grant all privileges on *.* to \'lamber\'@\'%\' identified by \'13082171785\';\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\n```\n\n## 2-Linux\n\n在Linux平台下可以使用cmake进行编译安装。\n\n### 2.1-编译安装\n\n- 准备包和环境依赖\n\n  ```mysql\n  # 首先安装初始环境所需要的包：\n  [root@db02 ~]# yum -y install ncurses-devel libaio-devel  \n  [root@db02 ~]# rpm -qa ncurses-devel libaio-devel       \n  ncurses-devel-5.7-4.20090207.el6.x86_64\n  libaio-devel-0.3.107-10.el6.x86_64\n  [root@db02 ~]# yum -y install cmake \n  [root@db02 log]# useradd mysql -s /sbin/nologin -M\n  [root@db02 log]# id mysql\n  uid=502(mysql) gid=502(mysql) groups=502(mysql)\n  # 切换到下载目录中去：\n  [root@db02 tools]# tar xf mysql-5.5.32.tar.gz \n  ```\n\n- 使用cmake进行编译，然后进行安装\n\n  ```shell\n  预编译：\n  [root@db02 mysql-5.5.32]# cmake . -DCMAKE_INSTALL_PREFIX=/application/mysql-5.5.32 \\\n  -DMYSQL_DATADIR=/application/mysql-5.5.32/data \\\n  -DMYSQL_UNIX_ADDR=/application/mysql-5.5.32/tmp/mysql.sock \\\n  -DDEFAULT_CHARSET=utf8 \\\n  -DDEFAULT_COLLATION=utf8_general_ci \\\n  -DEXTRA_CHARSETS=gbk,gb2312,utf8,ascii \\\n  -DENABLED_LOCAL_INFILE=ON \\\n  -DWITH_INNOBASE_STORAGE_ENGINE=1 \\\n  -DWITH_FEDERATED_STORAGE_ENGINE=1 \\\n  -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\\n  -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 \\\n  -DWITHOUT_PARTITION_STORAGE_ENGINE=1 \\\n  -DWITH_FAST_MUTEXES=1 \\\n  -DWITH_ZLIB=bundled \\\n  -DENABLED_LOCAL_INFILE=1 \\\n  -DWITH_READLINE=1 \\\n  -DWITH_EMBEDDED_SERVER=1 \\\n  -DWITH_DEBUG=0\n  编译和安装：\n  make && make install & cd ..\n  ```\n\n- 创建数据目录进行初始化操作\n\n  ```shell\n  mkdir /data/3306/data        # 这个目录你自己按照自己的规划和需求整\n  find /data -type f -name mysql | xargs chmod +x    # 修改权限\n  ./scripts/mysql_install_db --basedir=/application/mysql/ --datadir=/data/3306/data/ --user=mysql                   # 初始化操作,加载mysql自身的库和表\n  ```\n\n- mysql启动，然后就可以进行连接了\n\n  ```shell\n   /data/3306/mysql start\n  ```\n\n#### =====编译安装过程中遇到的一些问题=====\n\n- 编译安装的过程中，cmake可能会报下面的错误\n\n  ```shell\n  -- Could NOT find Curses (missing:  CURSES_LIBRARY CURSES_INCLUDE_PATH)\n  CMake Error at cmake/readline.cmake:82 (MESSAGE):\n    Curses library not found.  Please install appropriate package,\n        remove CMakeCache.txt and rerun cmake.On Debian/Ubuntu, package name is libncurses5-dev, on Redhat and derivates it is ncurses-devel.\n  Call Stack (most recent call first):\n    cmake/readline.cmake:126 (FIND_CURSES)\n    cmake/readline.cmake:216 (MYSQL_USE_BUNDLED_LIBEDIT)\n    CMakeLists.txt:250 (MYSQL_CHECK_READLINE)\n  ```\n\n  解决办法：\n\n  ```shell\n  [root@localhost mysql-5.6.1]# rm CMakeCache.txt\n  [root@localhost mysql-5.6.1]# yum install ncurses-devel\n  [root@localhost mysql-5.5.11]# yum install bison\n  ```\n\n### 2.2-二进制tar.gz包解压直接使用\n\n二进制包的方式，都是已经编译好的，现成的东西，解压初始化以后就可以进行使用，多bb两句。\n\n>mysql5.7和之前的二进制包的部署方式有点小小的不一样。接下来呈现安装过程。\n\n\n1. 下载5.7的mysql安装包，这个破安装包竟然有600多m大，吓死人了。。\n```\nwget http://mirrors.sohu.com/mysql/MySQL-5.7/mysql-5.7.16-linux-glibc2.5-x86_64.tar.gz\n```\n2. 解压缩，移动到/application目录中\n```\ntar xf mysql-5.7.16-linux-glibc2.5-x86_64.tar.gz \nmkdir /application\n[root@nfs01 tools]# mv mysql-5.7.16-linux-glibc2.5-x86_64 /application/mysql-5.7.16\n[root@nfs01 tools]# cd /application/\n[root@nfs01 application]# ln -s /application/mysql-5.7.16/ /application/mysql\n[root@nfs01 application]# ll\ntotal 728\nlrwxrwxrwx. 1 root root     26 Feb  8 15:30 mysql -> /application/mysql-5.7.16/\ndrwxr-xr-x. 9 root root   4096 Feb  8 15:28 mysql-5.7.16\n```\n3. 数据库初始化\n\n\n```\nuseradd mysql -M -s /sbin/nologin \nmkdir /data/mysql\ncd /data/\nchown -R mysql.mysql mysql/\n./bin/mysqld --initialize --user=mysql --datadir=/data/mysql\n#在初始化的最后我们能看到这样一条日志信息\n2017-02-08T07:42:24.827356Z 1 [Note] A temporary password is generated for root@localhost: _p-2Abg:dqiU\n#这条日志信息的意思就是告诉你说，我们已经为root@localhost账户生成了一个临时的密码。这个密码就是_p-2Abg:dqiU，这个密码要先记下来，后面我们会用到\n[root@nfs01 mysql]# ./bin/mysql_ssl_rsa_setup --datadir=/data/mysql\nGenerating a 2048 bit RSA private key\n...+++\n....................................+++\nwriting new private key to \'ca-key.pem\'\n-----\nGenerating a 2048 bit RSA private key\n....................+++\n  ............+++\nwriting new private key to \'server-key.pem\'\n-----\nGenerating a 2048 bit RSA private key\n.........................................................+++\n........+++\nwriting new private key to \'client-key.pem\'\n-----\ncp support-files/my-default.cnf /etc/my.cnf\n[root@nfs01 mysql]# cp support-files/my-default.cnf /etc/my.cnf\n#修改我们的配置文件\n[root@nfs01 mysql]# vim /etc/my.cnf\nbasedir = /application/mysql\ndatadir = /data/mysql\nport = 3306\n# server_id = .....\nsocket = /tmp/mysql.sock\n#复制启动脚本\n[root@nfs01 mysql]# cp support-files/mysql.server /etc/init.d/mysqld\n[root@nfs01 mysql]# vim /etc/init.d/mysqld\nbasedir=/application/mysql\ndatadir=/data/mysql\n#启动mysql\n[root@nfs01 mysql]# /etc/init.d/mysqld start\nStarting MySQL. SUCCESS! \n#用我们刚才生成的临时密码登录进行修改密码的操作\n[root@nfs01 mysql]# /application/mysql/bin/mysql -uroot -p_p-2Abg:dqiU\nmysql> set password = password(\'redhat\');\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\n#还有一种情况，就是不知道初始化密码\nvim /etc/my.cnf\n#在[mysqld]下面增加一行\nskip-grant-tables\n#重启  \n/etc/init.d/mysqld restart\n/usr/local/mysql/bin/mysql -uroot \nmysql> update mysql.user set authentication_string=password(\'123333\') where user=\'root\';\n#退出来后，更改my.cnf，去掉刚加的 skip-grant-tables\n#重启 \n/etc/init.d/mysqld restart\n\n此时就可以使用新的密码了。\n```\n4. 排错\n  如果说在启动过程中遇到了如下的报错的话：\n```\n[root@nfs01 mysql]# /etc/init.d/mysqld start\nStarting MySQL.... ERROR! The server quit without updating PID file (/data/mysql/nfs01.pid).\n```\n一般来讲，出现这个报错的原因大多是权限问题，去看一下你的目录权限吧，很可能你的sock文件无权限在你设定的文件夹中生成。\n\n### 2.3- Yum安装\n\nPass\n\n## Mac\n\n太穷，买不起mac，不做了\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/78130839.jpg)\n\n\n\n","timestamp":1541470330295},{"name":"23-23、innodb和myisam.md","path":"01-Linux运维/07-DBA运维/01-Mysql/23-23、innodb和myisam.md","content":"","timestamp":1541470330295},{"name":"24-24、mysql监控.md","path":"01-Linux运维/07-DBA运维/01-Mysql/24-24、mysql监控.md","content":"# Mysql的监控\n\n## 1、监控的意义\n\n- 监控更偏重于趋势分析\n  - 通过监控的数据展现了了解趋势增长情况\n  - 监控程序采集的数据指标也可以用当前DB的性能分析\n- 监控分为：\n  - 趋势分析类：zabbix，其他等\n  - 当前指标分析类：top，iostat，dstat，pt-ioprofile，mysqladmin\n    - dstat：一款由Python编写的脚本工具，可以去好好读读dstat的脚本，从中会有所收获的，下载地址如下：http://dstat.sourcearchive.com/\n    - pt-ioprofile：这是一个percona提供的工具，属于percona-tools中的一个工具。可以定义mysqld进程进行分析，分析哪个io调用比较高，它可以进行排序并显示出来。pt-ioprofile依赖strace，因此需要安装strace。percona-tools安装如下：\n\n\n\ngoogle也开源出来一个监控插件叫[cadvisor](https://github.com/google/cadvisor)，这个是用Go语言写的。\n\n## 2、常用监控工具\n\n### 2.1、top\n\n- user的cpu占用高，常常是因为索引不合理或者是大量的order by，group by的处理\n- io_wait高，通常是因为系统io不给力，造成CPU等待，或者随机IO过重，可以使用pt-ioprofile去查看一下到底是谁占用比较高。直接在命令行输入pt-ioprofile就可以。\n- sys占用高，一般是因为numa没有关闭；如果不敢确定的话可以使用`pref top`去看一下，\n- st占用高，多出现于虚拟化环境，通常是虚拟化环境资源竞争过于严重。如果用的云厂商的话直接投诉云厂商就可以了。\n\n### 2.2、vmstat\n\nsi：swap-in、so：swap-out，vmstat中的r和b，r是正在运行的，b是等待io的。如果b比较大的话就需要pt-ioprofile去查一下了。\n\n\n\niops是什么？IO吞吐量是什么？\n\niops：每秒钟的io处理能力。其中包含了读和写。\n\niostat：yum -y install sysstat","timestamp":1541470330295},{"name":"01-Redis初探&安装.md","path":"01-Linux运维/07-DBA运维/02-Redis/01-Redis初探&安装.md","content":"# Redis安装\n\n>- 支持数据结构类型丰富，比如string字符串，散列hashes，列表lists，集合sets，有序集合sorted sets于范围查询，bitmaps，hyperlogslogs和地理空间（geospatial）索引半径查询。\n>- 丰富的支持主流语言的客户端，c，c++，python，erlang，R，c#，java，php，obc，perl，ruby，scala，go，js\n>- 基于内存并且支持持久化，高性能的kv键值对的nosql数据库\n>- 用途：缓存，数据库，消息中间件，队列\n>- 官方网站：http://www.redis.io\n\n## NoSQL的分类\n\n| 类型      | 主要产品               | 简介                                                         |\n| --------- | ---------------------- | ------------------------------------------------------------ |\n| KV存储    | redis，memcached       | 使用键快速的找到value，memcached支持string类型的value，redis除了支持string之外还支持set，hash，sort set，list等 |\n| 文档存储  | MongoDB，CouchDB       | 使用JSON或者类json的数据结构，存储内容为文档型，能实现部分关系数据库的功能 |\n| 列存储    | Hbase，Cassandra       | 按照列进行数据存储，便于存储结构化和半结构化数据（比如输出日志这类的，属于一种半结构化的数据，这种逗号分隔的，我们也知道每一个字段都是什么内容），方便做数据压缩和针对某一列和某几列的数据查询 |\n| 图存储    | Neo4J，FlockDB         | 图形相关的存储，能够很好地弥补关系型数据库在图形存储的不足   |\n| 对象存储  | Db4o，Versant          | 通过类似面向对象语言的方式操作数据库，通过对象的方式存取数据 |\n| XML数据库 | Berkeley DB XML，BaseX | 高效存储XML数据，支持XML的内部查询语法，比如XQuery和XPath    |\n\n## Redis安装\n\n> Redis版本：2.8\n>\n> 操作系统：Centos7.3\n>\n> 可视化客户端：RedisDesktopManager\n>\n\n### Redis功能特性：\n\n- 持久化功能，将存储在内存的数据保存到硬盘里面去，保证数据的安全，方便备份和恢复\n- 发布与订阅，生产者和消费者，相当于与消息中间件。\n- 过期键功能，为key设置一个过期时间，让它在指定的时间之后自动被删除\n- 事物功能：原子的执行多个操作，并提供乐观锁的功能，保证处理数据时的安全性\n- Lua脚本功能：在服务器端原子的执行多个功能，完成复杂的功能，并减少客户端与服务器之间的通信往返次数，\n- 复制：为指定的redis服务器创建一个或者多个复制品，用于提升数据的安全性。并分担读请求负载。\n- Sentinel（哨兵）：监控redis服务器状态，并在服务器发生故障的时候，进行自动的故障转移\n- 集群：创建分布式的数据库，每个服务器分别执行一部分写操作和读操作。\n\n### 安装过程\n\n```shell\n# redis安装包下载地址\nhttp://download.redis.io/releases/\n\n# 我要安装在tools下面\ncd /tools\nwget http://download.redis.io/releases/redis-2.8.18.tar.gz\ntar xf redis-2.8.18.tar.gz\nyum install gcc tcl -y   # 准备编译安装的环境\nmake\nmkdir /usr/local/redis2.8\nmake PREFIX=/usr/local/redis2.8 install\n\n# 拷贝对应的执行程序，设置环境变量\ncd /tools/redis-2.8.18\ncp redis.conf /usr/local/redis2.8/\ncd /tools/redis-2.8.18/src\ncp redis-sentinel /usr/local/redis2.8/bin/\necho -e \'export REDIS_HOME=/usr/local/redis2.8\\nexport PATH=$PATH:$REDIS_HOME/bin\' >> ~/.bash_profile\n. ~/.bash_profile\n\n# 查看redis-server的使用帮助信息\n[root@maxiaoyu 15:03:53 /root]\n#redis-server --help\nUsage: ./redis-server [/path/to/redis.conf] [options]\n       ./redis-server - (read config from stdin)\n       ./redis-server -v or --version\n       ./redis-server -h or --help\n       ./redis-server --test-memory <megabytes>\n\nExamples:\n       ./redis-server (run the server with default conf)\n       ./redis-server /etc/redis/6379.conf\n       ./redis-server --port 7777\n       ./redis-server --port 7777 --slaveof 127.0.0.1 8888\n       ./redis-server /etc/myredis.conf --loglevel verbose\n\nSentinel mode:\n       ./redis-server /etc/sentinel.conf --sentinel\n       \n# 可选：把redis做成后台daemon模式\ncd /tools/redis-2.8.18/utils\n./install_server.sh \n# 把编译好的redis作为一个服务器，把6379.conf放到了/etc/init.d/redis_6379\ncd /etc/init.d\nmv redis_6379 redisd\nchkconfig --add redisd\nservice redisd start\nss -tanl\n```\n\n现在就可以启用redis了：\n\n```shell\nredis-server /usr/local/redis2.8/redis.conf\n```\n\n使用redis-cli进行连接\n\n- -h：指定要连接的机器\n- -p：指定要连接的port，新浪一台开了四个redis，对应四个端口\n- -a：传password\n- -n：一个redis里面可以由多个database，默认是16个，不同的db是隔离的。database number。默认的db是db0号，我们可以选择不同的号码切换到不同的数据库，数据库的数量可以在配置文件中去配置。\n\n## Redis保护模式\n\n- Bind 指定ip进行监听\n\n  ```shell\n  bind ip1 ip2 ip3 ip4\n  ```\n\n- protect mode 配置文件中有一个protected-mode\n\n  ```shell\n  protected-mode yes\n  # 单单只开启这个还没用还要加一个requirepass\n  requirepass testpass1\n\n  # 那么在登录的时候可以指定密码\n  redis-cli -p xxx -a testpass1 -h x.x.x.x\n  # 或者先使用redis-cli进来以后然后执行auth命令，然后再去执行redis命令\n  auth testpass1\n  ```\n\n  ​","timestamp":1541470330295},{"name":"02-redis配置文件详解.md","path":"01-Linux运维/07-DBA运维/02-Redis/02-redis配置文件详解.md","content":"# Redis配置文件详解\n\n## 单位\n\n```shell\n# 1k => 1000 bytes\n# 1kb => 1024 bytes\n# 1m => 1000000 bytes\n# 1mb => 1024*1024 bytes\n# 1g => 1000000000 bytes\n# 1gb => 1024*1024*1024 bytes\n```\n\n- 只支持字节，不支持bit。\n- 大小写不敏感\n\n## Include\n\n包含其他的配置文件，你可以有一个标准模板给大多数的机器用，你也可以引入一些配置文件给一些自定义的机器使用，比较推荐在配置文件的最后一行加上。\n\n```shell\n# include /path/to/local.conf\n# include /path/to/other.conf\n```\n\n## 通用配置\n\n```shell\n# 是否允许以守护进程的方式运行\ndaemonize yes\n\n# pid文件位置\npidfile /var/run/redis_6379.pid\n\n# 监听端口\nport 6379\n\n# 设置tcp的backlog，backlog其实是一个连接队列，backlog的队列总和=未完成三次握手的队列+已完成三次握手的队列。在高并发环境下你需要一个较高的tco-backlog值来避免客户端连接慢的问题，注意，linux内核回降这个值减小到/proc/sys/net/core/somaxconn的值，因此需要确认增大somaxconn和tcp_max_sync_backlog这两个值来达到想要的效果。\ntcp-backlog 511\n\n# redis默认监听来自所有网络接口的连接。你可以通过设置这里来设置允许谁来访问\n# bind 192.168.1.100 10.0.0.1\n# bind 127.0.0.1\n\n# 可以通过自定义socket来处理用户请求。如果不指定的话redis就不会通过监听socket来处理访问连接。\n# unixsocket /tmp/redis.sock\n# unixsocketperm 700\n\n# 超时时间，0表示永不超时。\ntimeout 0\n\n# TCP keepalive.单位为秒，如果设置为0那么就不会进行keepaliverd检测，建议设置成60\ntcp-keepalive 0\n\n# 设置日志的级别，默认是notice，还有debug，verbose，warning集中可以选择。debug适用于开发模式，verbose有用的信息不多，但是没有debug那么乱，notice是适度的较为详细的日志，生产环境一般你想看的这里都体现了，warning只会打印非常重要的或者致命的问题。\nloglevel notice\n\n# 日志位置配置，这里可以为空，这样Redis会将日志输出到标准输出，但是如果redis不是以daemon方式运行的话那么就直接给输出到/dev/null里去了。logfile stdout\nlogfile /usr/local/redis2.8/redis_6379.log\n\n# 如果要允许日志记录到系统日志的话就设置这个选项为yes。\n# syslog-enabled no\n\n# 指定系统记录的日志以redis开头。指定系统日志中的标识\n# syslog-ident redis\n\n# 输出日志的设备，可以是USER，LOCAL0~7\n# syslog-facility local0\n\n# 默认有16个库，可以使用select命令切换库。\ndatabases 16\n\n\n\n\n\n################################ LATENCY MONITOR ##############################\n\n# The Redis latency monitoring subsystem samples different operations\n# at runtime in order to collect data related to possible sources of\n# latency of a Redis instance.\n#\n# Via the LATENCY command this information is available to the user that can\n# print graphs and obtain reports.\n#\n# The system only logs operations that were performed in a time equal or\n# greater than the amount of milliseconds specified via the\n# latency-monitor-threshold configuration directive. When its value is set\n# to zero, the latency monitor is turned off.\n#\n# By default latency monitoring is disabled since it is mostly not needed\n# if you don\'t have latency issues, and collecting data has a performance\n# impact, that while very small, can be measured under big load. Latency\n# monitoring can easily be enalbed at runtime using the command\n# \"CONFIG SET latency-monitor-threshold <milliseconds>\" if needed.\nlatency-monitor-threshold 0\n\n############################# Event notification ##############################\n\n# Redis can notify Pub/Sub clients about events happening in the key space.\n# This feature is documented at http://redis.io/topics/notifications\n#\n# For instance if keyspace events notification is enabled, and a client\n# performs a DEL operation on key \"foo\" stored in the Database 0, two\n# messages will be published via Pub/Sub:\n#\n# PUBLISH __keyspace@0__:foo del\n# PUBLISH __keyevent@0__:del foo\n#\n# It is possible to select the events that Redis will notify among a set\n# of classes. Every class is identified by a single character:\n#\n#  K     Keyspace events, published with __keyspace@<db>__ prefix.\n#  E     Keyevent events, published with __keyevent@<db>__ prefix.\n#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...\n#  $     String commands\n#  l     List commands\n#  s     Set commands\n#  h     Hash commands\n#  z     Sorted set commands\n#  x     Expired events (events generated every time a key expires)\n#  e     Evicted events (events generated when a key is evicted for maxmemory)\n#  A     Alias for g$lshzxe, so that the \"AKE\" string means all the events.\n#\n#  The \"notify-keyspace-events\" takes as argument a string that is composed\n#  of zero or multiple characters. The empty string means that notifications\n#  are disabled.\n#\n#  Example: to enable list and generic events, from the point of view of the\n#           event name, use:\n#\n#  notify-keyspace-events Elg\n#\n#  Example 2: to get the stream of the expired keys subscribing to channel\n#             name __keyevent@0__:expired use:\n#\n#  notify-keyspace-events Ex\n#\n#  By default all notifications are disabled because most users don\'t need\n#  this feature and the feature has some overhead. Note that if you don\'t\n#  specify at least one of K or E, no events will be delivered.\nnotify-keyspace-events \"\"\n\n############################### ADVANCED CONFIG ###############################\n\n# Hashes are encoded using a memory efficient data structure when they have a\n# small number of entries, and the biggest entry does not exceed a given\n# threshold. These thresholds can be configured using the following directives.\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\n\n# Similarly to hashes, small lists are also encoded in a special way in order\n# to save a lot of space. The special representation is only used when\n# you are under the following limits:\nlist-max-ziplist-entries 512\nlist-max-ziplist-value 64\n\n# Sets have a special encoding in just one case: when a set is composed\n# of just strings that happen to be integers in radix 10 in the range\n# of 64 bit signed integers.\n# The following configuration setting sets the limit in the size of the\n# set in order to use this special memory saving encoding.\nset-max-intset-entries 512\n\n# Similarly to hashes and lists, sorted sets are also specially encoded in\n# order to save a lot of space. This encoding is only used when the length and\n# elements of a sorted set are below the following limits:\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\n\n# HyperLogLog sparse representation bytes limit. The limit includes the\n# 16 bytes header. When an HyperLogLog using the sparse representation crosses\n# this limit, it is converted into the dense representation.\n#\n# A value greater than 16000 is totally useless, since at that point the\n# dense representation is more memory efficient.\n#\n# The suggested value is ~ 3000 in order to have the benefits of\n# the space efficient encoding without slowing down too much PFADD,\n# which is O(N) with the sparse encoding. The value can be raised to\n# ~ 10000 when CPU is not a concern, but space is, and the data set is\n# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.\nhll-sparse-max-bytes 3000\n\n# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in\n# order to help rehashing the main Redis hash table (the one mapping top-level\n# keys to values). The hash table implementation Redis uses (see dict.c)\n# performs a lazy rehashing: the more operation you run into a hash table\n# that is rehashing, the more rehashing \"steps\" are performed, so if the\n# server is idle the rehashing is never complete and some more memory is used\n# by the hash table.\n#\n# The default is to use this millisecond 10 times every second in order to\n# actively rehash the main dictionaries, freeing memory when possible.\n#\n# If unsure:\n# use \"activerehashing no\" if you have hard latency requirements and it is\n# not a good thing in your environment that Redis can reply from time to time\n# to queries with 2 milliseconds delay.\n#\n# use \"activerehashing yes\" if you don\'t have such hard requirements but\n# want to free memory asap when possible.\nactiverehashing yes\n\n# The client output buffer limits can be used to force disconnection of clients\n# that are not reading data from the server fast enough for some reason (a\n# common reason is that a Pub/Sub client can\'t consume messages as fast as the\n# publisher can produce them).\n#\n# The limit can be set differently for the three different classes of clients:\n#\n# normal -> normal clients including MONITOR clients\n# slave  -> slave clients\n# pubsub -> clients subscribed to at least one pubsub channel or pattern\n#\n# The syntax of every client-output-buffer-limit directive is the following:\n#\n# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>\n#\n# A client is immediately disconnected once the hard limit is reached, or if\n# the soft limit is reached and remains reached for the specified number of\n# seconds (continuously).\n# So for instance if the hard limit is 32 megabytes and the soft limit is\n# 16 megabytes / 10 seconds, the client will get disconnected immediately\n# if the size of the output buffers reach 32 megabytes, but will also get\n# disconnected if the client reaches 16 megabytes and continuously overcomes\n# the limit for 10 seconds.\n#\n# By default normal clients are not limited because they don\'t receive data\n# without asking (in a push way), but just after a request, so only\n# asynchronous clients may create a scenario where data is requested faster\n# than it can read.\n#\n# Instead there is a default limit for pubsub and slave clients, since\n# subscribers and slaves receive data in a push fashion.\n#\n# Both the hard or the soft limit can be disabled by setting them to zero.\nclient-output-buffer-limit normal 0 0 0\nclient-output-buffer-limit slave 256mb 64mb 60\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n# Redis calls an internal function to perform many background tasks, like\n# closing connections of clients in timeout, purging expired keys that are\n# never requested, and so forth.\n#\n# Not all tasks are performed with the same frequency, but Redis checks for\n# tasks to perform according to the specified \"hz\" value.\n#\n# By default \"hz\" is set to 10. Raising the value will use more CPU when\n# Redis is idle, but at the same time will make Redis more responsive when\n# there are many keys expiring at the same time, and timeouts may be\n# handled with more precision.\n#\n# The range is between 1 and 500, however a value over 100 is usually not\n# a good idea. Most users should use the default of 10 and raise this up to\n# 100 only in environments where very low latency is required.\nhz 10\n\n# When a child rewrites the AOF file, if the following option is enabled\n# the file will be fsync-ed every 32 MB of data generated. This is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\naof-rewrite-incremental-fsync yes\n```\n\n## 快照\n\n```shell\n# 其实就是RDB持久化\nsave 900 1\nsave 300 10\nsave 60 10000\n\n# 在开启了rdb的情况下，如果最新的后台写入出错，那么redis将停止接收写请求。默认是yes，如果设置成no表示你不在乎数据不一致或者有其他的手段发现和控制。后台保存功能恢复以后redis自动开始允许写入。\nstop-writes-on-bgsave-error yes\n\n# 启用LZF算法进行压缩快照文件\nrdbcompression yes\n\n# 在存储快照后，还可以让redis使用crc64算法来进行数据的校验。\nrdbchecksum yes\n\n# rdb文件的文件名\ndbfilename dump.rdb\n\n# 指定数据库的存放目录\ndir /usr/local/redis2.8/6379\n```\n\n## AOF\n\n```shell\n# 默认aof是关闭的，如果要开启需要手动改为yes。rdb和aof可以一起打开的。如果aof开启的话，redis启动以后会优先加载aof的记录的备份而不是rdb的。\nappendonly no\n\n# aof文件名，(default: \"appendonly.aof\")\nappendfilename \"appendonly.aof\"\n\n# 备份策略\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n\n# 重写时是否可以运用appendfsync，用默认no就可以了，保证数据的安全性。\nno-appendfsync-on-rewrite no\n\n# 自动重写机制，redis会记录上一次重写的aof的大小，默认配置是当aof文件大小是上次rewrite后大小的一倍并且文件大于64M时触发。如果说刚启动，还没有冲写过，那么这个上一次的大小就被记录为使用的aof文件的大小。百分比设置为0意味着禁用自动重写功能。\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n\n# 指redis在恢复时，会忽略最后一条可能存在问题的指令。默认值yes。即在aof写入时，可能存在指令写错的问题(突然断电，写了一半)，这种情况下，yes会log并继续，而no会直接恢复失败.\naof-load-truncated yes\n```\n\n## 安全选项设置\n\n```shell\n# 设置用户密码，你访问之前要输入密码，针对redis的配置文件有一个“config get requirepass”可以查看配置文件设置的密码。\n# auth 密码，然后再在cli操作下就可以使用了，或者在连接的时候可以用-a参数，比如redis-cli -a 密码 -p 6379\n# requirepass foobared\n```\n\n## Limits\n\n```shell\n# 限制并发客户端的数量，默认是10000\n# maxclients 10000\n\n# 设置可以使用的最大内存，一般这个是要进行限制的，不能让redis无限制的使用。\n# maxmemory <bytes>\n\n# 缓存过期策略，或者当达到设置的内存上限以后redis处理缓存的策略，有几个过期策略供你选择。生产环境中不要使用永不过期。\n# noeviction：永不过期，写不了就直接报错，但是可以读。\n# volatile-lru：使用LRU算法移除key，只对设置了过期时间的key，默认值\n# allkeys-lru：使用LRU算法移除key\n# volatile-random：在过期集合中随机移除key，只对设置了过期时间的key\n# allkeys-random：移除随机的key\n# volatile-ttl：移除那些ttl值最小的key，即那些最近要过期的key。\n# maxmemory-policy volatile-lru\n\n# 设置样本数量，LRU算法和最小TTL算法并非都是精准的算法，而是估算值。下面的配置就是默认选取3个样本进行内部的一个检测。所以你可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU(less recently use)的那个\n# maxmemory-samples 3\n```\n\n## 主从复制\n\n```shell\n################################# REPLICATION #################################\n\n# Master-Slave replication. Use slaveof to make a Redis instance a copy of\n# another Redis server. A few things to understand ASAP about Redis replication.\n#\n# 1) Redis replication is asynchronous, but you can configure a master to\n#    stop accepting writes if it appears to be not connected with at least\n#    a given number of slaves.\n# 2) Redis slaves are able to perform a partial resynchronization with the\n#    master if the replication link is lost for a relatively small amount of\n#    time. You may want to configure the replication backlog size (see the next\n#    sections of this file) with a sensible value depending on your needs.\n# 3) Replication is automatic and does not need user intervention. After a\n#    network partition slaves automatically try to reconnect to masters\n#    and resynchronize with them.\n#\n# slaveof <masterip> <masterport>\n\n# If the master is password protected (using the \"requirepass\" configuration\n# directive below) it is possible to tell the slave to authenticate before\n# starting the replication synchronization process, otherwise the master will\n# refuse the slave request.\n#\n# masterauth <master-password>\n\n# When a slave loses its connection with the master, or when the replication\n# is still in progress, the slave can act in two different ways:\n#\n# 1) if slave-serve-stale-data is set to \'yes\' (the default) the slave will\n#    still reply to client requests, possibly with out of date data, or the\n#    data set may just be empty if this is the first synchronization.\n#\n# 2) if slave-serve-stale-data is set to \'no\' the slave will reply with\n#    an error \"SYNC with master in progress\" to all the kind of commands\n#    but to INFO and SLAVEOF.\n#\nslave-serve-stale-data yes\n\n# You can configure a slave instance to accept writes or not. Writing against\n# a slave instance may be useful to store some ephemeral data (because data\n# written on a slave will be easily deleted after resync with the master) but\n# may also cause problems if clients are writing to it because of a\n# misconfiguration.\n#\n# Since Redis 2.6 by default slaves are read-only.\n#\n# Note: read only slaves are not designed to be exposed to untrusted clients\n# on the internet. It\'s just a protection layer against misuse of the instance.\n# Still a read only slave exports by default all the administrative commands\n# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve\n# security of read only slaves using \'rename-command\' to shadow all the\n# administrative / dangerous commands.\nslave-read-only yes\n\n# Replication SYNC strategy: disk or socket.\n#\n# -------------------------------------------------------\n# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY\n# -------------------------------------------------------\n#\n# New slaves and reconnecting slaves that are not able to continue the replication\n# process just receiving differences, need to do what is called a \"full\n# synchronization\". An RDB file is transmitted from the master to the slaves.\n# The transmission can happen in two different ways:\n#\n# 1) Disk-backed: The Redis master creates a new process that writes the RDB\n#                 file on disk. Later the file is transferred by the parent\n#                 process to the slaves incrementally.\n# 2) Diskless: The Redis master creates a new process that directly writes the\n#              RDB file to slave sockets, without touching the disk at all.\n#\n# With disk-backed replication, while the RDB file is generated, more slaves\n# can be queued and served with the RDB file as soon as the current child producing\n# the RDB file finishes its work. With diskless replication instead once\n# the transfer starts, new slaves arriving will be queued and a new transfer\n# will start when the current one terminates.\n#\n# When diskless replication is used, the master waits a configurable amount of\n# time (in seconds) before starting the transfer in the hope that multiple slaves\n# will arrive and the transfer can be parallelized.\n#\n# With slow disks and fast (large bandwidth) networks, diskless replication\n# works better.\nrepl-diskless-sync no\n\n# When diskless replication is enabled, it is possible to configure the delay\n# the server waits in order to spawn the child that trnasfers the RDB via socket\n# to the slaves.\n#\n# This is important since once the transfer starts, it is not possible to serve\n# new slaves arriving, that will be queued for the next RDB transfer, so the server\n# waits a delay in order to let more slaves arrive.\n#\n# The delay is specified in seconds, and by default is 5 seconds. To disable\n# it entirely just set it to 0 seconds and the transfer will start ASAP.\nrepl-diskless-sync-delay 5\n\n# Slaves send PINGs to server in a predefined interval. It\'s possible to change\n# this interval with the repl_ping_slave_period option. The default value is 10\n# seconds.\n#\n# repl-ping-slave-period 10\n\n# The following option sets the replication timeout for:\n#\n# 1) Bulk transfer I/O during SYNC, from the point of view of slave.\n# 2) Master timeout from the point of view of slaves (data, pings).\n# 3) Slave timeout from the point of view of masters (REPLCONF ACK pings).\n#\n# It is important to make sure that this value is greater than the value\n# specified for repl-ping-slave-period otherwise a timeout will be detected\n# every time there is low traffic between the master and the slave.\n#\n# repl-timeout 60\n\n# Disable TCP_NODELAY on the slave socket after SYNC?\n#\n# If you select \"yes\" Redis will use a smaller number of TCP packets and\n# less bandwidth to send data to slaves. But this can add a delay for\n# the data to appear on the slave side, up to 40 milliseconds with\n# Linux kernels using a default configuration.\n#\n# If you select \"no\" the delay for data to appear on the slave side will\n# be reduced but more bandwidth will be used for replication.\n#\n# By default we optimize for low latency, but in very high traffic conditions\n# or when the master and slaves are many hops away, turning this to \"yes\" may\n# be a good idea.\nrepl-disable-tcp-nodelay no\n\n# Set the replication backlog size. The backlog is a buffer that accumulates\n# slave data when slaves are disconnected for some time, so that when a slave\n# wants to reconnect again, often a full resync is not needed, but a partial\n# resync is enough, just passing the portion of data the slave missed while\n# disconnected.\n#\n# The bigger the replication backlog, the longer the time the slave can be\n# disconnected and later be able to perform a partial resynchronization.\n#\n# The backlog is only allocated once there is at least a slave connected.\n#\n# repl-backlog-size 1mb\n\n# After a master has no longer connected slaves for some time, the backlog\n# will be freed. The following option configures the amount of seconds that\n# need to elapse, starting from the time the last slave disconnected, for\n# the backlog buffer to be freed.\n#\n# A value of 0 means to never release the backlog.\n#\n# repl-backlog-ttl 3600\n\n# The slave priority is an integer number published by Redis in the INFO output.\n# It is used by Redis Sentinel in order to select a slave to promote into a\n# master if the master is no longer working correctly.\n#\n# A slave with a low priority number is considered better for promotion, so\n# for instance if there are three slaves with priority 10, 100, 25 Sentinel will\n# pick the one with priority 10, that is the lowest.\n#\n# However a special priority of 0 marks the slave as not able to perform the\n# role of master, so a slave with priority of 0 will never be selected by\n# Redis Sentinel for promotion.\n#\n# By default the priority is 100.\nslave-priority 100\n\n# It is possible for a master to stop accepting writes if there are less than\n# N slaves connected, having a lag less or equal than M seconds.\n#\n# The N slaves need to be in \"online\" state.\n#\n# The lag in seconds, that must be <= the specified value, is calculated from\n# the last ping received from the slave, that is usually sent every second.\n#\n# This option does not GUARANTEE that N replicas will accept the write, but\n# will limit the window of exposure for lost writes in case not enough slaves\n# are available, to the specified number of seconds.\n#\n# For example to require at least 3 slaves with a lag <= 10 seconds use:\n#\n# min-slaves-to-write 3\n# min-slaves-max-lag 10\n#\n# Setting one or the other to 0 disables the feature.\n#\n# By default min-slaves-to-write is set to 0 (feature disabled) and\n# min-slaves-max-lag is set to 10.\n```\n\n## Lua脚本\n\n```shell\n################################ LUA SCRIPTING  ###############################\n\n# Max execution time of a Lua script in milliseconds.\n#\n# If the maximum execution time is reached Redis will log that a script is\n# still in execution after the maximum allowed time and will start to\n# reply to queries with an error.\n#\n# When a long running script exceeds the maximum execution time only the\n# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be\n# used to stop a script that did not yet called write commands. The second\n# is the only way to shut down the server in the case a write command was\n# already issued by the script but the user doesn\'t want to wait for the natural\n# termination of the script.\n#\n# Set it to 0 or a negative value for unlimited execution without warnings.\nlua-time-limit 5000\n```\n\n## 慢日志\n\n```shell\n################################## SLOW LOG ###################################\n\n# The Redis Slow Log is a system to log queries that exceeded a specified\n# execution time. The execution time does not include the I/O operations\n# like talking with the client, sending the reply and so forth,\n# but just the time needed to actually execute the command (this is the only\n# stage of command execution where the thread is blocked and can not serve\n# other requests in the meantime).\n#\n# You can configure the slow log with two parameters: one tells Redis\n# what is the execution time, in microseconds, to exceed in order for the\n# command to get logged, and the other parameter is the length of the\n# slow log. When a new command is logged the oldest one is removed from the\n# queue of logged commands.\n\n# The following time is expressed in microseconds, so 1000000 is equivalent\n# to one second. Note that a negative number disables the slow log, while\n# a value of zero forces the logging of every command.\nslowlog-log-slower-than 10000\n\n# There is no limit to this length. Just be aware that it will consume memory.\n# You can reclaim memory used by the slow log with SLOWLOG RESET.\nslowlog-max-len 128\n```\n\n","timestamp":1541470330295},{"name":"03-redis的简单实用.md","path":"01-Linux运维/07-DBA运维/02-Redis/03-redis的简单实用.md","content":"# Redis的简单使用\n\n> redis中最简单的数据结构，它即可以存储文字，又可以存储数字，和浮点数，还可以进行二进制的存储，redis为这几类型的值分贝设置相应的操作命令，让用户可以针对不同的值做不同的处理。\n\n## 简单操作\n\n### help\n\n```shell\n# 熟练使用帮助信息\n127.0.0.1:6379> help set\n\n  SET key value [EX seconds] [PX milliseconds] [NX|XX]\n  summary: Set the string value of a key\n  since: 1.0.0\n  group: string\n  \n# 查看有关字符串的操作\nhelp @string\n\n# 查看关于集合的操作\nhelp @set\n```\n\n### String\n\n> 一个字符串类型的值最多能存储512M字节的内容\n\n```shell\n# 多次设置同一个key，key会被后设置所覆盖，也就是key是唯一的。\nset msg \"hello world\"\n\n# nx表示key不存在的时候才进行设置，当key已经存在的时候就不设置，返回nil\nset msg \"redis\" nx\n\n# xx表示当key存在的时候才可以设置，因为之前设置了msg，所以这个key存在，现在可以设置msg\nset msg \'bbb\' xx\n\n# 设置键的过期时间，ex，后面10表示秒数，意思就是10s以后删除temp这个key，px接的数字单位是毫秒\nset temp \"temp\" ex 10\nset temp \"temp\" px 10\n\n# 使用get来获取设置的内容\nget msg\n\n# setnx，nx表示not exist的意思，当不存在的时候设置\n127.0.0.1:6379> setnx key1 \"key1\"\n(integer) 1\n127.0.0.1:6379> get key1\n\"key1\"\n127.0.0.1:6379> setnx key1 \'key1bak\'\n(integer) 0\n127.0.0.1:6379> get key1\n\"key1\"\n\n# 同时设置多个值，同时获取多个值，mget，mset\n127.0.0.1:6379> mset key1 \"key1\" key2 \"key2\" key3 \"key3\"\nOK\n127.0.0.1:6379> mget key1 key2 key3\n1) \"key1\"\n2) \"key2\"\n3) \"key3\"\n\n# msetnx同时设置多个值，具有原子性，要不成功就是整体不成功。nx还是not exist，当不存在这个key的时候设置，当至少有一个是存在的时候，那么msetnx将不执行任何操作\n127.0.0.1:6379> mset a 1 b 2\nOK\n127.0.0.1:6379> msetnx a 1 c 3\n(integer) 0 # 返回integer 0就是表示没有设置成功\n127.0.0.1:6379> get c\n(nil)\n\n# getset可以将key的值设置一个新的value，并返回key之前存储的旧值。内部实现其实就是一个get，一个set，然后return get拿到的值，但是操作由两次变成了一次。\n127.0.0.1:6379> get a\n\"a_old\"\n127.0.0.1:6379> getset a \'a_new\'\n\"a_old\"\n127.0.0.1:6379> get a\n\"a_new\"\n\n# append将值value插入到字符串key已存储内容的末尾\n127.0.0.1:6379> set a \"hahaha\"\nOK\n127.0.0.1:6379> append a \"_?????\"\n(integer) 12\n127.0.0.1:6379> get a\n\"hahaha_?????\"\n\n# strlen 接收一个key，返回value字符串的长度\n127.0.0.1:6379> set a \"hahaha\"\nOK\n127.0.0.1:6379> STRLEN a\n(integer) 6\n```\n\n#### key的命名规范\n\n因为redis数据库的key是唯一的，因此在设计key的命名的时候我们可以这样去设置，比如用户lamber的email地址这样一个内容的key可以设置为`lamber::email`，这样的话，大家每个人的内容就不会造成冲突，举个复杂点的例子比如：`user::10086::info`可以表示为id是10086的用户的信息，`news::sport::cache`可以表示新闻类网站体育分类的缓存，两个冒号是大众习惯的分隔符，当然这个不是固定死的，也可以使用其它的分隔符，比如使用`/`也是可以的，在程序中统一规范即可。\n\nredis的key值是二进制安全的，这意味着可以用任何二进制序列作为key值，从形如“foo”的简单字符串到一个jpeg的文件的内容都可以，空字符串也可以是有效的key值。\n\n- 键值不要太长，消耗内存， 并且在查找这类key值的计算成本较高，而且存储的键的个数不宜过多，在存储键值这一块，值就是值本身，但是key的存储往往携带一些附属内容，比如key的过期时间以及其他属性。\n- key值也不要过短，太短的话可读性太差。\n\n#### 字符串索引\n\n> 索引从0开始，除了正向索引外，还有一个负数的索引，负数索引从-1开始，表示字符串的结尾，这个其实和python的字符串索引很像。\n\n通过字符串的索引去进行范围查找\n\n```shell\n# setrange命令可以从索引index开始，用你想写入的value值替换到给定key所存储的字符串部分，注意这个目前是只支持正数索引，替换完成以后返回的内容为字符串的长度。没替换到的地方保留，超过的地方追加\n127.0.0.1:6379> set a \"hello\"\nOK\n127.0.0.1:6379> setrange a 1 \"appy\"\n(integer) 5\n127.0.0.1:6379> get a\n\"happy\"\n\n# getrange是获取某个区间范围内的值，注意范围左右都是闭区间，也就是说都可以取到的。getrange接收的区间范围的值可以是正数也可以是负数\n127.0.0.1:6379> set msg \"hello world\"\nOK\n127.0.0.1:6379> getrange msg 0 4\n\"hello\"\n127.0.0.1:6379> getrange msg -5 -1\n\"world\"\n# 注意这里的负数取值的时候其实顺序还是从左到右的，-1到-5相当于从右向左取是取不到的。\n127.0.0.1:6379> getrange msg -1 -5\n\"\"\n127.0.0.1:6379> getrange msg 0 -1\n\"hello world\"   # 获取整个字符串\n```\n\n#### BitMap\n\n> - BitMap(位图)不是真正的数据类型，它是定义在字符串类型中的\n> - 一个字符串类型的值最多能存储512M字节的内容\n> - 位上限2^(9+10+10+3)=2^32b\n\n```shell\n# 设置某一位上的值，offset表示偏移量，从0开始，0是最右侧的那个，比如01001011，第0个为1\nsetbit key offset value、\n# 获取某一位上的值\ngetbit key offset\n# 返回指定值0或者1在指定区间上第一次出现的位置\nbitpos key bit [start] [end]\n```\n\n位操作\n\n```shell\n# 对一个或者多个保存二进制的字符串key进行位元操作，并将结果保存到destkey上\n# operation可以使AND OR NOT XOR这四种操作的一种。\n# 除了not操作之外，其他操作都可以接受一个或者多个key作为输入\n# 当bitop处理不同长度的字符串的时候，较短的字符串所缺少的部分会被看做是0\n# 空的key也被看做是包含0的字符串序列\n\n# 对一个或多个key求逻辑与，并将结果保存到destkey\nbitop and destkey key [key....] \n\n# 对一个或多个key求逻辑或，并将结果保存到destkey\nbitop or destkey key [key....] \n\n# 对一个或多个key求逻辑异或，并将结果保存到destkey\nbitop xor destkey key [key....]\n\n# 对一个或多个key求逻辑非，并将结果保存到destkey\nbitop not destkey key\n\n# 统计指定位区间上的值为1的个数，左边从0起，从右向左是从-1开始，官方start，end是位，测试后是字节\nbitcount key [start] [end]\n# 表示第一个字节的统计\nbitcount key 0 0 \n# 最常用的就是bitcount testkey\nbitcount testkey 0 -1 等价于 bitcount testkey\n\n# eg:\nset k1 99\nbitcount 99 # return 8 这里的99会被转换为字符串，字符串去找ascii，然后转换成二进制去查看。\n\n# Tip \nbitcount在处理中文的时候要要特殊注意\n```\n\n位图的应用：\n\n```shell\n# 网站用户的上线次数统计(活跃用户)\n用户id为key，天作为offset，上线就置位为1\n比如id为500的用户，今天的第一天上线，第30天上线\nsetbit u500 1 1\nsetbit u500 30 1\nbitcount u500\nkeys u*\n\n# 按天统计网站活跃用户\n天作为key，用户id为offset，上线置位为1，求一段时间内的活跃用户数\nsetbit 20160602 15 1\nsetbit 20160601 123 1\nsetbit 20160608 123 1\n求6月1日到6月10号的活跃用户\nbitop or 20160601-10 20160601 20160602 20160603 …… 20160610\nbitcount 20160601-10\n```\n\npython脚本示例：\n\n```python\nimport redis\nr = redis.Redis(host=\'127.0.0.1\',port=6379,db=0)\nr.setbit(\'u1\',1,1)\nr.setbit(\'u1\',30,1)\n\n# 模拟用户在一年内登录的记录\nfor i in range(3, 365, 3):\n    r.setbit(\'u101\', i, 1)\n    \nfor i in range(4, 365, 2):\n    r.setbit(\'u105\', i, 1)\n    \nuserlit = r.keys(\'u*\')\n# 活跃用户列表\nAu = []\n# 非活跃用户列表\nNau = []\nfor u in userlist:\n    loginCount = r.bitcount(u)\n    if loginCount > 100:\n        Au.append((u,loginCount))\n    else:\n        Nau.append((u,loginCount))\n```\n\n### 数字操作\n\n> redis有一些命令可以专门处理数字的值，只要存储在字符串key里的值可以被解释为64位整数或者标准的64位浮点数，那么用户就可以针对这个字符串执行针对数字值的命令，下面列出来了一些值来说明他们能否被解释为整数或者浮点数，科学计数法不会视图解释，直接当字符串了。\n>\n> 即使字符串key存储的是数字值，但是它仍然可以执行append，strlen，setrange和getrange，当用户针对一个数字执行这些命令的时候，redis会先将数字值转换为字符串，然后再执行命令。\n\n| 数值                              | 是否可以被解释 | 说明                                |\n| --------------------------------- | -------------- | ----------------------------------- |\n| 10086                             | yes            | 值可以被解析为整数                  |\n| 3.14                              | yes            | 值可以被解析为浮点数                |\n| +123                              | yes            | 值可以被解析为整数                  |\n| 123123123123123123123123123123123 | no             | 值太大，没办法使用64位整数来存储    |\n| 2.0e7                             | no             | redis不解释以科学计数法表示的浮点数 |\n| 123ABC                            | no             | 值包含文字                          |\n| ABC                               | no             | 值为文字                            |\n\n#### 增加或减少数字的值\n\n对于一个键是字符串的key，值是数字的，我们可以使用incrby命令增加值，或者是decrby命令来减少值，命令返回操作执行后，key的当前值是什么，如果key本来就不存在，那么redis会生成一个key为键，value为0的键值对，然后再来进行增量或者减量的操作\n\n```shell\n# 字符串值会被解释成64位有符号的十进制整数来操作，结果依然转换成字符串\n127.0.0.1:6379> INCRBY num 2\n(integer) 2\n127.0.0.1:6379> get num\n\"2\"\n127.0.0.1:6379> decrby num1 3\n(integer) -3\n127.0.0.1:6379> get num1\n\"-3\"\n```\n\n因为针对数字的加一减一操作很常用，比如微博的浏览量增加减少等。因此redis针对这个操作创建了incr和decr这两个命令：\n\n```shell\n127.0.0.1:6379> incr num\n(integer) 3\n127.0.0.1:6379> decr num\n(integer) 2\n```\n\n针对浮点数的增加\n\n```shell\n# 针对浮点数有增加，但是没有对应的减少的功能，但是我们可以通过加负值实现减法的功能\n127.0.0.1:6379> set num 10\nOK\n127.0.0.1:6379> INCRBYFLOAT num 3.14\n\"13.14\"\n127.0.0.1:6379> INCRBYFLOAT num -2\n\"11.14\"\n```\n\n## 其他操作\n\n- 清空redis\n\n  ```shell\n  # 这个基本不要用，会丢饭碗的~，这是清楚当前库数据\n  flusbdb\n  # 清除所有库中的数据\n  flushall\n  ```\n\n- 过期相关操作\n\n  ```shell\n  # 给key设置一个过期时间\n  expire key 秒数\n  pexpire key 毫秒数\n\n  # 设置一个指定的unix时间戳过期\n  expireat key 时间戳\n  pexpireat key milliseconds-timestamp\n\n  # 删除过期，在未过期的时间把把过期的设置取消掉。比如设置5s过期，5s内执行以下删除过期就不会过期了\n  persist key\n  ```\n\n- 生存时间\n\n  ```shell\n  # 查看剩余的生存时间\n  ttl key\n  pttl key\n  - key存在但是没有设置ttl，返回-1\n  - key存在，但还在生存期内，返回剩余的秒数或者毫秒数\n  - key曾经存在，但是已经消亡，返回-2，2.8以前的版本返回-1\n  ```\n\n- key的查找\n\n  ```shell\n  # 通过正则来查看数据库有哪些key\n  keys *\n  keys msg[1-3]\n  keys msg???\n\n  - *：表示任意长度字符\n  - ？：任意一个字符\n  - []：字符集合，表示可以是集合中的任意一个，比如[123]\n  ```\n\n- key属性相关\n\n  ```shell\n  # 查看key类型\n  type key\n  # 查看key是否存在，存在返回1，不存在返回0\n  exists key\n  # key的重命名\n  rename old_key new_key\n  # 如果这个键不存在重命名这个key，你重命名的这个新key有可能是现在已经存在的，如果你真的覆盖了，那么这个之前存在的key就被覆盖了，所以renamenx表示只有当你重命名的这个new key不存在的时候重命名（return 1），如果已经存在了就不重命名了（return 0）。\n  renamenx key newkey\n  # key删除\n  del key [key……]\n  ```\n\n  ​\n\n## 使用python客户端进行连接\n\n### 安装\n\n```python\npip install redis\n```\n\n### 简单连接使用\n\n```python\nIn [1]: import redis\n\nIn [2]: rds = redis.Redis(host=\"127.0.0.1\", port=6379, db=0)\n\nIn [3]: rds.set(\'testbin\', 0b01100010)\nOut[3]: True\n\nIn [4]: rds.get(\'testbin\')\nOut[4]: b\'98\'\n\nIn [5]: rds.set(0b0011, 0b01100011)\nOut[5]: True\n\nIn [6]: rds.get(0b0011)\nOut[6]: b\'99\'\n\n# 返回的是一个列表list\nIn [7]: rds.keys(\'*\')\nOut[7]: \n[b\'msg\',\n b\'3\',\n b\'key3\',\n b\'key2\',\n b\'num\',\n b\'mykey\',\n b\'num1\',\n b\'key1\',\n b\'testbin\',\n b\'a\',\n b\'b\']\n\nIn [8]: rds.set(\'test16\', 0x62)\nOut[8]: True\n\nIn [9]: rds.get(\'test16\')\nOut[9]: b\'98\'\n```\n\n","timestamp":1541470330295},{"name":"04-Hash散列操作.md","path":"01-Linux运维/07-DBA运维/02-Redis/04-Hash散列操作.md","content":"# List列表\n\n>- 基于Linked List实现\n>- 元素是字符串类型\n>- 列表头尾增删快，中间增删慢，增删元素是常态\n>- 元素可以重复出现\n>- 最多包含2的32次幂-1个元素\n>- 索引左到右是从0开始，从右刀座是从-1开始。\n\n## 命令说明\n\n- B block块，阻塞\n- L left 做\n- R right 右\n- X exist 存在\n\n## 常用操作\n\n**左右或者头尾压入元素**\n\n- LPUSH key value [value ……]\n\n  从左边压入元素\n\n- LPUSHX key value\n\n- RPUSH key value [value ..]\n\n- RPUSHX key value\n\n**左右或者头尾弹出元素**\n\n- LPOP key\n- RPOP key\n\n**从一个列表尾部弹出元素压入另一个列表的头部**\n\n- RPOPLPUSH source destination\n\n**返回列表中指定范围的元素**\n\n- LRANGE key start stop\n- LRANGE key 0 -1 表示返回所有元素\n\n**获取指定位置的元素**\n\n- LINDEX key index\n\n**设置指定位置元素的值**\n\n- LSET key index value\n\n**列表长度，元素个数**\n\n- LLEN key\n\n**从列表头部开始删除值等于value的元素count次**\n\n- LREM key count value\n  - count > 0 ：从表头开始向表尾搜索，移除与value相等的元素，数量为count\n  - count < 0 ：从表尾开始向表头搜索，移除与value相等的元素，数量为count的绝对值\n  - count = 0 ：移除表中所有与value相等的值。\n\n**去除指定范围外元素**\n\n- LTRIM key start stop （一个范围，把范围外的都删掉。）\n\n  ```shell\n  # 删除微博的评论最后500条\n  LTRIM u1234:forumid:comments 0 499\n  ```\n\n  ​","timestamp":1541470330295},{"name":"05-集合-有序集合.md","path":"01-Linux运维/07-DBA运维/02-Redis/05-集合-有序集合.md","content":"","timestamp":1541470330295},{"name":"06-redis的持久化.md","path":"01-Linux运维/07-DBA运维/02-Redis/06-redis的持久化.md","content":"# 持久化\n\n> 将数据从掉电容易失去的内存放到可以永久存储的设备上，保证了数据的安全性，并且也可以让服务器在重启的时候载入持久化文件来还原服务器在关闭之前的数据键数据，或者使用持久化文件来进行数据备份和数据迁移的工作。redis的持久化功能可以将服务器包含的所有数据库以二进制文件的形式保存到硬盘里，一定程度上节省了空间。\n>\n> **redis为什么需要持久化**\n>\n> - Redis是基于内存的\n> - 缓存服务器，作为缓存，数据丢失可能损失并不是很大\n> - 内存数据库，数据丢失影响就很大了。\n> - 消息队列\n\n## redis持久化方式\n\n### RDB（Redis DB）\n\n#### 创建RDB三种最常见的方式\n\n1. 服务器执行客户端发送save命令\n\n   ```shell\n   # 在手动执行save命令的过程中，也是rdb文件的创建过程中，redis服务器将被阻塞，无法处理客户端发送的命令请求，只有save命令执行完毕之后，rdb文件生成之后，服务器才会重新开始处理客户端发送的命令请求。如果说rdb文件已经存在，服务器将自动使用心得rdb文件替代就的rdb文件。\n\n   # 我们可以写一个定时的任务，定期的去把dump.rdb转移走。相当于一个备份，防止有人flushdb然后save。给自己留一个后路，同时保存固定的数量个，然后用对应的时间命名。这样操作同样也是为了防止机房出现硬件级别的问题。\n   ```\n\n2. 服务器执行客户端发送bgsave命令\n\n   ```shell\n   # bgsave也会创建一个新的rdb文件，和save不同的地方在于，bgsave不会造成redis服务的阻塞，在执行bgsave的时候，服务器仍然可以接受用户的请求的。\n\n   # 不会造成则色的原因有以下三个\n   # 1、redis在接收到一个bgsave命令的时候它不是自己创建rdb文件，而是fork出来一个子进程去处理rdb文件的创建工作，自己继续去处理用户的请求\n   # 2、当子进程创建好rdb文件并退出的时候会向父进程(也就是负责处理命令处理的redis服务器)发送一个讯号，告知它这个rdb文件已经创建完毕了。\n   # 3、redis服务器(父进程)接收子进程创建的rdb文件bgsave执行完毕\n\n   # bgsave本身是一个异步的过程，发送命令客户端会立即得到回复，但是实际操作在回复之后才会开始。\n\n   # 创建子进程，会消耗额外的内存，所以save创建会比bgsave稍微快一些，这两种没有好坏之分，而是哪一种更适合你，比如数据库在线上跑着，那肯定要用bgsave，如果停机维护那就save，因为即使被阻塞也没有什么影响，停机期间，没有用户请求的。\n   ```\n\n   ![](http://omk1n04i8.bkt.clouddn.com/18-5-2/21724319.jpg)\n\n   ![](http://omk1n04i8.bkt.clouddn.com/18-5-2/28727078.jpg)\n\n3. 使用save配置选项设置自动保存，服务器自动执行bgsave\n\n   - save 300 10：表示距离上一次创建rdb文件过去了300s，并且服务器的所有数据库总共发生了不少于10次的修改，那么就执行bgsave命令。\n   - save 60 10000：距离上一次创建rdb文件过去了60s，并且服务器的所有数据库总共发生了不少于10000次修改，那么就执行bgsave命令\n   - 另外，用户还可以通过设置多个save选项来设置多个启动保存的条件，当任意一个条件被满足的时候就会执行这个bgsave的命令。每一次创建rdb文件后，服务器为实现自动持久化而设置的时间计数器和次数计数器就会被清零并开始重新技术，所以说多个保存条件效果是不会互相叠加的。\n\n#### 配置项\n\n在配置文件中设置rdb文件的文件名和文件位置\n\n```shell\n# The filename where to dump the DB\ndbfilename dump.rdb\n```\n\n自动保存的配置\n\n```shell\n# 这个你可以写多条\nsave 900 1\nsave 300 10\nsave 60 10000\n```\n\n#### RDB文件内容\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-2/88585687.jpg)\n\nrdb文件是一个二进制文件，它保存了redis服务器创建rdb文件的时候所有数据库的数据。\n\n#### 问题\n\n- rdb是单文件，如果库很大的话文件也会很大，查询起来，速度也会受到影响。\n- rdb文件操作也不能太过频繁，过于频繁会严重影响服务器的性能。\n- 重启以后redis会自己读取rdb文件加载到内存中。从配置中的dir获取目录\n- 可以通过lastsave查看最后一次备份成功的时间\n- 执行flushdb命令也会产生dump.rdb文件，但里面是空的，没有意义。\n\n### AOF（AppendOnlyFile）\n\n> RBD持久化还是存在一些问题的，一个是频繁操作可能存在性能的损耗，再有就是在配置文件中体现的那些自动执行bgsave的触发条件，随便拿一个`save 60 10000`来讲，即使一分钟内修改超过了1w次，那么要等一分钟以后才会重新生成一个文件，这期间其实就存在说突然宕机的可能。那这个时间段内的数据就极有可能丢失。针对那些对数据的一致性要求很高的环境，rdb就存在一定的缺陷，因此针对这个问题，还有一种持久化方式，那么就是AOF的持久化方式。\n\nAOF持久化有一个很大的优势那就是，用户可以根据自己的需要对AOF持久化进行调整，让redis在遭遇意外宕机或者停机的时候不丢失数据，或者丢失的数据很少很少，比如丢失前1s的数据。这个可以把损失降到最低。\n\n#### AOF原理\n\nAOF持久化的操作原理是被当有**<u>修改数据库的命令</u>**被执行的时候，服务器就会将执行的命令写入到AOF文件的末尾。和RDB不一样，AOF保存的是执行的操作，而不是数据本身。因为AOF文件里储存了服务器执行过的所有数据库修改的命令，所以给定一个AOF文件，服务器只要重新执行一遍AOF文件里面包含的所有命令，就可以达到还原数据库的目的。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-2/39781256.jpg)\n\n举一个AOF文件记录的内容的例子，比如：\n\n```shell\nSELECT 0\nSET msg \"hello\"\nINCR counter\nSADD alphabets \"a\" \"b\" \"c\"\nINCR counter\n```\n\n#### 安全性问题\n\n虽然服务器执行一个修改数据库的命令，就会把执行的命令记录到AOF文件中，但这个并不意味着AOF持久化一点数据也不会丢，在目前常见的操作系统中，执行系统调用函数write函数，将一些内容写到某个文件里面的时候为了提高效率，系统通常不会直接将内容写入到硬盘里，而是先放到一个内存的缓冲区（buffer）里面，缓冲区满了，或者用户手动执行fsync调用和fdatasync调用的时候才会将缓冲区的内容写到硬盘里。\n\n因此对于AOF来说，当一条命令真正的被写到硬盘里后才是真正意义上的保存住了。因此AOF持久化在遭遇停机时丢失命令的数量，取决于命令被写入到硬盘的时间，越早的将命令写到硬盘，发生意外丢失的数据就越少，反之丢失的就越多。\n\n##### appendfsync\n\n```shell\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n```\n\n为了控制redis服务器遇到意外停机而导致数据丢失，redis的aof持久化提供了一个appendfsync选项，这个选项的值可以是always，everysec或者是no。\n\n- no：就是服务器不主动调用fdatasync，这个操作让操作系统自行去决定写入硬盘的时机，这个在遭遇问题的时候丢失的数据量其实是不可控的。\n- Always：服务器的每写入一个命令，就调用一次fdatasync，将修改写入到应硬盘，这种模式下，即使遭遇意外停机，也不会丢失任何已经成功操作的命令数据。\n- Everysec：一秒执行一次fdatasync，较always频率要低，如果遭遇了宕机也就是丢失一秒钟内的执行的命令数据。\n\n因为always是执行一个就写一次，所以这个其实是运行速度最慢的，其他的两个都很快。建议使用的是everysec，同时默认值也是everysec。\n\n#### AOF中的冗余命令\n\n随着服务器的运行，不断的记录数据库的变化，AOF文件的体积是不断增加的。所以针对AOF文件的大小要进行合理的控制，针对这个问题redis提供了一个aof重写的功能，通过这个功能，服务器可以生成一个新的aof文件。\n\n- 新的aof文件记录的数据库数据和原有的aof文件记录的数据库数据完全一样。\n- 新的aof文件会使用极可能少的命令来记录数据库数据，因此新的aof文件的体积通常会比原有的aof文件体积小很多。\n- aof重写期间，服务器不会被阻塞，可以正常处理客户端发送的命令请求。\n\n简单来讲就是在保证数据一致性完整性的前提下将命令进行一定程度的精简从而达到节省空间的目的，比如：\n\n![AOF缩减](http://omk1n04i8.bkt.clouddn.com/18-5-2/75273038.jpg)\n\n**控制AOF重写的方式**\n\n1. 客户端向服务器发送`BGREWRITEAOF`命令\n2. 通知配置选项来让服务器自动执行`bgwriteaof`，命令。\n   - auto-aof-rewrite-min-size：触发aof重写需要的最小的体积，只要aof文件的体积大于等于这个size的时候服务器才会考虑是否需要进行aof重写，这个选项用于避免对体积过小的aof文件重写\n   - auto-aof-rewrite-percentage：指定触发重写所需要的aof体积的百分比，当aof的文件体积大于`auto-aof-rewrite-min-size`指定的体积的时候，并且超过上一次重写之后的aof文件体积的`percent%`，就会触发重新。如果服务器刚重启，还没有进行过aof重写，那么使用服务器启动时载入的aof文件的体积来作为基准值，如果将这个值设置为0的时候表示关闭aof的重写。（怎么理解这个例子，比如设置的最小大小，如果这个百分比设置为100，也就是AOF文件的增量大于100%以后才会触发重写。）\n\n#### AOF配置\n\n```shell\nappendonly no\nappendfilename \"appendonly.aof\"\nappendfsync everysec\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n```\n\n#### Tip\n\n由于aof记录的是操作命令，所以说如果有人手贱执行了flushdb的话那么在aof的文件中也会有这个内容，紧急情况下，也可以手动编辑aof的备份文件，把最后执行的flushdb这条记录的内容手动删掉。所以说AOF文件里有FLUSHALL这个其实挺坑的。\n\n假如说aof的备份文件有问题的话，比如我手动给aof文件的末尾加了一堆乱起八糟的字符。会导致aof备份文件无法成功加载，进而导致redis服务根本起不来。如果说aof文件有问题可以使用自带的修复软件进行修复\n\n```shel\nredis-check-aof --fix appendonly.aof\n```\n\n## 小结\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-2/29823792.jpg)\n\n一般来说为了数据的安全性，可以两种持久化都开启。然后还原数据的时候优先使用aof的数据进行还原。rdb适合大规模的数据恢复，但是对数据的一致性和完整性要求不高。RDB更适合备份数据库，所以以后在做主从的时候slave上可以只开rdb持久化，15min备一次就够。只保留save 900 1.当然这个只是一个建议值，具体还是要结合实际环境来。\n\n如果Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。\n\n\n如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。新浪微博就选用了这种架构","timestamp":1541470330295},{"name":"07-redis事物.md","path":"01-Linux运维/07-DBA运维/02-Redis/07-redis事物.md","content":"redis事物\n\n>可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞\n\n","timestamp":1541470330295},{"name":"08-redis消息发布与订阅.md","path":"01-Linux运维/07-DBA运维/02-Redis/08-redis消息发布与订阅.md","content":"","timestamp":1541470330295},{"name":"09-redis主从.md","path":"01-Linux运维/07-DBA运维/02-Redis/09-redis主从.md","content":"# Redis主从\n\n> - 一个redis服务可以由多个该服务的复制品，这个redis服务成为master，其它的复制品为slave\n> - 只要网络连接正常，master就会一直把自己的数据更新同步给slave，保持主从同步\n> - 只有master可以执行写命令，slave只能执行读命令\n\n## 主从复制的创建\n\n- 配置当前服务器为某redis服务器的slave，在启动的时候。\n\n```shell\nredis-server --port 端口 --slaveof <master-ip> <master-port>\n```\n\n- slaveof host port 命令将当前服务器状态从master修改为别的服务器的slave\n\n```shell\n# 将服务器转换为slave\nslaveof 192.168.1.1 6379   \n# 将服务器重新恢复到master，不会丢弃已经同步的数据\nsalveof no one\n```\n\n- 配置方式：启动的时候，服务器读取配置文件，并自动成为指定服务器的从服务器。\n\n```shell\nslaveof <masterip> <masterport>\nslaveof 127.0.0.1 6379\n```\n\n- master可以设置密码，设置密码后，需要需要填写密码\n\n```shell\nmasterauth <passord>\n```\n\n- 设置slave大于多少后才允许写入\n\n```shell\nmin-slaves-to-write <number of slaves>\n```\n\n- 设置从服务器的延迟不大于xx\n\n```shell\nmin-slaves-max-lag <number of seconds>\n```\n\n可以看到主从复制的设置方式其实是及其简单的，直接配置一下就可以了。\n\n- 一个master可以有多个slave，首次的复制是全量的，后续的是增量的。\n- slave下线只是读请求的性能下降，因为slave一般是只读。\n- master下线，写请求无法执行\n- 可以手动在一台从机上执行slaveof no one，然后再其它redis上使用slaveof指向这个新的master，实现数据的同步。不过这个过程是纯手动的，如果想要实现自动就需要Sentine哨兵，实现故障转移FailOver操作。\n- info replication可以查看主从状态。\n\n### 主从方案\n\n- 一主双从\n- 薪火相传，比如ABC，A是B的master，B是C的master。B在角色上是salve，不过在info replication中也是可以看到C这个slave的。\n\n## 哨兵\n\n> 哨兵Sentinel是由官方提供的一个高可用的方案，可以用它来管理多个redis服务的实例，当我们在make编译完成以后会生成一个redis-sentinel的程序文件。Redis Sentinel是一个分布式系统，可以在一个架构中运行多个Sentinel进程\n\n### 启动Sentinel\n\n1. 将src目录下产生的redis-sentinel程序拷贝到`$REDIS_HOME/bin`目录下\n\n2. 期待用一个运行在Sentinel模式下的redis服务实例\n\n   ```shell\n   # 第一种方法\n   redis-sentinel\n   # 第二种方法\n   redis-server config路径 --sentinel\n   ```\n\n#### Tip\n\n- Sentinel会不断检查Master和slave是否正常\n- 每一个Sentinel可以监控任意多个master和该master下的slave\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-3/22700090.jpg)\n\n当然哨兵本身就是一个单点，存在单点故障。因此我们可以搭建一个Sentinel的集群\n\n### Sentinel网络\n\n> 监控同一个master的Sentinel会自动连接，组成一个分布式的Sentinel网络，互相通信并交换彼此关于被监视服务器的信息。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-3/90204474.jpg)\n\n- 当一个Sentinel认为被监视的服务器已经下线时，它会向网络中的其他Sentinel进行确认，判断该服务器是否真的已经下线\n- 如果下线的服务器为master，那么Sentinel网络将对下线master服务器进行故障转移，通过将下线的master的某一个slave提升为新的master，并让其它的slave的复制指向新的master，以此来让系统重新回到上线的状态。故障机修复以后自动成为slave。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-3/6339105.jpg)\n\n### Sentinel配置文件\n\n- 至少包含一个监控配置选项，用于指定被监控的master的相关信息\n\n  ```shell\n  sentinel monitor <name> <ip> <port> <quorum>\n  - name : 给监控的主服务器起一个名称\n  - ip ：ip地址\n  - port ： 端口\n  - quorum ：仲裁，需要几台Sentinel同意才判定有效\n  举例：\n  # 表示master的ip为127.0.0.1，端口为6379的主服务器设置名称为master，仲裁数目为2，表示将这个master判定为下线失效，需要至少两个Sentinel统一，如果多数sentinel同意才会执行故障转移\n  sentinel monitor mymaster 127.0.0.1 6379 2\n  ```\n\n- 不需要给Sentinel配置从的信息，因为master是知道的，Sentinel会根据master的配置自动发现master的slaves。\n\n- Sentinel的默认端口为26379\n\n#### 配置举例\n\n**配置项**\n\n```shell\nport 26379\nsentinel monitor m1 192.168.56.101 6379 1\nsentinel auth-pass m1 testpass\n# 超过3w毫秒后认为主机宕机\nsentinel down-after-milliseconds m1 30000\nsentinel parallel-syncs m1 1\n# 当主从切换多久后认为主从切换失败\nsebtinel failover-timeout m1 180000\n```\n\n我准备了两台机器，一台192.168.56.101，一台192.168.56.102，101上起了6379.6380.6381三个实例，然后也在102上起了一个实例，其中101的6379是master，其他的都是slave。启动以后哨兵会去自动发现master的slaves这个其实在日志里我们就可以看到，可以很直接的体现：\n\n```shell\n# Sentinel runid is 7e5e9e712ad101aeb577042106a5cc8ffddbb45a\n# +monitor master m1 127.0.0.1 6379 quorum 1\n* +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n* +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6379\n* +slave slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6379\n```\n\n现在手动把master停掉可以发现哨兵的日志立即就有反应，这样的报错会间隔一段时间，有这样一个过程：\n\n```shell\n# Connection with master lost.\n* Caching the disconnected master state.\n* Connecting to MASTER 127.0.0.1:6379\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n```\n\n当哨兵真的认为这个master已经挂掉了的时候就会开始采取提主的操作：\n\n```shell\n# +sdown master m1 127.0.0.1 6379\n+odown master m1 127.0.0.1 6379 #quorum 1/1\n# +new-epoch 1\n# +try-failover master m1 127.0.0.1 6379\n# +vote-for-leader 7e5e9e712ad101aeb577042106a5cc8ffddbb45a 1\n# +elected-leader master m1 127.0.0.1 6379\n# +failover-state-select-slave master m1 127.0.0.1 6379\n# +selected-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n* +failover-state-send-slaveof-noone slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n* +failover-state-wait-promotion slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n* Discarding previously cached master state.\n* MASTER MODE enabled (user request)\n* Connecting to MASTER 127.0.0.1:6379\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n# +promoted-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n# +failover-state-reconf-slaves master m1 127.0.0.1 6379\n* +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6379\n* Discarding previously cached master state.\n* SLAVE OF 127.0.0.1:6380 enabled (user request)\n* Connecting to MASTER 127.0.0.1:6380\n* MASTER <-> SLAVE sync started\n* Non blocking connect for SYNC fired the event.\n* Master replied to PING, replication can continue...\n* Partial resynchronization not possible (no cached master)\n* Slave 127.0.0.1:6381 asks for synchronization\n* Full resync requested by slave 127.0.0.1:6381\n* Starting BGSAVE for SYNC with target: disk\n* Background saving started by pid 6474\n* Full resync from master: 2b29611014608aa041ec4b36b1ddb35dc7172ea7:1\n* DB saved on disk\n* RDB: 0 MB of memory used by copy-on-write\n* Background saving terminated with success\n* Synchronization with slave 127.0.0.1:6381 succeeded\n* MASTER <-> SLAVE sync: receiving 41 bytes from master\n* MASTER <-> SLAVE sync: Flushing old data\n* MASTER <-> SLAVE sync: Loading DB in memory\n* MASTER <-> SLAVE sync: Finished with success\n* +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6379\n* +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6379\n* +slave-reconf-sent slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6379\n* +slave-reconf-inprog slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6379\n# +failover-end-for-timeout master m1 127.0.0.1 6379\n# +failover-end master m1 127.0.0.1 6379\n* +slave-reconf-sent-be slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6379\n* +slave-reconf-sent-be slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n# +switch-master m1 127.0.0.1 6379 127.0.0.1 6380\n* +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6380\n* +slave slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6380\n* +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ m1 127.0.0.1 6380\n# +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ m1 127.0.0.1 6380\n```\n\n#### 注意事项\n\n- 注意不要在哨兵中写127.0.0.1这种的地址，如果哨兵真的开始切换地址以后从机有可能找不到master。\n\n## 总结\n\n- 主从复制，解决了读请求的分担，从节点下线，会使得读请求能力有所下降\n- Master只有一个，存在单点问题\n- Sentinel会在master下线后自动执行failover操作，提升一台slave为master，并让其他的slaves重新成为新的master的slaves。\n- 主从复制+哨兵Sentinel只解决了读性能和高可用问题，但是并没有解决写性能安全和瓶颈，同时也没有应对应用动态切换地址的方案。","timestamp":1541470330295},{"name":"10-Twitter-TwemProxy.md","path":"01-Linux运维/07-DBA运维/02-Redis/10-Twitter-TwemProxy.md","content":"# Twitter-TwemProxy\n\n>- 主从对写压力没有分担，因此考虑可以使用多个节点进行分担，将请求分担到不同的节点处理\n>- 分片sharding，多借点分担的思路就是关系型数据库处理大表水平切分的思路。\n>\n>![](/var/folders/8l/g95nllln61j4ly_zm_tqj2m40000gn/T/abnerworks.Typora/image-201805040949289.png)\n\n## Twemproxy\n\n> Twitter开发的，用来代理用户的读写请求。\n>\n> - Twitter开发的代理服务器，它兼容redis也兼容memcached，允许用户将多个redis服务器添加到一个服务器池（pool）里面，并通过用户选择的**散列函数**和**分布函数**，将来自客户端的命令请求分发给服务池中的各个服务器\n> - 通过使用twemproxy我们可以将数据库分片到多态redis服务器上面，并使用这些服务器来分担系统压力以及数据库容量：在服务器硬件条件相同的情况下，对于一个包含n台redis服务器的池来说，池中每台平均处理1/N的客户端请求\n> - 向池里添加更多服务器可以线性的扩展系统处理命令请求的能力，以及系统能够保存的数据量。之所以这么说是客户端写请求过来的时候twemproxy会计算一个key的散列值，每一个服务器会有一个自己散列值对应的的范围，如果这个key的散列值范围在对应的服务器范围内，那么请求就到对应的服务器上。\n> - 一个代理存在单点故障\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-4/22811802.jpg)\n\n## Twemproxy安装\n\n> Github:https://github.com/twitter/twemproxy\n\n安装步骤：\n\n```shell\n# 如果说yum安装的相关软件包的版本过低的话需要自己手动编译安装。\nyum -y install autoconf automake libtool\ntar xf nutcracker-0.4.1.tar.gz\ncd nutcracker-0.4.1\nmkdir /usr/local/twemproxy\n./configure --prefix=/usr/local/twemproxy\nmake && make install\n```\n\n新建一个配置文件，在当前目录下就可以，配置内容如下：\n\n```shell\n[root@DB102 20:41:49 /root/nutcracker-0.4.1]\n#vim tp.yml\nsxt:\n  listen: 192.168.56.101:22121\n  hash: fnv1a_64\n  distribution: ketama\n  auto_eject_hosts: true\n  redis: true\n  server_retry_timeout: 2000\n  server_failure_limit: 3\n  servers:\n    - 192.168.56.101:6379:1\n    - 192.168.56.101:6380:1\n    - 192.168.56.101:6381:1\n```\n\n启动twemproxy之前先确保redis都起来了。\n\n```shell\n[root@DB102 20:45:56 /root/nutcracker-0.4.1]\n#ps -ef | grep redis | grep -v grep\nroot     18526  7402  0 20:45 pts/0    00:00:00 redis-server *:6379\nroot     18542  7402  0 20:45 pts/0    00:00:00 redis-server *:6380\nroot     18550  7402  0 20:45 pts/0    00:00:00 redis-server *:6381\n```\n\n启动twemproxy：\n\n```shell\n# 其中-d表示以daemon的方式去运行。-c指定配置文件\n[root@DB102 20:47:36 /root/nutcracker-0.4.1]\n#/usr/local/twemproxy/sbin/nutcracker -d -c tp.yml\n```\n\n查看服务状态\n\n```shell\n#netstat -antup | grep 22121\ntcp        0      0 192.168.56.101:22121    0.0.0.0:*               LISTEN      18774/nutcracker \n```\n\ntwemproxy代理了redis协议，我们就可以直接去连接它了，记得加上-h主机。\n\n```shell\n[root@DB102 20:56:22 /root/nutcracker-0.4.1]\n#redis-cli -p 22121 -h 192.168.56.101\n192.168.56.101:22121> set msg 111 \nOK\n192.168.56.101:22121> get msg\n\"111\"\n```\n\n最后这个数据会放到后端的一台机器上，我们现在后端代理了三台机器，会放到其中一台机器上。这里我们也看到了这个问题，就是目前几台数据是不同步的。如果其中有一个节点挂掉了，那么这个数据就访问不到了，除非你再上线这个redis才能访问到。\n\n## Twemproxy配置\n\n```shell\n# 这个配置是yaml格式的，每一个层级固定两个空格。而且冒号后要有一个空格。\nsxt:\n  listen:192.168.56.201:22121\n  hash:fnv1a_64\n  distribution:ketama\n  auto_eject_hosts:true\n  redis:true\n  server_retry_timeout:2000\n  server_failure_limit:3\n  servers:\n    - 192.168.56.201:6379:1\n    - 192.168.56.202:6379:1\n    - 192.168.56.203:6379:1\n```\n\n- ext：server pool的名称，可以创建多个serverpool\n- listen：server pool监听的地址和端口号\n- hash：key的散列算法，用于将key映射为一个散列值\n- distribution：key的分布算法，决定key被分布到哪一个服务器\n- redis：代理redis请求，不给定这个值的时候默认代理memcached请求，true表示代理redis\n- servers：pool中各个服务器的地址和端口号以及权重\n- server_retry_timeout：连不上的超时时间\n- auto_eject_hosts：设置为true表示当请求的散列范围对应到某个服务器，但是服务器无法访问的时候直接拒绝掉这个请求，这样效率会高一些。\n- server_failure_limit：twemproxy连续n次向同一个服务器发送命令请求都遇到错误的时候，twemproxy就会将改服务器标记为下线，并交由pool中其他在线服务器采集；哦\n\n## 整合方案\n\nredis-mgr：通过整合复制，哨兵以及twemproxy等组件，提供了一站式的redis服务器部署，监控，迁移功能。网址`https://github.com/changyibiao/redis-mgr`。或者使用更好的方案，redis集群。\n\n## 小结\n\n- 扩展不是很方便，容错率低\n- 代理存在单点问题\n- 后端服务器数据不同步\n- 前端使用proxy做代理，后端的redis可以基本根据key来进行比较均衡的分布\n- 如果后端的redis挂掉以后，代理能够自动摘除，恢复后，代理还能自动识别，恢复并加入到redis分组中重新使用。\n- redis挂掉以后，后端数据是否丢失依据redis本身的持久化策略配置，与twemproxy无关\n- 新加redis需要重启twemproxy，并且数据不会自动重新的rebanlance，需要人工写脚本来实现。\n- 如果原来有两个节点redis，后续又增加两个redis，则数据分布计算与原来的redis分布无关，现有数据如果需要分布均匀的话，需要人工单独处理。\n- 如果twemproxy的后端节点数量发生变化，twemproxy相同算法的前提下，原来的数据必须重新处理分布，否则会存在找不到key值的情况。\n- 不管twemproxy后端有几台redis，前端的单个twemproxy的性能最大也只能和单台redis性能差不多。\n- 如同时部署多台twemproxy配置一样，客户端分别连接多台twemproxy可以在一定条件下提高性能。","timestamp":1541470330295},{"name":"11-redis3.x集群.md","path":"01-Linux运维/07-DBA运维/02-Redis/11-redis3.x集群.md","content":"# Redis集群\n\n> - 3.0支持\n> - 由多个redis服务器足证的分布式网络服务集群\n> - 每一个redis服务器成为节点node，节点之间会互相通信，两两相连。\n> - redis集群无中心节点，没有一个主从的概念，不建议节点数量太多，可能会受到网络io的影响。\n> - redis集群不支持那些需要同时处理多个键的redis命令，因为执行这些命令需要在多个redis节点之间移动数据，并且高负载的情况下，这些命令将降低redis集群的性能，并导致不可预测的行为。\n\n## Redis集群节点复制\n\n- redis集群的每个节点都有两种角色可以选择，主节点，master node。从节点，slave node。其中主节点用于存储数据，而从节点是某一个主节点的复制品。\n- 当用户需要处理更多读请求的时候，添加从节点可以扩展系统的读性能。因为redis集群重用了单机redis复制特性的代码，所以集群的复制行为和我们之前介绍的单机复制特性行为是完全一致的。所以一般搭建就是6个node，3主3从。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-4/82220774.jpg)\n\n## Redis集群故障转移\n\n- Redis集群的主节点内置了类似redis哨兵的节点故障检测和自动故障转移功能，当集群中的某个主节点下线的时候，集群中的其他在线节点会注意到这一点，并对已下线的主节点进行故障转移。\n- 集群进行故障转移的方法和redis哨兵进行故障转移的方法进本一样，不同的是在集群里面，故障转移是由集群中其他的主节点负责进行的，所以集群不必另外使用redis哨兵。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-4/80981446.jpg)\n\n## Redis集群分片\n\n- 集群将整个数据库分为16384个槽位（slot），key会存放在这些槽位中的一个，key的槽位的计算公式为（slot_number=crc16(key)%16384），其中crc16位16位的循环冗余校验和函数。\n- 集群中的每一个主节点都可以处理0个至16383个槽，当16384个槽为都有某个节点在负责处理的时候集群进入上线状态，并开始处理客户端发送的数据命令请求。\n\n### Example\n\n- 三个主节点7000、7001、7002平均分片16384个slot槽位\n- 节点7000分到0~5460\n- 节点7001分到5461~10922\n- 节点7002分到10923~16383\n\n## Redis集群的重定向\n\n由于redis集群没有中心节点，所以请求会发给任意的主节点。主节点只会处理自己负责的槽位的命令请求，针对其他槽位的命令请求，该主节点会返回客户端一个redirect错误，客户端根据错误中包含的地址和端口重新向正确的负责的主节点发起命令请求。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-4/6189858.jpg)\n\n## 搭建Redis集群\n\n- 创建多个主节点\n- 为每一个节点指派slot，将多个节点连接起来，组成一个集群。\n- 槽位分片完成以后，集群进入上线状态。\n- 6个节点，3个主节点，每一个主节点有一个从节点。\n- 在应用端可以写一个列表，愿意连接哪个就连接哪个\n\n### 安装新版redis\n\n```shell\n# 编译安装过程\ncd /tools/\nwget http://download.redis.io/releases/redis-4.0.9.tar.gz\ntar xf redis-4.0.9.tar.gz \ncd redis-4.0.9\nmake\nmkdir /usr/local/redis4\nmake PREFIX=/usr/local/redis4 install\n\n# 修改环境变量过程\nvim ~/.bash_profile\n# 添加上这么一行\nexport PATH=$PATH:/usr/local/redis4/bin\n# 生效环境变量\n. ~/.bash_profile\n查看生效结果\n# which redis-cli\n/usr/local/redis4/bin/redis-cli\n```\n\n查看编译生成的redis的bin目录\n\n```shell\n# 哨兵和sever整合到一起去了\n[root@localhost bin]# ll\ntotal 21860\n-rwxr-xr-x. 1 root root 2451872 May  3 10:23 redis-benchmark\n-rwxr-xr-x. 1 root root 5770168 May  3 10:23 redis-check-aof\n-rwxr-xr-x. 1 root root 5770168 May  3 10:23 redis-check-rdb\n-rwxr-xr-x. 1 root root 2616976 May  3 10:23 redis-cli\nlrwxrwxrwx. 1 root root      12 May  3 10:23 redis-sentinel -> redis-server\n-rwxr-xr-x. 1 root root 5770168 May  3 10:23 redis-server\n```\n\n准备6个实例，为每一个实例新建一个目录用来保存各自的配置文件\n\n```shell\nmkdir -p clustertest/700{0..5}\n```\n\n在对应的每一个目录一下新建redis的配置文件，内容如下：\n\n```shell\ncluster-enabled yes\n# 端口随着每个实例的变动而更改\nport 7000\nlogfile /root/clustertest/7000/redis.log\ndaemonize yes\ncluster-config-file /root/clustertest/7000/nodes.conf\ncluster-node-timeout 5000\npidfile \"/root/clustertest/7000/redis7000.pid\"\n```\n\n文件目录：\n\n```shell\n[root@DB102 22:38:19 /root/clustertest]\n#tree .\n.\n├── 7000\n│   └── redis.conf\n├── 7001\n│   └── redis.conf\n├── 7002\n│   └── redis.conf\n├── 7003\n│   └── redis.conf\n├── 7004\n│   └── redis.conf\n└── 7005\n    └── redis.conf\n```\n\n启动实例，这里有一个值得注意的点就是在配置文件里我没有指定nodes.conf，那么nodes.conf就会生成在运行redis-server的当前目录，所以需要切换到对应的700x目录里面去运行，否者多个实例启动nodes.conf会冲突，如果不想这样的话就在每一个redis.conf中指定nodes.conf的位置：`cluster-config-file nodes.conf`\n\n```shell\nredis-server redis.conf\n```\n\n查看端口：\n\n```shell\n// 其中700x是客户端端口，1700x是彼此交互用的端口，这个交互用的端口会在cluster-enable=yes的时候启动起来。\n[root@DB102 23:30:13 /root/clustertest/7003]\n#ss -tanl | grep 700\nLISTEN     0      128          *:17002                    *:*                  \nLISTEN     0      128          *:17003                    *:*                  \nLISTEN     0      128          *:17004                    *:*                  \nLISTEN     0      128          *:17005                    *:*                  \nLISTEN     0      128          *:7000                     *:*                  \nLISTEN     0      128          *:7001                     *:*                  \nLISTEN     0      128          *:7002                     *:*                  \nLISTEN     0      128          *:7003                     *:*                  \nLISTEN     0      128          *:7004                     *:*                  \nLISTEN     0      128          *:7005                     *:*                  \nLISTEN     0      128          *:17000                    *:*                  \nLISTEN     0      128          *:17001                    *:*                  \nLISTEN     0      128         :::17002                   :::*                  \nLISTEN     0      128         :::17003                   :::*                  \nLISTEN     0      128         :::17004                   :::*                  \nLISTEN     0      128         :::17005                   :::*                  \nLISTEN     0      128         :::7000                    :::*                  \nLISTEN     0      128         :::7001                    :::*                  \nLISTEN     0      128         :::7002                    :::*                  \nLISTEN     0      128         :::7003                    :::*                  \nLISTEN     0      128         :::7004                    :::*                  \nLISTEN     0      128         :::7005                    :::*                  \nLISTEN     0      128         :::17000                   :::*                  \nLISTEN     0      128         :::17001                   :::* \n```\n\n### 创建集群\n\n> 脚本槽位分配通过redis-trib这个脚本来进行分配，但是这个脚本是ruby写的，所以还要安装ruby的环境。\n>\n> ```shell\n> yum -y install ruby rubygems\n> # ruby用于连接redis的一个组件\n> gem install redis\n> # 如果说卡住不动可能是镜像源问题，切换一下镜像源\n> gem sources --add https://gems.ruby-china.org/ --remove https://rubygems.org/\n> gem sources -l\n> # 或者将gem的redis安装包下载下来进行本地的安装，也是没有问题的\n> gem install --local redis-x.x.x.gem\n>\n> # 在centos7中有可能会遇到如下的报错：\n> #gem install redis\n> Fetching: redis-4.0.1.gem (100%)\n> ERROR:  Error installing redis:\n>         redis requires Ruby version >= 2.2.2.\n>         \n> # 这是因为centos7的yum库的ruby版本支持到2.0.0，因此需要自己需要自己去升级一下\n> #ruby --version\n> ruby 2.0.0p648 (2015-12-16) [x86_64-linux]\n> ```\n>\n> 升级ruby的版本\n>\n> ```shell\n> # 使用rvm的方式来更新ruby\n> 1、安装rvm\n> gpg2 --keyserver hkp://keys.gnupg.net --recv-keys D39DC0E3\n> curl -L get.rvm.io | bash -s stable\n>\n> # find / -name rvm -print\n> /usr/local/rvm\n> /usr/local/rvm/src/rvm\n> /usr/local/rvm/src/rvm/bin/rvm\n> /usr/local/rvm/src/rvm/lib/rvm\n> /usr/local/rvm/src/rvm/scripts/rvm\n> /usr/local/rvm/bin/rvm\n> /usr/local/rvm/lib/rvm\n> /usr/local/rvm/scripts/rvm\n>\n> source /usr/local/rvm/scripts/rvm\n>\n> 2、查看rvm库中已知的ruby版本\n> #rvm list known \n> # MRI Rubies\n> [ruby-]1.8.6[-p420]\n> [ruby-]1.8.7[-head] # security released on head\n> [ruby-]1.9.1[-p431]\n> [ruby-]1.9.2[-p330]\n> [ruby-]1.9.3[-p551]\n> [ruby-]2.0.0[-p648]\n> [ruby-]2.1[.10]\n> [ruby-]2.2[.7]\n> [ruby-]2.3[.4]\n> [ruby-]2.4[.1]\n> ……………………………………省略后续的内容\n>\n> 3、安装一个新的版本并使用，设置默认版本\n> rvm install 2.4.1\n> rvm use 2.4.1\n> rvm use 2.4.1 --default\n>\n> 4、移除旧版的ruby\n> rvm remove 2.0.0\n>\n> 5、查看ruby版本，然后再执行上面的安装就没问题了\n> #ruby --version\n> ruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]\n> ```\n\n找到redis源码包中的src中的redis-trib.rb文件\n\n```shell\n[root@DB102 03:36:46 /tools/redis-4.0.9/src]\n#pwd\n/tools/redis-4.0.9/src\n\n[root@DB102 03:36:55 /tools/redis-4.0.9/src]\n#ll redis-trib.rb \n-rwxrwxr-x. 1 root root 65991 3月  27 00:04 redis-trib.rb\n```\n\n执行redis-trib.rb文件，简单说明一下，其中`--replicas 1`指定副本数有1，也就后面跟的6个实例里三主三从。\n\n```shell\n# create表示希望创建一个新的集群\n./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005\n\n>>> Creating cluster\n>>> Performing hash slots allocation on 6 nodes...\nUsing 3 masters:\n127.0.0.1:7000\n127.0.0.1:7001\n127.0.0.1:7002\nAdding replica 127.0.0.1:7004 to 127.0.0.1:7000\nAdding replica 127.0.0.1:7005 to 127.0.0.1:7001\nAdding replica 127.0.0.1:7003 to 127.0.0.1:7002\n>>> Trying to optimize slaves allocation for anti-affinity\n[WARNING] Some slaves are in the same host as their master\nM: 5ced0e3831b746e8d260abd3cad99f2bd5f746a4 127.0.0.1:7000\n   slots:0-5460 (5461 slots) master\nM: fc49467f603f0e1ba1bb0f4affc20db1d6d2cc01 127.0.0.1:7001\n   slots:5461-10922 (5462 slots) master\nM: 35ed50b89426faeb20b50a13854775c4c72bbb5f 127.0.0.1:7002\n   slots:10923-16383 (5461 slots) master\nS: f582f464475f45be65234e387c8b47375dce07d2 127.0.0.1:7003\n   replicates 35ed50b89426faeb20b50a13854775c4c72bbb5f\nS: b74bdc8c4e6d0eb8827f8dfb263ff27f68c51945 127.0.0.1:7004\n   replicates 5ced0e3831b746e8d260abd3cad99f2bd5f746a4\nS: 59b4d618cc6d3afa148a0eb550cde759a8664151 127.0.0.1:7005\n   replicates fc49467f603f0e1ba1bb0f4affc20db1d6d2cc01\nCan I set the above configuration? (type \'yes\' to accept): yes\n>>> Nodes configuration updated\n>>> Assign a different config epoch to each node\n>>> Sending CLUSTER MEET messages to join the cluster\nWaiting for the cluster to join....\n>>> Performing Cluster Check (using node 127.0.0.1:7000)\nM: 5ced0e3831b746e8d260abd3cad99f2bd5f746a4 127.0.0.1:7000\n   slots:0-5460 (5461 slots) master\n   1 additional replica(s)\nM: fc49467f603f0e1ba1bb0f4affc20db1d6d2cc01 127.0.0.1:7001\n   slots:5461-10922 (5462 slots) master\n   1 additional replica(s)\nS: f582f464475f45be65234e387c8b47375dce07d2 127.0.0.1:7003\n   slots: (0 slots) slave\n   replicates 35ed50b89426faeb20b50a13854775c4c72bbb5f\nM: 35ed50b89426faeb20b50a13854775c4c72bbb5f 127.0.0.1:7002\n   slots:10923-16383 (5461 slots) master\n   1 additional replica(s)\nS: b74bdc8c4e6d0eb8827f8dfb263ff27f68c51945 127.0.0.1:7004\n   slots: (0 slots) slave\n   replicates 5ced0e3831b746e8d260abd3cad99f2bd5f746a4\nS: 59b4d618cc6d3afa148a0eb550cde759a8664151 127.0.0.1:7005\n   slots: (0 slots) slave\n   replicates fc49467f603f0e1ba1bb0f4affc20db1d6d2cc01\n[OK] All nodes agree about slots configuration.\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\n```\n\n到此为止所有的槽位都被分配完毕了。可以看到slave的中声明的它是谁的从机。查看replicates就可以\n\n### 连接集群\n\n```shell\n# 此时使用-p连接谁都行，因为有重定向，-c指的是集群模式，我们可以在设置key的过程看到重定向的日志。所以说其实连接谁并没有所谓。使用keys *查看的话只能查看当前机器拥有的，但是直接get的话是会触发重定向去集群中的其他机器获取的。\n#redis-cli -p 7002 -c\n127.0.0.1:7002> keys *\n(empty list or set)\n127.0.0.1:7002> set name lamber\n-> Redirected to slot [5798] located at 127.0.0.1:7001\nOK\n127.0.0.1:7001> set k1 v1\n-> Redirected to slot [12706] located at 127.0.0.1:7002\nOK\n\n#redis-cli -p 7000 -c\n127.0.0.1:7000> get name\n-> Redirected to slot [5798] located at 127.0.0.1:7001\n\"lamber\"\n```\n\n### 测试集群故障迁移\n\n从上面分配主从的结果可以看到，7004端口的redis是7000redis的从机，我们现在把7000端口的机器干掉查看状况。同时监控7004的日志。\n\n```shell\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Marking node 5ced0e3831b746e8d260abd3cad99f2bd5f746a4 as failing (quorum reached).\n# Cluster state changed: fail\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Start of election delayed for 586 milliseconds (rank #0, offset 696).\n# Error condition on socket for SYNC: Connection refused\n# Starting a failover election for epoch 7.\n# Failover election won: I\'m the new master.\n# configEpoch set to 7 after successful failover\n# Setting secondary replication ID to b99aa1d840d2595474737cbfed4bb0839fa205a7, valid up to offset: 697. New replication ID is 9051b056c1c9b176719449cead1a74162fa51076\n* Discarding previously cached master state.\n# Cluster state changed: ok\n```\n\n从上面的日志里可以看出，当7000断掉了以后从机是立即有所响应并尝试重连的。尝试多次以后通过投票将7000这个redis定义为失效。然后从机7004提升为master，而当我们把7000再次起来的时候7000会落地为从机，并不会去进行争抢。\n\n假如说将一个主干掉了，然后从起来了，但是这个由从提起来的主也挂了，此时相当于三分之一的槽位失效了，此时cluster会失效停止服务，无法进行数据的写入的。\n\n### 动态扩容\n\n重新分片\n\n```shell\n./redis-trib.rb reshared 127.0.0.1:7000\n```\n\n增加新的节点\n\n```shell\n./redis-trib.rb add-node 127.0.0.1:7006 127.0.0.1:7000\n```\n\n变成某一个实例的从\n\n```shell\n127.0.0.1:7006>cluster replicate 3c3aasddfasfd………………\n```\n\n删除一个节点\n\n```shell\n# 删除master节点之前首先要使用reshard移除master的全部slot，然后再删除当前节点\nredis-trib.rb del-node ip:port \'<node-id>\'\n```\n\n\n\n### 集群维护\n\n- 集群状态查看\n\n  ```shell\n  redis-cli -p 7000 cluster nodes | grep master\n  ```\n\n- 故障转移\n\n  ```shell\n  redis-cli -p 7000 debug segfault\n  ```\n\n  ​\n\n\n\n## 问题\n\n- 在客户端到底应该去连接谁？虽然cluster有重定向的功能，但是恰巧连接的这个节点挂了该怎么办？\n- 重新分片是否会造成数据丢失？\n- 为什么要重新分片（比如单片key的数据太大。）","timestamp":1541470330295},{"name":"15-Redis运维注意事项.md","path":"01-Linux运维/07-DBA运维/02-Redis/15-Redis运维注意事项.md","content":"# Redis运维注意事项\n\n","timestamp":1541470330295},{"name":"03-叶问.md","path":"01-Linux运维/07-DBA运维/03-叶问.md","content":"# 知数堂-叶师傅\n\n- 虽然命中索引但是SQL效率仍然慢，可能的原因有哪些？\n\n  ```\n  1、索引基数低（重复值太多）或NULL值太多\n  2、查询条件范围太广返回结果数太多，数据读取/扫描代价高\n  3、没有利用到覆盖索引，回表代价高\n  4、查询字段过多，尤其是有大对象字段时\n  5、索引字段数据分布太随机，需要随机读取更多数据页\n  6、优化器未选中最优索引\n  7、LIMIT子句中取值太高，例如LIMIT 100万,20\n  ```\n","timestamp":1541470330295},{"name":"01-Ansible.md","path":"01-Linux运维/08-运维自动化/03-Ansible/01-Ansible.md","content":"# Ansible\n\n> ansible官方网站：https://www.ansible.com/\n>\n> ansible document：https://docs.ansible.com/\n>\n> ansible在线支持文档（马哥版）：http://www.ansible.com.cn/index.html\n>\n> github：https://github.com/ansible/ansible\n>\n> - 批量命令执行\n> - 定时程序任务执行\n> - 批量程序应用服务安装\n> - 批量配置文件同步\n> - 批量代码部署\n\n## 安装\n\n> ansible是python中的一套模块，系统中的一套自动化工具，可以用来作为系统管理，自动化管理等任务。\n>\n> - ansible是python中的一套完整的自动化执行的任务模块。\n> - ansible的playbook模式，采用yaml模式，对于自动化任务执行一目了然。\n> - 自动化场景丰富。shell module，cron module等等。\n\n","timestamp":1541470330295},{"name":"01-Jenkins部署与简单应用.md","path":"01-Linux运维/08-运维自动化/04-Jenkins/01-Jenkins部署与简单应用.md","content":"# Jenkins部署与简单应用\n\n> 相关参考：https://www.cnblogs.com/kevingrace/p/6479813.html\n\n## Jenkins安装\n\nJenkins是Java编写的，所以需要先安装JDK，如果对版本有需求，可以直接在Oracle官网下载JDK。因此我们可以直接使用`yum install -y java-1.8.0`去下载或者直接在Oracle官方下载jdk包进行部署，jdk的部署过程不再赘述。\n\nJenkins的安装过程也是极其简单的。点进Jenkins[官方](https://jenkins.io/download/)下载界面这里提供了多种的安装方式，比如yum，docker，war包等。这里为了方便，以及利于迁移等就使用tomcat+war包的方式进行部署。\n\n先决条件：\n\n- 请以规范的方式进行tomcat的部署工作，具体部署内容在这里不再进行赘述。\n- 默认的启动tomcat的用户我们这里选用的是属主属组都是“tomcat”，目录权限也是如此。\n\n### Jenkins Docker部署\n\n```shell\n# 安装\ndocker pull jenkinsci/blueocean\n\n# 运行\ndocker run \\\n  -u root \\\n  -d \\\n  -p 9090:8080 \\\n  -v /var/jenkins-data:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkinsci/blueocean\n```\n\n### Jenkins war包部署\n\n这里采用的就是简单的war包部署，放到tomcat对应的webapps目录下即可。本次部署的主机ip为：192.168.33.22，并没有进行域名的映射。因此直接访问`http://192.168.33.22:8080/jenkins`即可访问到jenkins界面了。\n\n### 首次安装\n\n**提前设置一下JENKINS_HOME**\n\n如果有必要的话最好设置一下jenkins的家目录，这里我们是用tomcat启动的jenkins，因此默认情况下，jenkins会在`/home/tomcat/`下新建一个`.jenkins`的隐藏目录作为自己的家目录，为了更好的管理，这里我首先自定义一个JENKINS的家目录，修改tomcat的catalina.sh文件。\n\n```\n# OS specific support.  $var _must_ be set to either true or false.\nexport JENKINS_HOME=\"/usr/local/jenkins\"\n```\n\n或者我直接在/etc/profile下面添加这么一个变量也是可以的，反正你这台主机专门作为jenkins，个人觉得没有什么不妥，环境变量设置好以后，记得创建必要的目录，将目标权限修改为我们的tomcat用户。\n\n```shell\n[root@localhost ~]# mkdir /usr/local/jenkins\n[root@localhost ~]# chown -R tomcat.tomcat /usr/local/jenkins/\n[root@localhost ~]# ll /usr/local/jenkins/ -d\ndrwxr-xr-x. 2 tomcat tomcat 6 5月  23 11:02 /usr/local/jenkins/\n```\n\n**首次安装可能会遇到的小问题**\n\n首次安装的时候我们可能会发现Jenkins界面会一直卡在“Jenkins正在启动，请稍后……”的界面，其实这是因为Jenkins在启动的时候要去互联网获取更新插件的文件，但是由于网络原因可能会很慢，主要是服务器也在国外所致，所以你就会看到它不停的在刷新，解决这个问题有三种方案：\n\n- 一个是手动把这个文件下载下来\n\n- 第二个是使用国内的镜像源，使用方式很简单，修改`$JENKINS_HOME/hudson.model.UpdateCenter.xml`中的url为`http://mirror.xmission.com/jenkins/updates/update-center.json`就可以了。\n\n  ```xml\n  <?xml version=\'1.1\' encoding=\'UTF-8\'?>\n  <sites>\n    <site>\n      <id>default</id>\n      <url>http://mirror.xmission.com/jenkins/updates/update-center.json</url>\n    </site>\n  </sites>\n  ```\n\n- 找到updates目录下的defaults.json文件，把里面所有的谷歌地址改成百度的。updates文件夹也在`$JENKINS_HOME`下，替换文件的时候请用sed，文件内容很长。\n\n**输入密钥**\n\n首次使用需要对jenkins进行解锁，文件位置图中已经告诉你了，直接cat一下粘过来就行了。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/26918298.jpg)\n\n接下来Jenkins会让你选择安装一些插件，我们可以根据自己的需要进行选择，或者安装Jenkins推荐给我们使用的一些插件。安装过程保证服务器可以连接到外网，否者可能会报错提示当前jenkins主机已经离线。安装过程不再体现。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/92741140.jpg)\n\n接下来，我们需要创建一个用来登录和管理的用户账户。这个用户保存在`$JENKINS_HOME/users`下。\n\n![](/var/folders/8l/g95nllln61j4ly_zm_tqj2m40000gn/T/abnerworks.Typora/image-201805231115117.png)\n\n实例配置，记住这个地址很重要，影响到以后的访问：\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/92328485.jpg)\n\n到此为止，我们就可以使用Jenkins了。\n\n## Jenkins + Gitlab\n\n常用的一个用法就是Jenkins结合Gitlab实现一个整体构建过程。因此这里说明一下，如何配置一下Jenkins如何与Gitlab进行结合使用。\n\nJenkins之所以是很灵活的就是因为Jenkins的插件众多，可以实现不同的适配，结合Gitlab也是如此。在Jenkins系统设置中找到插件管理，安装`Gitlab Plugin`和`Gitlab Hook Plugin`这两个插件。\n\n### 新建一个任务\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/99863546.jpg)\n\n在General选项卡中，可以根据需要填写一些这个任务的相关信息，比如任务的描述等等。\n\n### 源码管理\n\n找到源码管理的选项卡，这里我们使用Git进行源码管理，结合gitlab进行相关操作。在操作这个内容的时候同时要在Gitlab和Jenkins两边同时操作，首先在Gitlab中添加一个Deploy Key，这个key是允许Jenkins对git上的代码进行一些操作的。注意这里填写的是tomcat的公钥。最后一个是否要提供写权限，这里要把控好了，一般来说deploy key只读就够了，虽然我这里勾上了。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/3300544.jpg)\n\nRepositories中的Respositories URL先别着急填写，先添加一下Credentials认证证书。直接点击add选Jenkins。其中用户为我们的tomcat，Private Key这里应该填写的是tomcat用户的私钥。其他的暂时都可以不填写，description可以填写说明一下，然后下拉点击报存。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/38812975.jpg)\n\n如果说这里Gitlab服务器没有开放对应的端口的话我们还有另外一个连接方式，就是http(https)的方式，从Gitlab的版本库把地址拿过来也是ok的。这个时候下面的这个证书就可以不写了，因此在设置的时候注意是用ssh的方式还是使用http的方式，ssh的方式要确保对应的端口打开。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/98339097.jpg)\n\n有些公司为了一定的安全性，因此并没有开放公开的22号端口，而是使用的其他端口代替，这种情况下，端口就变为了非标准端口，而连接的时候其实默认的是使用22号端口去连接的，可以参考一下[这篇文章](https://blog.csdn.net/wanwan5856/article/details/52797969)设置单独的连接方法。\n\n### 构建触发器\n\n到这里就可以开始配置Gitlab的钩子了，因为这个构建是需要认证的，简单来说就是jenkins这里要有一份，gitlab那里也要有一份，这样认证才能通过，认证的方式就是通过令牌的方式。但是有一个问题就是，在Jenkins的权限管理中我们设置的是只有登录用户才可以进行操作。但是这个认证提供访问的URL是需要先登录才会有这个token的，对于没有未登录的用户这个token是不存在的。因此我们还需要安装一个插件，才能使得双方能够进行验证，这里借助一个插件，Build Authorization Token Root。[官方wiki](https://wiki.jenkins-ci.org/display/JENKINS/Build+Token+Root+Plugin)\n\n构建触发器的身份验证令牌这里用openssl来生成：\n\n```shell\n[tomcat@localhost ~]$ openssl rand -hex 10\n81f44ed1f0e379df1927\n```\n\n在这里还可以设置一下触发的条件：\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/12528930.jpg)\n\n根据刚才我们下载那个插件的wiki，其中提供了用法为：\n\nExamples\n\nTrigger the RevolutionTest job with the token TacoTuesday\n\n```\nbuildByToken/build?job=RevolutionTest&token=TacoTuesday\n```\n\n那么对应的认证URL应该该为如下的格式：\n\n```\nhttp://192.168.33.22:8080/jenkins/buildByToken/build?job=auto-deploy&token=81f44ed1f0e379df1927\n```\n\n这里的Job名称和token名称都和我们自己的名称对应好了。然后我们回到Gitlab找到Settings，切刀Integrations选项卡，把我们这个钩子的URL添加进去。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/51495060.jpg)\n\n添加好了以后我们还可以对这个Hook进行测试，点击添加的内容右侧的Test，如果出现了如下的返回内容证明我们添加的hook是ok的。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/17304871.jpg)\n\n然后我们在Jenkins任务的配置项中找到构建选项卡，这里就是构建的操作了。先弄一个非常简单的。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/33363819.jpg)\n\n构建操作选择“执行-shell”，然后输入一点shell脚本。这个脚本的意思其实就是把jenkins这个workspace的job内容下的内容拷贝到我们的目标目录，我现在就是新建一个/tmp/jenkins_test目录而已，以后这个目录可以是本地的某个项目目录，或者是其他机器的项目目录，我们甚至可以结合saltstack或者ansible进行多台机器的批量部署。现在找到任务的主页，选择立即构建进行手动测试：\n\n![](/var/folders/8l/g95nllln61j4ly_zm_tqj2m40000gn/T/abnerworks.Typora/image-201805231555580.png)\n\n可以在左侧观察构建进度和构建状态，当构建出现问题以后左侧的提示标会变为红色，点进去可以查看具体的构建日志，选择控制台输出我们可以看到构建的详细过程，当然出错了以后也可以在这里查看构建的日志\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/60125218.jpg)\n\n这里看到构建成功，没有问题，接下来测试一下我们的webhook有没有生效吧。找一台测试机，先把我们的版本库clone下来然后提交点数据push上去，之前构建触发器的时候触发条件勾选上了Push Events，那么我们在操作Push操作的时候，会自动触发此次的构建。\n\n当我们push数据到Gitlab的时候，发现Jenkins这边的确是触发了任务\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-23/93796340.jpg)\n\n查看我们的目标目录下是否更新\n\n```shell\n[root@localhost ~]# cd /tmp/jenkins_test/\n[root@localhost jenkins_test]# ll\n总用量 4\n-rw-r-----. 1 root root  0 5月  23 16:11 aaaa\n-rw-r-----. 1 root root 39 5月  23 15:46 README\n```\n\n可以看到我们在其他客户端push的aaaa这个文件的确是放到了我们的目标位置，当然目前来讲是只有提交到master分支的时候才会触发这个钩子，还记得之前在源码管理的时候，有一个选项是Branches to build，写的是`*/mater`，这里留空的话那么就是所有分支的提交都会触发这个hook的执行，因此我们可以通过修改这里来控制当某一个分支有所操作的时候触发操作。\n\n\n\n\n\n\n\n\n\n","timestamp":1541470330295},{"name":"02-Jenkins参数化构建.md","path":"01-Linux运维/08-运维自动化/04-Jenkins/02-Jenkins参数化构建.md","content":"# Jenkins参数化构建\n\n> 背景：公司存在多个项目，每个项目也存在多个不同的分支，在项目较少的时候可以通过每一个分支建一个job的方式，这样一个项目如果分支多的话就会存在多个job，项目少的时候还好管理，项目多了以后管理起来就不是那么容易了，因此在这里引入一个参数化构建的方式，同一个项目根据项目不同需要部署不同的分支进行测试，只要针对输入的分支名来进行参数化构建就可以了，而不需要新建多个job。\n>\n> *内容参考*\n>\n> - https://blog.csdn.net/e295166319/article/details/54017231\n> - https://blog.csdn.net/tongtong0704/article/details/70140606\n\n## 步骤\n\n- 首先配置你的项目，在General部分有一个参数化构建的选项，要把这个选项勾上\n\n  ![](http://tuku.dcgamer.top/18-8-27/9045986.jpg)\n\n- 点击 **添加参数按钮**，选择需要的类型。 这里因为分支名称是个字符串，所以选择 **string parameter**，同时还要新建一个Choice。其中Choice用于给出多个选项，构建的时候可以手动选择参数，Choice中的每一项单独一行，默认Choice内的第一行数据就是默认值。参数描述会在构建的时候在下面显示；\n\n  ![](http://tuku.dcgamer.top/18-8-27/52431151.jpg)\n\n- 对于这个变量的引用，只需要把对应的地方替换成`${branch_name}`即可。修改需要引用变量的地方。在Job的源码管理那，Branches to build那把内容替换成 `*/${branch_name}`\n\n  ![](http://tuku.dcgamer.top/18-8-27/81220879.jpg)\n\n- 然后就会发现，左边的 **立即构建** 变成了 **Build with Parameters**\n\n  ![](http://tuku.dcgamer.top/18-8-27/23148672.jpg)\n\n- 此时如果再次进行构建的话就会优先让你填写参数\n\n  ![](http://tuku.dcgamer.top/18-8-27/2392000.jpg)\n\n到目前为止我们已经了解了如何使用进行参数化的构建，当然这个是手动操作的，那么如何让这个过程随着gitlab的webhook动态起来呢？在[Gitlab Pulgin](https://github.com/jenkinsci/gitlab-plugin)的git中有这样一段内容：\n\n```\nDefined variables\n\nWhen GitLab triggers a build via the plugin, various environment variables are set based on the JSON payload that GitLab sends. You can use these throughout your job configuration. The available variables are:\n\ngitlabBranch\ngitlabSourceBranch\ngitlabActionType\ngitlabUserName\ngitlabUserEmail\ngitlabSourceRepoHomepage\ngitlabSourceRepoName\ngitlabSourceNamespace\ngitlabSourceRepoURL\ngitlabSourceRepoSshUrl\ngitlabSourceRepoHttpUrl\ngitlabMergeRequestTitle\n…………………………\n```\n\n也就是说只要是使用了这个插件，那么在这个job的整个配置过程中，我们都是可以使用这些变量的，这里没有完整的列出来，有需要可以自行去git上查看。\n\n那么也就意味着，只要这个gitlab的webhook触发了，那么我就可以通过gitlabBranch这个变量拿到提交的分支，那么我们在拉取代码的时候就可以动态的这样拉取。\n\n![](http://tuku.dcgamer.top/18-8-27/66618431.jpg)\n\n那么这样，jenkins就可以动态的拿到具体提交的是哪一个分支了，也会拉取对应的分支代码下来。接下来如何进行操作就是我们自己的问题了，不管是执行shell还是用maven打包。","timestamp":1541470330295},{"name":"04-Jenkins回滚.md","path":"01-Linux运维/08-运维自动化/04-Jenkins/04-Jenkins回滚.md","content":"","timestamp":1541470330295},{"name":"05-Jenkins File.md","path":"01-Linux运维/08-运维自动化/04-Jenkins/05-Jenkins File.md","content":"","timestamp":1541470330295},{"name":"01-ELK认识.md","path":"01-Linux运维/09-ELK/01-ELK认识.md","content":"# ELK\n\n> 最复杂就是做一个日志的同期对比\n>\n> 通俗的来讲，ELK就是由ElasticSerach、LogStash、Kibana三个开源软件组成的一个Stack，官方网站为：http://www.elastic.co，这三个组件对应的功能为：logstash是收集，elasticsearch为存储+搜索，kibana则是为我们提供数据的展示。ELK的主要优点可以概括为如下几个：\n>\n> - 处理方式灵活：elasticsearch是实时全文索引，具有强大的搜索功能。\n> - 配置相对简单：elasticsearch全部使用json接口，logstash使用模块配置，kibana配置文件部分更简单\n> - 检索性能高效：优秀的设计，虽然每次查询都是实时，但是也可以到百亿级数据的查询秒级响应\n> - 集群线性扩展：elasticsearch和logstash都可以灵活线性扩展\n> - 前端操作绚丽：kibana的前端设计绚丽，而且操作简单\n>\n> ELK Installing：https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html\n\n## 认识ELK\n\n### Elasticsearch\n\n一个高度可扩展的开源全文搜索和分析引擎，它可以实现数据的实时全文搜索。搜索、支持分布式可实现高可用、提供API接口，可以处理大规模的日志数据，比如nginx，tomcat，系统日志等功能。\n\n## 安装\n\n### 环境初始化\n\n1. 设置主机名，最对应的解析\n2. 关闭防火墙和selinux\n3. 根据需要挂载磁盘\n\n## Elasticsearch\n\nElasticsearch提供了多种安装方式，常见的比如源码的，rpm的，以及docker的也有，甚至官方还给你提供了诸如puppet和ansible这样的脚本可以帮你安装。不过最佳实践使用yum安装是最好的。\n\n```shell\n# 环境依赖jdk，需要自己先准备好，可以直接去下载jdk或者yum安装，yum默认会帮你安装好最新的\nyum -y install java\n\n# 查看java是否安装成功\n[root@web01 ~]# java -version\nopenjdk version \"1.8.0_181\"\nOpenJDK Runtime Environment (build 1.8.0_181-b13)\nOpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode)\n\n# 导入ElasticSearch的PGP Key\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n\n# 添加yum仓库\n[root@web01 ~]# cat /etc/yum.repos.d/elasticsearch.repo \n[elasticsearch-6.x]\nname=Elasticsearch repository for 6.x packages\nbaseurl=https://artifacts.elastic.co/packages/6.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n\n# yum安装ElasticSearch\n\n```\n\n### LogStash\n\n安装套路基本都是一样的，这里依旧使用yum进行安装\n\n```shell\n# 导入key，如果你之前导入过的话那么现在就不用再导入了。\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n\n# 编辑repo文件，这个其实官方网站提供的是一套，如果安装elastcisearch的时候写好了，这里就可以忽略了。\n[logstash-6.x]\nname=Elastic repository for 6.x packages\nbaseurl=https://artifacts.elastic.co/packages/6.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n\n# 安装\nyum -y install logstash\n```\n\n### Kibana\n\n```shell\n# 安装方式都是一样的，使用pgp key和repo文件也是一套，如果你都导入过了就可以不用导入了。\nyum -y install kibana\n```\n\n","timestamp":1541470330295}]