if(typeof AWPageMounts=='undefined'){AWPageMounts={}};AWPageMounts['m03']=[{"name":"01-01、专业mysql部署.md","path":"03-DBA运维/01-Mysql/01-Mysql的部署/01-01、专业mysql部署.md","content":"# 专家级Mysql部署\n\n> 工欲善其事必先利其器，因此在玩转mysql之前一定要进行合理的Mysql的部署和优化，了解其启动原理等，本文针对Mysql的部署做分步骤的阐述和整理。\n\n## 1、软件准备\n\n目前oracle的mysql的最新的版本是mysql5.7.20.我们可以选择这一个版本进行安装，较旧版来说新版本修复了很多的bug信息，下载网站我们可以去mysql的[官方网站](https://dev.mysql.com)去寻找最新的安装包下载。\n\nMysql的安装方式不唯一，可以使用编译好的二进制包，可以使用cmake进行手动编译，亦或是yum，rpm方式的安装都是可以的，这里使用编译好的二进制包的方式进行部署。yum方式不做过多的赘述，如果需要了解cmake安装方式的请到第二篇文章查看。\n\n首先需要做的就是下载一个最新版本的符合自身系统的安装包：\n\n```shell\n[root@maxiaoyu opt]# ls\nmysql-5.7.20-linux-glibc2.12-x86_64.tar.gz\n```\n\n## 2、硬件环境的优化\n\n虚拟机或者云端的就不赘述，如果是物理机的还要在硬件和系统层面进行一些优化，因为机器在默认出厂的时候cpu和内存默认的都是节能模式，因此首要应该做的就是改成高性能模式。\n\n- 关闭numa\n  - [numa的取舍](http://www.cnblogs.com/yjf512/archive/2012/12/10/2811823.html)，可以查看这一篇文章对numa有一个简单的理解，Mysql属于那种既占用CPU又吃内存的应用，因此建议是关闭掉numa\n  - [如何关闭掉numa](http://www.dataguru.cn/thread-462113-1-1.html)，[numa特性禁用](http://www.cnblogs.com/wjoyxt/p/4804081.html).\n    - 硬件层：在bios设置中关闭掉\n    - OS层：在启动的时候设置关闭掉numa\n    - 可以用numactl命令将内存分配策略修改为interleave（交叉）\n\n在OS层我们可以设置启动的时候关闭，直接修改grub.conf文件即可：\n\n```shell\nvim /boot/grub/grub.conf\n```\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-6/63141757.jpg)\n\n- 网络优化&/etc/security/limits.conf \n\n```shell\n[root@maxiaoyu opt]# ulimit -a \ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 7285\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 65535\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 7285\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n\n修改ulimit\n\n```shell\necho -e \'* soft nproc 65535\\n* hard nproc 65535\\n* soft nofile 65535\\n* hard nofile 65535\\n\' >> /etc/security/limits.conf\n```\n\n修改一些内核参数：\n\n```shell\n# 在/etc/sysctl.conf后面添加如下内容\nnet.ipv4.tcp_max_syn_backlog = 819200\nnet.core.netdev_max_backlog = 400000\nnet.core.somaxconn = 4096\nnet.ipv4.tcp_tw_reuse=1\nnet.ipv4.tcp_tw_recycle=0\n# 添加完成以后手动生效\nsysctl -p\n```\n\n同时有一个需要注意的是，如果你的机器是开启的多实例的话建议修改一下`max user processes`这个参数，这个参数我们可以在刚才的ulimit -a中查看到，或者我们可以使用ulimit -u去单独查看这个参数的值，那么这个值代表什么意思呢？\n\n这个ulimit -u是用来限制每个用户的最大processes数量。如果ulimit -u进行了限制那么每个linux用户可以派生出来的process就会被限制再这个数值之内。在mysql多实例的时候就很可能会受到这个参数的影响而导致根本无法链接，具体设置可以参考：http://blog.csdn.net/bbaiggey/article/details/51004817\n\n- Swap优化：直接禁用，现在的数据库独立服务器的配置普遍已经很高了，按照之前的一些说法，swap要分内存的1.5~2倍，如果遇到64gb或者128gb内存的情况下，分1.5~2倍其实是很不理智的一个选择，现在内存大多数情况已经够用，因此swap是可以直接禁用掉的，如果要分的话建议分配不超过4g。\n\n- IO优化：针对不同的盘使用不同的策略可以带来不同的优化效果。\n\n  查看对应的磁盘的IO调度策略可以通过如下的方式查看：\n\n  ```shell\n  [root@DBServer1 ~]# cat /sys/block/sda/queue/scheduler \n  noop anticipatory deadline [cfq]\n  ```\n\n  被括号括起来的就是当前的IO调度策略。那么对于不同的磁盘建议的调度策略如下：\n\n  - SAS：deadline\n  - SSD：noop\n\n- 文件系统：关于数据目录毫不犹豫的使用xfs格式的。\n\n- selinux和iptables：selinux建议禁掉，如果你的mysql完全跑内网，那么iptables可以也不用开\n\n  ​\n\n## 3、Mysql的安装\n\n> 基础环境优化完毕以后，就可以进行Mysql数据库的安装了。当然这里使用的是二进制安装包的方式进行安装，如果你使用rpm安装的话这一切都会自动的为你搞定，因为默认的配置都给你设置好了，缺点就是你没办法进行自定义的调整配置。\n>\n> 当然你也可以把rpm解包，重新做相应的脚本以及再次做rpm包。\n\n### 创建账户\n\n```shell\ngroupadd mysql\nuseradd -g mysql -d /usr/local/mysql -s /sbin/nologin -M mysql\nid mysql\n```\n\n### 软件基本安装\n\n```shell\nmkdir /opt/mysql\ncd /opt/mysql\ntar xf mysql-5.7.20-linux-glibc2.12-x86_64.tar.gz \ncd /usr/local\nln -s /opt/mysql/mysql-5.7.20-linux-glibc2.12-x86_64/ /usr/local/mysql5.7.20\nchown -R mysql.mysql mysql5.7.20/\n```\n\n### 数据目录创建\n\n```shell\ncd /data\nmkdir -p 3330/{data,logs,tmp}\n```\n\n### 配置文件准备\n\n```shell\n# 准备配置文件，你默认的也好，自定义的也好\n[root@maxiaoyu 3330]# pwd\n/data/3330\n[root@maxiaoyu 3330]# ls -l my.cnf\n-rw-r--r-- 1 root root 4014 Nov  6 11:58 my.cnf\n```\n\n### 初始化Mysql\n\n```mysql\n# 5.7的初始化方式\ncd /usr/local/mysql5.7.20/\n./bin/mysqld --defaults-file=/etc/my.cnf --initialize\n\n# 5.6,5.5,5.1的初始化方式\n./script/mysql_db_install\n./bin/mysql_db_install\n```\n\n### 启动\n\n```shell\n# 数据库这里可以设置开启自启，但是一般不建议这么做，如果出问题了，应该先排查问题然后再手动重启。\ncp support-files/mysql.server /etc/init.d/mysql\n/etc/init.d/mysql start\n\n# 设置开机自启的方式（不建议）\nchkconfig add mysql\n\n# 手工启动\n/usr/local/mysql/bin/mysqld --defaults-file=/etc/my.cnf &\n/usr/local/mysql/bin/mysqld_safe --defaults-file=/etc/my.cnf &\n```\n\n### 检查错误日志查看是否正常\n\n启动起来以后还要修改环境变量，是否启动正常从以下几个角度排查\n\n- 起来以后确认进程在不在\n- 确认加载的配置文件对不对？\n- 看错误日志。查看有没有error信息\n\n### 链接数据库\n\n```shell\n# 默认第一次会生成一个随机密码，我们可以在errorlog里看到\ncat /data/mysql/mysql3306/data/error.log | grep password 看密码\nmysql -S /tmp/mysql3306.sock -p\n# 修改密码，这是必要的\n>alter user user() identified by \'new_pass\';\n```\n\n### 关闭数据库\n\n```shell\n# 利用系统脚本关闭\n/etc/init.d/mysql stop\n\n# 利用mysqladmin关闭，加上-h参数甚至可以关闭掉远端的mysql\nmysqladmin -S /tmp/mysql.sock -p shutdown\n\n# 在mysql5.7.19以后多了一个可以在mysql命令行直接打shutdown关闭的命令。\nmysql>shutdown;\n```\n\n## 4、Mysql安装过程中遇到的问题小结\n\n### 4.1、手贱授权错目录咋整\n\n前面提到了要给mysql的目录授权为属主是mysql，用户组也是mysql，假如说授权错误，比如直接授权给了根目录改咋整，这个时候一定不要退出，否则很可能你就再也登不上来了。具体问题可以参考Linux系统权限修复：http://www.cnblogs.com/xdxhg/p/6139818.html\n\n### 4.2、依赖缺失\n\n```shell\n# 查看库的依赖\n[root@DBServer1 ~]# ldd /home/mysql/db9018/bin/mysqld \n        linux-vdso.so.1 =>  (0x00007fffdd7ff000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x0000003c4c800000)\n        librt.so.1 => /lib64/librt.so.1 (0x0000003c4cc00000)\n        libcrypt.so.1 => /lib64/libcrypt.so.1 (0x0000003c5aa00000)\n        libdl.so.2 => /lib64/libdl.so.2 (0x0000003c4c000000)\n        libstdc++.so.6 => /usr/lib64/libstdc++.so.6 (0x0000003c53000000)\n        libm.so.6 => /lib64/libm.so.6 (0x0000003c4d000000)\n        libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x0000003c52400000)\n        libc.so.6 => /lib64/libc.so.6 (0x0000003c4c400000)\n        /lib64/ld-linux-x86-64.so.2 (0x0000003c4bc00000)\n        libfreebl3.so => /lib64/libfreebl3.so (0x0000003c5ae00000)\n```\n\n### 4.3、Selinux没有关闭\n\n```shell\n# 临时关闭\nsetenforce 0 \n# 修改配置文件永久关闭，需重启\n[root@innerManager1 ~]# cat /etc/sysconfig/selinux \n\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\nSELINUX=enforcing\n# SELINUXTYPE= can take one of these two values:\n#     targeted - Targeted processes are protected,\n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted \n\n将SELINUX=enforcing改为disabled即可\n```\n\n### 4.4、文件目录权限不对\n\n```shell\n# 如果出现permission denied的相关错误日志就要考虑一下是不是你的权限分配错误了？\nchown -R mysql.mysql /data/mysql\n```\n\n### 4.5、datadir非空\n\n当datadir不是空的时候，初始化会出现错误，因此确保初始化的时候datadir是空目录。\n\n### 4.6 磁盘空间不够\n\n```shell\ndf -h\n```\n\n### 4.7 初始化参数不对！\n\n参数写错了这个问题其实看似简单但是有时候操作者会有意无意的忽略掉，所以说对待这种问题的时候最好还是看看错误日志，可以立即打醒你。\n\n```shell\ncat /data/mysql/data/error.log | grep ERR\n```\n\n## 5、遇到问题该怎么处理？\n\n- 查看error.log\n\n大部分的日志错误都是可以在error.log中查看到的，直接去监控错误日志即可。\n\n- 把日志打开\n- 启动不起来的话利用mysqld手工启动一下查看\n- 利用strace再现一下启动过程\n\n```shell\n# 我们使用mysqld的方式去手动启动mysql\nstrace /usr/local/mysql/bin/mysqld --defaults-file=/etc/my.cnf\n# strace的结果是很长的，但是我们需要看的内容并不是很多，记住以下的几个用法即可阅读\n- execve相当于调用系统外部命令的一个命令\n- mmap相当于把数据读取到内存里面\n- access是访问一个文件\n- open是打开一个文件\n- fstat查看文件状态\n\nexecve(\"/usr/local/mysql/bin/mysqld\", [\"/usr/local/mysql/bin/mysqld\", \"--defaults-file=/etc/my.cnf\"], [/* 18 vars */]) = 0\nbrk(0)                                  = 0x37bc000\nmmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f45615b7000\naccess(\"/etc/ld.so.preload\", R_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3\nfstat(3, {st_mode=S_IFREG|0644, st_size=79083, ...}) = 0\nmmap(NULL, 79083, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f45615a3000\nclose(3)                                = 0\n# 简单的来看一段，可以发现系统的一开始调用了我们的命令，将对应的内容映射到内存中去，然后访问了对应的so库文件，查看文件状态，映射到内存中，接下来的操作基本都是读取各种库文件       \n```\n\n通过strace还可以看到加载配置文件的过程（如果指定了defaults-file这个参数，只会读取指定的这个配置文件）：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-6/57224031.jpg)\n\n默认的配置文件的读取顺序：\n\n```shell\n[root@maxiaoyu 15:29:19 /root]\n#mysqld --verbose --help | grep my.cnf\n/etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf \n# 可以看到如果没有指定配置文件的位置的话默认会从上面的四个位置读取配置文件。\n```\n\n查看加载表结构的过程：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-6/77738193.jpg)\n\nmysql5.7的io模型是基于poll的，当看到如下的字样的时候就代表mysql已经启动成功了\n\n```\npoll[{fd=33,events=POLLIN},{fd=36,events=POLLIN}],2,-1\n```\n\n### 5.1、查看报错代码的意思\n\n如果查看ERROR里面的code代码不知道什么意思的时候该如何处理？\n\n```shell\n[root@maxiaoyu 15:35:34 /root]\n#/usr/local/mysql/bin/perror 11\nOS error code  11:  Resource temporarily unavailable\n\n[root@maxiaoyu 15:35:58 /root]\n#/usr/local/mysql/bin/perror 13\nOS error code  13:  Permission denied\n\n[root@maxiaoyu 15:36:05 /root]\n#/usr/local/mysql/bin/perror 24\nOS error code  24:  Too many open files\n\n[root@maxiaoyu 15:36:12 /root]\n#/usr/local/mysql/bin/perror 27\nOS error code  27:  File too large\n\n[root@maxiaoyu 15:36:14 /root]\n#/usr/local/mysql/bin/perror 28\nOS error code  28:  No space left on device\n```\n\n\n\n","timestamp":1526281685638},{"name":"00-Mysql基础应用.md","path":"03-DBA运维/01-Mysql/02-MYSQL基本维护/00-Mysql基础应用.md","content":"# MySQL基础\n\n[TOC]\n\n## 日志\n\n- 日志可能会占用大量的磁盘空间\n- 现在部分日志可以存储在表里（现在不提倡使用）\n- 以文本格式写入日志（二进制日志除外）\n\n### **日志类型**\n\n- 错误日志\n- 慢查询日志\n- 常规日志\n- 二进制日志\n- 审计日志\n\n### **日志文件**\n\n| 日志文件 | 选项                                   | 文件名或表名称                     | 程序                            |\n| ---- | ------------------------------------ | --------------------------- | ----------------------------- |\n| 错误   | --log-error                          | host_name.err               | N/A                           |\n| 常规   | --general_log                        | host_name.log/general.log   | N/A                           |\n| 慢查询  | --slow_query_log & --long_query_time | host_name-slow.log/slow_log | mysqldumpslow/pt-query-digest |\n| 二进制  | --log-bin & --expire-logs-days       | host_name-bin.000001        | mysqlbinlog & binlog2sql      |\n| 审计   | --audit_log等                         | audit.log                   | N/A                           |\n| 中继   |                                      | host_name-relay.log         |                               |\n\n- 常规日志既会记录正确日志也会记录错误日志\n- long_query_time默认是10s，建议改成1s或者以下。慢日志分析推荐pt-query-digest\n- 一定要设置二进制日志的expire-logs-days，否则会被日志占满\n- relay-log的日志名字是和hostname有关的，不止relaylog，假如说更改了主机名，而且relay-log未定义，按照默认的走，改了主机名以后可能找不到对应命名的relay-log。\n\n查看mysql中和日志有关的变量：\n\n```mysql\nmysql> show global variables like \'%log%\';\n```\n\n其中的`log_queries_not_using_indexes`是可以不用开启的，因为小于1s的你用没用其实我也不用关心，你大于1s的即使你用了我毕业要想办法优化。\n\n还有就是log是可以定义到syslog中的，比如说用elk进行收集等等：\n\n```mysql\nlog_syslog                              | OFF   \nlog_syslog_facility                     | daemon\nlog_syslog_include_pid                  | ON    \nlog_syslog_tag                          |       \n```\n\n- relay_log_purge：relay-log被sql thread消耗完毕以后清除掉\n- relay_log_space_limit：这个参数默认是开启的，允许我们设置接受的relay-log的最大的大小，当relay-log超过设置的大小了以后就不再从master那边取了。因此这个参数不建议去使用。一般可用于磁盘紧张而且主从复制出现了大量延迟的时候避免被relay-log撑满磁盘空间可以使用这个参数。\n- general_log：默认是不开启的，如果想要开启可以`set global general_log = 1`不过这个参数一般也不会进行开启。可以用来排查问题或者在比较严格的环境做审计使用。\n\n**修改日志记录的时间：**\n\n```mysql\ntime_zone                       | SYSTEM \nsystem_time_zone                | CST \n```\n\n### 二进制日志\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-18/17887452.jpg)\n\n**二进制日志什么时间会刷新（切换）？**\n\n- 达到了系统定义的max_binlog_size\n- 运行了flush logs\n- 服务器重启\n\n在重启这里有一个要进行说明的，重启过程中mysql会去读取这些bin-log的文件名，只是读取文件名，然后根据文件名进行排序，获取最大的，然后在这个最大的序号基础上+1生成一个新的文件（不是根据mysqlbin.index文件产生的，单纯的是根据排序后的序号最大的+1产生的新文件），加入说binlog过多的话，比如上万个，这种情况下不管是开启还是关闭相对来说就会很慢，因此binlog的size要合理的进行设置，太小的话就会造成binlog文件过多的问题。默认的是1个G。用这个默认的设置其实就可以，不要太大也不要太小。\n\n那么mysqlbin.index是干什么用的？\n\n```mysql\nmysql> show binary logs;\n+----------------------+-----------+\n| Log_name             | File_size |\n+----------------------+-----------+\n| ecs-mysql-bin.000001 |    814133 |\n| ecs-mysql-bin.000002 |      1909 |\n| ecs-mysql-bin.000003 |       177 |\n| ecs-mysql-bin.000004 |       205 |\n| ecs-mysql-bin.000005 |       650 |\n+----------------------+-----------+\n13 rows in set (0.01 sec)\n```\n\n上面这一条命令是从index文件中读取的。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-18/80515399.jpg)\n\n关于binlog_format：推荐使用row格式。\n\n**查询二进制日志文件**\n\n```mysql\nshow binary logs;\n# 列出当前的日志文件以及大小\n\nshow master status;\n# 显示mysql当前的日志以及状态（需要super，replication，client权限）\n\nshow binlog events in \'mysql-bin.000010\';\n# mysql的二进制日志是以‘事件（event）’为单位存储到日志中的。一个insert，update……由多个事件组成，比如：\n- GTID event\n- query event\n- table_map event\n- write_rows event\n- xid event\n可以截取事件日志的其中一部分看一下：\n\n| ecs-mysql-bin.000013 | 1009189 | Query     | 1 | 1009263 | BEGIN                          |\n| ecs-mysql-bin.000013 | 1009263 | Table_map | 1 | 1009321 | table_id: 461 (zabbix.sessions)|\n| ecs-mysql-bin.000013 | 1009321 | Write_rows| 1 | 1009406 | table_id: 461 flags: STMT_END_F|\n| ecs-mysql-bin.000013 | 1009406 | Xid       | 1 | 1009437 | COMMIT /* xid=620202 */        |\n针对DDL语句，没有query（begin），xid（commit），table_map这样得event。\n\n# 专业名称：日志文件：mysqlbin.000010，字节偏移量（位置），position，单位是字节。\nmysql> show master status;\n+----------------------+----------+--------------+------------------+-------------------+\n| File                 | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+----------------------+----------+--------------+------------------+-------------------+\n| ecs-mysql-bin.000013 |  1012070 |              |                  |                   |\n+----------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n\n[root@maxiaoyu 21:09:53 /data/mysql]\n#ll /data/mysql/ecs-mysql-bin.000013\n-rw-r----- 1 mysql mysql 1012070 Nov 18 20:18 /data/mysql/ecs-mysql-bin.000013\n\n# 可以看到和上面的master status中的position是一致的。\n```\n\n**查看二进制日志：**\n\n二进制日志是无法用文本查看的，日志以紧凑的二进制格式存储，以事件组合，可以使用工具mysqlbinlog来进行查看：\n\n```mysql\nmysqlbinlog -v --base64-output=decode-rows ecs-mysql-bin.000013 | less\n```\n\n其中mysqlbinlog有几个比较重要的参数，比如：\n\n- --start-position\n- --stop-position\n- --start-datetime=name\n- --stop-datetime-name\n- --stop-never\n\n**二进制日志维护：**\n\n基于时间删除二进制日志\n\n```mysql\nset global expire_logs_days=7;\n\npurge binary logs before now() -interval 3 days;\nPURGE BINARY LOGS BEFORE \'2008-04-02 22:46:26\';\n# 如果忘了purge的使用方法，可以在mysql命令行中直接help purge;\n```\n\n根据文件名删除：\n\n```mysql\n# 把mysql-bin.000010之前的日志都干掉。\npurge binary logs to \'mysql-bin.000010\';\n```\n\n那么使用purge删除的话会保证主从复制所有数据都传递到从库？当然，这个是不能保证的。因此purge之前要确保日志都传递到从库了（确认方法可以在主库flush logs然后去从库看看有没有传递过去）。还有就是使用purge删除的话会把mysqlbin.index中的也删掉，这个是rm做不到的，因此不建议使用rm进行删除binlog，不过一定要使用rm删除的话，记得在数据库里使用purge调用一下。\n\n### 审计日志\n\n审计日志是官方的一个收费组件，需要购买企业版。\n\n- 基于策略的日志记录：\n  - 通过audit_log_policy选项设置\n  - 提供日志记录选项ALL、NONE、LOGINS或QUERIES，默认为ALL\n\n在日志文件中生成一个服务器活动审计的记录：\n\n- 内容取决于策略，可能包括：\n  - 在系统上发生的错误的记录\n  - 客户机链接和断开的链接的时间\n  - 客户机在连接期间执行的操作\n  - 客户机访问的数据库和表\n\n![](http://omk1n04i8.bkt.clouddn.com/17-11-18/45961731.jpg)\n\n## DBA运维常用命令总览\n\n### 认识information_schema数据库\n\n> 学习利用information_schema的字典信息生成语句，information_schema相当于Mysql的中央信息库。\n\n**模式和模式对象**\n\n服务器的统计信息（状态变量，设置，链接），该库不持久化，属于“虚拟数据库”，不可更改，即使是root也干不掉。我们在物理的datadir下是找不到这个数据库的，可以通过select访问。\n\n#### Information_schema重要对象\n\n比如当我们想统计哪些库中有哪些表的时候，我们就可以这样去访问：\n\n```mysql\nmysql> select table_name from information_schema.tables where table_schema=\'information_schema\' order by table_name;\n```\n\n查看库中的表和表引擎：\n\n```mysql\nmysql> select table_name,engine from information_schema.tables where table_schema=\'wordpress\';\n+----------------------------+--------+\n| table_name                 | engine |\n+----------------------------+--------+\n| mxyblog_commentmeta        | MyISAM |\n| mxyblog_comments           | MyISAM |\n| mxyblog_hermit             | MyISAM |\n| mxyblog_hermit_cat         | MyISAM |\n| mxyblog_links              | MyISAM |\n| mxyblog_ngg_album          | MyISAM |\n| mxyblog_ngg_gallery        | MyISAM |\n| mxyblog_ngg_pictures       | MyISAM |\n| mxyblog_options            | MyISAM |\n| mxyblog_postmeta           | MyISAM |\n| mxyblog_posts              | MyISAM |\n| mxyblog_term_relationships | MyISAM |\n| mxyblog_term_taxonomy      | MyISAM |\n| mxyblog_termmeta           | MyISAM |\n| mxyblog_terms              | MyISAM |\n| mxyblog_usermeta           | MyISAM |\n| mxyblog_users              | MyISAM |\n+----------------------------+--------+\n17 rows in set (0.00 sec)\n```\n\n查看mysql系统默认的字符集和校对集：\n\n```mysql\nmysql> select character_set_name,collation_name from information_schema.collations where is_default=\'Yes\';\n```\n\n查看每个库的表统计\n\n```mysql\nmysql> select table_schema,count(*) from information_schema.tables group by table_schema;\n+--------------------+----------+\n| table_schema       | count(*) |\n+--------------------+----------+\n| carbon             |       23 |\n| emlog              |       15 |\n| gogs               |       36 |\n| information_schema |       61 |\n| mysql              |       31 |\n| performance_schema |       87 |\n| sys                |      101 |\n| wordpress          |       17 |\n| zabbix             |      127 |\n+--------------------+----------+\n9 rows in set (0.00 sec)\n```\n\n常见用法-语句拼合生成(可以结合into outfile使用)：\n\n```mysql\nmysql> select concat(\"mysqldump -uroot -pxxxx\",\" \",table_schema,\" \",table_name,\">\",table_schema,\".\",table_name,\".bak.sql\") from information_schema.tables where table_name like \"mxyblog_%\"; \n```\n\n### show核心语句(help show)\n\n- show databases\n- show tables;/show tables from db_name;\n- show columns from db_name.tb_name;\n- show full columns from db_name.tb_name;\n- show processlist\n- show create table table_name\n- show index from table_name\n- show open tables;\n- show table status;\n\n####  show还支持like和where使用\n\n- show databases like \'mxyblog_%\';\n- show columns from zst where \'Default\' is null\n- show character set;\n- show collation;\n\n## Mysql的目录结构\n\n首先先来看一下data目录下都有什么内容：\n\n```shell\n[root@maxiaoyu 11:57:18 /data/mysql]\n#ls -lh\ntotal 186M\n-rw-r----- 1 mysql mysql    56 Jun 16 12:08 auto.cnf\n-rw------- 1 root  root   1.7K Jun 16 12:10 ca-key.pem\n-rw-r--r-- 1 root  root   1.1K Jun 16 12:10 ca.pem\n-rw-r--r-- 1 root  root   1.1K Jun 16 12:10 client-cert.pem\n-rw------- 1 root  root   1.7K Jun 16 12:10 client-key.pem\n-rw-r----- 1 mysql mysql 1005K Nov 19 11:22 ecs-mysql-bin.000013\n-rw-r----- 1 mysql mysql    23 Nov 18 21:36 ecs-mysql-bin.index\n-rw-r----- 1 mysql mysql   830 Nov  6 15:22 ib_buffer_pool\n-rw-r----- 1 mysql mysql   76M Nov 19 10:52 ibdata1\n-rw-r----- 1 mysql mysql   48M Nov 19 10:52 ib_logfile0\n-rw-r----- 1 mysql mysql   48M Aug 28 15:42 ib_logfile1\n-rw-r----- 1 mysql mysql   12M Nov 19 11:26 ibtmp1\n-rw-r----- 1 mysql mysql  113K Nov  6 14:41 maxiaoyu.err\n-rw-r----- 1 mysql mysql     6 Nov  6 15:23 maxiaoyu.pid\n-rw-r----- 1 mysql mysql  4.3K Nov  6 15:23 maxiaoyu-slow.log\ndrwxr-x--- 2 mysql mysql  4.0K Jun 16 12:08 mysql\ndrwxr-x--- 2 mysql mysql  4.0K Jun 16 12:08 performance_schema\n-rw------- 1 root  root   1.7K Jun 16 12:10 private_key.pem\n-rw-r--r-- 1 root  root    451 Jun 16 12:10 public_key.pem\n-rw-r--r-- 1 root  root   1.1K Jun 16 12:10 server-cert.pem\n-rw------- 1 root  root   1.7K Jun 16 12:10 server-key.pem\ndrwxr-x--- 2 mysql mysql   12K Jun 16 12:08 sys\n```\n\n- auto_cnf下存放的是server的uuid\n\n  ```mysql\n  [root@maxiaoyu 11:57:21 /data/mysql]\n  #cat auto.cnf \n  [auto]\n  server-uuid=7e40a68a-5249-11e7-94f1-00163e06bd3d\n  ```\n\n- ib_buffer_pool：insert buffer pool\n\n- ibdata1：整体的一个数据字典文件，Innodb表的元数据；变更缓冲区；双写缓冲区；撤销日志。ibdata1存储的内容可以参考[为什么mysql里的ibdata1文件不断的增长](https://linux.cn/article-5829-1.html)\n\n- ib_logfile0：redo文件，建议最少设置成3~5个。\n\n- ibtemp1：临时表文件\n\n**使用mysql_config查找对应的库位置：**\n\n```shell\n$sudo /usr/local/mysql/bin/mysql_config\nUsage: /usr/local/mysql/bin/mysql_config [OPTIONS]\nCompiler: GNU 4.4.4\nOptions:\n        --cflags         [-I/usr/local/mysql/include ]\n        --cxxflags       [-I/usr/local/mysql/include ]\n        --include        [-I/usr/local/mysql/include]\n        --libs           [-L/usr/local/mysql/lib -lmysqlclient -lpthread -lm -lrt -ldl]\n        --libs_r         [-L/usr/local/mysql/lib -lmysqlclient -lpthread -lm -lrt -ldl]\n        --plugindir      [/usr/local/mysql/lib/plugin]\n        --socket         [/tmp/mysql.sock]\n        --port           [0]\n        --version        [5.7.18]\n        --libmysqld-libs [-L/usr/local/mysql/lib -lmysqld -lpthread -lm -lrt -lcrypt -ldl -laio]\n        --variable=VAR   VAR is one of:\n                pkgincludedir [/usr/local/mysql/include]\n                pkglibdir     [/usr/local/mysql/lib]\n                plugindir     [/usr/local/mysql/lib/plugin]\n```\n\n**mysql对应的插件目录（比如半同步）**：\n\n```shell\n/usr/local/mysql/lib/plugin\n```\n\n**帮助手册：**\n\n如果说系统的帮助手册man不到mysql的话我们可以手动拷贝一下mysql安装目录中的man手册到系统下，这样就可以实现使用系统man查看帮助手册了：\n\n```shell\ncp /usr/local/mysql/man/man* /usr/local/share/man -r\n```\n\n**share目录**\n\nshare目录保存的是一些字符集，以及一些初始化用的sql。 \n\n**bin目录：**\n\n- mysqld\n- mysql\n- mysqldump\n- mysqlbinlog\n- mysqladmin\n- mysql_config_editor：配合--login-path使用\n- perror：展示错误代码\n- mysqlslap：做mysql的性能测试\n\n**性能测试工具：**\n\n- sysbench1.1\n- mysql-tpcc：使用percona版本\n- YCSB：雅虎的，可以适配多种数据库 & NOSQL\n- fio：磁盘性能监测\n\n***\n\n如果说遇到数据库整库打包迁移后域名解析错误该怎么办？\n\n```shell\n# 这种问题可以借助sql自带的resolveip来反解析一下看看对不对\n\n[lamber@maxiaoyu 12:59:52 /usr/local/mysql/bin]\n$./resolveip 47.94.132.15\nHost name of 47.94.132.15 is maxiaoyu, blog.dcgamer.top\n\n# 如果说不对的话可以使用strace来看一下\n$strace ./resolveip 47.94.132.15 \n```\n\n***\n\n安装percona-tools\n\n\n\nmysqlbinlog统计：\n\nhttps://github.com/wubx/mysql-binlog-statistic\n\n### Mysql的5.7的SYS库\n\n","timestamp":1526281685638},{"name":"01-Mysql用户账户维护.md","path":"03-DBA运维/01-Mysql/02-MYSQL基本维护/01-Mysql用户账户维护.md","content":"# Mysql用户维护\n\n账户管理的重要性\n\n- 在mysql中可以通过账户控制允许或者不允许用户执行操作\n- 可以精细分配不同的权限给不同职能的账户\n- 避免使用root账户\n  - 应用不能直接使用root\n  - 防止维护期间出错\n- 限定特定权限账户确保数据的完整性\n  - 允许特定授权账户完成期工作\n  - 阻止未经授权的用户访问超出其特权的数据\n\n在root上可以做一些限制的操作：\n\n```mysql\nupdate mysql.user set user=\'xroot\' where user=\'root\';\nflush privileges;\n```\n\n## 账户管理\n\n查看mysql账户\n\n```mysql\n# mysql 5.6及以前版本\nselect user,host,password from mysql.user;\n# 在初始化数据库以后要删除掉匿名账户(在5.7中会自动执行这条命令)\ndelete from mysql.user where user!=\'root\' or localhost!=\'localhost\';\n\n# mysql 5.7及以后\nmysql root@localhost:(none)> select user,host,authentication_string from mysql.user;\n```\n\nmysql的账户验证现在大多验证使用mysql_native_password这个plugin，在mysql验证的时候使用以下三个要素：\n\n- 用户名\n- 主机所属范围（主机来源）\n- 用户密码\n\n查看用户授权有两个函数，一个是user()另外一个是current_user()\n\n```mysql\nmysql maxiaoyu@localhost:(none)> select user(),current_user();\n+--------------------+----------------+\n| user()             | current_user() |\n+--------------------+----------------+\n| maxiaoyu@localhost | maxiaoyu@%     |\n+--------------------+----------------+\n1 row in set\nTime: 0.006s\n```\n\n从上面的结果可以看到user函数是指的当前登录进来的用户和它的主机范围，current_user这个函数指的是授权的信息。\n\n用户连接和查询流程\n\n![](http://omk1n04i8.bkt.clouddn.com/17-10-17/7497028.jpg)\n\n和用户权限把控相关的主要是mysql库中的四张表，user表，db表以及columns_priv表，table_priv表。\n\n创建用户\n\n```mysql\ncreate user 用户名@主机 identified by \'密码\'\n# 这样创建的账号的只有链接权限，其他的啥都做不了\n# %通配，_表示匹配一个。\n```\n\n用户名建议8~16个字符，密码一般是16-32个字符，mysql域名最好在60个字符以内。我们可以使用mkpasswd去生成随机密码，也可以使用其他的方式。linux可以生成随机密码的方式有很多，可以选择自己喜欢的方式做为常用方式去升级。\n\n创建用户要注意的几个风险：\n\n- 不要创建没有用户名的账号\n- 不要创建没有密码的账号\n- 在可能的情况下主机限制那里不要使用通配符，尽量缩小范围。\n\n关于主机名的匹配是走最精确的，比如‘root’@\'192.168.%\'和‘root’@‘192.168.1.%’，它会去优先匹配后面这个，不看排序只看精确程度，或者这里我们可以通过通配符结合/etc/hosts来进行域名的解析数据库的登录。\n\n那么如何针对一个大范围内的部分主机IP进行限制呢？\n\n```mysql\n# 比如授权一个\ncreate user \'lamber\'@\'192.168.1.%\' identified by \'password\'\n\n# 我现在唯独想把192.168.1.100这个ip的不让他进行访问，那么我们就可以单独处理\ncreate user \'lamber\'@\'192.168.1.100\' identified by \'otherpasswd\'\n\n# 由于最精确匹配的原则，这个1.100ip的人的密码就是这个otherpasswd而不是password因此就会限制这个ip的用户的登录\n```\n\n使用password函数查看加密处理的authentication_string是什么：\n\n```mysql\nmysql maxiaoyu@localhost:mysql> select password(\'maxiaoyuhahaha\');\n+-------------------------------------------+\n| password(\'maxiaoyuhahaha\')                |\n+-------------------------------------------+\n| *92A2BE17BB2A1064C25BAE92A1AAFCF8B961B8C2 |\n+-------------------------------------------+\n1 row in set\nTime: 0.006s\n```\n\n有时候忘了密码还能猜猜，当然你如果是随机密码那就别这么玩了。。不过密码忘了有一种暴力修改的方式就是：\n\n```mysql\nupdate mysql.user set authentication_string=password(\'new_pass\') where user=\'current_user\';\nflush privileges;\n```\n\n在使用这个暴力方法的时候务必要加where的条件，要不然不这个系统上的所有mysql账户全部gg，而且修改完以后要刷一下缓存。上面这一种方法并不是官方推荐的方法，当然你也尽可能的不要去使用，手抖一下问题还是挺多的。除了使用上面的暴力方法还可以使用下面这种方法为用户修改密码：\n\n```mysql\nset password for \'maxiaoyu\'@\'%\'=password(\'new_pass\');\n```\n\n更好地修改方法：\n\n```mysql\nset password for \'maxiaoyu\'@\'%\'=\'hahahaha\'\n\n# 因为使用password函数的方法将会在后期的版本被移除，这个信息可以通过show warnings查看\nmysql maxiaoyu@localhost:mysql> show warnings\\G;\n***************************[ 1. row ]***************************\nLevel   | Warning\nCode    | 1287\nMessage | \'SET PASSWORD FOR <user> = PASSWORD(\'<plaintext_password>\')\' is deprecated and will be removed in a future release. Please use SET PASSWORD FOR <user> = \'<plaintext_password>\' instead\n```\n\n使用alter的方法去修改用户的密码：\n\n```mysql\nmysql maxiaoyu@localhost:mysql> alter user \'maxiaoyu\'@\'%\' identified by \'new_pass\';\nQuery OK, 0 rows affected\nTime: 0.001s\n```\n\n确认没有密码的用户（把没有密码的用户干掉）：\n\n```mysql\nselect user,host from mysql.user where password=\'\';\nselect user,host from mysql.user where authentication_string=\'\';\n```\n\n让用户口令失效，登录后必须修改密码（5.7使用，如果是5.5或者以前的话登录直接会报错）：\n\n```mysql\nalter user \'maxiaoyu\'@\'%\' passwird expire;\n```\n\n删除用户：\n\n```mysql\n# 直接删除该用户，从授权表中删除该用户的记录\ndrop user \'maxiaoyu\'@\'%\'\n\n# 如果不加主机名的话默认会删除主机名为%的记录\ndrop user \'maxiaoyu\'(drop user \'maxiaoyu\'@\'%\')\n```\n\n重命名用户：\n\n```mysql\n# 更改账号的名称，保留权限，可以更改：用户名和主机名部分\nrename user \'maxiaoyu\'@\'%\' to \'lamber\'@\'%\'\n```\n\n如果忘记了语法的使用可以使用help\n\n```mysql\nhelp create user\n```\n\n## 权限管理\n\n使用create创建的用户其实是什么权限都没有的，只能看到一个information_schema这么一个库，如果你要创建一个和root一样的权限的账号，可以参考root的权限，很重要的一点就是`with grant option`。\n\n合理的控制授权也是dba的重要责任之一，权限可以划分的很细致，主要从以下几个方面：\n\n- 全局级别\n- 数据库级别\n- 表级别\n- 列级别\n- 存储过程级别\n\n**只读用户**\n\n全局，数据库或者表级别权限，只用select\n\n**开发用户**\n\n业务库权限：insert、update、delete、select，call\n\n**管理用户**\n\n全局级别，权限：insert、update、delete、create、alter、drop、file(现在基本不用给这个权限了)、process、shutdown、super\n\n### 以下权限需要注意\n\nFILE：允许用户指示mysql服务器在服务器主机文件系统中读写文件，在mysql5.7中需要打开配置文件中的一个参数来配合：\n\n```mysql\n# file\n# @secure-file-priv=/tmp\n```\n\n如果需要文件权限就需要打开这个注释，不过5.7还是默认把这个给干掉了，因为漏洞还是挺多的。\n\nPROCESS：允许用户使用show processlist语句，这个是管理中常用的语句（如果show processlist显示内容过多的话可以使用[pager more](http://wubx.net/mysql-client-tips/)这个功能）\n\nSUPER：运行用户终止其他客户机的链接，或者更改服务器的运行时的配置，执行kill set shutdown\n\nALL：授予所有权限（但是不能向其他用户授予权限）\n\nGRANT ALL … WITH GRANT OPTION：授予所有特权，相当于root\n\n### 权限的授予与去除（grant and revoke）\n\nGRANT命令可以给现有的用户添加权限，如果用户不存在的话还可以创建用户\n\n```mysql\ngrant select,insert,update,delete on *.* to \'maxiaoyu\'@\'%\' identified by \'password\'\n```\n\nTips:\n\n- 多个权限使用逗号隔开，不区分大小写\n- 授权的对象\n  - 全局级别：\\*.\\*\n  - 数据库级别：dbname.\\*\n  - 表级别：db_name.table_name\n- 要创建或是授权的用户：\'username\'@\'hostname(IP/network)\'\n- 密码：可选\n\n查看账户的权限：\n\n```mysql\nshow grants;\nshow grants for current_user();\nshow grants for \'root\'@\'localhost\';\n```\n\n我们可以通过`show privileges`来查看mysql支持的权限：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-10-19/55799788.jpg)\n\n### 权限控制表\n\n|     表（MyISAM）     |       用处       |\n| :---------------: | :------------: |\n|    mysql.user     | 每个创建的用户在这里都有记录 |\n|     mysql.db      |  限制用户做用户特定的db  |\n| mysql.tables_priv |   用于表级别的权限控制   |\n| mysql.procs_priv  | 用户存储过程和函数权限控制  |\n\nMysql启动的时候从mysql库中把权限读取加载到内存中，如果通过DML更新权限表需要借助于flush privilegesl才能生效。*<u>特别需要注意的是：不要对权限表进行DML操作</u>*。\n\n#### 权限的revoke\n\n使用revoke语句撤销对用户的授权：\n\n```mysql\nrevoke delete,insert,update on world_innodb.* from \'maxiaoyu\'@\'%\'\nrevoke all privileges,grant option from \'maxiaoyu\'@\'%\';\n\n# revoke语法：\n# revoke关键字：指定要撤掉的特权列表。\n# on子句：只是要撤销特权的级别（全局级别的时候可以不用带）。\n# from子句：指定账户名称。\n```\n\n批量对部分表进行授权：\n\n```mysql\nmysql root@localhost:(none)> use information_schema\nYou are now connected to database \"information_schema\" as user \"root\"\nTime: 0.001s\nmysql root@localhost:information_schema> select concat(\'grant select on \',table_schema,\'.\',table_name,\" to \'testuser2\'@\'%\';\") from tables where table_schema=\'wordpress\' and table_name like \"mxy%\";\n+-------------------------------------------------------------------------------+\n| concat(\'grant select on \',table_schema,\'.\',table_name,\" to \'testuser2\'@\'%\';\") |\n+-------------------------------------------------------------------------------+\n| grant select on wordpress.mxyblog_commentmeta to \'testuser2\'@\'%\';             |\n| grant select on wordpress.mxyblog_comments to \'testuser2\'@\'%\';                |\n| grant select on wordpress.mxyblog_hermit to \'testuser2\'@\'%\';                  |\n| grant select on wordpress.mxyblog_hermit_cat to \'testuser2\'@\'%\';              |\n| grant select on wordpress.mxyblog_links to \'testuser2\'@\'%\';                   |\n| grant select on wordpress.mxyblog_ngg_album to \'testuser2\'@\'%\';               |\n| grant select on wordpress.mxyblog_ngg_gallery to \'testuser2\'@\'%\';             |\n| grant select on wordpress.mxyblog_ngg_pictures to \'testuser2\'@\'%\';            |\n| grant select on wordpress.mxyblog_options to \'testuser2\'@\'%\';                 |\n| grant select on wordpress.mxyblog_postmeta to \'testuser2\'@\'%\';                |\n| grant select on wordpress.mxyblog_posts to \'testuser2\'@\'%\';                   |\n| grant select on wordpress.mxyblog_term_relationships to \'testuser2\'@\'%\';      |\n| grant select on wordpress.mxyblog_term_taxonomy to \'testuser2\'@\'%\';           |\n| grant select on wordpress.mxyblog_termmeta to \'testuser2\'@\'%\';                |\n| grant select on wordpress.mxyblog_terms to \'testuser2\'@\'%\';                   |\n| grant select on wordpress.mxyblog_usermeta to \'testuser2\'@\'%\';                |\n| grant select on wordpress.mxyblog_users to \'testuser2\'@\'%\';                   |\n+-------------------------------------------------------------------------------+\n17 rows in set\nTime: 0.008s\n```\n\n## 禁用验证控制\n\n视频点：第四课：1小时23分\n\n\n\n\n\n\n\n\n\n","timestamp":1526281685638},{"name":"01-01、Mysql主从.md","path":"03-DBA运维/01-Mysql/03-MYSQL数据安全/01-01、Mysql主从.md","content":"hexdump -C mysql-bin.010100\n\n","timestamp":1526281685638},{"name":"02-02、Mysql备份.md","path":"03-DBA运维/01-Mysql/03-MYSQL数据安全/02-02、Mysql备份.md","content":"","timestamp":1526281685638},{"name":"05-05、Mysql高可用.md","path":"03-DBA运维/01-Mysql/03-MYSQL数据安全/05-05、Mysql高可用.md","content":"# Mysql常见高可用架构\n\n> 常见Mysql高可用大纲\n>\n> - 基于主从的高可用\n> - 基于DRBD+Heartbeat的高可用\n> - 官方推荐的Mysql NDB Cluster\n> - 基于PXC模型的高可用\n> - 基于Proxy模型的高可用\n> - Mysql 5.7 Group Replication高可用\n> - 基于多源复制高可用\n> - 自主实现mysql高可用\n> - 业界DB四层架构设计\n\n## 1、基于复制的高可用\n\n**传统的复制模型：**\n\n- statement\n- mixed\n- row\n\n如果你的mysql版本是5.6以上的话毫不犹豫的建议使用GTID+ROW的形式\n\n### 1.1、基于Keepalived实现主从故障切换\n\n\n\n### 1.2、基于MHA的高可用\n\n> 作者已经放弃了对mha的维护了\n\n\n\n### 1.3、基于DNS或介入服务的高可用\n\n","timestamp":1526281685638},{"name":"02-02、mysql基础操作.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/02-02、mysql基础操作.md","content":"# Mysql基础操作\n\n## 1、库操作，DDL\n\n### 1.1 创建（create）\n\ncreate database 库名 [库选项]\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/45809924.jpg)\n\n注意的问题：\n\n库选项，只有字符集，校对集的概念！每个库，会对应一个数据目录\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/30978819.jpg)\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/91773687.jpg)\n\n默认的只有字符集，校对集的概念：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/9094061.jpg)\n\n其他需要注意的问题：\n\n- 关于创建名称大小写的问题，这个是跟着系统走的，看你操作是否大小写敏感，比如windows是大小写不敏感的，但是linux是敏感的，因此为了保持一致性，使用的时候要保持大小写敏感，从而保证系统的稳定运行\n\n- 你创建的库或者是表不能是关键字敏感的，比如下面的：\n\n  ```\n  mysql> create database order;\n  ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \'order\' at line 1\n  ```\n\n  但是这并不是绝对的，我们只要告诉数据库我要创建的这是一个表名称就可以了，需要将名称用反引号引起来，就是数组1左侧的那个按键：\n\n  ```\n  mysql> create database `order`;\n  Query OK, 1 row affected (0.00 sec)\n  ```\n\n- 中文等都可以作为标识符（库名），需要同样反引号！（多字节字符，还需要注意字符集的问题），需要设置字符集为gbk，因为当前是在windows上。不然无法创建的。\n\n  ```\n  mysql> set names gbk;\n  Query OK, 0 rows affected (0.00 sec)\n\n  mysql> create database `小雨`;\n  Query OK, 1 row affected (0.04 sec)\n\n  mysql> show databases;\n  +--------------------+\n  | Database           |\n  +--------------------+\n  | information_schema |\n  | 小雨               |\n  | mysql              |\n  | order              |\n  | performance_schema |\n  | sys                |\n  | test               |\n  +--------------------+\n  7 rows in set (0.00 sec)\n  ```\n\n### 1.2 查询库\n\n```mysql\nshow databases;\nshow databases likes \'%_scheme\';   # 使用like可以实现通配符匹配\n=========================================\n可以使用通配符（通用匹配符，可以匹配多个字符）\n% 匹配任意字符的任意次数（包括0次）的组合！\n_ 匹配任意字符的一次！\nlike ‘x_y’;\nx1y xby xxy（可以）\nxy(不可以)\n通配符是与 like 关键字一起使用！\n=========================================\n```\n\n注意如需要匹配特定的通配符，则需要对通配符转义，使用反斜杠\\完成转义！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/55760220.jpg)\n\n**查看某一个库的定义**\n\n```mysql\nmysql> show create database mysql\\G;\n*************************** 1. row ***************************\n       Database: mysql\nCreate Database: CREATE DATABASE `mysql` /*!40100 DEFAULT CHARACTER SET latin1 */\n1 row in set (0.00 sec)\n\nERROR:\nNo query specified\n```\n\n### 1.3 修改库\n\nalter database 数据库名\n\n```\nmysql> alter database `小雨` charset gbk;\nQuery OK, 1 row affected (0.00 sec)\n```\n\n### 1.4 删除库\n\ndrop database 名字\n\n### 1.5 if not exist,if exist\n\n```mysql\n在  create  与 drop 时，创建和删除时，有两个额外的操作：\n \ncreate database if not exists\n如果不存在则创建\n \ndrop database if exists\n如果存在，则删除\n```\n\n### 1.6 查看警告状态\n\nshow warnings;   \n\n此命令可以查看警告项\n\n## 2、表操作\n\n### 2.1 创建，create table\n\n```mysql\ncreate table 表名 (\n字段的定义\n) [表选项];\n\n其中表名，一定先要确定数据库！因此一个典型的表名是由两部分组成：\n所在库.表名（库与表之间用“.”连接）\ntest.itcast       test库内itcast表\nitcast.stu         itcast库内的stu表\n但是我们可以设置默认数据库，如果不指定则使用默认数据库（当前数据库）\nuse 数据库名。选择默认数据库！\n在使用表名但是没有指明其所在数据库时，默认数据库才会起作用！\n\n比如：\n在itcast库内创建：\nuse itcast ; create table stu;\n或者\ncreate table itcast.stu\n```\n\n**关于字段**\n\n字段才是最终的数据的载体（与变量的概念是类似的，都是基本保存数据的），mysql的是强类型，字段的类型是固定的，提前定义好的！因此，在定义字段时，至少要字段名和字段类型！两种最基本的mysql数据类型（int， varchar,varchar必须指定最大长度字符为单位）varchar单位为字符数，一般是255.比如大葱，这就是两个字符，在UTF-8中就是占用6个字节。具体多少字节和字符集有关系。\n\n创建一个表的示例：\n\n```mysql\nmysql> create table test2 (\n        id int auto_increment,\n        name varchar(255),\n        sex char(16)\n        ) engine=innodb charset=utf8;\n        \nAbout auto_increment:\nauto_increment指的是自增列，这个列可以实现数据id自增，常用与表的id列。\n我们可以指定auto_increment的起始位置\n\nalter table table_name AUTO_INCREMENT=20;\n或者在创建的时候在engine后面跟一个auto_increment=xx也可以\n\n当然现在自增是一个一个的，我们可以为它设置步长，可以跳着增加。\nmysql自增步长是基于会话级别的，什么叫会话级别的，就是你当前打开一个mysql终端\n这就是建立了一个会话，针对当前有一个设置有一个默认的步长：\nmysql> show session variables like \'auto_increment%\';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 1     |\n| auto_increment_offset    | 1     |\n+--------------------------+-------+\n2 rows in set, 1 warning (0.00 sec)\n大家默认的步长都是1，每个会话的步长可以不一样，我们可以通过set命令\n\nmysql> set session auto_increment_increment=2;\nQuery OK, 0 rows affected (0.00 sec)\n当然退出重新登录就相当于一个新的会话了，之前的设置就没了。\n\n如果要设置所有人都一样的话也不是不可以，设置全局变量即可：\nmysql> set global auto_increment_increment=200;\nQuery OK, 0 rows affected (0.00 sec)\n当然服务器重启以后还是会重置，如果需要永久修改还是放到配置文件去吧。\n\n当然还有基于表级别的设置步长，给一个表单独设置步长。这个和会话就没关系了。\n```\n\n- 当然字段可以创建的时候就指定好，也可以后续的添加：\n\n```\nalter table table_name add column 字段定义 [字段位置]\n\neg:\nmysql> alter table test2 add column age int;\nQuery OK, 0 rows affected (0.91 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> desc test2;\n+-------+--------------+------+-----+---------+-------+\n| Field | Type         | Null | Key | Default | Extra |\n+-------+--------------+------+-----+---------+-------+\n| id    | int(11)      | YES  |     | NULL    |       |\n| name  | varchar(255) | YES  |     | NULL    |       |\n| sex   | char(16)     | YES  |     | NULL    |       |\n| age   | int(11)      | YES  |     | NULL    |       |\n+-------+--------------+------+-----+---------+-------+\n4 rows in set (0.00 sec)\n\n指定添加字段的位置，加在某一个字段后可以使用after，加在第一行可以使用first关键字：\nmysql> alter table test2 add column comment varchar(255) after sex;\nQuery OK, 0 rows affected (0.68 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> desc test2;\n+---------+--------------+------+-----+---------+-------+\n| Field   | Type         | Null | Key | Default | Extra |\n+---------+--------------+------+-----+---------+-------+\n| id      | int(11)      | YES  |     | NULL    |       |\n| name    | varchar(255) | YES  |     | NULL    |       |\n| sex     | char(16)     | YES  |     | NULL    |       |\n| comment | varchar(255) | YES  |     | NULL    |       |\n| age     | int(11)      | YES  |     | NULL    |       |\n+---------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n```\n\n### 2.2 查\n\n查看所有的表：\n\n```mysql\nmysql> show tables;\n+----------------+\n| Tables_in_test |\n+----------------+\n| test1          |\n| test2          |\n+----------------+\n2 rows in set (0.00 sec)\n```\n\n使用like进行模糊匹配：\n\n```mysql\nmysql> show tables like \'%es%\';\n+-----------------------+\n| Tables_in_test (%es%) |\n+-----------------------+\n| test1                 |\n| test2                 |\n+-----------------------+\n2 rows in set (0.02 sec)\n```\n\n查看建表的时候相关信息：\n\n```python\nmysql> show create table test1\\G;\n*************************** 1. row ***************************\n       Table: test1\nCreate Table: CREATE TABLE `test1` (\n  `id` int(11) DEFAULT NULL,\n  `name` varchar(255) DEFAULT NULL,\n  `sex` char(16) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n1 row in set (0.00 sec)\n```\n\n查询表结构\n\n```mysql\nmysql> desc test1;\n+-------+--------------+------+-----+---------+-------+\n| Field | Type         | Null | Key | Default | Extra |\n+-------+--------------+------+-----+---------+-------+\n| id    | int(11)      | YES  |     | NULL    |       |\n| name  | varchar(255) | YES  |     | NULL    |       |\n| sex   | char(16)     | YES  |     | NULL    |       |\n+-------+--------------+------+-----+---------+-------+\n3 rows in set (0.00 sec)\n```\n\n### 2.3 改\n\nalter命令进行修改的操作，alter table table_name 设置对应的字段值：\n\n```mysql\nmysql> alter table test1 engine=myisam charset=gbk;\nQuery OK, 0 rows affected (0.64 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> show create table test1\\G;\n*************************** 1. row ***************************\n       Table: test1\nCreate Table: CREATE TABLE `test1` (\n  `id` int(11) DEFAULT NULL,\n  `name` varchar(255) CHARACTER SET latin1 DEFAULT NULL,\n  `sex` char(16) CHARACTER SET latin1 DEFAULT NULL\n) ENGINE=MyISAM DEFAULT CHARSET=gbk\n1 row in set (0.00 sec)\n```\n\n表名称的修改\n\n```mysql\nrename table test1 to hahahal\n\nmysql> show tables;\n+----------------+\n| Tables_in_test |\n+----------------+\n| hahahal        |\n| test2          |\n+----------------+\n2 rows in set (0.00 sec) \n\n注意，表名可以由库名.表名形式的！因此，可以跨库修改表名：只要在表名前增加库名即可\n```\n\n针对字段的定义的修改：\n\n```mysql\nalter table table_name modify column column_name 新的定义！\n\neg:\nmysql> desc test2;\n+---------+--------------+------+-----+---------+-------+\n| Field   | Type         | Null | Key | Default | Extra |\n+---------+--------------+------+-----+---------+-------+\n| id      | int(11)      | YES  |     | NULL    |       |\n| name    | varchar(255) | YES  |     | NULL    |       |\n| sex     | char(16)     | YES  |     | NULL    |       |\n| comment | varchar(255) | YES  |     | NULL    |       |\n| age     | int(11)      | YES  |     | NULL    |       |\n+---------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n\nmysql> alter table test2 modify column id char(4) after age;\nQuery OK, 0 rows affected (0.79 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> desc test2;\n+---------+--------------+------+-----+---------+-------+\n| Field   | Type         | Null | Key | Default | Extra |\n+---------+--------------+------+-----+---------+-------+\n| name    | varchar(255) | YES  |     | NULL    |       |\n| sex     | char(16)     | YES  |     | NULL    |       |\n| comment | varchar(255) | YES  |     | NULL    |       |\n| age     | int(11)      | YES  |     | NULL    |       |\n| id      | char(4)      | YES  |     | NULL    |       |\n+---------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n```\n\n修改字段名称：\n\n```mysql\nalter table table_name change column 原字段名 新字段名 新字段定义！【选项】\n注意，不是纯粹的改名，而是需要在修改定义的同时改名！\n\nmysql> desc test2;\n+---------+--------------+------+-----+---------+-------+\n| Field   | Type         | Null | Key | Default | Extra |\n+---------+--------------+------+-----+---------+-------+\n| name    | varchar(255) | YES  |     | NULL    |       |\n| sex     | char(16)     | YES  |     | NULL    |       |\n| comment | varchar(255) | YES  |     | NULL    |       |\n| age     | int(11)      | YES  |     | NULL    |       |\n| id      | char(4)      | YES  |     | NULL    |       |\n+---------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n\nmysql> alter table test2 change column name username char(128) after sex;\nQuery OK, 0 rows affected (0.77 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> desc test2;\n+----------+--------------+------+-----+---------+-------+\n| Field    | Type         | Null | Key | Default | Extra |\n+----------+--------------+------+-----+---------+-------+\n| sex      | char(16)     | YES  |     | NULL    |       |\n| username | char(128)    | YES  |     | NULL    |       |\n| comment  | varchar(255) | YES  |     | NULL    |       |\n| age      | int(11)      | YES  |     | NULL    |       |\n| id       | char(4)      | YES  |     | NULL    |       |\n+----------+--------------+------+-----+---------+-------+\n5 rows in set (0.00 sec)\n```\n\n### 2.4 删\n\n- 直接删除表\n\n```mysql\ndrop table table_name;\n```\n\n- 删除字段\n\n```mysql\nalter table table_name drop column column_name;\n```\n\n## 3、数据操作\n\n### 3.1 增\n\ninsert into 表名 (字段列表) values (与字段相对的值列表)。不一定要一次性插入所有字段，或者按照原始的字段顺序插入，但是字段要与值的数量匹配。\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/38995012.jpg)\n\n如果数量不匹配的话就会报错：\n\n```mysql\nmysql> insert into test2 (sex,username,comment) values(\'male\');\nERROR 1136 (21S01): Column count doesn\'t match value count at row 1\n```\n\n当然如果要向所有的字段插入数据的话那么就可以省略字段直接添加values，同样的，要一一对应。\n\n```mysql\nmysql> insert into test2 values(\'male\',\'lamber\',\'test\',26,2);\nQuery OK, 1 row affected (0.11 sec)\n\nmysql> select * from test2;\n+------+----------+---------+------+------+\n| sex  | username | comment | age  | id   |\n+------+----------+---------+------+------+\n| male | lamber   | test    |   26 | 2    |\n+------+----------+---------+------+------+\n1 row in set (0.00 sec)\n\n也可以一条命令添加多条数据：\ninsert into test2 values(\'male\',\'lamber\',\'test\',26,2),(\'female\',\'testuser1\',\'test2\',27,1)……;\n多个数据之间都接在values后面用逗号隔开。\n```\n\n将A表里的数据插入到B表：\n\n```mysql\ninsert into tableB(name,age) select name,age from tableA\n```\n\n也是支持上面这种写法的。\n\n### 3.2 删\n\n- 清空表数据\n\n```mysql\ndelete from table_name;\ntruncate table table_name;\n\n说下二者的区别，truncate是要比delete from清空数据快的多的，DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。 简单来说delete比较慢的原因是它是一行一行删的。\n\nTRUNCATE,DELETE,DROP放在一起比较：\nTRUNCATE TABLE：删除内容、释放空间但不删除定义。\nDELETE TABLE:删除内容不删除定义，不释放空间。\nDROP TABLE：删除内容和定义，释放空间。\n```\n\n- 删除详细数据就要结合where条件语句\n\n```mysql\ndelete from 表名 where 条件;\n关于条件，可以省略。表示永远为真。注意，删除是不可逆的。要避免没有条件的删除！\n\ndelete from t_name where id > 2; [> < != = or and]\n```\n\n### 3.3 改\n\nupdate操作\n\n```mysql\nupdate 表名 set 字段=新值, 字段n=新值n where 条件\n\neg:\nmysql> update test2 set name=\'shiyue2\' where name=\'shiyue\';\nQuery OK, 1 row affected (0.30 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n\nmysql> select * from test2;\n+----+---------+------+---------+\n| id | name    | age  | comment |\n+----+---------+------+---------+\n|  1 | lamber  |   26 | test1   |\n|  2 | shiyue2 |   23 | test2   |\n+----+---------+------+---------+\n2 rows in set (0.00 sec)\n```\n\n### 3.4 查\n\n`select 字段列表 from 表名 [where 条件表达式]`\n\n其中字段列表可以使用 * 表示所有字段！\n\n```mysql\nmysql> select * from test2;\n+----+--------+------+---------+\n| id | name   | age  | comment |\n+----+--------+------+---------+\n|  1 | lamber |   26 | test1   |\n|  2 | shiyue |   23 | test2   |\n+----+--------+------+---------+\n2 rows in set (0.00 sec)\n```\n\n关于条件表达式，默认是没有，表示永远为真！但是，很少出现没有条件的情况！为了突出，应该所有的语句都有查询条件！即使没有条件，我也强制增加一个 where 1;（1表示true）\n\n```mysql\nmysql> select * from test2 where id=2;\n+----+--------+------+---------+\n| id | name   | age  | comment |\n+----+--------+------+---------+\n|  2 | shiyue |   23 | test2   |\n+----+--------+------+---------+\n1 row in set (0.00 sec)\n```\n\n## 4、数据类型\n\n```mysql\nbit[(M)]\n二进制位（101001），m表示二进制位的长度（1-64），默认m＝1\n\ntinyint[(m)] [unsigned] [zerofill]\n小整数，数据类型用于保存一些范围的整数数值范围：\n有符号：-128 ～ 127.\n无符号：～ 255\n\n特别的： MySQL中无布尔值，使用tinyint(1)构造。\n\nint[(m)][unsigned][zerofill]\n整数，数据类型用于保存一些范围的整数数值范围：\n有符号：-2147483648 ～ 2147483647\n无符号：～ 4294967295\n\n特别的：整数类型中的m仅用于显示，对存储范围无限制。例如： int(5),当插入数据2时，select 时数据显示为： 00002\n\nbigint[(m)][unsigned][zerofill]\n大整数，数据类型用于保存一些范围的整数数值范围：\n有符号：-9223372036854775808 ～ 9223372036854775807\n无符号：～  18446744073709551615\n\ndecimal[(m[,d])] [unsigned] [zerofill]\n准确的小数值，m是数字总个数，算上小数点前+小数点后面支持的总位数（负号不算），d是小数点后个数。 m最大值为65，d最大值为30。\n用法：decimal(10,5)\n特别的：对于精确数值计算时需要用此类型.decaimal能够存储精确值的原因在于其内部按照字符串存储。\n\nFLOAT[(M,D)] [UNSIGNED] [ZEROFILL]\n单精度浮点数（非准确小数值），m是数字总个数，d是小数点后个数。\n无符号：\n-3.402823466E+38 to -1.175494351E-38,\n1.175494351E-38 to 3.402823466E+38\n有符号：\n1.175494351E-38 to 3.402823466E+38\n**** 数值越大，越不准确 ****\n\nDOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]\n双精度浮点数（非准确小数值），m是数字总个数，d是小数点后个数。\n无符号：\n-1.7976931348623157E+308 to -2.2250738585072014E-308\n2.2250738585072014E-308 to 1.7976931348623157E+308\n有符号：\n2.2250738585072014E-308 to 1.7976931348623157E+308\n**** 数值越大，越不准确 ****\n\n\nchar (m)\nchar数据类型用于表示固定长度的字符串，可以包含最多达255个字符。其中m代表字符串的长度。char一上来就会开辟你指定的空间的大小。如果没有占满会填充空\nPS: 即使数据小于m长度，也会占用m长度\nvarchar(m)【节省空间，但是速度没有char快】\nvarchars数据类型用于变长的字符串，可以包含最多达255个字符。其中m代表该数据类型所允许保存的字符串的最大长度，只要长度小于该最大值的字符串都可以被保存在该数据类型中。\n\n注：虽然varchar使用起来较为灵活，但是从整个系统的性能角度来说，char数据类型的处理速度更快，有时甚至可以超出varchar处理速度的50%。因此，用户在设计数据库时应当综合考虑各方面的因素，以求达到最佳的平衡。因此定长的往前放，变长的往后放。\n\ntext\ntext数据类型用于保存变长的大字符串，可以组多到65535 (2**16 − 1)个字符。\n\nmediumtext\nA TEXT column with a maximum length of 16,777,215 (2**24 − 1) characters.\n\nlongtext\nA TEXT column with a maximum length of 4,294,967,295 or 4GB (2**32 − 1) characters.\n\nenum，枚举类型：\nAn ENUM column can have a maximum of 65,535 distinct elements. (The practical limit is less than 3000.)\n示例：\nCREATE TABLE shirts (\n    name VARCHAR(40),\n    size ENUM(\'x-small\', \'small\', \'medium\', \'large\', \'x-large\')\n);\nINSERT INTO shirts (name, size) VALUES (\'dress shirt\',\'large\'), (\'t-shirt\',\'medium\'),(\'polo shirt\',\'small\');\n\nset\n集合类型\nA SET column can have a maximum of 64 distinct members.\n示例：\n    CREATE TABLE myset (col SET(\'a\', \'b\', \'c\', \'d\'));\n    INSERT INTO myset (col) VALUES (\'a,d\'), (\'d,a\'), (\'a,d,a\'), (\'a,d,d\'), (\'d,a,d\');\n\nDATE\n    YYYY-MM-DD（1000-01-01/9999-12-31）\n\nTIME\n    HH:MM:SS（\'-838:59:59\'/\'838:59:59\'）\n\nYEAR\n    YYYY（1901/2155）\n\nDATETIME\n\n    YYYY-MM-DD HH:MM:SS（1000-01-01 00:00:00/9999-12-31 23:59:59    Y）\n\nTIMESTAMP\n\n    YYYYMMDD HHMMSS（1970-01-01 00:00:00/2037 年某时）\n    \n二进制数据类型：\n二进制数据：TinyBlob、Blob、MediumBlob、LongBlob\n```\n\n### 4.1 针对枚举和set单独拿出来说一下\n\n#### 枚举\n\n需要在定义枚举类型时，列出哪些是可能的！意义在于：\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/28981298.jpg)\n\n1. 限制可以插入值的可能性，不让你随便插入值。\n2. 速度快，比普通的字符串速度快！原因是枚举型是利用整数进行管理的，能够2个字节进行管理！每个值，都是一个整数标识，从第一个选项开始为1，逐一递增！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/91520219.jpg)\n\n管理时整数的形式，速度比字符串快！2 个字节，0-65535，因此可以有 65535个选项可以使用！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/19664276.jpg)\n\nTip：注意enum(\'obj1\',\'obj2\')里面的条目要用单引号引起来。\n\n#### 集合\n\n类似于 enum枚举，在定义时，也需要指定其已有值！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/4899381.jpg)\n\n与字符串相比，优势是：\n\n1. 也是采用整数进行管理的！采用位运算，从第一位开始为1,逐一x2！\n2. 每个集合类型8个字节，64位，因此可以表示64个元素！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/80926930.jpg)\n\n```\n注意：\n站在 mysql的角度，尽量多用枚举和集合！\n但是站在python操作mysql的角度，尽量少用！（兼容性差）\n```\n\n## 5、键和约束\n\n### 5.1 主键\n\n主键的用处：保持数据的唯一性。主键不能为空\n\n一张表只能有一个主键，但是并不代表一个主键只能代表一列，我们可以指定多列联合为一个主键：\n\n```mysql\ncreate table test(\nid int unsigned not null auto_increment,\nname varchar(255) not null,\nsex char(8),\ncontent text,\nprimary key(id,name)\n) engine=innodb default charset=utf8;\n```\n\n### 5.2 外键约束\n\n约束的作用，是用于保证数据的完整性或者合理性的工具!\n\n外键：foreign key，当前表内，指向其他表的主键的字段，称之为外键！\n\n外键约束：用于限制相关联的记录在逻辑上保证合理性的约束称之为外键约束！\n\n**约束，不是字段。**\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/39334644.jpg)\n\n这样每一次写所属班级的时候不用写班级的名字，直接写班级的id，一定的程度上节省了空间。同时约束可以保证数据的一致性，导致不会让你随便写个班级id导致实际的班级找不到。\n\n首先创建两个表，添加约束。\n\n```mysql\nmysql> use test;\nDatabase changed\n\ncreate table userinfo(\nuid int unsigned auto_increment primary key,\nname varchar(32),\ndepartment_id int unsigned,\nconstraint fk_user_depart foreign key (`department_id`) references department(`id`)\n# 添加约束   约束名称        外键    （约束可以添加多个，多个约束名字不一样即可）      \n) engine=innodb default charset=utf8;\n\n\ncreate table department(\nid int unsigned auto_increment primary key,\ntitle char(15)\n) engine=innodb default charset=utf8;\nQuery OK, 0 rows affected (0.31 sec)\n\n如果建表的时候没有加的话可以后续手动加上：\nmysql> alter table userinfo add constraint fk_user_depart foreign key (`department_id`) references department(`id`);\nQuery OK, 0 rows affected (1.11 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> show create table userinfo\\G;\n*************************** 1. row ***************************\n       Table: userinfo\nCreate Table: CREATE TABLE `userinfo` (\n  `uid` int(10) unsigned NOT NULL AUTO_INCREMENT,\n  `name` varchar(32) DEFAULT NULL,\n  `department_id` int(10) unsigned DEFAULT NULL,\n  PRIMARY KEY (`uid`),\n  KEY `fk_user_depart` (`department_id`),\n  CONSTRAINT `fk_user_depart` FOREIGN KEY (`department_id`) REFERENCES `department` (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n1 row in set (0.00 sec)\n```\n\nTip：字段，键（key）用反引号引起来。\n\n被约束关联的表是无法直接删除的，比如上面图中的学生表里所属的班级表里的班级id，如果有一个外键在学生表里还有引用，那么这个班级就无法删除，必须把这个学生和这个班级id的关联取消才可以进行删除。\n\n外键的名字是不允许重复的，如果约束引用的表的主键是联合的，那么在设置约束的时候也可以设置多列。如果约束引用的表的主键不是联合主键是单列的就不可以使用这种方式了。\n\n```mysql\nCONSTRAINT `test` FOREIGN KEY (`id1`,`id2`) REFERENCES `department`(`d_id`,`s_id`) \n```\n\n## 6、索引\n\n> 索引的目标就是加速查找，比如书的目录\n>\n> - 约束不能重复（但是可以为空，但是主键不能为空）\n> - 加速查找\n\n建立索引最直观的就是加快访问速度，但是建立索引是会占用空间的，因此索引虽然加快了查找的速度但不是完全没有代价的。如果对索引进行滥用的话，虽然大大提高了查询速度，但是会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快。\n\n### 6.1 普通索引\n\n添加普通索引：\n\n```mysql\n# 修改表结构添加索引\nmysql> alter table test add index idx_id (`id`);\nQuery OK, 0 rows affected (0.34 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\nmysql> show create table test\\G;\n*************************** 1. row ***************************\n       Table: test\nCreate Table: CREATE TABLE `test` (\n  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n  `name` varchar(255) NOT NULL,\n  `sex` char(8) DEFAULT NULL,\n  `content` text,\n  PRIMARY KEY (`id`,`name`),\n  KEY `idx_id` (`id`)   # 我们添加的索引\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n1 row in set (0.00 sec)\n\n\n# 添加索引\nCREATE INDEX indexName ON table_name(column(前缀长度length)); \n\n# 建表的时候添加索引\nindex index_name (column(length))\n```\n\n删除索引\n\n```mysql\ndrop index index_name on table_name;\n```\n\n### 6.2 唯一索引\n\n唯一索引可以在创建的时候添加也可以在创建以后补加，唯一索引的索引列的值可以为空，但是必须唯一，如果是组合索引，那么组合索引的值必须唯一。\n\n- 创建的时候添加\n\n```mysql\nunique 索引名称 (索引字段)\n```\n\n- 创建后补加\n\n```mysql\nALTER TABLE `table_name` ADD UNIQUE index_name (`column`(length))  # length可以不写\nCREATE UNIQUE INDEX indexName ON table_name(username(length)) \n```\n\n***\n\n上面说到的是单列索引，当然索引和是多列的，称为组合索引。如果where判定条件有一个的话那么单列索引就足够了。\n\n>有四种方式来添加数据表的索引：\n>\n>- ALTER TABLE tbl_name ADD PRIMARY KEY (column_list):  该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。\n>- **ALTER TABLE tbl_name ADD UNIQUE index_name (column_list):** 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。\n>- **ALTER TABLE tbl_name ADD INDEX index_name (column_list):** 添加普通索引，索引值可出现多次。\n>- **ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):**该语句指定了索引为 FULLTEXT ，用于全文索引。\n\n查看表索引信息：\n\n```mysql\nmysql> show index from test\\G;\n```\n\n","timestamp":1526281685638},{"name":"03-03、关于索引.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/03-03、关于索引.md","content":"http://www.cnblogs.com/aspnethot/articles/1504082.html\n\nhttp://www.cnblogs.com/hustcat/archive/2009/10/28/1591648.html\n\nhttp://www.open-open.com/lib/view/open1370089357102.html\n\nhttp://www.cnblogs.com/dreamhome/archive/2013/04/16/3025304.html\n\nhttp://blog.csdn.net/xluren/article/details/32746183\n\n# 索引\n\n- 普通索引：加速查找\n\n\n- 主键索引：加速查找，不能为空，不能重复。\n- 唯一索引：加速查找，不能重复\n- 联合索引（组合索引）：多列组合成一个索引\n  - 联合主键索引\n  - 联合唯一索引\n  - 联合普通索引\n\n```python\n### 使用pymysql创建测试数据，插入200w条数据：\n表结构：\nmysql> desc user;\n+--------+------------------+------+-----+---------+----------------+\n| Field  | Type             | Null | Key | Default | Extra          |\n+--------+------------------+------+-----+---------+----------------+\n| id     | int(10) unsigned | NO   | PRI | NULL    | auto_increment |\n| gender | char(16)         | NO   |     | NULL    |                |\n| age    | int(10) unsigned | NO   |     | NULL    |                |\n| name   | varchar(32)      | NO   |     | NULL    |                |\n+--------+------------------+------+-----+---------+----------------+\n\n# 模拟数据的Python脚本\n#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n# author:maxiaoyu\nimport pymysql\nimport random\n\n# make a generator\ncreate_user = (x for x in range(2000000))\n\n# connect to the mysqld\nconn = pymysql.connect(host=\'192.168.171.10\',user=\'maxiaoyu\',password=\'13082171785\',database=\'indextest\')\n\n# tools to get data\ncursor = conn.cursor()\nprint(cursor.__dict__)\nsql = \"insert into user(gender,age,name) values(%s,%s,%s)\"\n\n\nfor user in create_user:\n    user_name = \'testuser\'+str(user)\n    cursor.execute(sql,(random.choice([\'male\',\'female\']),random.randint(1,100),user_name))\n    conn.commit()\n\n\ncursor.close()\nconn.close()\n```\n\n速度测试：\n\n```mysql\nmysql> select * from user where name=\'testuser1111232\';  \n+---------+--------+-----+-----------------+\n| id      | gender | age | name            |\n+---------+--------+-----+-----------------+\n| 1111237 | male   |   2 | testuser1111232 |\n+---------+--------+-----+-----------------+\n1 row in set (1.31 sec)\n\n\nmysql> select * from user where id=\'1111232\'; \n+---------+--------+-----+-----------------+\n| id      | gender | age | name            |\n+---------+--------+-----+-----------------+\n| 1111232 | female |  18 | testuser1111227 |\n+---------+--------+-----+-----------------+\n1 row in set (0.04 sec)\n```\n\n观察这个可以发现通过id查询的效率是非常高的仅有0.04s，但是通过name查找则会发现有1.31s。因为我们为id添加了主键索引了。\n\n> ##### 如何去理解索引：\n>\n> 索引可以理解为字典或者书的目录，我们可以认为计算机很笨，在没有索引的情况下它去翻阅一本字典取找一个字只能一页一页一行一行的从头翻到尾，如果要找的字在前面还好，如果要找到的字在最后那真的就是从头翻到尾了。\n>\n> 为了能够更好的查找数据我们添加了索引（index），其实也就是目录的意思，添加一个目录，我们没有必要去知道所有的内容，只看针对某一个字段或者某一部分的关键字就可以知道我们要找的内容在哪里。就好比可以根据拼音首字母，或者根据笔画去查，可以很快的根据索引定位到多少页。索引可以帮我们定位数据在表中的位置。当然创建索引（做目录的时候）也是需要一定的时间的，当数据量够大的时候会发现创建索引也是挺慢的。\n>\n> 当然就如大家所知道的，一本字典很厚，索引页也占用好几十页的空间，也就是说索引不是凭空的，而是真实的占用空间的，如果不恰当的使用索引就会导致索引的内容非常大，想想一下一本书，目录就占了半本，我为什么不直接去翻正文呢？\n\n创建普通索引的方法：\n\n```mysql\ncreate index name_index on user (name); \ncreate index 索引名     on 表 (column(length)……)\n```\n\n### 索引种类\n\n#### hash索引：索引表\n\n会把对应的列的数据转换成hash值放到一个表里，同时把对应的hash值对应的数据的存储地址也记录上。当对应的hash值被匹配到了以后就会直接去找这个数据所在的地址，然后通过游标直接跳过去即可。\n\n当然索引表是有一个缺陷的，在找**单值**的时候速度很快，但是如果去匹配一个条件，比如id>102321这样的就会比较慢了，因为索引表存储的索引信息其实是无序的。对于这样非单值的查找比如连续性的范围就很耗费时间了。\n\n#### BTree索引（innodb引擎）\n\n二叉树，具体二叉树相关内容请参考：\n\n\n\n建立索引：\n\n- 额外的文件保存特殊的数据结构\n- ​","timestamp":1526281685638},{"name":"04-04、mysql进阶.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/04-04、mysql进阶.md","content":"#  \n\n## 1、实体之间的关系\n\n多个是体表应该如何设计！\n\n### 实体之间存在哪些关系？\n\n```\n班级，学生两类实体！(一个班级对应多个学生实体，多个学生实体对应一个班级实体)\n一对多，多对一，1:N, N:1\n \n班级，讲师两类实体！（一个讲师可以在多个班级任教，反过来也是一样的。）\n多对多，M：N\n \n学生常用信息，学生不常用信息（学生与自己个人信息的肯定是一一对应的）\n一对一，1：1\n```\n\n### 如何设计？\n\n#### 多对一，一对多\n\n在多的那端（那个表内），增加一个字段，用于保存于当前记录相关联的一端记录的主键！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-27/92928316.jpg)\n\n#### 多对多\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-27/74244288.jpg)\n\n增加一个专门管理关联的表，使班级与讲师都与关连表存在联系。从而是两个实体间有多对多的关系！\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-27/81487.jpg)\n\n因此，一个多对多，会拆分成两个多对一！这里的班级id和讲师id都应该是foreign key，同时应该还应该做一个联合唯一，因为这种关系对应有一个就够了。\n\n### 一对一\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-27/54806190.jpg)\n\n可见，两个表之间存在相同的主键ID即可！也可以做外键+唯一约束。外键保证这个用户真实存在，唯一约束保证不为空且不重复。\n\n## 2、mysql语句扩展\n\n- 在查询的时候给字段起别名：\n\n```mysql\nmysql> desc test;\n+---------+------------------+------+-----+---------+----------------+\n| Field   | Type             | Null | Key | Default | Extra          |\n+---------+------------------+------+-----+---------+----------------+\n| id      | int(10) unsigned | NO   | PRI | NULL    | auto_increment |\n| name    | varchar(255)     | NO   | PRI | NULL    |                |\n| sex     | char(8)          | YES  |     | NULL    |                |\n| content | text             | YES  |     | NULL    |                |\n+---------+------------------+------+-----+---------+----------------+\n4 rows in set (0.00 sec)\n\n\nmysql> select name as testname,sex from test;\n+----------+--------+\n| testname | sex    |\n+----------+--------+\n| user1    | male   |\n| user2    | female |\n+----------+--------+\n2 rows in set (0.00 sec)\n```\n\n也可以在查询后加额外的一列，比如：\n\n```mysql\nmysql> select name,sex,123 from test;\n+-------+--------+-----+\n| name  | sex    | 123 |\n+-------+--------+-----+\n| user1 | male   | 123 |\n| user2 | female | 123 |\n+-------+--------+-----+\n2 rows in set (0.00 sec)\n\n那么这玩意有什么用呢？\n```\n\n### 2.1 查询深入\n\n```mysql\nselect * from table where id > 2\nselect * from table where id < 2\nselect * from table where id = 2\nselect * from table where id != 2\nselect * from table where id <> 2\nselect * from table where id > 2 and name=\'xxx\'\nselect * from table where id > 100 or id=30 or id=20 or id=40;\nselect * from table where id in (20,30,40)\nselect * from table where id in (select nid from table_name) # 子查询\nselect * from table where id not in (20,30,40)\nselect * from table where id between 6 and 12; # 这个锁定的范围是闭区间\nselect * from table limit 10; # 查看前10条\nselect * from table limit 0,2; # 从第一条开始取（位置），往后取两条（数量）\nselect * from table limit 20 offset 10; # 取20条，从第11个位置开始\n\n如何取到后10条？那么就先顺序倒过来，然后再limit 10就可以了。\n```\n\n### 2.2 排序（order by）\n\n```mysql\nselect * from table order by id desc; # 倒序\nselect * from table order by id asc;  # 正序\n\n# 当按照一列的规则进行排序的时候有可能有重复的，针对相同的这一些按照列2的规则排\nselect * from 表 order by 列1 desc,列2 asc\n```\n\n### 2.3 分组\n\n```mysql\n首先说说分组能干啥，比如有很多学生，他们都有自己所属的班级id，那么我只要：\nselect class_id,max(stu_id) from stu group by class_id=\'xxx\'\n就可以以班级id为标准把id一样的人分组给分出来,返回的结果重复的去掉。取出来的id去重复内容条目中的最大的。\n\n- max:取最大值\n- min：去最小值\n- count：取总数\n- sum：求和\n- avg：取平均值\n\nselect num from 表 group by num\nselect num,nid from 表 group by num,nid\nselect num,nid from 表  where nid > 10 group by num,nid order nid desc\nselect num,nid,count(*),sum(score),max(score),min(score) from 表 group by num,nid\n \nselect num from 表 group by num having max(id) > 10\n\n特别的：group by 必须在where之后，order by之前\n```\n\n### 2.4 表链接\n\n```mysql\n无对应关系则不显示\nselect A.num, A.name, B.name\nfrom A,B\nWhere A.nid = B.nid\n\n无对应关系则不显示\nselect A.num, A.name, B.name\nfrom A inner join B\non A.nid = B.nid\n\nA表所有显示，如果B中无对应关系，则值为null\nselect A.num, A.name, B.name\nfrom A left join B\non A.nid = B.nid\n\nB表所有显示，如果B中无对应关系，则值为null\nselect A.num, A.name, B.name\nfrom A right join B\non A.nid = B.nid\n```\n\n#### 2.4.1 简单连接\n\n```mysql\nmysql> select * from student;\n+----+--------+\n| id | name   |\n+----+--------+\n|  1 | 张三   |\n|  2 | 李四   |\n|  3 | 王二   |\n+----+--------+\n3 rows in set (0.00 sec)\n\nmysql> select * from course;\n+----+--------+\n| id | cname  |\n+----+--------+\n|  1 | 足球   |\n|  2 | 音乐   |\n|  3 | 美术   |\n+----+--------+\n3 rows in set (0.00 sec)\n```\n\n简单的表连接\n\n```mysql\nmysql> select * from student,course;\n+----+--------+----+--------+\n| id | name   | id | cname  |\n+----+--------+----+--------+\n|  1 | 张三   |  1 | 足球   |\n|  2 | 李四   |  1 | 足球   |\n|  3 | 王二   |  1 | 足球   |\n|  1 | 张三   |  2 | 音乐   |\n|  2 | 李四   |  2 | 音乐   |\n|  3 | 王二   |  2 | 音乐   |\n|  1 | 张三   |  3 | 美术   |\n|  2 | 李四   |  3 | 美术   |\n|  3 | 王二   |  3 | 美术   |\n+----+--------+----+--------+\n9 rows in set (0.00 sec)\n```\n\n可以看到简单的表连接是对两个表做了笛卡尔积。\n\n> 笛卡尔积：\n>\n> ![](http://omk1n04i8.bkt.clouddn.com/17-9-28/87001516.jpg)\n>\n> 依次做匹配，比如樱木给一个前锋位置给一个后卫位置，其他人同理。\n\n不过当然平常的情况下我们并不会这样去做，而是建立在某种条件的约束下进行表连接\n\n```mysql\nmysql> select * from student,course where student.id=course.id;\n+----+--------+----+--------+\n| id | name   | id | cname  |\n+----+--------+----+--------+\n|  1 | 张三   |  1 | 足球   |\n|  2 | 李四   |  2 | 音乐   |\n|  3 | 王二   |  3 | 美术   |\n+----+--------+----+--------+\n3 rows in set (0.00 sec)\n```\n\n当然上面这个例子很不合适，但是代表了是建立在某种约束下查询出来的。\n\n#### 2.4.2 Join连接\n\n>http://www.blogjava.net/GavinMiao/archive/2011/10/20/361640.html\n>\n>http://blog.163.com/xueling1231989@126/blog/static/102640807201231493651609/\n>\n>http://www.cnblogs.com/stone-d/p/7258340.html\n>\n>http://www.cnblogs.com/qiuqiuqiu/p/6442791.html\n>\n>http://blog.163.com/li_hx/blog/static/18399141320141127102622383/\n>\n>\n\n\n\nJoin连接类型，可分为三种：\n\n- 内连接（inner）\n- 外连接（outer）\n- 交叉连接（cross）\n\n##### 内连接\n\n\n\n\n\n内连接(INNER JOIN)使用比\n\n较运算符进行表间某(些)列数据的比较操作，并列出这些表中与连接条件相匹配的数据行。根据所使用\n\n的比较方式不同，内连接又分为等值连接、自然连接和不等连接三种。\n\n外连接分为左外连接(LEFT OUTER JOIN或LEFT JOIN)、右外连接(RIGHT OUTER JOIN或RIGHT JOIN)\n\n和全外连接(FULL OUTER JOIN或FULL JOIN)三种。与内连接不同的是，外连接不只列出与连接条件相匹\n\n配的行，而是列出左表(左外连接时)、右表(右外连接时)或两个表(全外连接时)中所有符合搜索条件的\n\n数据行。\n\n交叉连接(CROSS JOIN)没有WHERE 子句，它返回连接表中所有数据行的笛卡尔积，其结果集合中的\n\n数据行数等于第一个表中符合查询条件的数据行数乘以第二个表中符合查询条件的数据行数。\n\n连接操作中的ON (join_condition) 子句指出连接条件，它由被连接表中的列和比较运算符、逻辑\n\n运算符等构成。\n\n无论哪种连接都不能对text、ntext和image数据类型列进行直接连接，但可以对这三种列进行间接\n\n连接。\n\n","timestamp":1526281685638},{"name":"07-07、SQL优化.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/07-07、SQL优化.md","content":"http://blog.csdn.net/hguisu/article/details/5731629","timestamp":1526281685638},{"name":"08-08、数据库优化.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/08-08、数据库优化.md","content":"","timestamp":1526281685638},{"name":"22-22、Mysql练习.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/22-22、Mysql练习.md","content":"# Mysql Exercise\n\n> 请创建如下表，并创建相关约束\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-26/59526112.jpg)\n\n1、自行创建测试数据\n\n```mysql\n/*\n Navicat Premium Data Transfer\n\n Source Server         : localhost\n Source Server Type    : MySQL\n Source Server Version : 50624\n Source Host           : localhost\n Source Database       : sqlexam\n\n Target Server Type    : MySQL\n Target Server Version : 50624\n File Encoding         : utf-8\n\n Date: 10/21/2016 06:46:46 AM\n*/\n\nSET NAMES utf8;\nSET FOREIGN_KEY_CHECKS = 0;\n\n-- ----------------------------\n--  Table structure for `class`\n-- ----------------------------\nDROP TABLE IF EXISTS `class`;\nCREATE TABLE `class` (\n  `cid` int(11) NOT NULL AUTO_INCREMENT,\n  `caption` varchar(32) NOT NULL,\n  PRIMARY KEY (`cid`)\n) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `class`\n-- ----------------------------\nBEGIN;\nINSERT INTO `class` VALUES (\'1\', \'三年二班\'), (\'2\', \'三年三班\'), (\'3\', \'一年二班\'), (\'4\', \'二年九班\');\nCOMMIT;\n\n-- ----------------------------\n--  Table structure for `course`\n-- ----------------------------\nDROP TABLE IF EXISTS `course`;\nCREATE TABLE `course` (\n  `cid` int(11) NOT NULL AUTO_INCREMENT,\n  `cname` varchar(32) NOT NULL,\n  `teacher_id` int(11) NOT NULL,\n  PRIMARY KEY (`cid`),\n  KEY `fk_course_teacher` (`teacher_id`),\n  CONSTRAINT `fk_course_teacher` FOREIGN KEY (`teacher_id`) REFERENCES `teacher` (`tid`)\n) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `course`\n-- ----------------------------\nBEGIN;\nINSERT INTO `course` VALUES (\'1\', \'生物\', \'1\'), (\'2\', \'物理\', \'2\'), (\'3\', \'体育\', \'3\'), (\'4\', \'美术\', \'2\');\nCOMMIT;\n\n-- ----------------------------\n--  Table structure for `score`\n-- ----------------------------\nDROP TABLE IF EXISTS `score`;\nCREATE TABLE `score` (\n  `sid` int(11) NOT NULL AUTO_INCREMENT,\n  `student_id` int(11) NOT NULL,\n  `course_id` int(11) NOT NULL,\n  `num` int(11) NOT NULL,\n  PRIMARY KEY (`sid`),\n  KEY `fk_score_student` (`student_id`),\n  KEY `fk_score_course` (`course_id`),\n  CONSTRAINT `fk_score_course` FOREIGN KEY (`course_id`) REFERENCES `course` (`cid`),\n  CONSTRAINT `fk_score_student` FOREIGN KEY (`student_id`) REFERENCES `student` (`sid`)\n) ENGINE=InnoDB AUTO_INCREMENT=53 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `score`\n-- ----------------------------\nBEGIN;\nINSERT INTO `score` VALUES (\'1\', \'1\', \'1\', \'10\'), (\'2\', \'1\', \'2\', \'9\'), (\'5\', \'1\', \'4\', \'66\'), (\'6\', \'2\', \'1\', \'8\'), (\'8\', \'2\', \'3\', \'68\'), (\'9\', \'2\', \'4\', \'99\'), (\'10\', \'3\', \'1\', \'77\'), (\'11\', \'3\', \'2\', \'66\'), (\'12\', \'3\', \'3\', \'87\'), (\'13\', \'3\', \'4\', \'99\'), (\'14\', \'4\', \'1\', \'79\'), (\'15\', \'4\', \'2\', \'11\'), (\'16\', \'4\', \'3\', \'67\'), (\'17\', \'4\', \'4\', \'100\'), (\'18\', \'5\', \'1\', \'79\'), (\'19\', \'5\', \'2\', \'11\'), (\'20\', \'5\', \'3\', \'67\'), (\'21\', \'5\', \'4\', \'100\'), (\'22\', \'6\', \'1\', \'9\'), (\'23\', \'6\', \'2\', \'100\'), (\'24\', \'6\', \'3\', \'67\'), (\'25\', \'6\', \'4\', \'100\'), (\'26\', \'7\', \'1\', \'9\'), (\'27\', \'7\', \'2\', \'100\'), (\'28\', \'7\', \'3\', \'67\'), (\'29\', \'7\', \'4\', \'88\'), (\'30\', \'8\', \'1\', \'9\'), (\'31\', \'8\', \'2\', \'100\'), (\'32\', \'8\', \'3\', \'67\'), (\'33\', \'8\', \'4\', \'88\'), (\'34\', \'9\', \'1\', \'91\'), (\'35\', \'9\', \'2\', \'88\'), (\'36\', \'9\', \'3\', \'67\'), (\'37\', \'9\', \'4\', \'22\'), (\'38\', \'10\', \'1\', \'90\'), (\'39\', \'10\', \'2\', \'77\'), (\'40\', \'10\', \'3\', \'43\'), (\'41\', \'10\', \'4\', \'87\'), (\'42\', \'11\', \'1\', \'90\'), (\'43\', \'11\', \'2\', \'77\'), (\'44\', \'11\', \'3\', \'43\'), (\'45\', \'11\', \'4\', \'87\'), (\'46\', \'12\', \'1\', \'90\'), (\'47\', \'12\', \'2\', \'77\'), (\'48\', \'12\', \'3\', \'43\'), (\'49\', \'12\', \'4\', \'87\'), (\'52\', \'13\', \'3\', \'87\');\nCOMMIT;\n\n-- ----------------------------\n--  Table structure for `student`\n-- ----------------------------\nDROP TABLE IF EXISTS `student`;\nCREATE TABLE `student` (\n  `sid` int(11) NOT NULL AUTO_INCREMENT,\n  `gender` char(1) NOT NULL,\n  `class_id` int(11) NOT NULL,\n  `sname` varchar(32) NOT NULL,\n  PRIMARY KEY (`sid`),\n  KEY `fk_class` (`class_id`),\n  CONSTRAINT `fk_class` FOREIGN KEY (`class_id`) REFERENCES `class` (`cid`)\n) ENGINE=InnoDB AUTO_INCREMENT=17 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `student`\n-- ----------------------------\nBEGIN;\nINSERT INTO `student` VALUES (\'1\', \'男\', \'1\', \'理解\'), (\'2\', \'女\', \'1\', \'钢蛋\'), (\'3\', \'男\', \'1\', \'张三\'), (\'4\', \'男\', \'1\', \'张一\'), (\'5\', \'女\', \'1\', \'张二\'), (\'6\', \'男\', \'1\', \'张四\'), (\'7\', \'女\', \'2\', \'铁锤\'), (\'8\', \'男\', \'2\', \'李三\'), (\'9\', \'男\', \'2\', \'李一\'), (\'10\', \'女\', \'2\', \'李二\'), (\'11\', \'男\', \'2\', \'李四\'), (\'12\', \'女\', \'3\', \'如花\'), (\'13\', \'男\', \'3\', \'刘三\'), (\'14\', \'男\', \'3\', \'刘一\'), (\'15\', \'女\', \'3\', \'刘二\'), (\'16\', \'男\', \'3\', \'刘四\');\nCOMMIT;\n\n-- ----------------------------\n--  Table structure for `teacher`\n-- ----------------------------\nDROP TABLE IF EXISTS `teacher`;\nCREATE TABLE `teacher` (\n  `tid` int(11) NOT NULL AUTO_INCREMENT,\n  `tname` varchar(32) NOT NULL,\n  PRIMARY KEY (`tid`)\n) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;\n\n-- ----------------------------\n--  Records of `teacher`\n-- ----------------------------\nBEGIN;\nINSERT INTO `teacher` VALUES (\'1\', \'张磊老师\'), (\'2\', \'李平老师\'), (\'3\', \'刘海燕老师\'), (\'4\', \'朱云海老师\'), (\'5\', \'李杰老师\');\nCOMMIT;\n\nSET FOREIGN_KEY_CHECKS = 1;\n\n表结构和数据\n```\n\n2、查询“生物”课程比“物理”课程成绩高的所有学生的学号；\n\n```mysql\nselect A.student_id from \n(select score.sid,score.student_id,course.cname,score.num from score LEFT JOIN course on score.course_id=course.cid where course.cname=\'生物\' ) as A\nINNER JOIN \n(select score.sid,score.student_id,course.cname,score.num from score LEFT JOIN course on score.course_id=course.cid where course.cname=\'物理\' ) as B\non A.student_id=B.student_id where A.num>B.num\n```\n\n3、查询平均成绩大于60分的同学的学号和平均成绩； \n\n```mysql\nselect temp.student_id,student.sname,temp.number from (select student_id,avg(num) as number from score  GROUP BY student_id having number > 60) as temp LEFT JOIN student on temp.student_id=sid;\n```\n\n4、查询所有同学的学号、姓名、选课数、总成绩；\n\n```mysql\nselect score.student_id,student.sname,count(score.student_id),sum(score.num) from score LEFT JOIN\nstudent on score.student_id=student.sid\nGROUP BY score.student_id\n```\n\n5、查询姓“李”的老师的个数；\n\n```mysql\nselect * from teacher where t_name like \'李%\';\n```\n\n6、查询没学过“叶平”老师课的同学的学号、姓名；\n\n```mysql\nselect student.sid,student.sname from student where sid not in (\nselect student_id from score where score.course_id  in \n(select cid from course LEFT JOIN teacher on course.teacher_id=teacher.tid where tname=\'李平老师\')\nGROUP BY student_id\n)\n```\n\n7、查询学过“001”并且也学过编号“002”课程的同学的学号、姓名；\n\n```mysql\nselect student_id,student.sname as count from score \nLEFT JOIN student on score.student_id=student.sid\nwhere course_id=1 or course_id=2 GROUP BY student_id HAVING count(student_id) > 1\n```\n\n8、查询学过“叶平”老师所教的所有课的同学的学号、姓名；\n\n```mysql\nselect score.student_id,student.sname from score \nLEFT JOIN student on score.student_id=student.sid\nwhere course_id in \n(select cid from course \nLEFT JOIN teacher on \ncourse.teacher_id=teacher.tid WHERE teacher.tname=\'李平老师\')\nGROUP BY student_id having COUNT(course_id) = \n(select count(cid) from course \nLEFT JOIN teacher on \ncourse.teacher_id=teacher.tid WHERE teacher.tname=\'李平老师\')\n```\n\n9、查询课程编号“002”的成绩比课程编号“001”课程低的所有同学的学号、姓名；\n\n```mysql\nselect A.student_id,student.sname from \n(select * from score LEFT JOIN course on score.course_id=course.cid where course.cid=1) as A\nINNER JOIN\n(select * from score LEFT JOIN course on score.course_id=course.cid where course.cid=2) as B\non A.student_id=B.student_id\nLEFT JOIN student on A.student_id=student.sid\nwhere A.num > B.num\n```\n\n10、查询有课程成绩小于60分的同学的学号、姓名；\n\n```mysql\nselect student.sid,student.sname from score\nLEFT JOIN student on student.sid=score.student_id\nwhere score.num < 60\nGROUP BY sid\n\n或者使用distinct\n\nselect DISTINCT student.sid,student.sname from score\nLEFT JOIN student on student.sid=score.student_id\nwhere score.num < 60\n\n但是distinct效率并不是很高，能少用就少用。\n```\n\n11、查询没有学全所有课的同学的学号、姓名；\n\n```mysql\n-- 以后要么count主键，要么就count1\nselect student_id,student.sname as count_num from score\nLEFT JOIN student on score.student_id=student.sid\nGROUP BY student_id\nHAVING count(1) < (select count(1) from course)\n```\n\n12、查询至少有一门课与学号为“001”的同学所学相同的同学的学号和姓名；\n\n```mysql\n-- 假如001学了3门课程，只要001学过的任何一门课程我学过，那么我就是符合条件的。\nselect student_id,sname from score \nLEFT JOIN student on score.student_id=student.sid\nwhere student.sid <> 1 and score.course_id in\n(select course.cid from score \nLEFT JOIN course on score.course_id=course.cid\nwhere student_id=1)\nGROUP BY student_id\n```\n\n13、查询至少学过学号为“001”同学所有课的**其他同学**学号和姓名；\n\n```mysql\nselect student_id,sname from score \nLEFT JOIN student on score.student_id=student.sid\nwhere student.sid <> 1 and score.course_id in\n(select course.cid from score \nLEFT JOIN course on score.course_id=course.cid\nwhere student_id=1)\nGROUP BY student_id \nhaving count(1)=(select count(score.course_id) from score where student_id = 1)\n```\n\n14、查询和“002”号的同学学习的课程完全相同的其他同学学号和姓名；\n\n```mysql\n-- 先把和002选择个数一样的，再把不在002选择课程内的剔除\nselect student_id,sname from score LEFT JOIN student on score.student_id=student.sid\nwhere student_id in \n(select student_id from score where student_id <> 1 GROUP BY student_id HAVING count(1) = (select count(1) from score where student_id=1))\nand course_id in (select course_id from score where student_id=1)\nGROUP BY student_id HAVING count(1) = (select count(1) from score where student_id=1)\n```\n\n15、删除学习“李平”老师课的SC表记录；\n\n```mysql\nDELETE from score where score.course_id in \n(select cid from course LEFT JOIN teacher on course.teacher_id=teacher.tid where tname=\'李平老师\')\n```\n\n16、向Score表中插入一些记录，这些记录要求符合以下条件：①没有上过编号“002”课程的同学学号；②插入“002”号课程的平均成绩； \n\n```mysql\ninsert into score(student_id,course_id,num)\nselect student_id,2,(select avg(num) from score where course_id=2) from score where course_id!=2\n```\n\n17、按平均成绩从低到高显示所有学生的“语文”、“数学”、“英语”三门的课程成绩，按如下形式显示： 学生ID,语文,数学,英语,有效课程数,有效平均分；\n\n```mysql\nselect \n   student_id as \'学生ID\',\n   (select num from score as s2 where s2.student_id=s1.student_id and course_id=1) as \'语文\',\n   (select num from score as s2 where s2.student_id=s1.student_id and course_id=2) as \'数学\',\n   (select num from score as s2 where s2.student_id=s1.student_id and course_id=3) as \'英语\'\nfrom score as s1;\n```\n\n18、查询各科成绩最高和最低的分：以如下形式显示：课程ID，最高分，最低分；\n\n```mysql\nselect course_id,max(num),min(num) from score GROUP BY course_id\n\n假如说要求最低分小于10的就显示0那么可以写成如下的：\nselect course_id,max(num),min(num),case when min(num)<10 then 0 else min(num) end from score GROUP BY course_id\n```\n\n19、按各科平均成绩从低到高和及格率的百分数从高到低顺序；\n\n```mysql\nselect course_id,AVG(num),sum(case when num<60 then 0 else 1 end),sum(1),sum(case when num<60 then 0 else 1 end)/sum(1) as jigelv from score GROUP BY course_id ORDER BY avg(num) asc,jigelv desc\n```\n\n20、课程平均分从高到低显示（显示任课老师）；\n\n```mysql\nselect score.course_id,course.cname,avg(IF(ISNULL(score.num),0,score.num)),teacher.tname from score \nLEFT JOIN course on score.course_id=course.cid \nLEFT JOIN teacher on teacher.tid=course.teacher_id\nGROUP BY score.course_id order by avg(num) desc\n\n# 三目运算符，如果score.num为null的话（也就是范围为true，那么给个默认值为0.否则为score.num）\n```\n\n21、查询各科成绩前三名的记录:(不考虑成绩并列情况) \n\n```mysql\n\n```\n\n22、查询每门课程被选修的学生数；\n\n```mysql\nselect course_id, count(1) from score group by course_id;\n```\n\n23、查询出只选修了一门课程的全部学生的学号和姓名；\n\n```mysql\nselect student_id,sname,count(1) as num from score \nLEFT JOIN student on score.student_id=student.sid\nGROUP BY student_id having num=1\n```\n\n24、查询男生、女生的人数；\n\n```mysql\nselect gender,count(1) from student group by gender\n```\n\n25、查询姓“张”的学生名单；\n\n```mysql\nselect sname from student where sname like \'张%\';\n```\n\n26、查询同名同姓学生名单，并统计同名人数；\n\n```mysql\nselect sname,count(1) as count from student group by sname;\n```\n\n27、查询每门课程的平均成绩，结果按平均成绩升序排列，平均成绩相同时，按课程号降序排列；\n\n```mysql\nselect course_id,avg(if(isnull(num), 0 ,num)) as avg from score group by course_id order by avg asc,course_id desc;\n```\n\n28、查询平均成绩大于85的所有学生的学号、姓名和平均成绩；\n\n```mysql\nselect student_id,sname, avg(if(isnull(num), 0 ,num)) as avgnum from score left join student on score.student_id = student.sid group by student_id having avgnum > 85\n```\n\n29、查询课程名称为“数学”，且分数低于60的学生姓名和分数；\n\n```mysql\nselect student.sname,A.num from student join (\nselect student_id,num from score left join course on score.course_id = course.cid\nwhere cname=\'生物\' and num < 60\n) as A\non student.sid = A.student_id\n\n-- 或者\n\nselect student.sname,score.num from score\nleft join course on score.course_id = course.cid\nleft join student on score.student_id = student.sid\nwhere score.num < 60 and course.cname = \'生物\'\n```\n\n30、查询课程编号为003且课程成绩在80分以上的学生的学号和姓名； \n\n```mysql\nselect * from score where score.student_id = 3 and score.num > 80\n```\n\n31、求选了课程的学生人数\n\n```mysql\n-- 1、\nselect count(c) from \n(\nselect count(student_id) as c from score group by student_id\n) as A\n\n-- 2、\nselect count(distinct student_id) from score\n```\n\n32、查询选修“张磊”老师所授课程的学生中，成绩最高的学生姓名及其成绩；\n\n```mysql\nselect sname,num from score\nleft join student on score.student_id = student.sid\nwhere score.course_id in \n(\nselect course.cid from course \nleft join teacher on course.teacher_id = teacher.tid \nwhere tname=\'张磊老师\'\n) order by num desc limit 1;\n```\n\n33、查询各个课程及相应的选修人数；\n\n```mysql\nselect course.cname,count(course_id) from score left join course\non score.course_id = course.cid\nGROUP BY course.cid\n```\n\n*34、查询不同课程但成绩相同的学生的学号、课程号、学生成绩；\n\n```mysql\nselect DISTINCT s1.course_id,s2.course_id,s1.num,s2.num from score as s1, score as s2 where s1.num = s2.num and s1.course_id != s2.course_id;\n```\n\n*35、查询每门课程成绩最好的前两名；\n\n```mysql\nselect score.sid,score.course_id,score.num,T.first_num,T.second_num from score left join\n(\nselect\n    sid,\n    (select num from score as s2 where s2.course_id = s1.course_id order by num desc limit 0,1) as first_num,\n    (select num from score as s2 where s2.course_id = s1.course_id order by num desc limit 1,1) as second_num\n    from\n        score as s1\n) as T\n    on score.sid =T.sid\n    where score.num <= T.first_num and score.num >= T.second_num\n```\n\n36、检索至少选修两门课程的学生学号；\n\n```mysql\nselect student_id from score group by student_id having count(student_id) > 1\n```\n\n37、查询全部学生都选修的课程的课程号和课程名；\n\n```mysql\n-- 找到学生的总数，哪一门课的成绩统计数=课程总数就证明，这门课所有人都学习了\nselect course_id,count(1) from score group by course_id having count(1) = (select count(1) from student);\n```\n\n38、查询没学过“叶平”老师讲授的任一门课程的学生姓名；\n\n```mysql\nselect student_id,student.sname from score\nleft join student on score.student_id = student.sid\nwhere score.course_id not in \n(\n-- 首先获取到\nselect cid from course left join teacher on course.teacher_id = teacher.tid where tname = \'张磊老师\'\n)\ngroup by student_id\n```\n\n39、查询两门以上不及格课程的同学的学号及其平均成绩；\n\n```mysql\nselect student_id,count(1) from score where num < 60 group by student_id having count(1) > 2\n```\n\n40、检索“004”课程分数小于60，按分数降序排列的同学学号；\n\n```mysql\nselect student_id from score where course_id = 4 and num < 60 order by num desc;\n```\n\n41、删除“002”同学的“001”课程的成绩；\n\n```mysql\ndelete from score where course_id = 1 and student_id = 2;\n```\n\n","timestamp":1526281685638},{"name":"24-24、视图.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/24-24、视图.md","content":"# 视图\n\n>视图是一个虚拟表（非真实存在），其本质是【根据SQL语句获取动态的数据集，并为其命名】，用户使用时只需使用【名称】即可获取结果集，并可以将其当作表来使用。\n\n临时表取一个别名，也是我们查询出来的，但是这个表并不是真实存在的。因此给某一个查询语句设置别名，日后方便使用，创建的这个别名的行为就是创建一个视图。别名也就是视图的名称。\n\n```mysql\n# 创建视图\ncreate view as v1 select * from student where sid>10;\n# 以后直接搜索视图就可以了\nselect * from v1\n```\n\n视图是虚拟的，动态的从真实表中读取出来放到内存中，因此视图不能增删改，这个是不允许的，而且如果数据源表进行了更改以后，视图结果也会跟着改变。\n\n修改视图：\n\n```mysql\n# 修改视图\nalter view view_name as new_sql\n# 删除视图\ndrop view view_name\n```\n\nTip：在开发中并不常用~开发中就直接写子查询，写在代码里","timestamp":1526281685638},{"name":"25-25、触发器.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/25-25、触发器.md","content":"# 触发器\n\n> 触发器在开发中也并不是很常用\n\n情境：用户注册，每注册一个插入用的同时要去日志表插入一条数据。针对这个问题，在程序级别上，可以分两步进行操作，用户注册的同时，分别向两个表里插入数据，当然这里也可以使用触发器。\n\n### 触发器创建基本语法\n\n```mysql\nBEFORE ：在xxx操作之前\nAFTER  ：在XXX操作之后\nFOR EACH ROW ：操作每一行的时候触发器就会执行一遍\n\n# 插入前\nCREATE TRIGGER tri_before_insert_tb1 BEFORE INSERT ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 插入后\nCREATE TRIGGER tri_after_insert_tb1 AFTER INSERT ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 删除前\nCREATE TRIGGER tri_before_delete_tb1 BEFORE DELETE ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 删除后\nCREATE TRIGGER tri_after_delete_tb1 AFTER DELETE ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 更新前\nCREATE TRIGGER tri_before_update_tb1 BEFORE UPDATE ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n\n# 更新后\nCREATE TRIGGER tri_after_update_tb1 AFTER UPDATE ON tb1 FOR EACH ROW\nBEGIN\n    ...\nEND\n```\n\n可以发现唯独查询的时候，没有触发操作。\n\n```mysql\ndelimiter //\ncreate trigger t1 before insert on student for each ROW\nBEGIN\n  INSERT into teacher(tname) values(\'hahaha\');\nEND //\ndelimiter ;\n\n# 语句中的触发语句用分号去分割，因此如果使用默认的分隔符，到END之前就会终止\n# 因此我们要使用delimiter先去指定其他的分隔符，比如指定//\n# 在执行完了以后还要将分隔符设置回来，不影响其他人使用\n```\n\n比如说触发器执行增删改操作的时候触发操作的数据要和用户增删改的数据关联，那么久需要用到如下的两个参数：\n\n- NEW：指的是新插入的数据，一整行\n- OLD：指的是即将删除的数据行\n\n针对insert和update操作的时候用到NEW，针对delete和update操作的时候用到OLD\n\n```mysql\ndelimiter //\nCREATE TRIGGER tri_after_insert_tb1 AFTER INSERT ON tb1 FOR EACH ROW\nBEGIN\n    IF NEW. num = 666 THEN\n        INSERT INTO tb2 (NAME)\n        VALUES\n            (\'666\'),\n            (\'666\') ;\n    ELSEIF NEW. num = 555 THEN\n        INSERT INTO tb2 (NAME)\n        VALUES\n            (\'555\'),\n            (\'555\') ;\n    END IF;\nEND//\ndelimiter ;\n\n# 可以直接讲NEW.column放到插入的values里作为插入的值。\n```\n\n删除触发器：\n\n```mysql\nDROP TRIGGER tri_after_insert_tb1;\n```\n\n使用触发器：\n\n```mysql\n# 触发器无法由用户直接调用，而知由于对表的【增/删/改】操作被动引发的。\ninsert into tb1(num) values(666)\n```\n\n\n\n","timestamp":1526281685638},{"name":"26-26、存储过程.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/26-26、存储过程.md","content":"","timestamp":1526281685638},{"name":"27-28、函数.md","path":"03-DBA运维/01-Mysql/05-SQL语法基础/27-28、函数.md","content":"# Mysql函数\n\n>\n\n如何使用内置函数？\n\n```mysql\n# select 函数名\nmysql> select CURDATE();\n+------------+\n| CURDATE()  |\n+------------+\n| 2017-10-13 |\n+------------+\n1 row in set (0.11 sec)\n```\n\n部分内置函数：\n\n```mysql\nCHAR_LENGTH(str)\n返回值为字符串str 的长度，长度的单位为字符。一个多字节字符算作一个单字符。\n对于一个包含五个二字节字符集, LENGTH()返回值为 10, 而CHAR_LENGTH()的返回值为5。\n\nCONCAT(str1,str2,...)\n字符串拼接\n如有任何一个参数为NULL ，则返回值为 NULL。\n\nCONCAT_WS(separator,str1,str2,...)\n字符串拼接（自定义连接符）\nCONCAT_WS()不会忽略任何空字符串。 (然而会忽略所有的 NULL）。\n\nCONV(N,from_base,to_base)\n进制转换\n例如：\n    SELECT CONV(\'a\',16,2); 表示将 a 由16进制转换为2进制字符串表示\n\nFORMAT(X,D)\n将数字X的格式写为\'#,###,###.##\',以四舍五入的方式保留小数点后 D 位， 并将结果以字符串的形式返回。若D为0, 则返回结果不带有小数点，或不含小数部分。\n例如：\nSELECT FORMAT(12332.1,4); 结果为： \'12,332.1000\'\nINSERT(str,pos,len,newstr)\n        在str的指定位置插入字符串\n            pos：要替换位置起始位置\n            len：替换的长度\n            newstr：新字符串\n        特别的：\n            如果pos超过原字符串长度，则返回原字符串\n            如果len超过原字符串长度，则由新字符串完全替换\nINSTR(str,substr)\n        返回字符串 str 中子字符串的第一个出现位置。\n\n    LEFT(str,len)\n        返回字符串str 从开始的len位置的子序列字符。\n\n    LOWER(str)\n        变小写\n\n    UPPER(str)\n        变大写\n\n    LTRIM(str)\n        返回字符串 str ，其引导空格字符被删除。\n    RTRIM(str)\n        返回字符串 str ，结尾空格字符被删去。\n    SUBSTRING(str,pos,len)\n        获取字符串子序列\n\n    LOCATE(substr,str,pos)\n        获取子序列索引位置\n\n    REPEAT(str,count)\n        返回一个由重复的字符串str 组成的字符串，字符串str的数目等于count 。\n        若 count <= 0,则返回一个空字符串。\n        若str 或 count 为 NULL，则返回 NULL 。\n    REPLACE(str,from_str,to_str)\n        返回字符串str 以及所有被字符串to_str替代的字符串from_str 。\n    REVERSE(str)\n        返回字符串 str ，顺序和字符顺序相反。\n    RIGHT(str,len)\n        从字符串str 开始，返回从后边开始len个字符组成的子序列\n\n    SPACE(N)\n        返回一个由N空格组成的字符串。\n\n    SUBSTRING(str,pos) , SUBSTRING(str FROM pos) SUBSTRING(str,pos,len) , SUBSTRING(str FROM pos FOR len)\n        不带有len 参数的格式从字符串str返回一个子字符串，起始于位置 pos。带有len参数的格式从字符串str返回一个长度同len字符相同的子字符串，起始于位置 pos。 使用 FROM的格式为标准 SQL 语法。也可能对pos使用一个负值。假若这样，则子字符串的位置起始于字符串结尾的pos 字符，而不是字符串的开头位置。在以下格式的函数中可以对pos 使用一个负值。\n\n        mysql> SELECT SUBSTRING(\'Quadratically\',5);\n            -> \'ratically\'\n\n        mysql> SELECT SUBSTRING(\'foobarbar\' FROM 4);\n            -> \'barbar\'\n\n        mysql> SELECT SUBSTRING(\'Quadratically\',5,6);\n            -> \'ratica\'\n\n        mysql> SELECT SUBSTRING(\'Sakila\', -3);\n            -> \'ila\'\n\n        mysql> SELECT SUBSTRING(\'Sakila\', -5, 3);\n            -> \'aki\'\n\n        mysql> SELECT SUBSTRING(\'Sakila\' FROM -4 FOR 2);\n            -> \'ki\'\n\n    TRIM([{BOTH | LEADING | TRAILING} [remstr] FROM] str) TRIM(remstr FROM] str)\n        返回字符串 str ， 其中所有remstr 前缀和/或后缀都已被删除。若分类符BOTH、LEADIN或TRAILING中没有一个是给定的,则假设为BOTH 。 remstr 为可选项，在未指定情况下，可删除空格。\n\n        mysql> SELECT TRIM(\'  bar   \');\n                -> \'bar\'\n\n        mysql> SELECT TRIM(LEADING \'x\' FROM \'xxxbarxxx\');\n                -> \'barxxx\'\n\n        mysql> SELECT TRIM(BOTH \'x\' FROM \'xxxbarxxx\');\n                -> \'bar\'\n\n        mysql> SELECT TRIM(TRAILING \'xyz\' FROM \'barxxyz\');\n                -> \'barx\'\n\n部分内置函数\n```\n\n","timestamp":1526281685638},{"name":"09-01、数据库安装.md","path":"03-DBA运维/01-Mysql/09-01、数据库安装.md","content":"# Mysql的安装\n\n> 现在安装mysql有很多的方式，接下来分不同的平台进行说明。\n>\n> 安装包下载地址：\n>\n> https://dev.mysql.com/downloads/mysql/\n\n## 1-Windows\n\n### 1.1-Mysql Installer\n\n使用Mysql安装包的形式进行安装\n\n### 1.2-ZIP Archive\n\n使用已经打包好的内容进行安装。\n\n- 首先我把mysql的zip程序解压到了d:/mysql/下，在这个目录下创建一个data目录，当然现在这个data目录肯定是空的，啥都没有的。\n\n- 然后再命令行初始化数据库\n\n  ```mysql\n  D:\\mysql\\bin>mysqld -install                # 添加到windows系统服务\n  D:\\mysql\\bin>mysqld --initialise-insecure\n  ```\n\n  如果说你遇到下面这个报错的话说明你运行程序的权限是有问题的。这个时候我们只要以windows的administrator的权限去运行就可以了。这个其实和linux给一个道理，一般我们linux编译安装的时候都是用root，就算是不用root你也得用个sudo不~\n\n  ```\n  mysqld: Could not create or access the registry key needed for the MySQL application\n  to log to the Windows EventLog. Run the application with sufficient\n  privileges once to create the key, add the key manually, or turn off\n  logging for that application.\n  ```\n\n  解决方法很简单：打开cmd，右键使用管理员身份运行。然后再运行如上的这条初始化命令就好了。\n\n- 查看一下data目录下多了什么？\n\n  ```python\n  D:\\mysql\\data>dir\n   驱动器 D 中的卷是 workspace\n   卷的序列号是 F466-9ADB\n\n   D:\\mysql\\data 的目录\n\n  2017/09/25 周一  10:55    <DIR>          .\n  2017/09/25 周一  10:55    <DIR>          ..\n  2017/09/25 周一  10:55             7,552 DESKTOP-CH3QMNF.err\n  2017/09/25 周一  10:55        12,582,912 ibdata1\n  2017/09/25 周一  10:55               253 ib_buffer_pool\n  2017/09/25 周一  10:55        50,331,648 ib_logfile0\n  2017/09/25 周一  10:55        50,331,648 ib_logfile1\n                 5 个文件    113,254,013 字节\n                 2 个目录 138,721,185,792 可用字节\n  ```\n\n- 默认初始化以后密码为空的，mysql肯定是需要配置文件的，不过5.7.18版本后的配置文件就需要自己手动创建了。创建的内容文本如下，创建好了后保存为my.ini文件，移动到bin目录下：\n\n  ```\n  [client]\n  port=3306\n  default-character-set=utf8\n  [mysqld]\n  port=3306\n  character_set_server=utf8\n  basedir=D:\\mysql\n  datadir=D:\\mysql\\data\n  [WinMySQLAdmin]\n  D:\\mysql\\bin\\mysqld.exe\n  ```\n\n- 启动mysql服务，启动完成以后就可以链接了：\n\n  ```mysql\n  net start mysql       # 只有添加到windows的启动服务列表里才可以使用这条命令\n  关闭：\n  net stop mysql\n\n  # 链接mysql\n  mysql -uroot -p\n  ```\n\n新建用户：\n\n```\nmysql> create user \'lamber\'@\'localhost\' identified by \'13082171785\';\nQuery OK, 0 rows affected (0.00 sec)\n\n使用通配符的：\nmysql> create user \'testuser1\'@\'%\' identified by \'13082171785\';\nQuery OK, 0 rows affected (0.00 sec)\n\n授权：\ngrant select,insert on db_name.table_name to \'testuser1\'@\'%\'\n\n或者可以使用grant语句授权，省去创建用户的步骤而且直接把密码也给了：\nmysql> grant all privileges on *.* to \'lamber\'@\'%\' identified by \'13082171785\';\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\n```\n\n## 2-Linux\n\n在Linux平台下可以使用cmake进行编译安装。\n\n### 2.1-编译安装\n\n- 准备包和环境依赖\n\n  ```mysql\n  # 首先安装初始环境所需要的包：\n  [root@db02 ~]# yum -y install ncurses-devel libaio-devel  \n  [root@db02 ~]# rpm -qa ncurses-devel libaio-devel       \n  ncurses-devel-5.7-4.20090207.el6.x86_64\n  libaio-devel-0.3.107-10.el6.x86_64\n  [root@db02 ~]# yum -y install cmake \n  [root@db02 log]# useradd mysql -s /sbin/nologin -M\n  [root@db02 log]# id mysql\n  uid=502(mysql) gid=502(mysql) groups=502(mysql)\n  # 切换到下载目录中去：\n  [root@db02 tools]# tar xf mysql-5.5.32.tar.gz \n  ```\n\n- 使用cmake进行编译，然后进行安装\n\n  ```shell\n  预编译：\n  [root@db02 mysql-5.5.32]# cmake . -DCMAKE_INSTALL_PREFIX=/application/mysql-5.5.32 \\\n  -DMYSQL_DATADIR=/application/mysql-5.5.32/data \\\n  -DMYSQL_UNIX_ADDR=/application/mysql-5.5.32/tmp/mysql.sock \\\n  -DDEFAULT_CHARSET=utf8 \\\n  -DDEFAULT_COLLATION=utf8_general_ci \\\n  -DEXTRA_CHARSETS=gbk,gb2312,utf8,ascii \\\n  -DENABLED_LOCAL_INFILE=ON \\\n  -DWITH_INNOBASE_STORAGE_ENGINE=1 \\\n  -DWITH_FEDERATED_STORAGE_ENGINE=1 \\\n  -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\\n  -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 \\\n  -DWITHOUT_PARTITION_STORAGE_ENGINE=1 \\\n  -DWITH_FAST_MUTEXES=1 \\\n  -DWITH_ZLIB=bundled \\\n  -DENABLED_LOCAL_INFILE=1 \\\n  -DWITH_READLINE=1 \\\n  -DWITH_EMBEDDED_SERVER=1 \\\n  -DWITH_DEBUG=0\n  编译和安装：\n  make && make install & cd ..\n  ```\n\n- 创建数据目录进行初始化操作\n\n  ```shell\n  mkdir /data/3306/data        # 这个目录你自己按照自己的规划和需求整\n  find /data -type f -name mysql | xargs chmod +x    # 修改权限\n  ./scripts/mysql_install_db --basedir=/application/mysql/ --datadir=/data/3306/data/ --user=mysql                   # 初始化操作,加载mysql自身的库和表\n  ```\n\n- mysql启动，然后就可以进行连接了\n\n  ```shell\n   /data/3306/mysql start\n  ```\n\n#### =====编译安装过程中遇到的一些问题=====\n\n- 编译安装的过程中，cmake可能会报下面的错误\n\n  ```shell\n  -- Could NOT find Curses (missing:  CURSES_LIBRARY CURSES_INCLUDE_PATH)\n  CMake Error at cmake/readline.cmake:82 (MESSAGE):\n    Curses library not found.  Please install appropriate package,\n        remove CMakeCache.txt and rerun cmake.On Debian/Ubuntu, package name is libncurses5-dev, on Redhat and derivates it is ncurses-devel.\n  Call Stack (most recent call first):\n    cmake/readline.cmake:126 (FIND_CURSES)\n    cmake/readline.cmake:216 (MYSQL_USE_BUNDLED_LIBEDIT)\n    CMakeLists.txt:250 (MYSQL_CHECK_READLINE)\n  ```\n\n  解决办法：\n\n  ```shell\n  [root@localhost mysql-5.6.1]# rm CMakeCache.txt\n  [root@localhost mysql-5.6.1]# yum install ncurses-devel\n  [root@localhost mysql-5.5.11]# yum install bison\n  ```\n\n### 2.2-二进制tar.gz包解压直接使用\n\n二进制包的方式，都是已经编译好的，现成的东西，解压初始化以后就可以进行使用，多bb两句。\n\n>mysql5.7和之前的二进制包的部署方式有点小小的不一样。接下来呈现安装过程。\n\n\n1. 下载5.7的mysql安装包，这个破安装包竟然有600多m大，吓死人了。。\n```\nwget http://mirrors.sohu.com/mysql/MySQL-5.7/mysql-5.7.16-linux-glibc2.5-x86_64.tar.gz\n```\n2. 解压缩，移动到/application目录中\n```\ntar xf mysql-5.7.16-linux-glibc2.5-x86_64.tar.gz \nmkdir /application\n[root@nfs01 tools]# mv mysql-5.7.16-linux-glibc2.5-x86_64 /application/mysql-5.7.16\n[root@nfs01 tools]# cd /application/\n[root@nfs01 application]# ln -s /application/mysql-5.7.16/ /application/mysql\n[root@nfs01 application]# ll\ntotal 728\nlrwxrwxrwx. 1 root root     26 Feb  8 15:30 mysql -> /application/mysql-5.7.16/\ndrwxr-xr-x. 9 root root   4096 Feb  8 15:28 mysql-5.7.16\n```\n3. 数据库初始化\n\n\n```\nuseradd mysql -M -s /sbin/nologin \nmkdir /data/mysql\ncd /data/\nchown -R mysql.mysql mysql/\n./bin/mysqld --initialize --user=mysql --datadir=/data/mysql\n#在初始化的最后我们能看到这样一条日志信息\n2017-02-08T07:42:24.827356Z 1 [Note] A temporary password is generated for root@localhost: _p-2Abg:dqiU\n#这条日志信息的意思就是告诉你说，我们已经为root@localhost账户生成了一个临时的密码。这个密码就是_p-2Abg:dqiU，这个密码要先记下来，后面我们会用到\n[root@nfs01 mysql]# ./bin/mysql_ssl_rsa_setup --datadir=/data/mysql\nGenerating a 2048 bit RSA private key\n...+++\n....................................+++\nwriting new private key to \'ca-key.pem\'\n-----\nGenerating a 2048 bit RSA private key\n....................+++\n  ............+++\nwriting new private key to \'server-key.pem\'\n-----\nGenerating a 2048 bit RSA private key\n.........................................................+++\n........+++\nwriting new private key to \'client-key.pem\'\n-----\ncp support-files/my-default.cnf /etc/my.cnf\n[root@nfs01 mysql]# cp support-files/my-default.cnf /etc/my.cnf\n#修改我们的配置文件\n[root@nfs01 mysql]# vim /etc/my.cnf\nbasedir = /application/mysql\ndatadir = /data/mysql\nport = 3306\n# server_id = .....\nsocket = /tmp/mysql.sock\n#复制启动脚本\n[root@nfs01 mysql]# cp support-files/mysql.server /etc/init.d/mysqld\n[root@nfs01 mysql]# vim /etc/init.d/mysqld\nbasedir=/application/mysql\ndatadir=/data/mysql\n#启动mysql\n[root@nfs01 mysql]# /etc/init.d/mysqld start\nStarting MySQL. SUCCESS! \n#用我们刚才生成的临时密码登录进行修改密码的操作\n[root@nfs01 mysql]# /application/mysql/bin/mysql -uroot -p_p-2Abg:dqiU\nmysql> set password = password(\'redhat\');\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\n#还有一种情况，就是不知道初始化密码\nvim /etc/my.cnf\n#在[mysqld]下面增加一行\nskip-grant-tables\n#重启  \n/etc/init.d/mysqld restart\n/usr/local/mysql/bin/mysql -uroot \nmysql> update mysql.user set authentication_string=password(\'123333\') where user=\'root\';\n#退出来后，更改my.cnf，去掉刚加的 skip-grant-tables\n#重启 \n/etc/init.d/mysqld restart\n\n此时就可以使用新的密码了。\n```\n4. 排错\n  如果说在启动过程中遇到了如下的报错的话：\n```\n[root@nfs01 mysql]# /etc/init.d/mysqld start\nStarting MySQL.... ERROR! The server quit without updating PID file (/data/mysql/nfs01.pid).\n```\n一般来讲，出现这个报错的原因大多是权限问题，去看一下你的目录权限吧，很可能你的sock文件无权限在你设定的文件夹中生成。\n\n### 2.3- Yum安装\n\nPass\n\n## Mac\n\n太穷，买不起mac，不做了\n\n![](http://omk1n04i8.bkt.clouddn.com/17-9-25/78130839.jpg)\n\n\n\n","timestamp":1526281685638},{"name":"23-23、innodb和myisam.md","path":"03-DBA运维/01-Mysql/23-23、innodb和myisam.md","content":"","timestamp":1526281685638},{"name":"24-24、mysql监控.md","path":"03-DBA运维/01-Mysql/24-24、mysql监控.md","content":"# Mysql的监控\n\n## 1、监控的意义\n\n- 监控更偏重于趋势分析\n  - 通过监控的数据展现了了解趋势增长情况\n  - 监控程序采集的数据指标也可以用当前DB的性能分析\n- 监控分为：\n  - 趋势分析类：zabbix，其他等\n  - 当前指标分析类：top，iostat，dstat，pt-ioprofile，mysqladmin\n    - dstat：一款由Python编写的脚本工具，可以去好好读读dstat的脚本，从中会有所收获的，下载地址如下：http://dstat.sourcearchive.com/\n    - pt-ioprofile：这是一个percona提供的工具，属于percona-tools中的一个工具。可以定义mysqld进程进行分析，分析哪个io调用比较高，它可以进行排序并显示出来。pt-ioprofile依赖strace，因此需要安装strace。percona-tools安装如下：\n\n\n\ngoogle也开源出来一个监控插件叫[cadvisor](https://github.com/google/cadvisor)，这个是用Go语言写的。\n\n## 2、常用监控工具\n\n### 2.1、top\n\n- user的cpu占用高，常常是因为索引不合理或者是大量的order by，group by的处理\n- io_wait高，通常是因为系统io不给力，造成CPU等待，或者随机IO过重，可以使用pt-ioprofile去查看一下到底是谁占用比较高。直接在命令行输入pt-ioprofile就可以。\n- sys占用高，一般是因为numa没有关闭；如果不敢确定的话可以使用`pref top`去看一下，\n- st占用高，多出现于虚拟化环境，通常是虚拟化环境资源竞争过于严重。如果用的云厂商的话直接投诉云厂商就可以了。\n\n### 2.2、vmstat\n\nsi：swap-in、so：swap-out，vmstat中的r和b，r是正在运行的，b是等待io的。如果b比较大的话就需要pt-ioprofile去查一下了。\n\n\n\niops是什么？IO吞吐量是什么？\n\niops：每秒钟的io处理能力。其中包含了读和写。\n\niostat：yum -y install sysstat","timestamp":1526281685638},{"name":"01-Redis初探&安装.md","path":"03-DBA运维/02-Redis/01-Redis初探&安装.md","content":"# Redis安装\n\n>- 支持数据结构类型丰富，比如string字符串，散列hashes，列表lists，集合sets，有序集合sorted sets于范围查询，bitmaps，hyperlogslogs和地理空间（geospatial）索引半径查询。\n>- 丰富的支持主流语言的客户端，c，c++，python，erlang，R，c#，java，php，obc，perl，ruby，scala，go，js\n>- 基于内存并且支持持久化，高性能的kv键值对的nosql数据库\n>- 用途：缓存，数据库，消息中间件，队列\n>- 官方网站：http://www.redis.io\n\n## NoSQL的分类\n\n| 类型      | 主要产品               | 简介                                                         |\n| --------- | ---------------------- | ------------------------------------------------------------ |\n| KV存储    | redis，memcached       | 使用键快速的找到value，memcached支持string类型的value，redis除了支持string之外还支持set，hash，sort set，list等 |\n| 文档存储  | MongoDB，CouchDB       | 使用JSON或者类json的数据结构，存储内容为文档型，能实现部分关系数据库的功能 |\n| 列存储    | Hbase，Cassandra       | 按照列进行数据存储，便于存储结构化和半结构化数据（比如输出日志这类的，属于一种半结构化的数据，这种逗号分隔的，我们也知道每一个字段都是什么内容），方便做数据压缩和针对某一列和某几列的数据查询 |\n| 图存储    | Neo4J，FlockDB         | 图形相关的存储，能够很好地弥补关系型数据库在图形存储的不足   |\n| 对象存储  | Db4o，Versant          | 通过类似面向对象语言的方式操作数据库，通过对象的方式存取数据 |\n| XML数据库 | Berkeley DB XML，BaseX | 高效存储XML数据，支持XML的内部查询语法，比如XQuery和XPath    |\n\n## Redis安装\n\n> Redis版本：2.8\n>\n> 操作系统：Centos7.3\n>\n> 可视化客户端：RedisDesktopManager\n>\n\n### Redis功能特性：\n\n- 持久化功能，将存储在内存的数据保存到硬盘里面去，保证数据的安全，方便备份和恢复\n- 发布与订阅，生产者和消费者，相当于与消息中间件。\n- 过期键功能，为key设置一个过期时间，让它在指定的时间之后自动被删除\n- 事物功能：原子的执行多个操作，并提供乐观锁的功能，保证处理数据时的安全性\n- Lua脚本功能：在服务器端原子的执行多个功能，完成复杂的功能，并减少客户端与服务器之间的通信往返次数，\n- 复制：为指定的redis服务器创建一个或者多个复制品，用于提升数据的安全性。并分担读请求负载。\n- Sentinel（哨兵）：监控redis服务器状态，并在服务器发生故障的时候，进行自动的故障转移\n- 集群：创建分布式的数据库，每个服务器分别执行一部分写操作和读操作。\n\n### 安装过程\n\n```shell\n# redis安装包下载地址\nhttp://download.redis.io/releases/\n\n# 我要安装在tools下面\ncd /tools\nwget http://download.redis.io/releases/redis-2.8.18.tar.gz\ntar xf redis-2.8.18.tar.gz\nyum install gcc tcl -y   # 准备编译安装的环境\nmake\nmkdir /usr/local/redis2.8\nmake PREFIX=/usr/local/redis2.8 install\n\n# 拷贝对应的执行程序，设置环境变量\ncd /tools/redis-2.8.18\ncp redis.conf /usr/local/redis2.8/\ncd /tools/redis-2.8.18/src\ncp redis-sentinel /usr/local/redis2.8/bin/\necho -e \'export REDIS_HOME=/usr/local/redis2.8\\nexport PATH=$PATH:$REDIS_HOME/bin\' >> ~/.bash_profile\n. ~/.bash_profile\n\n# 查看redis-server的使用帮助信息\n[root@maxiaoyu 15:03:53 /root]\n#redis-server --help\nUsage: ./redis-server [/path/to/redis.conf] [options]\n       ./redis-server - (read config from stdin)\n       ./redis-server -v or --version\n       ./redis-server -h or --help\n       ./redis-server --test-memory <megabytes>\n\nExamples:\n       ./redis-server (run the server with default conf)\n       ./redis-server /etc/redis/6379.conf\n       ./redis-server --port 7777\n       ./redis-server --port 7777 --slaveof 127.0.0.1 8888\n       ./redis-server /etc/myredis.conf --loglevel verbose\n\nSentinel mode:\n       ./redis-server /etc/sentinel.conf --sentinel\n       \n# 可选：把redis做成后台daemon模式\ncd /tools/redis-2.8.18/utils\n./install_server.sh \n# 把编译好的redis作为一个服务器，把6379.conf放到了/etc/init.d/redis_6379\ncd /etc/init.d\nmv redis_6379 redisd\nchkconfig --add redisd\nservice redisd start\nss -tanl\n```\n\n现在就可以启用redis了：\n\n```shell\nredis-server /usr/local/redis2.8/redis.conf\n```\n\n使用redis-cli进行连接\n\n- -h：指定要连接的机器\n- -p：指定要连接的port，新浪一台开了四个redis，对应四个端口\n- -a：传password\n- -n：一个redis里面可以由多个database，默认是16个，不同的db是隔离的。database number。默认的db是db0号，我们可以选择不同的号码切换到不同的数据库，数据库的数量可以在配置文件中去配置。\n\n## Redis保护模式\n\n- Bind 指定ip进行监听\n\n  ```shell\n  bind ip1 ip2 ip3 ip4\n  ```\n\n- protect mode 配置文件中有一个protected-mode\n\n  ```shell\n  protected-mode yes\n  # 单单只开启这个还没用还要加一个requirepass\n  requirepass testpass1\n\n  # 那么在登录的时候可以指定密码\n  redis-cli -p xxx -a testpass1 -h x.x.x.x\n  # 或者先使用redis-cli进来以后然后执行auth命令，然后再去执行redis命令\n  auth testpass1\n  ```\n\n  ​","timestamp":1526281685638},{"name":"02-redis配置文件详解.md","path":"03-DBA运维/02-Redis/02-redis配置文件详解.md","content":"# Redis配置文件详解\n\n## 单位\n\n```shell\n# 1k => 1000 bytes\n# 1kb => 1024 bytes\n# 1m => 1000000 bytes\n# 1mb => 1024*1024 bytes\n# 1g => 1000000000 bytes\n# 1gb => 1024*1024*1024 bytes\n```\n\n- 只支持字节，不支持bit。\n- 大小写不敏感\n\n## Include\n\n包含其他的配置文件，你可以有一个标准模板给大多数的机器用，你也可以引入一些配置文件给一些自定义的机器使用，比较推荐在配置文件的最后一行加上。\n\n```shell\n# include /path/to/local.conf\n# include /path/to/other.conf\n```\n\n## 通用配置\n\n```shell\n# 是否允许以守护进程的方式运行\ndaemonize yes\n\n# pid文件位置\npidfile /var/run/redis_6379.pid\n\n# 监听端口\nport 6379\n\n# 设置tcp的backlog，backlog其实是一个连接队列，backlog的队列总和=未完成三次握手的队列+已完成三次握手的队列。在高并发环境下你需要一个较高的tco-backlog值来避免客户端连接慢的问题，注意，linux内核回降这个值减小到/proc/sys/net/core/somaxconn的值，因此需要确认增大somaxconn和tcp_max_sync_backlog这两个值来达到想要的效果。\ntcp-backlog 511\n\n# redis默认监听来自所有网络接口的连接。你可以通过设置这里来设置允许谁来访问\n# bind 192.168.1.100 10.0.0.1\n# bind 127.0.0.1\n\n# 可以通过自定义socket来处理用户请求。如果不指定的话redis就不会通过监听socket来处理访问连接。\n# unixsocket /tmp/redis.sock\n# unixsocketperm 700\n\n# 超时时间，0表示永不超时。\ntimeout 0\n\n# TCP keepalive.单位为秒，如果设置为0那么就不会进行keepaliverd检测，建议设置成60\ntcp-keepalive 0\n\n# 设置日志的级别，默认是notice，还有debug，verbose，warning集中可以选择。debug适用于开发模式，verbose有用的信息不多，但是没有debug那么乱，notice是适度的较为详细的日志，生产环境一般你想看的这里都体现了，warning只会打印非常重要的或者致命的问题。\nloglevel notice\n\n# 日志位置配置，这里可以为空，这样Redis会将日志输出到标准输出，但是如果redis不是以daemon方式运行的话那么就直接给输出到/dev/null里去了。logfile stdout\nlogfile /usr/local/redis2.8/redis_6379.log\n\n# 如果要允许日志记录到系统日志的话就设置这个选项为yes。\n# syslog-enabled no\n\n# 指定系统记录的日志以redis开头。指定系统日志中的标识\n# syslog-ident redis\n\n# 输出日志的设备，可以是USER，LOCAL0~7\n# syslog-facility local0\n\n# 默认有16个库，可以使用select命令切换库。\ndatabases 16\n\n\n\n\n\n################################ LATENCY MONITOR ##############################\n\n# The Redis latency monitoring subsystem samples different operations\n# at runtime in order to collect data related to possible sources of\n# latency of a Redis instance.\n#\n# Via the LATENCY command this information is available to the user that can\n# print graphs and obtain reports.\n#\n# The system only logs operations that were performed in a time equal or\n# greater than the amount of milliseconds specified via the\n# latency-monitor-threshold configuration directive. When its value is set\n# to zero, the latency monitor is turned off.\n#\n# By default latency monitoring is disabled since it is mostly not needed\n# if you don\'t have latency issues, and collecting data has a performance\n# impact, that while very small, can be measured under big load. Latency\n# monitoring can easily be enalbed at runtime using the command\n# \"CONFIG SET latency-monitor-threshold <milliseconds>\" if needed.\nlatency-monitor-threshold 0\n\n############################# Event notification ##############################\n\n# Redis can notify Pub/Sub clients about events happening in the key space.\n# This feature is documented at http://redis.io/topics/notifications\n#\n# For instance if keyspace events notification is enabled, and a client\n# performs a DEL operation on key \"foo\" stored in the Database 0, two\n# messages will be published via Pub/Sub:\n#\n# PUBLISH __keyspace@0__:foo del\n# PUBLISH __keyevent@0__:del foo\n#\n# It is possible to select the events that Redis will notify among a set\n# of classes. Every class is identified by a single character:\n#\n#  K     Keyspace events, published with __keyspace@<db>__ prefix.\n#  E     Keyevent events, published with __keyevent@<db>__ prefix.\n#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...\n#  $     String commands\n#  l     List commands\n#  s     Set commands\n#  h     Hash commands\n#  z     Sorted set commands\n#  x     Expired events (events generated every time a key expires)\n#  e     Evicted events (events generated when a key is evicted for maxmemory)\n#  A     Alias for g$lshzxe, so that the \"AKE\" string means all the events.\n#\n#  The \"notify-keyspace-events\" takes as argument a string that is composed\n#  of zero or multiple characters. The empty string means that notifications\n#  are disabled.\n#\n#  Example: to enable list and generic events, from the point of view of the\n#           event name, use:\n#\n#  notify-keyspace-events Elg\n#\n#  Example 2: to get the stream of the expired keys subscribing to channel\n#             name __keyevent@0__:expired use:\n#\n#  notify-keyspace-events Ex\n#\n#  By default all notifications are disabled because most users don\'t need\n#  this feature and the feature has some overhead. Note that if you don\'t\n#  specify at least one of K or E, no events will be delivered.\nnotify-keyspace-events \"\"\n\n############################### ADVANCED CONFIG ###############################\n\n# Hashes are encoded using a memory efficient data structure when they have a\n# small number of entries, and the biggest entry does not exceed a given\n# threshold. These thresholds can be configured using the following directives.\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\n\n# Similarly to hashes, small lists are also encoded in a special way in order\n# to save a lot of space. The special representation is only used when\n# you are under the following limits:\nlist-max-ziplist-entries 512\nlist-max-ziplist-value 64\n\n# Sets have a special encoding in just one case: when a set is composed\n# of just strings that happen to be integers in radix 10 in the range\n# of 64 bit signed integers.\n# The following configuration setting sets the limit in the size of the\n# set in order to use this special memory saving encoding.\nset-max-intset-entries 512\n\n# Similarly to hashes and lists, sorted sets are also specially encoded in\n# order to save a lot of space. This encoding is only used when the length and\n# elements of a sorted set are below the following limits:\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\n\n# HyperLogLog sparse representation bytes limit. The limit includes the\n# 16 bytes header. When an HyperLogLog using the sparse representation crosses\n# this limit, it is converted into the dense representation.\n#\n# A value greater than 16000 is totally useless, since at that point the\n# dense representation is more memory efficient.\n#\n# The suggested value is ~ 3000 in order to have the benefits of\n# the space efficient encoding without slowing down too much PFADD,\n# which is O(N) with the sparse encoding. The value can be raised to\n# ~ 10000 when CPU is not a concern, but space is, and the data set is\n# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.\nhll-sparse-max-bytes 3000\n\n# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in\n# order to help rehashing the main Redis hash table (the one mapping top-level\n# keys to values). The hash table implementation Redis uses (see dict.c)\n# performs a lazy rehashing: the more operation you run into a hash table\n# that is rehashing, the more rehashing \"steps\" are performed, so if the\n# server is idle the rehashing is never complete and some more memory is used\n# by the hash table.\n#\n# The default is to use this millisecond 10 times every second in order to\n# actively rehash the main dictionaries, freeing memory when possible.\n#\n# If unsure:\n# use \"activerehashing no\" if you have hard latency requirements and it is\n# not a good thing in your environment that Redis can reply from time to time\n# to queries with 2 milliseconds delay.\n#\n# use \"activerehashing yes\" if you don\'t have such hard requirements but\n# want to free memory asap when possible.\nactiverehashing yes\n\n# The client output buffer limits can be used to force disconnection of clients\n# that are not reading data from the server fast enough for some reason (a\n# common reason is that a Pub/Sub client can\'t consume messages as fast as the\n# publisher can produce them).\n#\n# The limit can be set differently for the three different classes of clients:\n#\n# normal -> normal clients including MONITOR clients\n# slave  -> slave clients\n# pubsub -> clients subscribed to at least one pubsub channel or pattern\n#\n# The syntax of every client-output-buffer-limit directive is the following:\n#\n# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>\n#\n# A client is immediately disconnected once the hard limit is reached, or if\n# the soft limit is reached and remains reached for the specified number of\n# seconds (continuously).\n# So for instance if the hard limit is 32 megabytes and the soft limit is\n# 16 megabytes / 10 seconds, the client will get disconnected immediately\n# if the size of the output buffers reach 32 megabytes, but will also get\n# disconnected if the client reaches 16 megabytes and continuously overcomes\n# the limit for 10 seconds.\n#\n# By default normal clients are not limited because they don\'t receive data\n# without asking (in a push way), but just after a request, so only\n# asynchronous clients may create a scenario where data is requested faster\n# than it can read.\n#\n# Instead there is a default limit for pubsub and slave clients, since\n# subscribers and slaves receive data in a push fashion.\n#\n# Both the hard or the soft limit can be disabled by setting them to zero.\nclient-output-buffer-limit normal 0 0 0\nclient-output-buffer-limit slave 256mb 64mb 60\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n# Redis calls an internal function to perform many background tasks, like\n# closing connections of clients in timeout, purging expired keys that are\n# never requested, and so forth.\n#\n# Not all tasks are performed with the same frequency, but Redis checks for\n# tasks to perform according to the specified \"hz\" value.\n#\n# By default \"hz\" is set to 10. Raising the value will use more CPU when\n# Redis is idle, but at the same time will make Redis more responsive when\n# there are many keys expiring at the same time, and timeouts may be\n# handled with more precision.\n#\n# The range is between 1 and 500, however a value over 100 is usually not\n# a good idea. Most users should use the default of 10 and raise this up to\n# 100 only in environments where very low latency is required.\nhz 10\n\n# When a child rewrites the AOF file, if the following option is enabled\n# the file will be fsync-ed every 32 MB of data generated. This is useful\n# in order to commit the file to the disk more incrementally and avoid\n# big latency spikes.\naof-rewrite-incremental-fsync yes\n```\n\n## 快照\n\n```shell\n# 其实就是RDB持久化\nsave 900 1\nsave 300 10\nsave 60 10000\n\n# 在开启了rdb的情况下，如果最新的后台写入出错，那么redis将停止接收写请求。默认是yes，如果设置成no表示你不在乎数据不一致或者有其他的手段发现和控制。后台保存功能恢复以后redis自动开始允许写入。\nstop-writes-on-bgsave-error yes\n\n# 启用LZF算法进行压缩快照文件\nrdbcompression yes\n\n# 在存储快照后，还可以让redis使用crc64算法来进行数据的校验。\nrdbchecksum yes\n\n# rdb文件的文件名\ndbfilename dump.rdb\n\n# 指定数据库的存放目录\ndir /usr/local/redis2.8/6379\n```\n\n## AOF\n\n```shell\n# 默认aof是关闭的，如果要开启需要手动改为yes。rdb和aof可以一起打开的。如果aof开启的话，redis启动以后会优先加载aof的记录的备份而不是rdb的。\nappendonly no\n\n# aof文件名，(default: \"appendonly.aof\")\nappendfilename \"appendonly.aof\"\n\n# 备份策略\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n\n# 重写时是否可以运用appendfsync，用默认no就可以了，保证数据的安全性。\nno-appendfsync-on-rewrite no\n\n# 自动重写机制，redis会记录上一次重写的aof的大小，默认配置是当aof文件大小是上次rewrite后大小的一倍并且文件大于64M时触发。如果说刚启动，还没有冲写过，那么这个上一次的大小就被记录为使用的aof文件的大小。百分比设置为0意味着禁用自动重写功能。\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n\n# 指redis在恢复时，会忽略最后一条可能存在问题的指令。默认值yes。即在aof写入时，可能存在指令写错的问题(突然断电，写了一半)，这种情况下，yes会log并继续，而no会直接恢复失败.\naof-load-truncated yes\n```\n\n## 安全选项设置\n\n```shell\n# 设置用户密码，你访问之前要输入密码，针对redis的配置文件有一个“config get requirepass”可以查看配置文件设置的密码。\n# auth 密码，然后再在cli操作下就可以使用了，或者在连接的时候可以用-a参数，比如redis-cli -a 密码 -p 6379\n# requirepass foobared\n```\n\n## Limits\n\n```shell\n# 限制并发客户端的数量，默认是10000\n# maxclients 10000\n\n# 设置可以使用的最大内存，一般这个是要进行限制的，不能让redis无限制的使用。\n# maxmemory <bytes>\n\n# 缓存过期策略，或者当达到设置的内存上限以后redis处理缓存的策略，有几个过期策略供你选择。生产环境中不要使用永不过期。\n# noeviction：永不过期，写不了就直接报错，但是可以读。\n# volatile-lru：使用LRU算法移除key，只对设置了过期时间的key，默认值\n# allkeys-lru：使用LRU算法移除key\n# volatile-random：在过期集合中随机移除key，只对设置了过期时间的key\n# allkeys-random：移除随机的key\n# volatile-ttl：移除那些ttl值最小的key，即那些最近要过期的key。\n# maxmemory-policy volatile-lru\n\n# 设置样本数量，LRU算法和最小TTL算法并非都是精准的算法，而是估算值。下面的配置就是默认选取3个样本进行内部的一个检测。所以你可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU(less recently use)的那个\n# maxmemory-samples 3\n```\n\n## 主从复制\n\n```shell\n################################# REPLICATION #################################\n\n# Master-Slave replication. Use slaveof to make a Redis instance a copy of\n# another Redis server. A few things to understand ASAP about Redis replication.\n#\n# 1) Redis replication is asynchronous, but you can configure a master to\n#    stop accepting writes if it appears to be not connected with at least\n#    a given number of slaves.\n# 2) Redis slaves are able to perform a partial resynchronization with the\n#    master if the replication link is lost for a relatively small amount of\n#    time. You may want to configure the replication backlog size (see the next\n#    sections of this file) with a sensible value depending on your needs.\n# 3) Replication is automatic and does not need user intervention. After a\n#    network partition slaves automatically try to reconnect to masters\n#    and resynchronize with them.\n#\n# slaveof <masterip> <masterport>\n\n# If the master is password protected (using the \"requirepass\" configuration\n# directive below) it is possible to tell the slave to authenticate before\n# starting the replication synchronization process, otherwise the master will\n# refuse the slave request.\n#\n# masterauth <master-password>\n\n# When a slave loses its connection with the master, or when the replication\n# is still in progress, the slave can act in two different ways:\n#\n# 1) if slave-serve-stale-data is set to \'yes\' (the default) the slave will\n#    still reply to client requests, possibly with out of date data, or the\n#    data set may just be empty if this is the first synchronization.\n#\n# 2) if slave-serve-stale-data is set to \'no\' the slave will reply with\n#    an error \"SYNC with master in progress\" to all the kind of commands\n#    but to INFO and SLAVEOF.\n#\nslave-serve-stale-data yes\n\n# You can configure a slave instance to accept writes or not. Writing against\n# a slave instance may be useful to store some ephemeral data (because data\n# written on a slave will be easily deleted after resync with the master) but\n# may also cause problems if clients are writing to it because of a\n# misconfiguration.\n#\n# Since Redis 2.6 by default slaves are read-only.\n#\n# Note: read only slaves are not designed to be exposed to untrusted clients\n# on the internet. It\'s just a protection layer against misuse of the instance.\n# Still a read only slave exports by default all the administrative commands\n# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve\n# security of read only slaves using \'rename-command\' to shadow all the\n# administrative / dangerous commands.\nslave-read-only yes\n\n# Replication SYNC strategy: disk or socket.\n#\n# -------------------------------------------------------\n# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY\n# -------------------------------------------------------\n#\n# New slaves and reconnecting slaves that are not able to continue the replication\n# process just receiving differences, need to do what is called a \"full\n# synchronization\". An RDB file is transmitted from the master to the slaves.\n# The transmission can happen in two different ways:\n#\n# 1) Disk-backed: The Redis master creates a new process that writes the RDB\n#                 file on disk. Later the file is transferred by the parent\n#                 process to the slaves incrementally.\n# 2) Diskless: The Redis master creates a new process that directly writes the\n#              RDB file to slave sockets, without touching the disk at all.\n#\n# With disk-backed replication, while the RDB file is generated, more slaves\n# can be queued and served with the RDB file as soon as the current child producing\n# the RDB file finishes its work. With diskless replication instead once\n# the transfer starts, new slaves arriving will be queued and a new transfer\n# will start when the current one terminates.\n#\n# When diskless replication is used, the master waits a configurable amount of\n# time (in seconds) before starting the transfer in the hope that multiple slaves\n# will arrive and the transfer can be parallelized.\n#\n# With slow disks and fast (large bandwidth) networks, diskless replication\n# works better.\nrepl-diskless-sync no\n\n# When diskless replication is enabled, it is possible to configure the delay\n# the server waits in order to spawn the child that trnasfers the RDB via socket\n# to the slaves.\n#\n# This is important since once the transfer starts, it is not possible to serve\n# new slaves arriving, that will be queued for the next RDB transfer, so the server\n# waits a delay in order to let more slaves arrive.\n#\n# The delay is specified in seconds, and by default is 5 seconds. To disable\n# it entirely just set it to 0 seconds and the transfer will start ASAP.\nrepl-diskless-sync-delay 5\n\n# Slaves send PINGs to server in a predefined interval. It\'s possible to change\n# this interval with the repl_ping_slave_period option. The default value is 10\n# seconds.\n#\n# repl-ping-slave-period 10\n\n# The following option sets the replication timeout for:\n#\n# 1) Bulk transfer I/O during SYNC, from the point of view of slave.\n# 2) Master timeout from the point of view of slaves (data, pings).\n# 3) Slave timeout from the point of view of masters (REPLCONF ACK pings).\n#\n# It is important to make sure that this value is greater than the value\n# specified for repl-ping-slave-period otherwise a timeout will be detected\n# every time there is low traffic between the master and the slave.\n#\n# repl-timeout 60\n\n# Disable TCP_NODELAY on the slave socket after SYNC?\n#\n# If you select \"yes\" Redis will use a smaller number of TCP packets and\n# less bandwidth to send data to slaves. But this can add a delay for\n# the data to appear on the slave side, up to 40 milliseconds with\n# Linux kernels using a default configuration.\n#\n# If you select \"no\" the delay for data to appear on the slave side will\n# be reduced but more bandwidth will be used for replication.\n#\n# By default we optimize for low latency, but in very high traffic conditions\n# or when the master and slaves are many hops away, turning this to \"yes\" may\n# be a good idea.\nrepl-disable-tcp-nodelay no\n\n# Set the replication backlog size. The backlog is a buffer that accumulates\n# slave data when slaves are disconnected for some time, so that when a slave\n# wants to reconnect again, often a full resync is not needed, but a partial\n# resync is enough, just passing the portion of data the slave missed while\n# disconnected.\n#\n# The bigger the replication backlog, the longer the time the slave can be\n# disconnected and later be able to perform a partial resynchronization.\n#\n# The backlog is only allocated once there is at least a slave connected.\n#\n# repl-backlog-size 1mb\n\n# After a master has no longer connected slaves for some time, the backlog\n# will be freed. The following option configures the amount of seconds that\n# need to elapse, starting from the time the last slave disconnected, for\n# the backlog buffer to be freed.\n#\n# A value of 0 means to never release the backlog.\n#\n# repl-backlog-ttl 3600\n\n# The slave priority is an integer number published by Redis in the INFO output.\n# It is used by Redis Sentinel in order to select a slave to promote into a\n# master if the master is no longer working correctly.\n#\n# A slave with a low priority number is considered better for promotion, so\n# for instance if there are three slaves with priority 10, 100, 25 Sentinel will\n# pick the one with priority 10, that is the lowest.\n#\n# However a special priority of 0 marks the slave as not able to perform the\n# role of master, so a slave with priority of 0 will never be selected by\n# Redis Sentinel for promotion.\n#\n# By default the priority is 100.\nslave-priority 100\n\n# It is possible for a master to stop accepting writes if there are less than\n# N slaves connected, having a lag less or equal than M seconds.\n#\n# The N slaves need to be in \"online\" state.\n#\n# The lag in seconds, that must be <= the specified value, is calculated from\n# the last ping received from the slave, that is usually sent every second.\n#\n# This option does not GUARANTEE that N replicas will accept the write, but\n# will limit the window of exposure for lost writes in case not enough slaves\n# are available, to the specified number of seconds.\n#\n# For example to require at least 3 slaves with a lag <= 10 seconds use:\n#\n# min-slaves-to-write 3\n# min-slaves-max-lag 10\n#\n# Setting one or the other to 0 disables the feature.\n#\n# By default min-slaves-to-write is set to 0 (feature disabled) and\n# min-slaves-max-lag is set to 10.\n```\n\n## Lua脚本\n\n```shell\n################################ LUA SCRIPTING  ###############################\n\n# Max execution time of a Lua script in milliseconds.\n#\n# If the maximum execution time is reached Redis will log that a script is\n# still in execution after the maximum allowed time and will start to\n# reply to queries with an error.\n#\n# When a long running script exceeds the maximum execution time only the\n# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be\n# used to stop a script that did not yet called write commands. The second\n# is the only way to shut down the server in the case a write command was\n# already issued by the script but the user doesn\'t want to wait for the natural\n# termination of the script.\n#\n# Set it to 0 or a negative value for unlimited execution without warnings.\nlua-time-limit 5000\n```\n\n## 慢日志\n\n```shell\n################################## SLOW LOG ###################################\n\n# The Redis Slow Log is a system to log queries that exceeded a specified\n# execution time. The execution time does not include the I/O operations\n# like talking with the client, sending the reply and so forth,\n# but just the time needed to actually execute the command (this is the only\n# stage of command execution where the thread is blocked and can not serve\n# other requests in the meantime).\n#\n# You can configure the slow log with two parameters: one tells Redis\n# what is the execution time, in microseconds, to exceed in order for the\n# command to get logged, and the other parameter is the length of the\n# slow log. When a new command is logged the oldest one is removed from the\n# queue of logged commands.\n\n# The following time is expressed in microseconds, so 1000000 is equivalent\n# to one second. Note that a negative number disables the slow log, while\n# a value of zero forces the logging of every command.\nslowlog-log-slower-than 10000\n\n# There is no limit to this length. Just be aware that it will consume memory.\n# You can reclaim memory used by the slow log with SLOWLOG RESET.\nslowlog-max-len 128\n```\n\n","timestamp":1526281685638},{"name":"03-redis的简单实用.md","path":"03-DBA运维/02-Redis/03-redis的简单实用.md","content":"# Redis的简单使用\n\n> redis中最简单的数据结构，它即可以存储文字，又可以存储数字，和浮点数，还可以进行二进制的存储，redis为这几类型的值分贝设置相应的操作命令，让用户可以针对不同的值做不同的处理。\n\n## 简单操作\n\n### help\n\n```shell\n# 熟练使用帮助信息\n127.0.0.1:6379> help set\n\n  SET key value [EX seconds] [PX milliseconds] [NX|XX]\n  summary: Set the string value of a key\n  since: 1.0.0\n  group: string\n  \n# 查看有关字符串的操作\nhelp @string\n\n# 查看关于集合的操作\nhelp @set\n```\n\n### String\n\n> 一个字符串类型的值最多能存储512M字节的内容\n\n```shell\n# 多次设置同一个key，key会被后设置所覆盖，也就是key是唯一的。\nset msg \"hello world\"\n\n# nx表示key不存在的时候才进行设置，当key已经存在的时候就不设置，返回nil\nset msg \"redis\" nx\n\n# xx表示当key存在的时候才可以设置，因为之前设置了msg，所以这个key存在，现在可以设置msg\nset msg \'bbb\' xx\n\n# 设置键的过期时间，ex，后面10表示秒数，意思就是10s以后删除temp这个key，px接的数字单位是毫秒\nset temp \"temp\" ex 10\nset temp \"temp\" px 10\n\n# 使用get来获取设置的内容\nget msg\n\n# setnx，nx表示not exist的意思，当不存在的时候设置\n127.0.0.1:6379> setnx key1 \"key1\"\n(integer) 1\n127.0.0.1:6379> get key1\n\"key1\"\n127.0.0.1:6379> setnx key1 \'key1bak\'\n(integer) 0\n127.0.0.1:6379> get key1\n\"key1\"\n\n# 同时设置多个值，同时获取多个值，mget，mset\n127.0.0.1:6379> mset key1 \"key1\" key2 \"key2\" key3 \"key3\"\nOK\n127.0.0.1:6379> mget key1 key2 key3\n1) \"key1\"\n2) \"key2\"\n3) \"key3\"\n\n# msetnx同时设置多个值，具有原子性，要不成功就是整体不成功。nx还是not exist，当不存在这个key的时候设置，当至少有一个是存在的时候，那么msetnx将不执行任何操作\n127.0.0.1:6379> mset a 1 b 2\nOK\n127.0.0.1:6379> msetnx a 1 c 3\n(integer) 0 # 返回integer 0就是表示没有设置成功\n127.0.0.1:6379> get c\n(nil)\n\n# getset可以将key的值设置一个新的value，并返回key之前存储的旧值。内部实现其实就是一个get，一个set，然后return get拿到的值，但是操作由两次变成了一次。\n127.0.0.1:6379> get a\n\"a_old\"\n127.0.0.1:6379> getset a \'a_new\'\n\"a_old\"\n127.0.0.1:6379> get a\n\"a_new\"\n\n# append将值value插入到字符串key已存储内容的末尾\n127.0.0.1:6379> set a \"hahaha\"\nOK\n127.0.0.1:6379> append a \"_?????\"\n(integer) 12\n127.0.0.1:6379> get a\n\"hahaha_?????\"\n\n# strlen 接收一个key，返回value字符串的长度\n127.0.0.1:6379> set a \"hahaha\"\nOK\n127.0.0.1:6379> STRLEN a\n(integer) 6\n```\n\n#### key的命名规范\n\n因为redis数据库的key是唯一的，因此在设计key的命名的时候我们可以这样去设置，比如用户lamber的email地址这样一个内容的key可以设置为`lamber::email`，这样的话，大家每个人的内容就不会造成冲突，举个复杂点的例子比如：`user::10086::info`可以表示为id是10086的用户的信息，`news::sport::cache`可以表示新闻类网站体育分类的缓存，两个冒号是大众习惯的分隔符，当然这个不是固定死的，也可以使用其它的分隔符，比如使用`/`也是可以的，在程序中统一规范即可。\n\nredis的key值是二进制安全的，这意味着可以用任何二进制序列作为key值，从形如“foo”的简单字符串到一个jpeg的文件的内容都可以，空字符串也可以是有效的key值。\n\n- 键值不要太长，消耗内存， 并且在查找这类key值的计算成本较高，而且存储的键的个数不宜过多，在存储键值这一块，值就是值本身，但是key的存储往往携带一些附属内容，比如key的过期时间以及其他属性。\n- key值也不要过短，太短的话可读性太差。\n\n#### 字符串索引\n\n> 索引从0开始，除了正向索引外，还有一个负数的索引，负数索引从-1开始，表示字符串的结尾，这个其实和python的字符串索引很像。\n\n通过字符串的索引去进行范围查找\n\n```shell\n# setrange命令可以从索引index开始，用你想写入的value值替换到给定key所存储的字符串部分，注意这个目前是只支持正数索引，替换完成以后返回的内容为字符串的长度。没替换到的地方保留，超过的地方追加\n127.0.0.1:6379> set a \"hello\"\nOK\n127.0.0.1:6379> setrange a 1 \"appy\"\n(integer) 5\n127.0.0.1:6379> get a\n\"happy\"\n\n# getrange是获取某个区间范围内的值，注意范围左右都是闭区间，也就是说都可以取到的。getrange接收的区间范围的值可以是正数也可以是负数\n127.0.0.1:6379> set msg \"hello world\"\nOK\n127.0.0.1:6379> getrange msg 0 4\n\"hello\"\n127.0.0.1:6379> getrange msg -5 -1\n\"world\"\n# 注意这里的负数取值的时候其实顺序还是从左到右的，-1到-5相当于从右向左取是取不到的。\n127.0.0.1:6379> getrange msg -1 -5\n\"\"\n127.0.0.1:6379> getrange msg 0 -1\n\"hello world\"   # 获取整个字符串\n```\n\n#### BitMap\n\n> - BitMap(位图)不是真正的数据类型，它是定义在字符串类型中的\n> - 一个字符串类型的值最多能存储512M字节的内容\n> - 位上限2^(9+10+10+3)=2^32b\n\n```shell\n# 设置某一位上的值，offset表示偏移量，从0开始，0是最右侧的那个，比如01001011，第0个为1\nsetbit key offset value、\n# 获取某一位上的值\ngetbit key offset\n# 返回指定值0或者1在指定区间上第一次出现的位置\nbitpos key bit [start] [end]\n```\n\n位操作\n\n```shell\n# 对一个或者多个保存二进制的字符串key进行位元操作，并将结果保存到destkey上\n# operation可以使AND OR NOT XOR这四种操作的一种。\n# 除了not操作之外，其他操作都可以接受一个或者多个key作为输入\n# 当bitop处理不同长度的字符串的时候，较短的字符串所缺少的部分会被看做是0\n# 空的key也被看做是包含0的字符串序列\n\n# 对一个或多个key求逻辑与，并将结果保存到destkey\nbitop and destkey key [key....] \n\n# 对一个或多个key求逻辑或，并将结果保存到destkey\nbitop or destkey key [key....] \n\n# 对一个或多个key求逻辑异或，并将结果保存到destkey\nbitop xor destkey key [key....]\n\n# 对一个或多个key求逻辑非，并将结果保存到destkey\nbitop not destkey key\n\n# 统计指定位区间上的值为1的个数，左边从0起，从右向左是从-1开始，官方start，end是位，测试后是字节\nbitcount key [start] [end]\n# 表示第一个字节的统计\nbitcount key 0 0 \n# 最常用的就是bitcount testkey\nbitcount testkey 0 -1 等价于 bitcount testkey\n\n# eg:\nset k1 99\nbitcount 99 # return 8 这里的99会被转换为字符串，字符串去找ascii，然后转换成二进制去查看。\n\n# Tip \nbitcount在处理中文的时候要要特殊注意\n```\n\n位图的应用：\n\n```shell\n# 网站用户的上线次数统计(活跃用户)\n用户id为key，天作为offset，上线就置位为1\n比如id为500的用户，今天的第一天上线，第30天上线\nsetbit u500 1 1\nsetbit u500 30 1\nbitcount u500\nkeys u*\n\n# 按天统计网站活跃用户\n天作为key，用户id为offset，上线置位为1，求一段时间内的活跃用户数\nsetbit 20160602 15 1\nsetbit 20160601 123 1\nsetbit 20160608 123 1\n求6月1日到6月10号的活跃用户\nbitop or 20160601-10 20160601 20160602 20160603 …… 20160610\nbitcount 20160601-10\n```\n\npython脚本示例：\n\n```python\nimport redis\nr = redis.Redis(host=\'127.0.0.1\',port=6379,db=0)\nr.setbit(\'u1\',1,1)\nr.setbit(\'u1\',30,1)\n\n# 模拟用户在一年内登录的记录\nfor i in range(3, 365, 3):\n    r.setbit(\'u101\', i, 1)\n    \nfor i in range(4, 365, 2):\n    r.setbit(\'u105\', i, 1)\n    \nuserlit = r.keys(\'u*\')\n# 活跃用户列表\nAu = []\n# 非活跃用户列表\nNau = []\nfor u in userlist:\n    loginCount = r.bitcount(u)\n    if loginCount > 100:\n        Au.append((u,loginCount))\n    else:\n        Nau.append((u,loginCount))\n```\n\n### 数字操作\n\n> redis有一些命令可以专门处理数字的值，只要存储在字符串key里的值可以被解释为64位整数或者标准的64位浮点数，那么用户就可以针对这个字符串执行针对数字值的命令，下面列出来了一些值来说明他们能否被解释为整数或者浮点数，科学计数法不会视图解释，直接当字符串了。\n>\n> 即使字符串key存储的是数字值，但是它仍然可以执行append，strlen，setrange和getrange，当用户针对一个数字执行这些命令的时候，redis会先将数字值转换为字符串，然后再执行命令。\n\n| 数值                              | 是否可以被解释 | 说明                                |\n| --------------------------------- | -------------- | ----------------------------------- |\n| 10086                             | yes            | 值可以被解析为整数                  |\n| 3.14                              | yes            | 值可以被解析为浮点数                |\n| +123                              | yes            | 值可以被解析为整数                  |\n| 123123123123123123123123123123123 | no             | 值太大，没办法使用64位整数来存储    |\n| 2.0e7                             | no             | redis不解释以科学计数法表示的浮点数 |\n| 123ABC                            | no             | 值包含文字                          |\n| ABC                               | no             | 值为文字                            |\n\n#### 增加或减少数字的值\n\n对于一个键是字符串的key，值是数字的，我们可以使用incrby命令增加值，或者是decrby命令来减少值，命令返回操作执行后，key的当前值是什么，如果key本来就不存在，那么redis会生成一个key为键，value为0的键值对，然后再来进行增量或者减量的操作\n\n```shell\n# 字符串值会被解释成64位有符号的十进制整数来操作，结果依然转换成字符串\n127.0.0.1:6379> INCRBY num 2\n(integer) 2\n127.0.0.1:6379> get num\n\"2\"\n127.0.0.1:6379> decrby num1 3\n(integer) -3\n127.0.0.1:6379> get num1\n\"-3\"\n```\n\n因为针对数字的加一减一操作很常用，比如微博的浏览量增加减少等。因此redis针对这个操作创建了incr和decr这两个命令：\n\n```shell\n127.0.0.1:6379> incr num\n(integer) 3\n127.0.0.1:6379> decr num\n(integer) 2\n```\n\n针对浮点数的增加\n\n```shell\n# 针对浮点数有增加，但是没有对应的减少的功能，但是我们可以通过加负值实现减法的功能\n127.0.0.1:6379> set num 10\nOK\n127.0.0.1:6379> INCRBYFLOAT num 3.14\n\"13.14\"\n127.0.0.1:6379> INCRBYFLOAT num -2\n\"11.14\"\n```\n\n## 其他操作\n\n- 清空redis\n\n  ```shell\n  # 这个基本不要用，会丢饭碗的~，这是清楚当前库数据\n  flusbdb\n  # 清除所有库中的数据\n  flushall\n  ```\n\n- 过期相关操作\n\n  ```shell\n  # 给key设置一个过期时间\n  expire key 秒数\n  pexpire key 毫秒数\n\n  # 设置一个指定的unix时间戳过期\n  expireat key 时间戳\n  pexpireat key milliseconds-timestamp\n\n  # 删除过期，在未过期的时间把把过期的设置取消掉。比如设置5s过期，5s内执行以下删除过期就不会过期了\n  persist key\n  ```\n\n- 生存时间\n\n  ```shell\n  # 查看剩余的生存时间\n  ttl key\n  pttl key\n  - key存在但是没有设置ttl，返回-1\n  - key存在，但还在生存期内，返回剩余的秒数或者毫秒数\n  - key曾经存在，但是已经消亡，返回-2，2.8以前的版本返回-1\n  ```\n\n- key的查找\n\n  ```shell\n  # 通过正则来查看数据库有哪些key\n  keys *\n  keys msg[1-3]\n  keys msg???\n\n  - *：表示任意长度字符\n  - ？：任意一个字符\n  - []：字符集合，表示可以是集合中的任意一个，比如[123]\n  ```\n\n- key属性相关\n\n  ```shell\n  # 查看key类型\n  type key\n  # 查看key是否存在，存在返回1，不存在返回0\n  exists key\n  # key的重命名\n  rename old_key new_key\n  # 如果这个键不存在重命名这个key，你重命名的这个新key有可能是现在已经存在的，如果你真的覆盖了，那么这个之前存在的key就被覆盖了，所以renamenx表示只有当你重命名的这个new key不存在的时候重命名（return 1），如果已经存在了就不重命名了（return 0）。\n  renamenx key newkey\n  # key删除\n  del key [key……]\n  ```\n\n  ​\n\n## 使用python客户端进行连接\n\n### 安装\n\n```python\npip install redis\n```\n\n### 简单连接使用\n\n```python\nIn [1]: import redis\n\nIn [2]: rds = redis.Redis(host=\"127.0.0.1\", port=6379, db=0)\n\nIn [3]: rds.set(\'testbin\', 0b01100010)\nOut[3]: True\n\nIn [4]: rds.get(\'testbin\')\nOut[4]: b\'98\'\n\nIn [5]: rds.set(0b0011, 0b01100011)\nOut[5]: True\n\nIn [6]: rds.get(0b0011)\nOut[6]: b\'99\'\n\n# 返回的是一个列表list\nIn [7]: rds.keys(\'*\')\nOut[7]: \n[b\'msg\',\n b\'3\',\n b\'key3\',\n b\'key2\',\n b\'num\',\n b\'mykey\',\n b\'num1\',\n b\'key1\',\n b\'testbin\',\n b\'a\',\n b\'b\']\n\nIn [8]: rds.set(\'test16\', 0x62)\nOut[8]: True\n\nIn [9]: rds.get(\'test16\')\nOut[9]: b\'98\'\n```\n\n","timestamp":1526281685638},{"name":"04-Hash散列操作.md","path":"03-DBA运维/02-Redis/04-Hash散列操作.md","content":"# List列表\n\n>- 基于Linked List实现\n>- 元素是字符串类型\n>- 列表头尾增删快，中间增删慢，增删元素是常态\n>- 元素可以重复出现\n>- 最多包含2的32次幂-1个元素\n>- 索引左到右是从0开始，从右刀座是从-1开始。\n\n## 命令说明\n\n- B block块，阻塞\n- L left 做\n- R right 右\n- X exist 存在\n\n## 常用操作\n\n**左右或者头尾压入元素**\n\n- LPUSH key value [value ……]\n\n  从左边压入元素\n\n- LPUSHX key value\n\n- RPUSH key value [value ..]\n\n- RPUSHX key value\n\n**左右或者头尾弹出元素**\n\n- LPOP key\n- RPOP key\n\n**从一个列表尾部弹出元素压入另一个列表的头部**\n\n- RPOPLPUSH source destination\n\n**返回列表中指定范围的元素**\n\n- LRANGE key start stop\n- LRANGE key 0 -1 表示返回所有元素\n\n**获取指定位置的元素**\n\n- LINDEX key index\n\n**设置指定位置元素的值**\n\n- LSET key index value\n\n**列表长度，元素个数**\n\n- LLEN key\n\n**从列表头部开始删除值等于value的元素count次**\n\n- LREM key count value\n  - count > 0 ：从表头开始向表尾搜索，移除与value相等的元素，数量为count\n  - count < 0 ：从表尾开始向表头搜索，移除与value相等的元素，数量为count的绝对值\n  - count = 0 ：移除表中所有与value相等的值。\n\n**去除指定范围外元素**\n\n- LTRIM key start stop （一个范围，把范围外的都删掉。）\n\n  ```shell\n  # 删除微博的评论最后500条\n  LTRIM u1234:forumid:comments 0 499\n  ```\n\n  ​","timestamp":1526281685638},{"name":"05-集合-有序集合.md","path":"03-DBA运维/02-Redis/05-集合-有序集合.md","content":"","timestamp":1526281685638},{"name":"06-redis的持久化.md","path":"03-DBA运维/02-Redis/06-redis的持久化.md","content":"# 持久化\n\n> 将数据从掉电容易失去的内存放到可以永久存储的设备上，保证了数据的安全性，并且也可以让服务器在重启的时候载入持久化文件来还原服务器在关闭之前的数据键数据，或者使用持久化文件来进行数据备份和数据迁移的工作。redis的持久化功能可以将服务器包含的所有数据库以二进制文件的形式保存到硬盘里，一定程度上节省了空间。\n>\n> **redis为什么需要持久化**\n>\n> - Redis是基于内存的\n> - 缓存服务器，作为缓存，数据丢失可能损失并不是很大\n> - 内存数据库，数据丢失影响就很大了。\n> - 消息队列\n\n## redis持久化方式\n\n### RDB（Redis DB）\n\n#### 创建RDB三种最常见的方式\n\n1. 服务器执行客户端发送save命令\n\n   ```shell\n   # 在手动执行save命令的过程中，也是rdb文件的创建过程中，redis服务器将被阻塞，无法处理客户端发送的命令请求，只有save命令执行完毕之后，rdb文件生成之后，服务器才会重新开始处理客户端发送的命令请求。如果说rdb文件已经存在，服务器将自动使用心得rdb文件替代就的rdb文件。\n\n   # 我们可以写一个定时的任务，定期的去把dump.rdb转移走。相当于一个备份，防止有人flushdb然后save。给自己留一个后路，同时保存固定的数量个，然后用对应的时间命名。这样操作同样也是为了防止机房出现硬件级别的问题。\n   ```\n\n2. 服务器执行客户端发送bgsave命令\n\n   ```shell\n   # bgsave也会创建一个新的rdb文件，和save不同的地方在于，bgsave不会造成redis服务的阻塞，在执行bgsave的时候，服务器仍然可以接受用户的请求的。\n\n   # 不会造成则色的原因有以下三个\n   # 1、redis在接收到一个bgsave命令的时候它不是自己创建rdb文件，而是fork出来一个子进程去处理rdb文件的创建工作，自己继续去处理用户的请求\n   # 2、当子进程创建好rdb文件并退出的时候会向父进程(也就是负责处理命令处理的redis服务器)发送一个讯号，告知它这个rdb文件已经创建完毕了。\n   # 3、redis服务器(父进程)接收子进程创建的rdb文件bgsave执行完毕\n\n   # bgsave本身是一个异步的过程，发送命令客户端会立即得到回复，但是实际操作在回复之后才会开始。\n\n   # 创建子进程，会消耗额外的内存，所以save创建会比bgsave稍微快一些，这两种没有好坏之分，而是哪一种更适合你，比如数据库在线上跑着，那肯定要用bgsave，如果停机维护那就save，因为即使被阻塞也没有什么影响，停机期间，没有用户请求的。\n   ```\n\n   ![](http://omk1n04i8.bkt.clouddn.com/18-5-2/21724319.jpg)\n\n   ![](http://omk1n04i8.bkt.clouddn.com/18-5-2/28727078.jpg)\n\n3. 使用save配置选项设置自动保存，服务器自动执行bgsave\n\n   - save 300 10：表示距离上一次创建rdb文件过去了300s，并且服务器的所有数据库总共发生了不少于10次的修改，那么就执行bgsave命令。\n   - save 60 10000：距离上一次创建rdb文件过去了60s，并且服务器的所有数据库总共发生了不少于10000次修改，那么就执行bgsave命令\n   - 另外，用户还可以通过设置多个save选项来设置多个启动保存的条件，当任意一个条件被满足的时候就会执行这个bgsave的命令。每一次创建rdb文件后，服务器为实现自动持久化而设置的时间计数器和次数计数器就会被清零并开始重新技术，所以说多个保存条件效果是不会互相叠加的。\n\n#### 配置项\n\n在配置文件中设置rdb文件的文件名和文件位置\n\n```shell\n# The filename where to dump the DB\ndbfilename dump.rdb\n```\n\n自动保存的配置\n\n```shell\n# 这个你可以写多条\nsave 900 1\nsave 300 10\nsave 60 10000\n```\n\n#### RDB文件内容\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-2/88585687.jpg)\n\nrdb文件是一个二进制文件，它保存了redis服务器创建rdb文件的时候所有数据库的数据。\n\n#### 问题\n\n- rdb是单文件，如果库很大的话文件也会很大，查询起来，速度也会受到影响。\n- rdb文件操作也不能太过频繁，过于频繁会严重影响服务器的性能。\n- 重启以后redis会自己读取rdb文件加载到内存中。从配置中的dir获取目录\n- 可以通过lastsave查看最后一次备份成功的时间\n- 执行flushdb命令也会产生dump.rdb文件，但里面是空的，没有意义。\n\n### AOF（AppendOnlyFile）\n\n> RBD持久化还是存在一些问题的，一个是频繁操作可能存在性能的损耗，再有就是在配置文件中体现的那些自动执行bgsave的触发条件，随便拿一个`save 60 10000`来讲，即使一分钟内修改超过了1w次，那么要等一分钟以后才会重新生成一个文件，这期间其实就存在说突然宕机的可能。那这个时间段内的数据就极有可能丢失。针对那些对数据的一致性要求很高的环境，rdb就存在一定的缺陷，因此针对这个问题，还有一种持久化方式，那么就是AOF的持久化方式。\n\nAOF持久化有一个很大的优势那就是，用户可以根据自己的需要对AOF持久化进行调整，让redis在遭遇意外宕机或者停机的时候不丢失数据，或者丢失的数据很少很少，比如丢失前1s的数据。这个可以把损失降到最低。\n\n#### AOF原理\n\nAOF持久化的操作原理是被当有**<u>修改数据库的命令</u>**被执行的时候，服务器就会将执行的命令写入到AOF文件的末尾。和RDB不一样，AOF保存的是执行的操作，而不是数据本身。因为AOF文件里储存了服务器执行过的所有数据库修改的命令，所以给定一个AOF文件，服务器只要重新执行一遍AOF文件里面包含的所有命令，就可以达到还原数据库的目的。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-2/39781256.jpg)\n\n举一个AOF文件记录的内容的例子，比如：\n\n```shell\nSELECT 0\nSET msg \"hello\"\nINCR counter\nSADD alphabets \"a\" \"b\" \"c\"\nINCR counter\n```\n\n#### 安全性问题\n\n虽然服务器执行一个修改数据库的命令，就会把执行的命令记录到AOF文件中，但这个并不意味着AOF持久化一点数据也不会丢，在目前常见的操作系统中，执行系统调用函数write函数，将一些内容写到某个文件里面的时候为了提高效率，系统通常不会直接将内容写入到硬盘里，而是先放到一个内存的缓冲区（buffer）里面，缓冲区满了，或者用户手动执行fsync调用和fdatasync调用的时候才会将缓冲区的内容写到硬盘里。\n\n因此对于AOF来说，当一条命令真正的被写到硬盘里后才是真正意义上的保存住了。因此AOF持久化在遭遇停机时丢失命令的数量，取决于命令被写入到硬盘的时间，越早的将命令写到硬盘，发生意外丢失的数据就越少，反之丢失的就越多。\n\n##### appendfsync\n\n```shell\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n```\n\n为了控制redis服务器遇到意外停机而导致数据丢失，redis的aof持久化提供了一个appendfsync选项，这个选项的值可以是always，everysec或者是no。\n\n- no：就是服务器不主动调用fdatasync，这个操作让操作系统自行去决定写入硬盘的时机，这个在遭遇问题的时候丢失的数据量其实是不可控的。\n- Always：服务器的每写入一个命令，就调用一次fdatasync，将修改写入到应硬盘，这种模式下，即使遭遇意外停机，也不会丢失任何已经成功操作的命令数据。\n- Everysec：一秒执行一次fdatasync，较always频率要低，如果遭遇了宕机也就是丢失一秒钟内的执行的命令数据。\n\n因为always是执行一个就写一次，所以这个其实是运行速度最慢的，其他的两个都很快。建议使用的是everysec，同时默认值也是everysec。\n\n#### AOF中的冗余命令\n\n随着服务器的运行，不断的记录数据库的变化，AOF文件的体积是不断增加的。所以针对AOF文件的大小要进行合理的控制，针对这个问题redis提供了一个aof重写的功能，通过这个功能，服务器可以生成一个新的aof文件。\n\n- 新的aof文件记录的数据库数据和原有的aof文件记录的数据库数据完全一样。\n- 新的aof文件会使用极可能少的命令来记录数据库数据，因此新的aof文件的体积通常会比原有的aof文件体积小很多。\n- aof重写期间，服务器不会被阻塞，可以正常处理客户端发送的命令请求。\n\n简单来讲就是在保证数据一致性完整性的前提下将命令进行一定程度的精简从而达到节省空间的目的，比如：\n\n![AOF缩减](http://omk1n04i8.bkt.clouddn.com/18-5-2/75273038.jpg)\n\n**控制AOF重写的方式**\n\n1. 客户端向服务器发送`BGREWRITEAOF`命令\n2. 通知配置选项来让服务器自动执行`bgwriteaof`，命令。\n   - auto-aof-rewrite-min-size：触发aof重写需要的最小的体积，只要aof文件的体积大于等于这个size的时候服务器才会考虑是否需要进行aof重写，这个选项用于避免对体积过小的aof文件重写\n   - auto-aof-rewrite-percentage：指定触发重写所需要的aof体积的百分比，当aof的文件体积大于`auto-aof-rewrite-min-size`指定的体积的时候，并且超过上一次重写之后的aof文件体积的`percent%`，就会触发重新。如果服务器刚重启，还没有进行过aof重写，那么使用服务器启动时载入的aof文件的体积来作为基准值，如果将这个值设置为0的时候表示关闭aof的重写。（怎么理解这个例子，比如设置的最小大小，如果这个百分比设置为100，也就是AOF文件的增量大于100%以后才会触发重写。）\n\n#### AOF配置\n\n```shell\nappendonly no\nappendfilename \"appendonly.aof\"\nappendfsync everysec\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n```\n\n#### Tip\n\n由于aof记录的是操作命令，所以说如果有人手贱执行了flushdb的话那么在aof的文件中也会有这个内容，紧急情况下，也可以手动编辑aof的备份文件，把最后执行的flushdb这条记录的内容手动删掉。所以说AOF文件里有FLUSHALL这个其实挺坑的。\n\n假如说aof的备份文件有问题的话，比如我手动给aof文件的末尾加了一堆乱起八糟的字符。会导致aof备份文件无法成功加载，进而导致redis服务根本起不来。如果说aof文件有问题可以使用自带的修复软件进行修复\n\n```shel\nredis-check-aof --fix appendonly.aof\n```\n\n## 小结\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-2/29823792.jpg)\n\n一般来说为了数据的安全性，可以两种持久化都开启。然后还原数据的时候优先使用aof的数据进行还原。rdb适合大规模的数据恢复，但是对数据的一致性和完整性要求不高。RDB更适合备份数据库，所以以后在做主从的时候slave上可以只开rdb持久化，15min备一次就够。只保留save 900 1.当然这个只是一个建议值，具体还是要结合实际环境来。\n\n如果Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。\n\n\n如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。新浪微博就选用了这种架构","timestamp":1526281685638},{"name":"07-redis事物.md","path":"03-DBA运维/02-Redis/07-redis事物.md","content":"redis事物\n\n>可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞\n\n","timestamp":1526281685638},{"name":"08-redis消息发布与订阅.md","path":"03-DBA运维/02-Redis/08-redis消息发布与订阅.md","content":"","timestamp":1526281685638},{"name":"09-redis主从.md","path":"03-DBA运维/02-Redis/09-redis主从.md","content":"# Redis主从\n\n> - 一个redis服务可以由多个该服务的复制品，这个redis服务成为master，其它的复制品为slave\n> - 只要网络连接正常，master就会一直把自己的数据更新同步给slave，保持主从同步\n> - 只有master可以执行写命令，slave只能执行读命令\n\n## 主从复制的创建\n\n- 配置当前服务器为某redis服务器的slave，在启动的时候。\n\n```shell\nredis-server --port 端口 --slaveof <master-ip> <master-port>\n```\n\n- slaveof host port 命令将当前服务器状态从master修改为别的服务器的slave\n\n```shell\n# 将服务器转换为slave\nslaveof 192.168.1.1 6379   \n# 将服务器重新恢复到master，不会丢弃已经同步的数据\nsalveof no one\n```\n\n- 配置方式：启动的时候，服务器读取配置文件，并自动成为指定服务器的从服务器。\n\n```shell\nslaveof <masterip> <masterport>\nslaveof 127.0.0.1 6379\n```\n\n- master可以设置密码，设置密码后，需要需要填写密码\n\n```shell\nmasterauth <passord>\n```\n\n- 设置slave大于多少后才允许写入\n\n```shell\nmin-slaves-to-write <number of slaves>\n```\n\n- 设置从服务器的延迟不大于xx\n\n```shell\nmin-slaves-max-lag <number of seconds>\n```\n\n可以看到主从复制的设置方式其实是及其简单的，直接配置一下就可以了。\n\n- 一个master可以有多个slave，首次的复制是全量的，后续的是增量的。\n- slave下线只是读请求的性能下降，因为slave一般是只读。\n- master下线，写请求无法执行\n- 可以手动在一台从机上执行slaveof no one，然后再其它redis上使用slaveof指向这个新的master，实现数据的同步。不过这个过程是纯手动的，如果想要实现自动就需要Sentine哨兵，实现故障转移FailOver操作。\n- info replication可以查看主从状态。\n\n### 主从方案\n\n- 一主双从\n- 薪火相传，比如ABC，A是B的master，B是C的master。B在角色上是salve，不过在info replication中也是可以看到C这个slave的。\n\n## 哨兵\n\n> 哨兵Sentinel是由官方提供的一个高可用的方案，可以用它来管理多个redis服务的实例，当我们在make编译完成以后会生成一个redis-sentinel的程序文件。Redis Sentinel是一个分布式系统，可以在一个架构中运行多个Sentinel进程\n\n### 启动Sentinel\n\n1. 将src目录下产生的redis-sentinel程序拷贝到`$REDIS_HOME/bin`目录下\n\n2. 期待用一个运行在Sentinel模式下的redis服务实例\n\n   ```shell\n   # 第一种方法\n   redis-sentinel\n   # 第二种方法\n   redis-server config路径 --sentinel\n   ```\n\n#### Tip\n\n- Sentinel会不断检查Master和slave是否正常\n- 每一个Sentinel可以监控任意多个master和该master下的slave\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-3/22700090.jpg)\n\n当然哨兵本身就是一个单点，存在单点故障。因此我们可以搭建一个Sentinel的集群\n\n### Sentinel网络\n\n> 监控同一个master的Sentinel会自动连接，组成一个分布式的Sentinel网络，互相通信并交换彼此关于被监视服务器的信息。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-3/90204474.jpg)\n\n- 当一个Sentinel认为被监视的服务器已经下线时，它会向网络中的其他Sentinel进行确认，判断该服务器是否真的已经下线\n- 如果下线的服务器为master，那么Sentinel网络将对下线master服务器进行故障转移，通过将下线的master的某一个slave提升为新的master，并让其它的slave的复制指向新的master，以此来让系统重新回到上线的状态。故障机修复以后自动成为slave。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-3/6339105.jpg)\n\n### Sentinel配置文件\n\n- 至少包含一个监控配置选项，用于指定被监控的master的相关信息\n\n  ```shell\n  sentinel monitor <name> <ip> <port> <quorum>\n  - name : 给监控的主服务器起一个名称\n  - ip ：ip地址\n  - port ： 端口\n  - quorum ：仲裁，需要几台Sentinel同意才判定有效\n  举例：\n  # 表示master的ip为127.0.0.1，端口为6379的主服务器设置名称为master，仲裁数目为2，表示将这个master判定为下线失效，需要至少两个Sentinel统一，如果多数sentinel同意才会执行故障转移\n  sentinel monitor mymaster 127.0.0.1 6379 2\n  ```\n\n- 不需要给Sentinel配置从的信息，因为master是知道的，Sentinel会根据master的配置自动发现master的slaves。\n\n- Sentinel的默认端口为26379\n\n#### 配置举例\n\n**配置项**\n\n```shell\nport 26379\nsentinel monitor m1 192.168.56.101 6379 1\nsentinel auth-pass m1 testpass\n# 超过3w毫秒后认为主机宕机\nsentinel down-after-milliseconds m1 30000\nsentinel parallel-syncs m1 1\n# 当主从切换多久后认为主从切换失败\nsebtinel failover-timeout m1 180000\n```\n\n我准备了两台机器，一台192.168.56.101，一台192.168.56.102，101上起了6379.6380.6381三个实例，然后也在102上起了一个实例，其中101的6379是master，其他的都是slave。启动以后哨兵会去自动发现master的slaves这个其实在日志里我们就可以看到，可以很直接的体现：\n\n```shell\n# Sentinel runid is 7e5e9e712ad101aeb577042106a5cc8ffddbb45a\n# +monitor master m1 127.0.0.1 6379 quorum 1\n* +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n* +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6379\n* +slave slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6379\n```\n\n现在手动把master停掉可以发现哨兵的日志立即就有反应，这样的报错会间隔一段时间，有这样一个过程：\n\n```shell\n# Connection with master lost.\n* Caching the disconnected master state.\n* Connecting to MASTER 127.0.0.1:6379\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n```\n\n当哨兵真的认为这个master已经挂掉了的时候就会开始采取提主的操作：\n\n```shell\n# +sdown master m1 127.0.0.1 6379\n+odown master m1 127.0.0.1 6379 #quorum 1/1\n# +new-epoch 1\n# +try-failover master m1 127.0.0.1 6379\n# +vote-for-leader 7e5e9e712ad101aeb577042106a5cc8ffddbb45a 1\n# +elected-leader master m1 127.0.0.1 6379\n# +failover-state-select-slave master m1 127.0.0.1 6379\n# +selected-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n* +failover-state-send-slaveof-noone slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n* +failover-state-wait-promotion slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n* Discarding previously cached master state.\n* MASTER MODE enabled (user request)\n* Connecting to MASTER 127.0.0.1:6379\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n# +promoted-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n# +failover-state-reconf-slaves master m1 127.0.0.1 6379\n* +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6379\n* Discarding previously cached master state.\n* SLAVE OF 127.0.0.1:6380 enabled (user request)\n* Connecting to MASTER 127.0.0.1:6380\n* MASTER <-> SLAVE sync started\n* Non blocking connect for SYNC fired the event.\n* Master replied to PING, replication can continue...\n* Partial resynchronization not possible (no cached master)\n* Slave 127.0.0.1:6381 asks for synchronization\n* Full resync requested by slave 127.0.0.1:6381\n* Starting BGSAVE for SYNC with target: disk\n* Background saving started by pid 6474\n* Full resync from master: 2b29611014608aa041ec4b36b1ddb35dc7172ea7:1\n* DB saved on disk\n* RDB: 0 MB of memory used by copy-on-write\n* Background saving terminated with success\n* Synchronization with slave 127.0.0.1:6381 succeeded\n* MASTER <-> SLAVE sync: receiving 41 bytes from master\n* MASTER <-> SLAVE sync: Flushing old data\n* MASTER <-> SLAVE sync: Loading DB in memory\n* MASTER <-> SLAVE sync: Finished with success\n* +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6379\n* +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6379\n* +slave-reconf-sent slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6379\n* +slave-reconf-inprog slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6379\n# +failover-end-for-timeout master m1 127.0.0.1 6379\n# +failover-end master m1 127.0.0.1 6379\n* +slave-reconf-sent-be slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6379\n* +slave-reconf-sent-be slave 127.0.0.1:6380 127.0.0.1 6380 @ m1 127.0.0.1 6379\n# +switch-master m1 127.0.0.1 6379 127.0.0.1 6380\n* +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ m1 127.0.0.1 6380\n* +slave slave 192.168.56.102:6379 192.168.56.102 6379 @ m1 127.0.0.1 6380\n* +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ m1 127.0.0.1 6380\n# +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ m1 127.0.0.1 6380\n```\n\n#### 注意事项\n\n- 注意不要在哨兵中写127.0.0.1这种的地址，如果哨兵真的开始切换地址以后从机有可能找不到master。\n\n## 总结\n\n- 主从复制，解决了读请求的分担，从节点下线，会使得读请求能力有所下降\n- Master只有一个，存在单点问题\n- Sentinel会在master下线后自动执行failover操作，提升一台slave为master，并让其他的slaves重新成为新的master的slaves。\n- 主从复制+哨兵Sentinel只解决了读性能和高可用问题，但是并没有解决写性能安全和瓶颈，同时也没有应对应用动态切换地址的方案。","timestamp":1526281685638},{"name":"10-Twitter-TwemProxy.md","path":"03-DBA运维/02-Redis/10-Twitter-TwemProxy.md","content":"# Twitter-TwemProxy\n\n>- 主从对写压力没有分担，因此考虑可以使用多个节点进行分担，将请求分担到不同的节点处理\n>- 分片sharding，多借点分担的思路就是关系型数据库处理大表水平切分的思路。\n>\n>![](/var/folders/8l/g95nllln61j4ly_zm_tqj2m40000gn/T/abnerworks.Typora/image-201805040949289.png)\n\n## Twemproxy\n\n> Twitter开发的，用来代理用户的读写请求。\n>\n> - Twitter开发的代理服务器，它兼容redis也兼容memcached，允许用户将多个redis服务器添加到一个服务器池（pool）里面，并通过用户选择的**散列函数**和**分布函数**，将来自客户端的命令请求分发给服务池中的各个服务器\n> - 通过使用twemproxy我们可以将数据库分片到多态redis服务器上面，并使用这些服务器来分担系统压力以及数据库容量：在服务器硬件条件相同的情况下，对于一个包含n台redis服务器的池来说，池中每台平均处理1/N的客户端请求\n> - 向池里添加更多服务器可以线性的扩展系统处理命令请求的能力，以及系统能够保存的数据量。之所以这么说是客户端写请求过来的时候twemproxy会计算一个key的散列值，每一个服务器会有一个自己散列值对应的的范围，如果这个key的散列值范围在对应的服务器范围内，那么请求就到对应的服务器上。\n> - 一个代理存在单点故障\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-4/22811802.jpg)\n\n## Twemproxy安装\n\n> Github:https://github.com/twitter/twemproxy\n\n安装步骤：\n\n```shell\n# 如果说yum安装的相关软件包的版本过低的话需要自己手动编译安装。\nyum -y install autoconf automake libtool\ntar xf nutcracker-0.4.1.tar.gz\ncd nutcracker-0.4.1\nmkdir /usr/local/twemproxy\n./configure --prefix=/usr/local/twemproxy\nmake && make install\n```\n\n新建一个配置文件，在当前目录下就可以，配置内容如下：\n\n```shell\n[root@DB102 20:41:49 /root/nutcracker-0.4.1]\n#vim tp.yml\nsxt:\n  listen: 192.168.56.101:22121\n  hash: fnv1a_64\n  distribution: ketama\n  auto_eject_hosts: true\n  redis: true\n  server_retry_timeout: 2000\n  server_failure_limit: 3\n  servers:\n    - 192.168.56.101:6379:1\n    - 192.168.56.101:6380:1\n    - 192.168.56.101:6381:1\n```\n\n启动twemproxy之前先确保redis都起来了。\n\n```shell\n[root@DB102 20:45:56 /root/nutcracker-0.4.1]\n#ps -ef | grep redis | grep -v grep\nroot     18526  7402  0 20:45 pts/0    00:00:00 redis-server *:6379\nroot     18542  7402  0 20:45 pts/0    00:00:00 redis-server *:6380\nroot     18550  7402  0 20:45 pts/0    00:00:00 redis-server *:6381\n```\n\n启动twemproxy：\n\n```shell\n# 其中-d表示以daemon的方式去运行。-c指定配置文件\n[root@DB102 20:47:36 /root/nutcracker-0.4.1]\n#/usr/local/twemproxy/sbin/nutcracker -d -c tp.yml\n```\n\n查看服务状态\n\n```shell\n#netstat -antup | grep 22121\ntcp        0      0 192.168.56.101:22121    0.0.0.0:*               LISTEN      18774/nutcracker \n```\n\ntwemproxy代理了redis协议，我们就可以直接去连接它了，记得加上-h主机。\n\n```shell\n[root@DB102 20:56:22 /root/nutcracker-0.4.1]\n#redis-cli -p 22121 -h 192.168.56.101\n192.168.56.101:22121> set msg 111 \nOK\n192.168.56.101:22121> get msg\n\"111\"\n```\n\n最后这个数据会放到后端的一台机器上，我们现在后端代理了三台机器，会放到其中一台机器上。这里我们也看到了这个问题，就是目前几台数据是不同步的。如果其中有一个节点挂掉了，那么这个数据就访问不到了，除非你再上线这个redis才能访问到。\n\n## Twemproxy配置\n\n```shell\n# 这个配置是yaml格式的，每一个层级固定两个空格。而且冒号后要有一个空格。\nsxt:\n  listen:192.168.56.201:22121\n  hash:fnv1a_64\n  distribution:ketama\n  auto_eject_hosts:true\n  redis:true\n  server_retry_timeout:2000\n  server_failure_limit:3\n  servers:\n    - 192.168.56.201:6379:1\n    - 192.168.56.202:6379:1\n    - 192.168.56.203:6379:1\n```\n\n- ext：server pool的名称，可以创建多个serverpool\n- listen：server pool监听的地址和端口号\n- hash：key的散列算法，用于将key映射为一个散列值\n- distribution：key的分布算法，决定key被分布到哪一个服务器\n- redis：代理redis请求，不给定这个值的时候默认代理memcached请求，true表示代理redis\n- servers：pool中各个服务器的地址和端口号以及权重\n- server_retry_timeout：连不上的超时时间\n- auto_eject_hosts：设置为true表示当请求的散列范围对应到某个服务器，但是服务器无法访问的时候直接拒绝掉这个请求，这样效率会高一些。\n- server_failure_limit：twemproxy连续n次向同一个服务器发送命令请求都遇到错误的时候，twemproxy就会将改服务器标记为下线，并交由pool中其他在线服务器采集；哦\n\n## 整合方案\n\nredis-mgr：通过整合复制，哨兵以及twemproxy等组件，提供了一站式的redis服务器部署，监控，迁移功能。网址`https://github.com/changyibiao/redis-mgr`。或者使用更好的方案，redis集群。\n\n## 小结\n\n- 扩展不是很方便，容错率低\n- 代理存在单点问题\n- 后端服务器数据不同步\n- 前端使用proxy做代理，后端的redis可以基本根据key来进行比较均衡的分布\n- 如果后端的redis挂掉以后，代理能够自动摘除，恢复后，代理还能自动识别，恢复并加入到redis分组中重新使用。\n- redis挂掉以后，后端数据是否丢失依据redis本身的持久化策略配置，与twemproxy无关\n- 新加redis需要重启twemproxy，并且数据不会自动重新的rebanlance，需要人工写脚本来实现。\n- 如果原来有两个节点redis，后续又增加两个redis，则数据分布计算与原来的redis分布无关，现有数据如果需要分布均匀的话，需要人工单独处理。\n- 如果twemproxy的后端节点数量发生变化，twemproxy相同算法的前提下，原来的数据必须重新处理分布，否则会存在找不到key值的情况。\n- 不管twemproxy后端有几台redis，前端的单个twemproxy的性能最大也只能和单台redis性能差不多。\n- 如同时部署多台twemproxy配置一样，客户端分别连接多台twemproxy可以在一定条件下提高性能。","timestamp":1526281685638},{"name":"11-redis3.x集群.md","path":"03-DBA运维/02-Redis/11-redis3.x集群.md","content":"# Redis集群\n\n> - 3.0支持\n> - 由多个redis服务器足证的分布式网络服务集群\n> - 每一个redis服务器成为节点node，节点之间会互相通信，两两相连。\n> - redis集群无中心节点，没有一个主从的概念，不建议节点数量太多，可能会受到网络io的影响。\n> - redis集群不支持那些需要同时处理多个键的redis命令，因为执行这些命令需要在多个redis节点之间移动数据，并且高负载的情况下，这些命令将降低redis集群的性能，并导致不可预测的行为。\n\n## Redis集群节点复制\n\n- redis集群的每个节点都有两种角色可以选择，主节点，master node。从节点，slave node。其中主节点用于存储数据，而从节点是某一个主节点的复制品。\n- 当用户需要处理更多读请求的时候，添加从节点可以扩展系统的读性能。因为redis集群重用了单机redis复制特性的代码，所以集群的复制行为和我们之前介绍的单机复制特性行为是完全一致的。所以一般搭建就是6个node，3主3从。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-4/82220774.jpg)\n\n## Redis集群故障转移\n\n- Redis集群的主节点内置了类似redis哨兵的节点故障检测和自动故障转移功能，当集群中的某个主节点下线的时候，集群中的其他在线节点会注意到这一点，并对已下线的主节点进行故障转移。\n- 集群进行故障转移的方法和redis哨兵进行故障转移的方法进本一样，不同的是在集群里面，故障转移是由集群中其他的主节点负责进行的，所以集群不必另外使用redis哨兵。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-4/80981446.jpg)\n\n## Redis集群分片\n\n- 集群将整个数据库分为16384个槽位（slot），key会存放在这些槽位中的一个，key的槽位的计算公式为（slot_number=crc16(key)%16384），其中crc16位16位的循环冗余校验和函数。\n- 集群中的每一个主节点都可以处理0个至16383个槽，当16384个槽为都有某个节点在负责处理的时候集群进入上线状态，并开始处理客户端发送的数据命令请求。\n\n### Example\n\n- 三个主节点7000、7001、7002平均分片16384个slot槽位\n- 节点7000分到0~5460\n- 节点7001分到5461~10922\n- 节点7002分到10923~16383\n\n## Redis集群的重定向\n\n由于redis集群没有中心节点，所以请求会发给任意的主节点。主节点只会处理自己负责的槽位的命令请求，针对其他槽位的命令请求，该主节点会返回客户端一个redirect错误，客户端根据错误中包含的地址和端口重新向正确的负责的主节点发起命令请求。\n\n![](http://omk1n04i8.bkt.clouddn.com/18-5-4/6189858.jpg)\n\n## 搭建Redis集群\n\n- 创建多个主节点\n- 为每一个节点指派slot，将多个节点连接起来，组成一个集群。\n- 槽位分片完成以后，集群进入上线状态。\n- 6个节点，3个主节点，每一个主节点有一个从节点。\n- 在应用端可以写一个列表，愿意连接哪个就连接哪个\n\n### 安装新版redis\n\n```shell\n# 编译安装过程\ncd /tools/\nwget http://download.redis.io/releases/redis-4.0.9.tar.gz\ntar xf redis-4.0.9.tar.gz \ncd redis-4.0.9\nmake\nmkdir /usr/local/redis4\nmake PREFIX=/usr/local/redis4 install\n\n# 修改环境变量过程\nvim ~/.bash_profile\n# 添加上这么一行\nexport PATH=$PATH:/usr/local/redis4/bin\n# 生效环境变量\n. ~/.bash_profile\n查看生效结果\n# which redis-cli\n/usr/local/redis4/bin/redis-cli\n```\n\n查看编译生成的redis的bin目录\n\n```shell\n# 哨兵和sever整合到一起去了\n[root@localhost bin]# ll\ntotal 21860\n-rwxr-xr-x. 1 root root 2451872 May  3 10:23 redis-benchmark\n-rwxr-xr-x. 1 root root 5770168 May  3 10:23 redis-check-aof\n-rwxr-xr-x. 1 root root 5770168 May  3 10:23 redis-check-rdb\n-rwxr-xr-x. 1 root root 2616976 May  3 10:23 redis-cli\nlrwxrwxrwx. 1 root root      12 May  3 10:23 redis-sentinel -> redis-server\n-rwxr-xr-x. 1 root root 5770168 May  3 10:23 redis-server\n```\n\n准备6个实例，为每一个实例新建一个目录用来保存各自的配置文件\n\n```shell\nmkdir -p clustertest/700{0..5}\n```\n\n在对应的每一个目录一下新建redis的配置文件，内容如下：\n\n```shell\ncluster-enabled yes\n# 端口随着每个实例的变动而更改\nport 7000\nlogfile /root/clustertest/7000/redis.log\ndaemonize yes\ncluster-config-file /root/clustertest/7000/nodes.conf\ncluster-node-timeout 5000\npidfile \"/root/clustertest/7000/redis7000.pid\"\n```\n\n文件目录：\n\n```shell\n[root@DB102 22:38:19 /root/clustertest]\n#tree .\n.\n├── 7000\n│   └── redis.conf\n├── 7001\n│   └── redis.conf\n├── 7002\n│   └── redis.conf\n├── 7003\n│   └── redis.conf\n├── 7004\n│   └── redis.conf\n└── 7005\n    └── redis.conf\n```\n\n启动实例，这里有一个值得注意的点就是在配置文件里我没有指定nodes.conf，那么nodes.conf就会生成在运行redis-server的当前目录，所以需要切换到对应的700x目录里面去运行，否者多个实例启动nodes.conf会冲突，如果不想这样的话就在每一个redis.conf中指定nodes.conf的位置：`cluster-config-file nodes.conf`\n\n```shell\nredis-server redis.conf\n```\n\n查看端口：\n\n```shell\n// 其中700x是客户端端口，1700x是彼此交互用的端口，这个交互用的端口会在cluster-enable=yes的时候启动起来。\n[root@DB102 23:30:13 /root/clustertest/7003]\n#ss -tanl | grep 700\nLISTEN     0      128          *:17002                    *:*                  \nLISTEN     0      128          *:17003                    *:*                  \nLISTEN     0      128          *:17004                    *:*                  \nLISTEN     0      128          *:17005                    *:*                  \nLISTEN     0      128          *:7000                     *:*                  \nLISTEN     0      128          *:7001                     *:*                  \nLISTEN     0      128          *:7002                     *:*                  \nLISTEN     0      128          *:7003                     *:*                  \nLISTEN     0      128          *:7004                     *:*                  \nLISTEN     0      128          *:7005                     *:*                  \nLISTEN     0      128          *:17000                    *:*                  \nLISTEN     0      128          *:17001                    *:*                  \nLISTEN     0      128         :::17002                   :::*                  \nLISTEN     0      128         :::17003                   :::*                  \nLISTEN     0      128         :::17004                   :::*                  \nLISTEN     0      128         :::17005                   :::*                  \nLISTEN     0      128         :::7000                    :::*                  \nLISTEN     0      128         :::7001                    :::*                  \nLISTEN     0      128         :::7002                    :::*                  \nLISTEN     0      128         :::7003                    :::*                  \nLISTEN     0      128         :::7004                    :::*                  \nLISTEN     0      128         :::7005                    :::*                  \nLISTEN     0      128         :::17000                   :::*                  \nLISTEN     0      128         :::17001                   :::* \n```\n\n### 创建集群\n\n> 脚本槽位分配通过redis-trib这个脚本来进行分配，但是这个脚本是ruby写的，所以还要安装ruby的环境。\n>\n> ```shell\n> yum -y install ruby rubygems\n> # ruby用于连接redis的一个组件\n> gem install redis\n> # 如果说卡住不动可能是镜像源问题，切换一下镜像源\n> gem sources --add https://gems.ruby-china.org/ --remove https://rubygems.org/\n> gem sources -l\n> # 或者将gem的redis安装包下载下来进行本地的安装，也是没有问题的\n> gem install --local redis-x.x.x.gem\n>\n> # 在centos7中有可能会遇到如下的报错：\n> #gem install redis\n> Fetching: redis-4.0.1.gem (100%)\n> ERROR:  Error installing redis:\n>         redis requires Ruby version >= 2.2.2.\n>         \n> # 这是因为centos7的yum库的ruby版本支持到2.0.0，因此需要自己需要自己去升级一下\n> #ruby --version\n> ruby 2.0.0p648 (2015-12-16) [x86_64-linux]\n> ```\n>\n> 升级ruby的版本\n>\n> ```shell\n> # 使用rvm的方式来更新ruby\n> 1、安装rvm\n> gpg2 --keyserver hkp://keys.gnupg.net --recv-keys D39DC0E3\n> curl -L get.rvm.io | bash -s stable\n>\n> # find / -name rvm -print\n> /usr/local/rvm\n> /usr/local/rvm/src/rvm\n> /usr/local/rvm/src/rvm/bin/rvm\n> /usr/local/rvm/src/rvm/lib/rvm\n> /usr/local/rvm/src/rvm/scripts/rvm\n> /usr/local/rvm/bin/rvm\n> /usr/local/rvm/lib/rvm\n> /usr/local/rvm/scripts/rvm\n>\n> source /usr/local/rvm/scripts/rvm\n>\n> 2、查看rvm库中已知的ruby版本\n> #rvm list known \n> # MRI Rubies\n> [ruby-]1.8.6[-p420]\n> [ruby-]1.8.7[-head] # security released on head\n> [ruby-]1.9.1[-p431]\n> [ruby-]1.9.2[-p330]\n> [ruby-]1.9.3[-p551]\n> [ruby-]2.0.0[-p648]\n> [ruby-]2.1[.10]\n> [ruby-]2.2[.7]\n> [ruby-]2.3[.4]\n> [ruby-]2.4[.1]\n> ……………………………………省略后续的内容\n>\n> 3、安装一个新的版本并使用，设置默认版本\n> rvm install 2.4.1\n> rvm use 2.4.1\n> rvm use 2.4.1 --default\n>\n> 4、移除旧版的ruby\n> rvm remove 2.0.0\n>\n> 5、查看ruby版本，然后再执行上面的安装就没问题了\n> #ruby --version\n> ruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]\n> ```\n\n找到redis源码包中的src中的redis-trib.rb文件\n\n```shell\n[root@DB102 03:36:46 /tools/redis-4.0.9/src]\n#pwd\n/tools/redis-4.0.9/src\n\n[root@DB102 03:36:55 /tools/redis-4.0.9/src]\n#ll redis-trib.rb \n-rwxrwxr-x. 1 root root 65991 3月  27 00:04 redis-trib.rb\n```\n\n执行redis-trib.rb文件，简单说明一下，其中`--replicas 1`指定副本数有1，也就后面跟的6个实例里三主三从。\n\n```shell\n# create表示希望创建一个新的集群\n./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005\n\n>>> Creating cluster\n>>> Performing hash slots allocation on 6 nodes...\nUsing 3 masters:\n127.0.0.1:7000\n127.0.0.1:7001\n127.0.0.1:7002\nAdding replica 127.0.0.1:7004 to 127.0.0.1:7000\nAdding replica 127.0.0.1:7005 to 127.0.0.1:7001\nAdding replica 127.0.0.1:7003 to 127.0.0.1:7002\n>>> Trying to optimize slaves allocation for anti-affinity\n[WARNING] Some slaves are in the same host as their master\nM: 5ced0e3831b746e8d260abd3cad99f2bd5f746a4 127.0.0.1:7000\n   slots:0-5460 (5461 slots) master\nM: fc49467f603f0e1ba1bb0f4affc20db1d6d2cc01 127.0.0.1:7001\n   slots:5461-10922 (5462 slots) master\nM: 35ed50b89426faeb20b50a13854775c4c72bbb5f 127.0.0.1:7002\n   slots:10923-16383 (5461 slots) master\nS: f582f464475f45be65234e387c8b47375dce07d2 127.0.0.1:7003\n   replicates 35ed50b89426faeb20b50a13854775c4c72bbb5f\nS: b74bdc8c4e6d0eb8827f8dfb263ff27f68c51945 127.0.0.1:7004\n   replicates 5ced0e3831b746e8d260abd3cad99f2bd5f746a4\nS: 59b4d618cc6d3afa148a0eb550cde759a8664151 127.0.0.1:7005\n   replicates fc49467f603f0e1ba1bb0f4affc20db1d6d2cc01\nCan I set the above configuration? (type \'yes\' to accept): yes\n>>> Nodes configuration updated\n>>> Assign a different config epoch to each node\n>>> Sending CLUSTER MEET messages to join the cluster\nWaiting for the cluster to join....\n>>> Performing Cluster Check (using node 127.0.0.1:7000)\nM: 5ced0e3831b746e8d260abd3cad99f2bd5f746a4 127.0.0.1:7000\n   slots:0-5460 (5461 slots) master\n   1 additional replica(s)\nM: fc49467f603f0e1ba1bb0f4affc20db1d6d2cc01 127.0.0.1:7001\n   slots:5461-10922 (5462 slots) master\n   1 additional replica(s)\nS: f582f464475f45be65234e387c8b47375dce07d2 127.0.0.1:7003\n   slots: (0 slots) slave\n   replicates 35ed50b89426faeb20b50a13854775c4c72bbb5f\nM: 35ed50b89426faeb20b50a13854775c4c72bbb5f 127.0.0.1:7002\n   slots:10923-16383 (5461 slots) master\n   1 additional replica(s)\nS: b74bdc8c4e6d0eb8827f8dfb263ff27f68c51945 127.0.0.1:7004\n   slots: (0 slots) slave\n   replicates 5ced0e3831b746e8d260abd3cad99f2bd5f746a4\nS: 59b4d618cc6d3afa148a0eb550cde759a8664151 127.0.0.1:7005\n   slots: (0 slots) slave\n   replicates fc49467f603f0e1ba1bb0f4affc20db1d6d2cc01\n[OK] All nodes agree about slots configuration.\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\n```\n\n到此为止所有的槽位都被分配完毕了。可以看到slave的中声明的它是谁的从机。查看replicates就可以\n\n### 连接集群\n\n```shell\n# 此时使用-p连接谁都行，因为有重定向，-c指的是集群模式，我们可以在设置key的过程看到重定向的日志。所以说其实连接谁并没有所谓。使用keys *查看的话只能查看当前机器拥有的，但是直接get的话是会触发重定向去集群中的其他机器获取的。\n#redis-cli -p 7002 -c\n127.0.0.1:7002> keys *\n(empty list or set)\n127.0.0.1:7002> set name lamber\n-> Redirected to slot [5798] located at 127.0.0.1:7001\nOK\n127.0.0.1:7001> set k1 v1\n-> Redirected to slot [12706] located at 127.0.0.1:7002\nOK\n\n#redis-cli -p 7000 -c\n127.0.0.1:7000> get name\n-> Redirected to slot [5798] located at 127.0.0.1:7001\n\"lamber\"\n```\n\n### 测试集群故障迁移\n\n从上面分配主从的结果可以看到，7004端口的redis是7000redis的从机，我们现在把7000端口的机器干掉查看状况。同时监控7004的日志。\n\n```shell\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Error condition on socket for SYNC: Connection refused\n* Marking node 5ced0e3831b746e8d260abd3cad99f2bd5f746a4 as failing (quorum reached).\n# Cluster state changed: fail\n* Connecting to MASTER 127.0.0.1:7000\n* MASTER <-> SLAVE sync started\n# Start of election delayed for 586 milliseconds (rank #0, offset 696).\n# Error condition on socket for SYNC: Connection refused\n# Starting a failover election for epoch 7.\n# Failover election won: I\'m the new master.\n# configEpoch set to 7 after successful failover\n# Setting secondary replication ID to b99aa1d840d2595474737cbfed4bb0839fa205a7, valid up to offset: 697. New replication ID is 9051b056c1c9b176719449cead1a74162fa51076\n* Discarding previously cached master state.\n# Cluster state changed: ok\n```\n\n从上面的日志里可以看出，当7000断掉了以后从机是立即有所响应并尝试重连的。尝试多次以后通过投票将7000这个redis定义为失效。然后从机7004提升为master，而当我们把7000再次起来的时候7000会落地为从机，并不会去进行争抢。\n\n假如说将一个主干掉了，然后从起来了，但是这个由从提起来的主也挂了，此时相当于三分之一的槽位失效了，此时cluster会失效停止服务，无法进行数据的写入的。\n\n### 动态扩容\n\n重新分片\n\n```shell\n./redis-trib.rb reshared 127.0.0.1:7000\n```\n\n增加新的节点\n\n```shell\n./redis-trib.rb add-node 127.0.0.1:7006 127.0.0.1:7000\n```\n\n变成某一个实例的从\n\n```shell\n127.0.0.1:7006>cluster replicate 3c3aasddfasfd………………\n```\n\n删除一个节点\n\n```shell\n# 删除master节点之前首先要使用reshard移除master的全部slot，然后再删除当前节点\nredis-trib.rb del-node ip:port \'<node-id>\'\n```\n\n\n\n### 集群维护\n\n- 集群状态查看\n\n  ```shell\n  redis-cli -p 7000 cluster nodes | grep master\n  ```\n\n- 故障转移\n\n  ```shell\n  redis-cli -p 7000 debug segfault\n  ```\n\n  ​\n\n\n\n## 问题\n\n- 在客户端到底应该去连接谁？虽然cluster有重定向的功能，但是恰巧连接的这个节点挂了该怎么办？\n- 重新分片是否会造成数据丢失？\n- 为什么要重新分片（比如单片key的数据太大。）","timestamp":1526281685638},{"name":"15-Redis运维注意事项.md","path":"03-DBA运维/02-Redis/15-Redis运维注意事项.md","content":"# Redis运维注意事项\n\n","timestamp":1526281685638}]